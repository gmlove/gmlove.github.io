<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>开篇</title>
    <url>/2015/12/08/first-blog/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>用markdown来写博客简直不要太爽！</p>
<p>有了这种黑客技，不得不说很激发写博客的热情，试试看吧！</p>
]]></content>
  </entry>
  <entry>
    <title>Getting Started</title>
    <url>/2015/12/07/2015-get-started/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="quick-start"><a class="markdownIt-Anchor" href="#quick-start"></a> Quick Start</h2>
<h3 id="create-a-new-post"><a class="markdownIt-Anchor" href="#create-a-new-post"></a> Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="run-server"><a class="markdownIt-Anchor" href="#run-server"></a> Run server</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="generate-static-files"><a class="markdownIt-Anchor" href="#generate-static-files"></a> Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="deploy-to-remote-sites"><a class="markdownIt-Anchor" href="#deploy-to-remote-sites"></a> Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>jasmine.any之坑</title>
    <url>/2015/12/08/pitfall-jasmin-any/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>坑说：<code>Jasmine</code>的<code>any(Object)</code>不能替代<code>any(&#123;premitive type&#125;)</code>，可以考虑使用<code>anything()</code></p>
<p>坑位：使用<code>toHaveBeenCalledWith</code>测试函数被调用时的参数。</p>
<p>当参数列表太长（如：<code>func(p1, p2, p3)&#123;...&#125;</code>）的时候，往往只需要验证某一部分参数正确性，这个时候使用<code>any()</code>。</p>
<span id="more"></span>
<p>坑点示例：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="title function_">it</span>(<span class="string">&quot;why any(Number) can not be replaced by any(Object)?&quot;</span>, <span class="keyword">function</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">var</span> foo = jasmine.<span class="title function_">createSpy</span>(<span class="string">&#x27;foo&#x27;</span>);</span><br><span class="line">  <span class="title function_">foo</span>(<span class="number">12</span>, <span class="keyword">function</span>(<span class="params"></span>) &#123;&#125;);</span><br><span class="line">  <span class="title function_">expect</span>(foo).<span class="title function_">toHaveBeenCalledWith</span>(jasmine.<span class="title function_">any</span>(<span class="title class_">Number</span>), jasmine.<span class="title function_">any</span>(<span class="title class_">Function</span>));</span><br><span class="line">  <span class="title function_">expect</span>(foo).<span class="title function_">toHaveBeenCalledWith</span>(jasmine.<span class="title function_">any</span>(<span class="title class_">Object</span>), jasmine.<span class="title function_">any</span>(<span class="title class_">Function</span>)); <span class="comment">// will fail</span></span><br><span class="line">  <span class="title function_">expect</span>(foo).<span class="title function_">toHaveBeenCalledWith</span>(<span class="number">2</span>, jasmine.<span class="title function_">any</span>(<span class="title class_">Object</span>)); <span class="comment">// will fail</span></span><br><span class="line">  <span class="title function_">expect</span>(foo).<span class="title function_">toHaveBeenCalledWith</span>(jasmine.<span class="title function_">anything</span>(), jasmine.<span class="title function_">anything</span>());</span><br><span class="line"></span><br><span class="line">  <span class="keyword">var</span> A = <span class="keyword">function</span>(<span class="params"></span>)&#123;&#125;;</span><br><span class="line">  <span class="keyword">var</span> a = <span class="keyword">new</span> <span class="title function_">A</span>();</span><br><span class="line">  <span class="title function_">expect</span>(a).<span class="title function_">toEqual</span>(jasmine.<span class="title function_">any</span>(<span class="title class_">Object</span>));</span><br><span class="line">  <span class="title function_">expect</span>(a).<span class="title function_">toEqual</span>(jasmine.<span class="title function_">any</span>(A));</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>原因：<code>jasmine</code>使用强类型进行验证匹配。对应的验证关系</p>
<ul>
<li>String -&gt; any(String) / anything()</li>
<li>Number -&gt; any(Number) / anything()</li>
<li>Boolean -&gt; any(Boolean) / anything()</li>
<li>null -&gt; any(Object)</li>
<li>Function -&gt; any(Function) / anything()</li>
<li>Object -&gt; any(Object) / anything()</li>
</ul>
<p>关于Javascript的类型，参考<code>w3schol</code>的官方解释：</p>
<blockquote>
<p>ECMAScript 有 5 种原始类型（primitive type），即 Undefined、Null、Boolean、Number 和 String。</p>
</blockquote>
<blockquote>
<p>对变量或值调用 typeof 运算符将返回下列值之一：</p>
</blockquote>
<blockquote>
<blockquote>
<ul>
<li>undefined - 如果变量是 Undefined 类型的</li>
<li>boolean - 如果变量是 Boolean 类型的</li>
<li>number - 如果变量是 Number 类型的</li>
<li>string - 如果变量是 String 类型的</li>
<li>object - 如果变量是一种引用类型或 Null 类型的</li>
</ul>
</blockquote>
</blockquote>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
  </entry>
  <entry>
    <title>CSS最佳实践</title>
    <url>/2016/01/15/css-best-practise/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h3 id="结构组织"><a class="markdownIt-Anchor" href="#结构组织"></a> 结构组织</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">css</span><br><span class="line"> |-[业务类文件夹]</span><br><span class="line"> |-[通用类-样式重置].css</span><br><span class="line"> |-[通用类-公用组件].css</span><br><span class="line"> |-[通用类-ie兼容].css</span><br></pre></td></tr></table></figure>
<h3 id="css样式排序"><a class="markdownIt-Anchor" href="#css样式排序"></a> css样式排序</h3>
<span id="more"></span>
<ul>
<li>显示与浮动（Display &amp; Flow）</li>
<li>定位（Positioning）</li>
<li>尺寸（Dimensions）</li>
<li>边框相关属性（Margins、Padding、Borders、Outline）</li>
<li>字体样式（Typographic Styles）</li>
<li>背景（Backgrounds）</li>
<li>其他样式（Opacity、Cursors、Generated Content）</li>
</ul>
<h3 id="元素单位"><a class="markdownIt-Anchor" href="#元素单位"></a> 元素单位</h3>
<ol>
<li>尽量设置相对尺寸</li>
<li>只有在可预知元素尺寸的情况下使用绝对尺寸</li>
<li>使用 rem 设置字体大小</li>
</ol>
<h3 id="选择器"><a class="markdownIt-Anchor" href="#选择器"></a> 选择器</h3>
<p>六种基础选择器：</p>
<ul>
<li>ID 选择器（如 <code>#page_content&#123;&#125;</code>）</li>
<li>类选择器(如 <code>.page-content-title&#123;&#125;</code>)</li>
<li>属性选择器（如 <code>a[href=&quot;http://www.google.com&quot;]&#123;&#125;</code>）</li>
<li>伪类和伪对象选择器（如 <code>:hover&#123;&#125;、::after&#123;&#125;</code>）</li>
<li>标签类型（如 <code>div&#123;&#125;</code>）</li>
<li>通配符选择器（如 <code>body *&#123;&#125;</code>）</li>
</ul>
<p>组合选择器：</p>
<ul>
<li>后代选择符（如 <code>.page .title&#123;&#125;</code>）</li>
<li>子选择符（如 <code>.page&gt;.title&#123;&#125;</code>）</li>
<li>相邻选择符（如 <code>.page+.title&#123;&#125;</code>）</li>
</ul>
<p>最佳实践：</p>
<ol>
<li><strong>CSS样式中尽量不要使用ID选择器。</strong></li>
<li><strong>减少子选择器的层级。</strong></li>
<li>**使用组合的CSS类选择器。**面向对象编程一条原则：“多组合，少继承”。</li>
</ol>
<h3 id="css代码格式"><a class="markdownIt-Anchor" href="#css代码格式"></a> CSS代码格式</h3>
<ul>
<li>用两个空格来代替制表符（tab） – 这是唯一能保证在所有环境下获得一致展现的方法。</li>
<li>为选择器分组时，将单独的选择器单独放在一行。</li>
<li>为了代码的易读性，在每个声明块的左花括号前添加一个空格。</li>
<li>声明块的右花括号应当单独成行。</li>
<li>每条声明语句的 : 后应该插入一个空格。</li>
<li>为了获得更准确的错误报告，每条声明都应该独占一行。</li>
<li>所有声明语句都应当以分号结尾。</li>
<li>对于以逗号分隔的属性值，每个逗号后面都应该插入一个空格</li>
<li>不要在 rgb()、rgba()、hsl()、hsla() 或 rect()值的内部的逗号后面插入空格。这样利于从多个属性值（既加逗号也加空格）中区分多个颜色值（只加逗号，不加空格）。</li>
<li>对于属性值或颜色参数，省略小于 1 的小数前面的 0（例如，.5 代替 0.5；-.5px 代替 -0.5px）。</li>
<li>十六进制值应该全部小写，例如，#fff。在扫描文档时，小写字符易于分辨，因为他们的形式更易于区分。</li>
<li>尽量使用简写形式的十六进制值，例如，用 #fff 代替 #ffffff。<br />
为选择器中的属性添加双引号，例如，input[type=“text”]* 。只有在某些情况下是可选的，但是，为了代码的一致性，建议都加上双引号。</li>
<li>避免为 0 值指定单位，例如，用 margin: 0; 代替 margin: 0px;。</li>
</ul>
<h3 id="css实践"><a class="markdownIt-Anchor" href="#css实践"></a> css实践</h3>
<p>class命名:</p>
<ul>
<li>class 名称中只能出现小写字符和破折号</li>
<li>避免过度任意的简写。.btn 代表 button，但是 .s 不能表达任何意思。</li>
<li>class 名称应当尽可能短，并且意义明确。</li>
<li>使用有意义的名称。使用有组织的或目的明确的名称，不要使用表现形式（presentational）的名称。</li>
<li>基于最近的父 class 或基本（base） class 作为新 class 的前缀。</li>
</ul>
<p>其他：</p>
<ul>
<li>媒体查询（Media query）的位置：将媒体查询放在尽可能相关规则的附近。</li>
<li>当使用特定厂商的带有前缀的属性时，通过缩进的方式，让每个属性的值在垂直方向对齐</li>
<li>对于只包含一条声明的样式，为了易读性和便于快速编辑，建议将语句放在同一行。对于带有多条声明的样式，还是应当将声明分为多行。</li>
</ul>
]]></content>
      <categories>
        <category>frontend</category>
      </categories>
      <tags>
        <tag>CSS</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title>Maven Tips</title>
    <url>/2016/03/04/maven-tips/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h2 id="配置文件"><a class="markdownIt-Anchor" href="#配置文件"></a> 配置文件</h2>
<h3 id="继承和聚合"><a class="markdownIt-Anchor" href="#继承和聚合"></a> 继承和聚合</h3>
<h3 id="属性"><a class="markdownIt-Anchor" href="#属性"></a> 属性</h3>
<p>内置、POM属性、自定义属性、settings属性、Java系统属性、环境变量</p>
<ul>
<li>finalName: 配置最终生成的war包的文件名，可以用于替换默认的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>j</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi mathvariant="normal">.</mi><mi>a</mi><mi>r</mi><mi>t</mi><mi>i</mi><mi>f</mi><mi>a</mi><mi>c</mi><mi>t</mi><mi>I</mi><mi>d</mi></mrow><mo>−</mo></mrow><annotation encoding="application/x-tex">{project.artifactId}-</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.05724em;">j</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">t</span><span class="mord">.</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">t</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault">a</span><span class="mord mathdefault">c</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord mathdefault">d</span></span><span class="mord">−</span></span></span></span>{project.version}，便于发布的时候生成合适的路径</li>
</ul>
<h2 id="生命周期"><a class="markdownIt-Anchor" href="#生命周期"></a> 生命周期</h2>
<h3 id="三套独立生命周期"><a class="markdownIt-Anchor" href="#三套独立生命周期"></a> 三套独立生命周期</h3>
<span id="more"></span>
<ul>
<li>clean: pre-clean -&gt; clean -&gt; post-clean</li>
<li>default:
<ul>
<li>validate -&gt; initialize -&gt;</li>
<li>[generate/process-sources -&gt; generate/process-resources] -&gt;</li>
<li>compile -&gt; process-classes -&gt;</li>
<li>[generate/process-test-sources -&gt; generate/process-test-resources] -&gt;</li>
<li>test-compile -&gt; process-test-classes -&gt;</li>
<li>test -&gt;</li>
<li>prepare-package -&gt; package -&gt;</li>
<li>pre-integration-test -&gt; integration-test -&gt; post-integration-test -&gt;</li>
<li>verify -&gt;</li>
<li>install -&gt;</li>
<li>deploy</li>
</ul>
</li>
<li>site: pre-site -&gt; site -&gt; post-site -&gt; site-deploy</li>
</ul>
<h3 id="绑定生命周期"><a class="markdownIt-Anchor" href="#绑定生命周期"></a> 绑定生命周期</h3>
<ul>
<li>内置绑定</li>
<li>自定义绑定</li>
</ul>
<h2 id="plugins"><a class="markdownIt-Anchor" href="#plugins"></a> Plugins</h2>
<ul>
<li>jetty-maven-plugin 热部署</li>
<li>maven-release-plugin 版本管理</li>
<li>maven-gpg-plugin 自动进行GPG签名</li>
<li>maven-resources-plugin 文件过滤</li>
<li>maven-site-plugin 生成项目站点</li>
<li>maven-javadoc-plugin</li>
<li>maven-checkstyle-plugin</li>
<li>maven-pdm-plugin 源代码分析工具</li>
<li>maven-changelog-plugin</li>
<li>cobertura-maven-plugin 测试覆盖率</li>
</ul>
<h2 id="仓库"><a class="markdownIt-Anchor" href="#仓库"></a> 仓库</h2>
<ul>
<li>公共仓库</li>
<li>Nexus私服</li>
</ul>
<h2 id="版本管理"><a class="markdownIt-Anchor" href="#版本管理"></a> 版本管理</h2>
<ul>
<li>快照版：开发中保持版本稳定</li>
<li>稳定版：
<ul>
<li>所有测试通过</li>
<li>没有快照版本依赖</li>
<li>没有快照版本插件</li>
<li>所有代码进入版本控制系统</li>
</ul>
</li>
</ul>
<h3 id="版本号"><a class="markdownIt-Anchor" href="#版本号"></a> 版本号</h3>
<p>1.3.4-beta-2</p>
<p>主版本(架构变更).次版本(较大范围功能变化).增量版本(重大bug修复)-里程碑版本</p>
]]></content>
      <categories>
        <category>build tools</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>java</tag>
        <tag>pom</tag>
      </tags>
  </entry>
  <entry>
    <title>Less -- 诡异的空格</title>
    <url>/2016/03/08/ghost-space-in-less/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>Original:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.a &#123;</span><br><span class="line">    &amp;.a-b &#123;</span><br><span class="line">        &amp;:hover &#123;</span><br><span class="line">            background-color: #5cb85c;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">.a-c &#123;</span><br><span class="line">    &amp;:extend(.a .a-b:hover);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<p>Compiled:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ lessc test.less</span><br><span class="line">extend &#x27; .a .a-b:hover&#x27; has no matches</span><br><span class="line">.a.a-b:hover &#123;</span><br><span class="line">  background-color: #5cb85c;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Improved:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.a &#123;</span><br><span class="line">    &amp;.a-b &#123;</span><br><span class="line">        &amp;:hover &#123;</span><br><span class="line">            background-color: #5cb85c;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">.a-c &#123;</span><br><span class="line">    &amp;:extend(.a.a-b:hover);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Compiled:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ lessc test.less</span><br><span class="line">.a.a-b:hover,</span><br><span class="line">.a-c &#123;</span><br><span class="line">  background-color: #5cb85c;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>css选择器：</p>
<ul>
<li><code>.a.a-b</code>表示同一个元素同时包含两个类，</li>
<li><code>.a .a-b</code>表示子元素选择器，表示当前有<code>a-b</code>类并且某一级父元素含有<code>a</code>类</li>
<li><code>.a, .a-b</code>表示多个独立选择器，表示选择当前有<code>a</code>类或者含有<code>a-b</code>类的的元素</li>
</ul>
]]></content>
      <categories>
        <category>frontend</category>
      </categories>
      <tags>
        <tag>less</tag>
        <tag>css</tag>
      </tags>
  </entry>
  <entry>
    <title>在Clearfix中使用`display:table`</title>
    <url>/2016/03/08/pitfall-clearfix-with-table-display/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>当子元素是浮动布局时，父元素无法获取到正确的宽高，这种情况常常使用clearfix方案来解决。</p>
<p>** 示例如下：**</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span>&gt;</span> <span class="comment">&lt;!-- 父元素无法获取到正确的尺寸 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">style</span>=<span class="string">&quot;float:left; width:100px; height:100px;&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<span id="more"></span>
<p>** clearfix方案：（参考<a href="https://getbootstrap.com/css/#helper-classes-clearfix">bootstrap文档</a>） **</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">.clearfix:before, .clearfix:after &#123; display: table; content: &quot; &quot;; &#125;</span><br><span class="line">.clearfix:after &#123; clear: both; &#125;</span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;clearfix&quot;</span>&gt;</span> <span class="comment">&lt;!-- 父元素可以获取到正确的尺寸 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">style</span>=<span class="string">&quot;float:left; width:100px; height:100px;&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>但是<code>display: table</code>事实上会产生一个额外的问题，因为table的布局会使父元素与旁边浮动的元素的高度对齐。请运行这个示例：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span><span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">style</span> <span class="attr">type</span>=<span class="string">&quot;text/css&quot;</span>&gt;</span><span class="language-css"></span></span><br><span class="line"><span class="language-css"><span class="selector-class">.content</span> &#123; <span class="attribute">max-width</span>: <span class="number">800px</span>; <span class="attribute">margin</span>: <span class="number">0</span> auto; <span class="attribute">background-color</span>: <span class="number">#eee</span>; &#125;</span></span><br><span class="line"><span class="language-css"><span class="selector-class">.right-panel</span> &#123; <span class="attribute">float</span>: right; <span class="attribute">width</span>: <span class="number">180px</span>; <span class="attribute">height</span>: <span class="number">500px</span>; <span class="attribute">margin</span>: <span class="number">0</span> <span class="number">10px</span>; <span class="attribute">background-color</span>: <span class="number">#5bc0de</span>; &#125;</span></span><br><span class="line"><span class="language-css"><span class="selector-class">.main-panel</span> &#123; <span class="attribute">max-width</span>: <span class="number">700px</span>; <span class="attribute">margin-right</span>: <span class="number">200px</span>; <span class="attribute">background-color</span>: <span class="number">#5cb85c</span>; &#125;</span></span><br><span class="line"><span class="language-css"><span class="selector-class">.bottom-panel</span> &#123; <span class="attribute">height</span>: <span class="number">200px</span>; <span class="attribute">background-color</span>: <span class="number">#f0ad4e</span>; &#125;</span></span><br><span class="line"><span class="language-css"><span class="selector-class">.floated-child</span> &#123; <span class="attribute">float</span>: left; <span class="attribute">background-color</span>: <span class="number">#d9534f</span>; &#125;</span></span><br><span class="line"><span class="language-css"><span class="selector-class">.clearfix</span><span class="selector-pseudo">:before</span>, <span class="selector-class">.clearfix</span><span class="selector-pseudo">:after</span> &#123; <span class="attribute">display</span>: table; <span class="attribute">content</span>: <span class="string">&quot; &quot;</span>; &#125;</span></span><br><span class="line"><span class="language-css"><span class="selector-class">.clearfix</span><span class="selector-pseudo">:after</span> &#123; <span class="attribute">clear</span>: both; &#125;</span></span><br><span class="line"><span class="language-css">    </span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;content&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;right-panel&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;main-panel&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">h2</span>&gt;</span>Main content title! title title title title title title<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;clearfix&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;floated-child&quot;</span>&gt;</span>some text here, some text here, some text here<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;bottom-panel&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>This is bottom panel<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>可以看到<code>clearfix</code>的那个div的高度与<code>right-panel</code>对齐了，调整<code>right-panel</code>的高度，<code>clearfix</code>的div的高度会跟着调整。</p>
<p>此时我们的修复方案是，将<code>clearfix</code>的display属性修改为inline。即<br />
<code>.clearfix:before, .clearfix:after &#123; display: inline; content: &quot; &quot;; &#125;</code></p>
<p>参考：[<a href="https://stackoverflow.com/questions/211383/which-method-of-clearfix-is-best">https://stackoverflow.com/questions/211383/which-method-of-clearfix-is-best</a>]</p>
]]></content>
      <categories>
        <category>frontend</category>
      </categories>
      <tags>
        <tag>css</tag>
      </tags>
  </entry>
  <entry>
    <title>程序员的自我修养</title>
    <url>/2016/03/09/self-cultivation-of-a-programmer/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h2 id="像她一样你也可以30岁成为外企高管"><a class="markdownIt-Anchor" href="#像她一样你也可以30岁成为外企高管"></a> <a href="https://mp.weixin.qq.com/s?__biz=MjM5MjY3OTgwMA==&amp;mid=403753929&amp;idx=1&amp;sn=a0e8f99a3bbed8ae9aa1ddb21ba30960&amp;srcid=0308IQMxPuvTg7yLZXe89MJO">像她一样，你也可以30岁成为外企高管</a></h2>
<ul>
<li>跳出舒适区 - 找比你厉害的人聊天</li>
<li>假装自信</li>
</ul>
<ul>
<li>Too complicated, can you send out an email about this?</li>
<li>If you feel it’s your fault, think twice before you raise it.</li>
<li>Try to spend some time finding every thing in the document before ask.</li>
<li>Ask yourself after a communication if this is a success one.</li>
</ul>
]]></content>
      <tags>
        <tag>personal</tag>
      </tags>
  </entry>
  <entry>
    <title>蓝牙知识学习</title>
    <url>/2016/03/14/bluetooth-summary/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><ul>
<li>工作过程：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">    StandBy(待机)</span><br><span class="line">Inqury(查询)      Page(寻呼)</span><br><span class="line">    Authentication(配对)</span><br><span class="line">    Connection(连接)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>连接状态：</p>
<ul>
<li>活动状态：正在通信</li>
<li>监听状态：随时准备通信</li>
<li>保持状态：仅仅定时器工作，无法通信</li>
<li>休眠模式：能耗最低，偶尔监听和检查网络信息</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>IoT</category>
      </categories>
  </entry>
  <entry>
    <title>Opengl知识学习</title>
    <url>/2016/03/17/opengl-summary/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h2 id="opengl-es-shading-language"><a class="markdownIt-Anchor" href="#opengl-es-shading-language"></a> opengl es shading language</h2>
<p>种类</p>
<ul>
<li>类型：vec2 vec3 vec4 mat2 mat3 mat4 int float</li>
<li>结构体：</li>
</ul>
<span id="more"></span>
<p>预编译：#ifdef #ifudef #if #endif #define</p>
<p>变量标识：precision midiump lowp in out const attribute(数组常量) varying(从vs传递到fs) uniform(全局变量)</p>
<p>控制语句：</p>
<ul>
<li>if … else …</li>
<li>for(…;…;…), while(…), break, return</li>
<li>discard: 终止执行，只能用在fragment shader中</li>
</ul>
<p>函数：</p>
<ul>
<li>数组限制 - 作为参数需要指定长度，不能作为返回值</li>
</ul>
<p>内置函数：</p>
<ul>
<li>访问硬件功能：纹理贴图</li>
<li>常用的细小功能：step(返回0,1) clamp mix(x*(1-a)+y*a) smoothstep faceforward</li>
<li>硬件加速的某些功能：sin cos</li>
</ul>
]]></content>
      <categories>
        <category>frontend</category>
      </categories>
      <tags>
        <tag>opengl</tag>
        <tag>html5</tag>
        <tag>game</tag>
      </tags>
  </entry>
  <entry>
    <title>在网页显示透明视频</title>
    <url>/2016/03/26/transparent-video/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>最近在一个网站上，看到了很炫的网页特效：视频背景透明。该网址是：<a href="http://videostir.com/">http://videostir.com/</a>。他们还为用户提供了制作透明视频的服务。用户只需要上传他们要求的格式的视频，就可以生成一个透明的视频。</p>
<p>正如该网站所演示的，这种视频作为网站的引导，效果非常赞，互动的感觉非常强烈。</p>
<span id="more"></span>
<p>作为一个技术人员，特别是曾经从事过游戏开发的技术人员，很想一探究竟。下面自己实现的一个简单的背景透明效果，仅仅作为技术研究用。</p>
<p>首先，网页视频播放有两个方案：html5的视频播放，flash的视频播放。作为研究用，就不用关注已经过时的flash了。直接看html5下面该如何处理。</p>
<p>html5直接播放视频是没有问题的，可以用来做整个视频背景透明，或者视频缩放，播放控制。很自然的一个想法是，能不能使用html5播放视频，按帧进行截图，然后在canvas上面显示。实际上是可以的。核心代码如下：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> width = <span class="number">496</span>, height = <span class="number">272</span>;</span><br><span class="line"><span class="keyword">var</span> canvas = $(<span class="string">&#x27;#tv-canvas&#x27;</span>).<span class="title function_">get</span>(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">var</span> cxt = canvas.<span class="title function_">getContext</span>(<span class="string">&quot;2d&quot;</span>);</span><br><span class="line"><span class="keyword">var</span> video = $(<span class="string">&#x27;#tv-video-origin&#x27;</span>).<span class="title function_">get</span>(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> i = <span class="number">0</span>, frameCount = <span class="number">12</span>;</span><br><span class="line">video.<span class="title function_">addEventListener</span>(<span class="string">&#x27;loadeddata&#x27;</span>, <span class="keyword">function</span>(<span class="params"></span>) &#123;</span><br><span class="line">    video.<span class="property">currentTime</span> = i / frameCount;</span><br><span class="line">&#125;, <span class="literal">false</span>);</span><br><span class="line">video.<span class="title function_">addEventListener</span>(<span class="string">&#x27;seeked&#x27;</span>, <span class="keyword">function</span>(<span class="params"></span>) &#123;</span><br><span class="line">    i += <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> (i &lt;= video.<span class="property">duration</span> * frameCount) &#123;</span><br><span class="line">        <span class="comment">/// this will trigger another seeked event</span></span><br><span class="line">        <span class="built_in">setTimeout</span>(<span class="keyword">function</span>(<span class="params"></span>) &#123;</span><br><span class="line">            video.<span class="property">currentTime</span> = i / frameCount;</span><br><span class="line">        &#125;, <span class="number">1000</span>/<span class="number">24</span>);</span><br><span class="line">        <span class="title function_">drawCanvas</span>();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;video end&#x27;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;, <span class="literal">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> drawCanvas = <span class="keyword">function</span> (<span class="params"></span>) &#123;</span><br><span class="line">    cxt.<span class="title function_">drawImage</span>(video, <span class="number">20</span>, <span class="number">20</span>, width/<span class="number">2</span>, height/<span class="number">2</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下面的问题就是canvas上面的图片处理了。这里可以对视频画面做一个要求，对于要透明的视频部分，可以在拍摄视频的时候，找一个纯黑色的背景，这些纯黑色的背景就是需要透明的部分。实际上videostir对视频也是这样要求的。一旦有了黑色透明背景，我们是不是就可以先将提取视频图片，对图片进行预处理，将纯黑色的部分透明化处理，就可以了？添加的代码如下：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> cxtt = canvast.<span class="title function_">getContext</span>(<span class="string">&quot;2d&quot;</span>);</span><br><span class="line"><span class="keyword">var</span> video = $(<span class="string">&#x27;#tv-video-origin&#x27;</span>).<span class="title function_">get</span>(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> drawCanvas = <span class="keyword">function</span> (<span class="params"></span>) &#123;</span><br><span class="line">    cxt.<span class="title function_">drawImage</span>(video, <span class="number">20</span>, <span class="number">20</span>, width/<span class="number">2</span>, height/<span class="number">2</span>);</span><br><span class="line">    <span class="keyword">var</span> img = cxt.<span class="title function_">getImageData</span>(<span class="number">0</span>, <span class="number">0</span>, width, height);</span><br><span class="line">    <span class="keyword">var</span> bounce = <span class="number">40</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; img.<span class="property">data</span>.<span class="property">length</span> / <span class="number">4</span>; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span>( img.<span class="property">data</span>[i * <span class="number">4</span>] &lt; bounce &amp;&amp; img.<span class="property">data</span>[i * <span class="number">4</span> + <span class="number">1</span>] &lt; bounce &amp;&amp; img.<span class="property">data</span>[i * <span class="number">4</span> + <span class="number">2</span>] &lt; bounce ) &#123;</span><br><span class="line">            img.<span class="property">data</span>[i * <span class="number">4</span> + <span class="number">3</span>] = <span class="number">0</span>; <span class="comment">// if color is black, set alpha to 0</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    cxtt.<span class="title function_">putImageData</span>(img, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到canvas上面直接处理视频虽然可以实现效果，但是最终的效果并不是很好，看起来图片质量下降比较严重，而且效率问题也比较严重，在配置低的电脑浏览器上面帧率会更低。</p>
<p>能不能还有其他方法实现这个呢，想到了html5游戏框架。于是在<a href="https://html5gameengine.com/">这里</a>找了一个：pixi。pixi在检测到浏览器支持webgl的时候，就可以使用webgl来渲染视频，可以看pixi的<a href="https://pixijs.github.io/examples/index.html?s=basics&amp;f=video.js&amp;title=Video">demo</a>。可以看到游戏框架对视频播放的优化已经做得很好。</p>
<p>pixi是支持webgl的filter的，并且内置了一些常用的filter。但是对于我们这个需求，内置的filter看起来并不够用。于是，我们自己来实现一个filter吧。</p>
<p>关键的shader代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">precision highp float;</span><br><span class="line"></span><br><span class="line">varying vec2 vTextureCoord;</span><br><span class="line">uniform sampler2D uSampler;</span><br><span class="line"></span><br><span class="line">void main(void)</span><br><span class="line">&#123;</span><br><span class="line">   vec2 uvs = vTextureCoord.xy;</span><br><span class="line">   vec4 fg = texture2D(uSampler, vTextureCoord);</span><br><span class="line"></span><br><span class="line">   float t = 0.12;</span><br><span class="line">   if (fg.r &lt; t &amp;&amp; fg.g &lt; t &amp;&amp; fg.b &lt; t) &#123;</span><br><span class="line">        fg.a = 0.0;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   gl_FragColor = fg;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其原理与js代码里面的类似，直接寻找接近黑色的像素，然后设置其透明度为0。可以明显看到硬件渲染出来的视频已经实现了这个效果，而且视频质量没有下降。</p>
<p>简单分析了一下videostir的实现，他们实现了一个专用的播放器，播放器实现看起来是相当复杂的，会根据浏览器的类型及版本分别采用flash或者opengl来实现。由于没有深入研究他的实现，就不做介绍了。</p>
<p>最后，<a href="/attaches/2016/2016-03-26-transparent-video/index.html">这里</a>是一个完整的示例，有兴趣的同学们可以研究研究。</p>
]]></content>
      <categories>
        <category>技术</category>
        <category>frontend</category>
      </categories>
      <tags>
        <tag>opengl</tag>
        <tag>html5</tag>
        <tag>game</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring Boot 迁移</title>
    <url>/2016/03/30/migrate-to-spring-boot/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h2 id="webxml"><a class="markdownIt-Anchor" href="#webxml"></a> web.xml</h2>
<h3 id="error-page"><a class="markdownIt-Anchor" href="#error-page"></a> error page</h3>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">error-page</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">error-code</span>&gt;</span>404<span class="tag">&lt;/<span class="name">error-code</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">location</span>&gt;</span>/WEB-INF/jsp/errors/error.jsp<span class="tag">&lt;/<span class="name">location</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">error-page</span>&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="keyword">public</span> ServerProperties <span class="title function_">serverProperties</span> <span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">ServerProperties</span>() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">customize</span><span class="params">(ConfigurableEmbeddedServletContainer container)</span> &#123;</span><br><span class="line">            <span class="built_in">super</span>.customize(container);</span><br><span class="line">            container.addErrorPages(<span class="keyword">new</span> <span class="title class_">ErrorPage</span>(HttpStatus.NOT_FOUND, <span class="string">&quot;/error/404&quot;</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="spring-contextxml"><a class="markdownIt-Anchor" href="#spring-contextxml"></a> spring-context.xml</h2>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ImportResource(&quot;classpath:spring-context.xml&quot;)</span></span><br><span class="line"><span class="meta">@EnableAdminServer</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WebApplication</span> <span class="keyword">extends</span> <span class="title class_">SpringBootServletInitializer</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="log-back-upgrade"><a class="markdownIt-Anchor" href="#log-back-upgrade"></a> log back upgrade</h2>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- change include to included for file that will be included, like this: --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- http://logback.qos.ch/manual/configuration.html --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">included</span>&gt;</span></span><br><span class="line">...</span><br><span class="line"><span class="tag">&lt;/<span class="name">included</span>&gt;</span></span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title>各种坑</title>
    <url>/2016/04/15/pitfall-collection/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h2 id="重复触发jenkins-build"><a class="markdownIt-Anchor" href="#重复触发jenkins-build"></a> 重复触发Jenkins build</h2>
<p>当使用Jenkins build我们的一个repo的时候，一般我们会想要build master分支。在Jenkins添加git repo的时候，默认添加的监控branch为<code>*/master</code>，这个默认的设置就可以满足我们的需求。</p>
<p>但是，事实上<code>*/master</code>是可以匹配<code>master</code> <code>xx/master</code>分支的。如果当前repo里面有一个branch为<code>xx/master</code>，那么就会匹配到两个分支。在这样的设置之下，如果master有新的commit，Jenkins就会尝试build这两个分支，于是就会触发两次build。</p>
<h2 id="grunt在压缩文件的时候一些自动生成的文件没有包含进去但当第二次运行编译文件又被编译进去了"><a class="markdownIt-Anchor" href="#grunt在压缩文件的时候一些自动生成的文件没有包含进去但当第二次运行编译文件又被编译进去了"></a> grunt在压缩文件的时候，一些自动生成的文件没有包含进去，但当第二次运行编译，文件又被编译进去了</h2>
<p>grunt可能在编译之前生成的待压缩的文件列表，由于第一次编译的时候，编译文件没有生成，在压缩的时候就不会包含这个中间文件。第二次编译的时候，中间文件已经存在（可能会在编译过程中更新这个文件），这个时候就可以包含这个文件了。</p>
]]></content>
      <categories>
        <category>frontend</category>
      </categories>
      <tags>
        <tag>那些年我们踩过的坑</tag>
      </tags>
  </entry>
  <entry>
    <title>微服务架构总结</title>
    <url>/2016/04/26/about-micro-service-architecture/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h2 id="概述"><a class="markdownIt-Anchor" href="#概述"></a> 概述</h2>
<p>From Martin Fowler <a href="http://martinfowler.com/articles/microservices.html">microservices</a>:</p>
<blockquote>
<p>微服务架构即是采用一组小服务来构建应用的方法。<br />
每个服务运行在独立的进程中，不同服务通过一些轻量级交互机制来通信， 例如 RPC、HTTP 等。<br />
服务围绕业务能力来构建，并依赖自动部署机制来独立部署。</p>
</blockquote>
<p>From Sam Newman [Building Microservices]:</p>
<blockquote>
<p>You should instead think of Microservices as a specific approach for SOA in  the same way that XP or Scrum are specific approaches for Agile software development.</p>
</blockquote>
<p>微服务即SOA的一种实现方式。企业服务总线（ESB）设计的失败给SOA带上了负面的标签。</p>
<span id="more"></span>
<h2 id="特征"><a class="markdownIt-Anchor" href="#特征"></a> 特征</h2>
<ul>
<li>组件服务化</li>
<li>按业务能力组织服务</li>
<li>服务即产品: You built it, you run it</li>
<li>技术栈和数据去中心化</li>
<li>基础设施自动化</li>
<li>容错设计</li>
<li>兼容设计</li>
</ul>
<h2 id="实施"><a class="markdownIt-Anchor" href="#实施"></a> 实施</h2>
<ul>
<li>前提：复杂度低于零界点，可能导致部署工作量上升</li>
<li>拆分：业务能力</li>
<li>协作：契约文档</li>
<li>测试：<a href="/attaches/2016/2016-04-26-about-micro-service-architecture/test-dimension.png">测试四象限</a> <a href="/attaches/2016/2016-04-26-about-micro-service-architecture/test-triangle.png">测试金字塔</a></li>
<li>部署：虚拟化或容器等隔离技术，每一个service一个主机</li>
<li>监控：基础监控（网络，磁盘，os） 服务监控（响应时间，TPS） 业务监控（多维度，长时间）</li>
<li>原则：<a href="/attaches/2016/2016-04-26-about-micro-service-architecture/principles.png">战略目标 架构原则 设计与交付实践</a></li>
</ul>
<h2 id="角色变化"><a class="markdownIt-Anchor" href="#角色变化"></a> 角色变化</h2>
<ul>
<li>普通工程师：仅仅开发功能 -&gt; 开发、运营服务</li>
<li>每个服务至少有一个工程师作为负责人，能力更强的人可能会负责更多的服务</li>
<li>开发人员交集减少，大规模的团队并行开发好处明显</li>
<li>对个人能力要求更高，个人成长路线的发展也打开了空间</li>
</ul>
<h2 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h2>
<p><a href="https://segmentfault.com/a/1190000004998167">https://segmentfault.com/a/1190000004998167</a></p>
]]></content>
      <categories>
        <category>架构</category>
        <category>micro service</category>
      </categories>
      <tags>
        <tag>micro service</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker和微服务</title>
    <url>/2016/04/25/docker-and-micro-service/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h2 id="微服务的优势和带来的挑战"><a class="markdownIt-Anchor" href="#微服务的优势和带来的挑战"></a> 微服务的优势和带来的挑战</h2>
<h2 id="docker给微服务部署带来的便利"><a class="markdownIt-Anchor" href="#docker给微服务部署带来的便利"></a> Docker给微服务部署带来的便利</h2>
<h2 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h2>
<p><a href="https://segmentfault.com/a/1190000004998167">https://segmentfault.com/a/1190000004998167</a></p>
]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>micro service</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring项目必备的admin Site工具</title>
    <url>/2016/04/25/must-have-admin-site-for-spring-projects/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>保持应用状态的可见性对应用的维护和线上问题调试无疑是很重要的；线上进行各种功能开关，日志查询通常也是线上应用运行时必备的功能。这些功能基本上可以放在Admin工具呈现。</p>
<p>对于经典java框架spring，我们是否有一个通用的Admin框架呢，答案是肯定的。</p>
<span id="more"></span>
<p>实际上spring的Spring Boot Actuator框架为这些常用的功能进行了规范化和实现。目前的功能列表可以在<a href="http://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#production-ready">这里</a>看到。<br />
很多有用的功能类似环境变量、健康状态、API接口信息、beans状态、各个维度的性能统计数据等等都有覆盖。</p>
<p>使用这些API就可以实现一个功能强大的Admin工具。目前有一个开源的实现<a href="https://github.com/codecentric/spring-boot-admin">Spring Boot Admin</a>。</p>
<p>但是这个工具也有一些缺陷：</p>
<ol>
<li>设计的功能有点过多了，甚至包括监控等</li>
<li>需要所有的服务引入新的jar包依赖</li>
<li>需要所有服务配置该服务可访问的地址和admin服务器的地址，如果没有服务自动发现的机制，这个也是比较麻烦的事情</li>
</ol>
<p>如果我们只需要一个简单的UI界面的话，可以参考我们自己修改过的一个<a href="https://github.com/gmlove/spring-boot-admin/tree/only-ui">简化版本</a>。这个版本移除了所有的服务器提供的功能直接由客户端来处理所有的数据，服务器提供代理的功能以解决跨域问题。服务只需要引入Spring Boot Actuator。</p>
]]></content>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>admin site</tag>
      </tags>
  </entry>
  <entry>
    <title>Business Trip Life in Sydney</title>
    <url>/2016/05/16/business-trip-life-in-sydney/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>应客户邀请到Sydney来出差，有幸可以来一次这个第一级世界都市。</p>
<p>从成都到香港转机再到悉尼，总共16个小时的时间，终于到达这个城市。很多印象很深的景象。</p>
<p>这里的空气真干净。即便是阴天，极目望去，也可以看到数十公里之外的景象；公路旁边停的车辆看起来都像洗过一样，反射着阳光，特别耀眼。</p>
<p>这里的鸟很多，都不怕人。在海湾旁边的步行街一路走过，可以看到一群一群的鸽子飞来飞去，有的就停在你身边，机灵的小脑袋一摆一摆，不时的啄一硺地面。</p>
<p>客户公司文化很开放。这边大家都没有固定的座位，每天都可以换位置坐，一般都是来上班了，就自己找位置坐下，走的时候，把自己的座位清理干净。这边座位也比较紧张，不少人都是在家办公。早上有时候会有Morning Tea，一般有新人来或者某一天有人离职的时候就会举行一次。</p>
<p>刚来到这边，吃的东西还真是不习惯。中午的快餐看起来很多样，就是sanwich。</p>
]]></content>
      <tags>
        <tag>personal</tag>
      </tags>
  </entry>
  <entry>
    <title>回溯搜索找到游戏解法</title>
    <url>/2016/07/09/backtracking-search-for-a-game/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>昨晚老婆在家玩游戏，遇到一个关卡，挺有意思，找不到图了，姑且文字描述一下。</p>
<ul>
<li>游戏模型：[1, 1, 1, 0, -1, -1, -1]</li>
<li>规则：1或-1可以移动到其旁边0的位置，或者移动到间隔一个障碍的下一个0的位置；1只能向右移动，-1只能向左移动</li>
<li>目标：所有-1移动到左边，1移动到右边，即最后状态为[-1, -1, -1, 0, 1, 1, 1]</li>
</ul>
<span id="more"></span>
<p>老婆尝试了好几次无果，给我试试。一看这个游戏，就想到可以用回溯搜索算法来找答案。于是打开电脑开始尝试，得到如下js代码：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="meta">&#x27;use strict&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> _ = <span class="built_in">require</span>(<span class="string">&#x27;lodash&#x27;</span>)</span><br><span class="line"><span class="keyword">var</span> cards = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, -<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> search = <span class="keyword">function</span> (<span class="params">cards, path</span>) &#123;</span><br><span class="line">  <span class="keyword">if</span> (_.<span class="title function_">isEqual</span>(cards, [-<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])) &#123;</span><br><span class="line">    <span class="title function_">replay</span>(path)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">var</span> idx = <span class="number">0</span>; idx &lt; cards.<span class="property">length</span>; idx++) &#123;</span><br><span class="line">    <span class="keyword">let</span> moved = <span class="title function_">move</span>(cards, idx)</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`moved: <span class="subst">$&#123;moved&#125;</span>, path: <span class="subst">$&#123;path&#125;</span>`</span>)</span><br><span class="line">    <span class="keyword">if</span> (moved &amp;&amp; <span class="title function_">search</span>(moved, _.<span class="title function_">concat</span>(path, [idx]))) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> move = <span class="keyword">function</span> (<span class="params">cards, idx</span>) &#123;</span><br><span class="line">  <span class="keyword">let</span> moved = _.<span class="title function_">clone</span>(cards)</span><br><span class="line">  <span class="keyword">if</span> (cards[idx] === <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (cards[idx + <span class="number">1</span>] === <span class="number">0</span>) &#123;</span><br><span class="line">      moved[idx] = <span class="number">0</span></span><br><span class="line">      moved[idx + <span class="number">1</span>] = <span class="number">1</span></span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (cards[idx + <span class="number">2</span>] === <span class="number">0</span>) &#123;</span><br><span class="line">      moved[idx] = <span class="number">0</span></span><br><span class="line">      moved[idx + <span class="number">2</span>] = <span class="number">1</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (cards[idx] === -<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (cards[idx - <span class="number">1</span>] === <span class="number">0</span>) &#123;</span><br><span class="line">      moved[idx] = <span class="number">0</span></span><br><span class="line">      moved[idx - <span class="number">1</span>] = -<span class="number">1</span></span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (cards[idx - <span class="number">2</span>] === <span class="number">0</span>) &#123;</span><br><span class="line">      moved[idx] = <span class="number">0</span></span><br><span class="line">      moved[idx - <span class="number">2</span>] = -<span class="number">1</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> moved</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> replay = <span class="keyword">function</span> (<span class="params">path</span>) &#123;</span><br><span class="line">  <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;path found: &#x27;</span>, path.<span class="title function_">join</span>(<span class="string">&#x27;,&#x27;</span>))</span><br><span class="line">  <span class="keyword">var</span> _cards = cards</span><br><span class="line">  <span class="variable language_">console</span>.<span class="title function_">log</span>(_cards.<span class="title function_">join</span>(<span class="string">&#x27;,&#x27;</span>))</span><br><span class="line">  path.<span class="title function_">forEach</span>(<span class="keyword">function</span> (<span class="params">idx</span>) &#123;</span><br><span class="line">    _cards = <span class="title function_">move</span>(_cards, idx)</span><br><span class="line">    <span class="variable language_">console</span>.<span class="title function_">log</span>(_cards.<span class="title function_">join</span>(<span class="string">&#x27;,&#x27;</span>))</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="title function_">search</span>(cards, [])</span><br></pre></td></tr></table></figure>
<p>最终找到的步骤如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">path found:  2,4,5,3,1,0,2,4,6,5,3,1,2,4,3</span><br><span class="line">1,1,1,0,-1,-1,-1</span><br><span class="line">1,1,0,1,-1,-1,-1</span><br><span class="line">1,1,-1,1,0,-1,-1</span><br><span class="line">1,1,-1,1,-1,0,-1</span><br><span class="line">1,1,-1,0,-1,1,-1</span><br><span class="line">1,0,-1,1,-1,1,-1</span><br><span class="line">0,1,-1,1,-1,1,-1</span><br><span class="line">-1,1,0,1,-1,1,-1</span><br><span class="line">-1,1,-1,1,0,1,-1</span><br><span class="line">-1,1,-1,1,-1,1,0</span><br><span class="line">-1,1,-1,1,-1,0,1</span><br><span class="line">-1,1,-1,0,-1,1,1</span><br><span class="line">-1,0,-1,1,-1,1,1</span><br><span class="line">-1,-1,0,1,-1,1,1</span><br><span class="line">-1,-1,-1,1,0,1,1</span><br><span class="line">-1,-1,-1,0,1,1,1</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title>Session Storage</title>
    <url>/2016/07/17/session-storage/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>保存客户端状态，Session Storage是用于</p>
<blockquote>
<p>The sessionStorage property allows you to access a session Storage object. sessionStorage is similar to Window.localStorage, the only difference is while data stored in localStorage has no expiration set, data stored in sessionStorage gets cleared when the page session ends. A page session lasts for as long as the browser is open and survives over page reloads and restores. Opening a page in a new tab or window will cause a new session to be initiated, which differs from how session cookies work.</p>
</blockquote>
]]></content>
      <categories>
        <category>frontend</category>
      </categories>
  </entry>
  <entry>
    <title>TDD Practise</title>
    <url>/2016/08/25/tdd-practise/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h2 id="总纲"><a class="markdownIt-Anchor" href="#总纲"></a> 总纲</h2>
<p>差的测试会增加维护的负担，好的测试才能指导开发。品质差的测试可能让开发慢如蜗牛。<br />
测试需要达到目的的同时尽量保证不要给重构及变更带来阻碍。</p>
<span id="more"></span>
<h2 id="测试"><a class="markdownIt-Anchor" href="#测试"></a> 测试</h2>
<p>测试的粒度：单元测试 -&gt; 集成测试 -&gt; 验收测试（用户场景测试）</p>
<p>单元测试使我们优化内部品质：模块能独立于系统运行，说明其边界是清晰的，高内聚，低耦合的，更可能在其他地方复用。验收测试保证外部品质。</p>
<p>TDD四步循环：失败 - 报告 - 通过 - 重构</p>
<p>测试的好处：</p>
<ul>
<li>确定要实现的目标</li>
<li>通过测试可以发现设计缺陷</li>
<li>有助于促进上下文无关性</li>
<li>促进通过分解、萌芽、打包来发现值类型和对象</li>
</ul>
<h2 id="起步"><a class="markdownIt-Anchor" href="#起步"></a> 起步</h2>
<ul>
<li>新项目：做最少的决定，实现可行走的骨架，尽早暴露不确定性，启动TDD循环 -&gt; 从反馈中学习。</li>
<li>现有代码：回归测试 -&gt; 单元测试 -&gt; 改动。</li>
</ul>
<h2 id="设计"><a class="markdownIt-Anchor" href="#设计"></a> 设计</h2>
<ul>
<li>对象间的关系：依赖、通知、调整</li>
<li>封装：确保通过API影响对象的行为；隐藏：实现方式不可见</li>
<li>组合比部分之和更简单</li>
<li>上下文无关性</li>
</ul>
<p>CRC卡进行辅助设计。</p>
<p>好的设计：</p>
<ul>
<li>根据角色进行命名，而不是根据实现</li>
<li>使用小的方法来去掉语法噪声，更好的表达意图，最后达到跟读文章一样的效果</li>
<li>分离并发策略与功能</li>
<li>事件源外部化，不使用内部的定时器</li>
</ul>
<h2 id="编写好的测试"><a class="markdownIt-Anchor" href="#编写好的测试"></a> 编写好的测试</h2>
<p>好的单元测试：</p>
<ul>
<li>针对行为进行测试而不是方法</li>
<li>更愿意读测试而不是代码</li>
<li>单个测试规模小，容易理解</li>
<li>依赖在对象构造时传入</li>
<li>模拟接口而不是模拟具体的类</li>
<li>少量的预期</li>
<li>准确指定应该发生什么，没有多余的指定</li>
</ul>
<p>坏味道：</p>
<ul>
<li>get查询方法暴露内部状态，破坏了封装</li>
<li>对象名字出现连词（与、或、但是），通常可以重构以抽取对象</li>
<li>接口以I打头，或者出现xxImpl：意味着实现不能很好的命名，实现包含领域信息，接口定义角色，总是有可能将其分开</li>
<li>模拟值类型</li>
<li>模拟一个无法替换的对象：单例是依赖关系、隐式依赖也是依赖</li>
<li>构造方法太大，测试很难编写：可能可以萌芽或者打包新的类型；关注点不集中，可能需要分解为新的类型；对通知关系和调整关系使用默认值，提供方法修改它们</li>
<li>测试中预期太多：测试的重点难以发现</li>
<li>测试中存在很多与重点无关的代码，如用try catch块捕捉异常</li>
<li>测试中存在具体值如null，应该为其命名以明确其含义</li>
<li>测试出错难以定位问题：测试描述不清楚</li>
</ul>
<p>编写测试：</p>
<ul>
<li>编写辅助对象进行测试，如FakeAuctionServer和测试数据建造者</li>
<li>使用自描述的值（覆盖toString），或者明显的预装值（Integer.MAX_VALUE）</li>
<li>忽略不相关的对象</li>
<li>明确事务边界、使用压力测试来测试线程问题</li>
<li>使用捕获通知来探测变化以测试异步功能，使用waitUntil assertEventually来检测状态变化</li>
<li>提取测试结构是注意不要让测试代码太抽象，无需像对待产品代码那样重构测试，测试代码的最高目标是让测试描述目标代码做了什么</li>
<li>如果类需要创建内部支持对象，在测试中该对象应该是不可见的，而不是mock它</li>
</ul>
<h2 id="其他"><a class="markdownIt-Anchor" href="#其他"></a> 其他：</h2>
<p>重构：</p>
<ul>
<li>为潜在的对象命名，因为某个东西有名字了，就可以控制它了</li>
</ul>
<p>日志：</p>
<ul>
<li>支持性日志是一项功能，是应用程序用户接口的一部分，可以用测试驱动</li>
<li>诊断性日志用于开发者发现问题，可以不用测试驱动，可以使用通知而不是记日志实现</li>
</ul>
]]></content>
      <categories>
        <category>development</category>
      </categories>
  </entry>
  <entry>
    <title>Tensorflow一瞥</title>
    <url>/2016/11/27/a-pick-into-tensorflow/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>今天跟大家分享一下时下非常流行的一个机器学习框架：TensorFlow。希望大家可以一瞥TensorFlow的易用性和强大功能。</p>
<p>TensorFlow目前在我司的技术雷达上面处于assess阶段。</p>
<h2 id="tensorflow是什么"><a class="markdownIt-Anchor" href="#tensorflow是什么"></a> TensorFlow是什么</h2>
<p>TensorFlow诞生于Google公司Google Brain项目。其前身是一个名为DistBelief的系统，DistBelief是Google内部使用非常广泛的一个机器学习系统。TensorFlow作为github上面的一个很火的开源项目，它的第一个提交是在2015年11月。到现在也不过刚好一年时间。</p>
<p>TensorFlow提供的API库可以用于编写富有表现力的程序。同时TensorFlow底层使用c++实现，其性能也是不错的。</p>
<p>TensorFlow在系统设计上使用一个有状态的数据流图来描述计算。使用TensorFlow时，需要先定义好计算图，以便TensorFlow可以在内部进行分布式的调度，然后一般会使用向计算图填充数据的形式进行迭代计算。</p>
<p>TensorFlow支持的系统非常广泛，从移动设备到桌面电脑再到大型分布式系统，从CPU到GPU，TensorFlow都提供了支持。</p>
<p>TensorFlow为了便于高效率的开发，同时也是顺应社区的技术潮流，提供的是Python的API。同时，也可以直接使用C++进行开发。目前还有Rust，Haskell的方言支持。</p>
<span id="more"></span>
<h2 id="为什么要用tensorflow"><a class="markdownIt-Anchor" href="#为什么要用tensorflow"></a> 为什么要用TensorFlow</h2>
<h3 id="良好而活跃的社区"><a class="markdownIt-Anchor" href="#良好而活跃的社区"></a> 良好而活跃的社区</h3>
<h4 id="丰富的入门教程"><a class="markdownIt-Anchor" href="#丰富的入门教程"></a> 丰富的入门教程</h4>
<p>TensorFlow有很多Tutorial入门教程，大大降低了入门的门槛。官方的教程已经不错了，社区技术爱好者们还贡献了很多相关的教程。我个人用过的教程，可以列举如下：</p>
<ul>
<li><a href="https://www.tensorflow.org/versions/r0.11/tutorials/index.html">官方教程</a></li>
<li>更有深度的<a href="https://github.com/pkmital/tensorflow_tutorials">MOOC教程</a></li>
<li><a href="https://classroom.udacity.com/courses/ud730/">Google在Udacity上面做的教程</a></li>
<li><a href="https://docs.google.com/presentation/d/1TVixw6ItiZ8igjp6U17tcgoFrLSaHWQmMOwjlgQY9co/pub?slide=id.g140797b42d_0_60">Tensorflow and deep learning, without a PhD</a></li>
</ul>
<h4 id="大量现成的机器学习模型"><a class="markdownIt-Anchor" href="#大量现成的机器学习模型"></a> 大量现成的机器学习模型</h4>
<p>Google内部使用TensorFlow实现了很多性能很好的机器学习模型（这里的性能指模型表现好，如分类错误率低），这些模型也都在<a href="https://github.com/tensorflow/models">github</a>上面开源了出来。如为图片生成标题的模型，识别街道名称的模型等等。我们可以方便的阅读学习这些模型，同时也可以作为一个很好的起点，用于研究设计自己的模型。</p>
<h4 id="提供了更简单的机器学习的接口"><a class="markdownIt-Anchor" href="#提供了更简单的机器学习的接口"></a> 提供了更简单的机器学习的接口</h4>
<p>TensorFlow同时提供了一个<a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn">简单的机器学习接口</a>。几行代码即可完成模型训练和使用。</p>
<h4 id="丰富的周边工具"><a class="markdownIt-Anchor" href="#丰富的周边工具"></a> 丰富的周边工具</h4>
<p>TensorFlow还提供了用于可视化参数的TensorBoard，大大方便了模型的调优工作。同时还提供了Caffe到TensorFlow模型转换的工具。</p>
<h3 id="tensorflow已经在业界广泛使用"><a class="markdownIt-Anchor" href="#tensorflow已经在业界广泛使用"></a> TensorFlow已经在业界广泛使用。</h3>
<p>众所周知的如Google自己，京东，Uber，DeepMind，SnapChat，Twitter等等，都在公司内部使用这个框架进行机器学习的研究。</p>
<h3 id="google趋势表现抢眼"><a class="markdownIt-Anchor" href="#google趋势表现抢眼"></a> Google趋势表现抢眼</h3>
<p>从Google趋势来看，TensorFlow也已成为当前非常流行的机器学习框架了。</p>
<p><img data-src="/attaches/2016/2016-11-27-a-pick-into-tensorflow/tf-googletrend.png" alt="TensorFlow in Google Trend" /></p>
<h2 id="一个简单的例子在tensorflow中使用logistic-regression来进行图片分类"><a class="markdownIt-Anchor" href="#一个简单的例子在tensorflow中使用logistic-regression来进行图片分类"></a> 一个简单的例子：在TensorFlow中使用Logistic Regression来进行图片分类</h2>
<p>下面用一个简单的例子演示一下TensorFlow的使用。这个例子中我们会对MNIST手写数字图片库进行分类。</p>
<p>MNIST数据集的是一个非常基础而简单的用于机器学习的数据集。下载好这个数据集之后，可以看到其包含的图片如下（一个数字对应一张图片）：</p>
<p><img data-src="/attaches/2016/2016-11-27-a-pick-into-tensorflow/mnist-overview.png" alt="MNIST Overview" /></p>
<p>我们将要使用的分类模型也是基础的Logistic Regression模型。</p>
<p><img data-src="/attaches/2016/2016-11-27-a-pick-into-tensorflow/model-overview.png" alt="Model Overview" /></p>
<p>这个模型用数学公司来描述就是如下这样：</p>
<p><img data-src="/attaches/2016/2016-11-27-a-pick-into-tensorflow/math.png" alt="Math" /></p>
<p>模型对应的核心代码TensorFlow代码就是：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Describe Graph</span></span><br><span class="line"></span><br><span class="line">Y = tf.nn.softmax(tf.matmul(XX, W) + b)</span><br><span class="line">cross_entropy = -tf.reduce_mean(Y_ * tf.log(Y)) * <span class="number">1000.0</span>  <span class="comment"># normalized for batches of 100 images</span></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.005</span>).minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line">predict = tf.argmax(tf.nn.softmax(tf.matmul(X, W) + b), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train the model</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.initialize_all_variables())</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10000</span>):</span><br><span class="line">    batch_X, batch_Y = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">    c = sess.run([cross_entropy], feed_dict=&#123;X: batch_X, Y_: batch_Y&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Predict</span></span><br><span class="line">labels = sess.run([predict], feed_dict=&#123;...&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>完整的代码可以参考这里的<a href="https://github.com/martin-gorner/tensorflow-mnist-tutorial.git">tutorial</a></p>
]]></content>
      <categories>
        <category>machine-learning</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>AI</tag>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>让机器自己玩游戏</title>
    <url>/2016/12/05/let-machine-play-games/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>大家好，这次要跟大家分享一个很炫酷的东西。我们要实现一个机器学习算法，这个算法可以通过观察屏幕，产生一系列操作，进而控制游戏，取得高分。</p>
<h2 id="我们的目标"><a class="markdownIt-Anchor" href="#我们的目标"></a> 我们的目标</h2>
<p>Atari是1972年成立的一家美国公司，主要做的是街机、家用电脑、家用游戏机。很多早期的经典游戏都是出自Atari，比如什么乒乓球、网球、各种弹珠游戏等等。我们今天要让机器来玩的游戏就是出自atari的游戏，名为breakout。这个游戏是基于乒乓球的玩法的一个游戏，与乒乓球不同的是，这个游戏可以由单人控制。相信只要是80后，肯定都玩过这个游戏。</p>
<p><img data-src="/attaches/2016/2016-12-05-let-machine-play-games/breakout-game.png" alt="Break out game" /></p>
<span id="more"></span>
<h2 id="openai-environment"><a class="markdownIt-Anchor" href="#openai-environment"></a> OpenAI Environment</h2>
<p>为了实现我们的机器学习算法，我们是否要自己实现一个这样的游戏呢？当然不必。</p>
<p>在去年11月的时候，由特斯拉汽车的创始人也是spaceX的创始人Elon Musk带头发起了一个叫OpenAI的项目，这个项目主要的目的是降低机器学习的门槛，让人工智能更容易上手和实现。于是他们做了一个开发库，可以方便开发者开发强化学习算法和比较、分享算法的结果。而这个项目在今年（2016）4月份就发布了第一个beta版本。</p>
<p>使用这个项目提供的开发库，我们可以方便的运行breakout这个游戏，并采集到相关的游戏数据。</p>
<p>通过下面的代码我们就可以运行一个breakout的环境，并随机进行操作来玩游戏。这里的breakout游戏每一局有5条命，分数累加。当球碰到顶上的墙壁砖块之后，砖块被击碎而消失，分数加一。虽然这样玩出来的得分是很低的，但是我们已经有了一个基础。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> gym</span><br><span class="line">env = gym.make(<span class="string">&#x27;Breakout-v0&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i_episode <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>):</span><br><span class="line">  observation = env.reset()</span><br><span class="line">  <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    env.render()</span><br><span class="line">    action = env.action_space.sample()</span><br><span class="line">    observation, reward, done, info = env.step(action)</span><br><span class="line">    <span class="keyword">if</span> done:</span><br><span class="line">      <span class="built_in">print</span>(<span class="string">&#x27;Episode finished after &#123;&#125; timesteps&#x27;</span>.<span class="built_in">format</span>(t + <span class="number">1</span>))</span><br><span class="line">      <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p><img data-src="/attaches/2016/2016-12-05-let-machine-play-games/breakout-in-openai.png" alt="Breakout in OpenAI" /></p>
<p>从上面的代码中，我们可以看到gym给我们提供的东西有：</p>
<ul>
<li>observation：这个返回的值就是屏幕的观察数据，是一个大小为(210, 160, 3)的三维矩阵，里面是每一个像素的rgb颜色值</li>
<li>reward：得分，当球撞击到墙壁砖块之后，返回1，否则返回0</li>
<li>env.action_space：我们可以进行的所有操作，这里将会返回一个Discrete(6)，即离散的6个操作，大家可以认为这6个操作想象为，左加速移动，右加速移动，不动等</li>
<li>env.step：执行一个操作，这个操作的值为0-5，即action_space中的某一个值</li>
</ul>
<p>当我们有了这些数据的时候，我们事实上是有了什么呢？</p>
<ul>
<li>当前游戏世界的状态</li>
<li>我们可以做的操作</li>
<li>一系列操作之后，我们可能会得到奖励，也就是得分</li>
</ul>
<p>我们要解决的问题是什么呢？</p>
<p>问题就是，为了获取最大得分，我们如何在每一步选择正确的操作，即如何生成一系列的操作。关于操作的选择，就是策略。前面代码里面其实也是有策略的，我们的策略就是随机策略。我们的问题其实就是求最佳策略。</p>
<p>下面将向大家介绍强化学习的相关理论知识。</p>
<h2 id="强化学习"><a class="markdownIt-Anchor" href="#强化学习"></a> 强化学习</h2>
<h3 id="马尔可夫决策过程"><a class="markdownIt-Anchor" href="#马尔可夫决策过程"></a> 马尔可夫决策过程</h3>
<p>请看这个图：</p>
<p><img data-src="/attaches/2016/2016-12-05-let-machine-play-games/mdp.png" alt="Markov Decision Process" /></p>
<p>这张图里面的过程我们就将其称为马尔可夫决策过程。</p>
<p>在马尔可夫决策过程中，有一个agent，它可以观察environment，并操作environment，environment在接受操作之后，会按照一定概率产生一个状态改变，并可能会有给agent奖励。当然environment可能自己有自己的运作规则，自己也会不停的产生状态改变。</p>
<h3 id="数学模型"><a class="markdownIt-Anchor" href="#数学模型"></a> 数学模型</h3>
<p>我们可以定义马尔可夫决策过程中的一些概念如下：</p>
<ul>
<li>S: 一个所有可能的状态集合，在breakout这个游戏中，状态就是屏幕的像素值集合</li>
<li>A: 一个所有可能的操作的集合，在breakout这个游戏中，就是action_space中指明的6种操作</li>
<li>P: 状态转移的可能性，即关于状态空间的一个概率分布，给定一个状态，P可以表示该状态可能会转到哪一个状态，以及以什么样的概率转移到那个状态。结合breakout游戏进行理解就是，当我们捕捉到一个游戏画面的时候，下一个画面（即下一个状态）可能有多种可能，这多种可能性会形成一个概率分布</li>
<li>R: 一个状态对应的奖励，有可能会跟随一个动作。需要说明的是，当有一个关键动作时，通常不会立即有奖励，大家可以想象一下breakout这个游戏，在球撞击顶部的墙砖时，就有正向奖励产生，而得分的前一时刻可能是不需要有动作的，或者说动作就是不做任何事</li>
</ul>
<p>这里比较重要的是状态和动作的转换关系。从一个状态开始，可以选择多种动作，一旦选择了某一个动作，这个动作可能导致的多种下一刻的状态。所以动作-状态-动作会形成一种树形的关系，如下图所示：</p>
<p><img data-src="/attaches/2016/2016-12-05-let-machine-play-games/state-action-tree.png" alt="State action tree" /></p>
<p>这棵树的某一个分支就形成一局游戏。</p>
<p>有了这些定义之后，我们如何衡量某一个状态的价值，或者如何定义某一个动作的价值呢？</p>
<p>对某一局游戏，假设我们有一系列状态、动作和奖励，事实上我们可以定义状态和动作的价值如下：</p>
<p><img data-src="/attaches/2016/2016-12-05-let-machine-play-games/state-action-value-formula.png" alt="state action value formula" /></p>
<p>从这个公式中，我们可以看出，当前状态和动作的价值不仅跟当前的价值R0相关，还跟将来的价值相关。比如买股票，你今天的投资价值，不仅仅取决于今天股票的涨幅，之后每一天的增长都是今天的投资所决定的。所以我们可以知道，当前的状态和动作的价值是当前得到的奖励和将来的潜在奖励的和。</p>
<p>公式中还有一个参数γ，表示折扣因子。为什么要这个折扣因子呢？经济学里面有一句话&quot;A dollar today is worth more than a dollar tomorrow!&quot;，就是说今天的一美金比明天的一美金更值钱。我们可以这样理解，明天的价值是一个估计值，既然是估计值，那么就是不准确的，很有可能根本没这么多。对于钱而言，明天的钱还会贬值呢。所以在这个公式中，我们加上这个折扣因子，时间往后的价值需要乘以一个折扣因子的乘方，也就是说时间越久的价值对当前的价值贡献越小。</p>
<p>如果我们只对状态价值进行建模，我们可以得到这样的公式：</p>
<p><img data-src="/attaches/2016/2016-12-05-let-machine-play-games/state-value-formula.png" alt="state value formula" /></p>
<p>如何衡量一个状态的overall的价值呢？我们可以对每一种可能的游戏局求平均，也就是上面的公式的期望值。</p>
<p><img data-src="/attaches/2016/2016-12-05-let-machine-play-games/expected-state-value-formula.png" alt="state value formula" /></p>
<p>思考一下我们的问题，现在我们可以定义一个状态的价值了，一个状态的价值大，说明这个状态是一个好状态，我们就要让我们的策略向好的状态方面靠。似乎有了一些解决问题的思路了。</p>
<p>我们更进一步，从策略着手来分析这个问题。</p>
<p><strong>策略</strong>就是一个从state到action的函数。也就是说，有了策略，我们就知道每一个状态下应该选择什么样的action了。我们通常用符号π来表示策略。</p>
<p>一个策略的价值函数就是：</p>
<p><img data-src="/attaches/2016/2016-12-05-let-machine-play-games/value-function-for-pi-formula.png" alt="Value function for pi formula" /></p>
<p>观察这个函数，我们可以发现这个函数其实可以写成迭代的形式。写成迭代的形式之后，我们就得到了著名的Bellman等式：</p>
<p><img data-src="/attaches/2016/2016-12-05-let-machine-play-games/bellman-equation.png" alt="Bellman Equation" /></p>
<p>有了这些之后，我们就可以定义最佳策略的价值为：</p>
<p><img data-src="/attaches/2016/2016-12-05-let-machine-play-games/optimal-value-function.png" alt="Optimal Value function" /></p>
<p>这个就是最佳策略的价值函数，它是所有可能的策略的一个最大值。写成迭代形式就是：</p>
<p><img data-src="/attaches/2016/2016-12-05-let-machine-play-games/iterable-optimal-value-function.png" alt="Iterable Optimal Value function" /></p>
<p>到这里我们似乎离问题更进一步了。但是，我们来考虑一下我们可以获取到什么。我们可以不断的用各种策略重复玩游戏，当我们的游戏局有相当的数量时，我们就可以近似得到状态转移函数，进而可以直接计算这个值。理论上这是可行的。但是实际上很难操作，特别是在状态太多的时候。而且就是可以得到最佳策略的状态价值，也不能直接得到最佳策略，需要经过计算才行。</p>
<p>我们再进一步考虑。能不能计算一个动作的价值呢？如果说可以计算在某一个状态下，某一个动作的价值，是不是就可以直接获取到最佳策略了？最佳策略就是选择动作价值最大的那个动作。事实上状态动作价值（或简称动作价值），我们一般称之为Q值，我们可以定义动作价值Q如下：</p>
<p><img data-src="/attaches/2016/2016-12-05-let-machine-play-games/q-value-formula.png" alt="Q value formula" /></p>
<p>写成迭代形式，也就是Q值的Bellman就是：</p>
<p><img data-src="/attaches/2016/2016-12-05-let-machine-play-games/q-value-bellman-formula.png" alt="Q value bellman formula" /></p>
<h3 id="迭代算法"><a class="markdownIt-Anchor" href="#迭代算法"></a> 迭代算法</h3>
<p>下面我们来看如何计算得到这个最佳Q值。</p>
<p>事实上我们只需要首先初始化每一个状态对应的价值为0，然后不停的玩游戏，进行迭代更新直到收敛就可以了。迭代算法如下：</p>
<p><img data-src="/attaches/2016/2016-12-05-let-machine-play-games/q-value-iteration-algorithm.png" alt="Q Value Iteration algorithm" /></p>
<p>对于一个状态空间比较小的MDP问题而言，我们直接用一个表来保存q值，然后迭代更新这个值就可以得到我们的最佳策略。这一算法是非常有效的。我这里不打算仔细分析这个算法。因为这个算法无法解决我们今天的问题。我们今天的问题状态空间太大了。所有可能的状态有<code>255^(260*160*3)</code>这么多种。</p>
<p>事实上，q值即是关于当前状态和动作的一个函数。既然这样，我们就可以想了，我们能不能用一个深度学习模型来模拟这个函数呢？当然可以，采用深度学习模型，我们可以将状态映射到一个动作价值上去。这就是深度强化学习啦！</p>
<h2 id="深度强化学习"><a class="markdownIt-Anchor" href="#深度强化学习"></a> 深度强化学习</h2>
<p>深度强化学习这个模型很早就有人研究，但是最早产生广泛影响力的是DeepMind公司在2013年发表的一篇论文。由于这篇论文的影响力，DeepMind也被google以数十亿美金收购。后来在2015年DeepMind进一步研究了这个模型，发表了一篇更清楚的论文：Human-level control through deep reinforcement learning。这篇论文就是讨论这个模型的。</p>
<p>这个模型使用的就是Q值迭代和神经网络的组合，所以算法全称为Deep Q Network，简称就是DQN。</p>
<p>核心算法如下：</p>
<p><img data-src="/attaches/2016/2016-12-05-let-machine-play-games/dqn-algorithm-by-deepmind.png" alt="DQN Algorithm by DeepMind" /></p>
<p>这个算法有这样一些关键步骤：</p>
<ul>
<li>初始化深度学习模型，并在这个模型生成的策略下进行游戏</li>
<li>存储游戏产生的数据，包括状态、动作、奖励、下一刻的状态</li>
<li>从存储的数据中抽样数据进行迭代计算，更新模型</li>
</ul>
<p>这个算法用到的神经网络模型如下：</p>
<p><img data-src="/attaches/2016/2016-12-05-let-machine-play-games/dqn-network-structure.png" alt="DQN Network Structure" /></p>
<p>这个卷积神经网络的参数如下：</p>
<p><img data-src="/attaches/2016/2016-12-05-let-machine-play-games/dqn-network-parameter.png" alt="DQN Network Parameters" /></p>
<p>关于卷积神经网络的资料，请大家参考斯坦福大学的cs231n课程。</p>
<p>我们只看一下这里的损失函数。回想一下我们之前的Q值迭代公式。从公式中我们可以看出，我们的最佳Q值就是最大的下一步的最佳Q值加上执行动作之后立即得到的奖励的均值。事实上当模型最终收敛时，平均起来看，当前时刻的Q值就等于下一步的Q值加上执行动作之后立即得到的奖励。于是我们只需要让当前时刻的Q值去逼近下一时刻的Q值和立即奖励之和。于是就有了我们的损失函数：</p>
<p><img data-src="/attaches/2016/2016-12-05-let-machine-play-games/dqn-network-loss-function.png" alt="DQN Network Loss Function" /></p>
<h3 id="探索"><a class="markdownIt-Anchor" href="#探索"></a> 探索</h3>
<p>在上面的伪代码中还可以看到，在玩游戏时，我们会以一定概率随机选择action进行执行。为什么需要这样呢？</p>
<p>大家可以想象一下，如果没有这个随机，会出现什么情况？在我们的算法迭代一段时间之后，算法发现了一个不错的策略，之后，可能就一直按照这个策略来生成动作了。这是有问题的，因为可能有很多潜在的表现更好的策略我们可能根本没有尝试过。加上这个随机过程，就使得我们有了探索策略空间的能力。</p>
<h2 id="代码"><a class="markdownIt-Anchor" href="#代码"></a> 代码</h2>
<p>接下来我们来分析代码。</p>
<p>这里我们使用tensorflow框架来实现这个算法，创建网络的代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">build_dqn_network</span>(<span class="params">self</span>):</span><br><span class="line">  self.w = &#123;&#125;</span><br><span class="line">  self.t_w = &#123;&#125;</span><br><span class="line"></span><br><span class="line">  initializer = tf.truncated_normal_initializer(<span class="number">0</span>, <span class="number">0.02</span>)</span><br><span class="line">  activation_fn = tf.nn.relu</span><br><span class="line"></span><br><span class="line">  self.l1, self.w[<span class="string">&#x27;l1_w&#x27;</span>], self.w[<span class="string">&#x27;l1_b&#x27;</span>] = conv2d(self.s_t,</span><br><span class="line">    <span class="number">32</span>, [<span class="number">8</span>, <span class="number">8</span>], [<span class="number">4</span>, <span class="number">4</span>], initializer, activation_fn, self.cnn_format, name=<span class="string">&#x27;l1&#x27;</span>)</span><br><span class="line">  self.l2, self.w[<span class="string">&#x27;l2_w&#x27;</span>], self.w[<span class="string">&#x27;l2_b&#x27;</span>] = conv2d(self.l1,</span><br><span class="line">    <span class="number">64</span>, [<span class="number">4</span>, <span class="number">4</span>], [<span class="number">2</span>, <span class="number">2</span>], initializer, activation_fn, self.cnn_format, name=<span class="string">&#x27;l2&#x27;</span>)</span><br><span class="line">  self.l3, self.w[<span class="string">&#x27;l3_w&#x27;</span>], self.w[<span class="string">&#x27;l3_b&#x27;</span>] = conv2d(self.l2,</span><br><span class="line">    <span class="number">64</span>, [<span class="number">3</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">1</span>], initializer, activation_fn, self.cnn_format, name=<span class="string">&#x27;l3&#x27;</span>)</span><br><span class="line"></span><br><span class="line">  shape = self.l3.get_shape().as_list()</span><br><span class="line">  self.l3_flat = tf.reshape(self.l3, [-<span class="number">1</span>, reduce(<span class="keyword">lambda</span> x, y: x * y, shape[<span class="number">1</span>:])])</span><br><span class="line"></span><br><span class="line">  self.l4, self.w[<span class="string">&#x27;l4_w&#x27;</span>], self.w[<span class="string">&#x27;l4_b&#x27;</span>] = linear(self.l3_flat, <span class="number">512</span>,</span><br><span class="line">    activation_fn=activation_fn, name=<span class="string">&#x27;l4&#x27;</span>)</span><br><span class="line">  self.q, self.w[<span class="string">&#x27;q_w&#x27;</span>], self.w[<span class="string">&#x27;q_b&#x27;</span>] = linear(self.l4, self.env.action_size, name=<span class="string">&#x27;q&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>网络一共四层，和前面的图里面的一一对应。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">build_optimizer</span>(<span class="params">self</span>):</span><br><span class="line">  self.target_q_t = tf.placeholder(<span class="string">&#x27;float32&#x27;</span>, [<span class="literal">None</span>], name=<span class="string">&#x27;target_q_t&#x27;</span>)</span><br><span class="line">  self.action = tf.placeholder(<span class="string">&#x27;int64&#x27;</span>, [<span class="literal">None</span>], name=<span class="string">&#x27;action&#x27;</span>)</span><br><span class="line"></span><br><span class="line">  action_one_hot = tf.one_hot(self.action, self.env.action_size, <span class="number">1.0</span>, <span class="number">0.0</span>,</span><br><span class="line">    name=<span class="string">&#x27;action_one_hot&#x27;</span>)</span><br><span class="line">  q_acted = tf.reduce_sum(self.q * action_one_hot, reduction_indices=<span class="number">1</span>,</span><br><span class="line">    name=<span class="string">&#x27;q_acted&#x27;</span>)</span><br><span class="line"></span><br><span class="line">  self.delta = self.target_q_t - q_acted</span><br><span class="line">  self.loss = tf.reduce_mean(tf.square(self.delta), name=<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line"></span><br><span class="line">  self.optim = tf.train.RMSPropOptimizer(</span><br><span class="line">    self.learning_rate_op, momentum=<span class="number">0.95</span>, epsilon=<span class="number">0.01</span>).minimize(self.loss)</span><br></pre></td></tr></table></figure>
<p>以上代码是关于loss函数的计算。可以看到，我们首先通过<code>self.q * action_one_hot</code>相乘得到当前action对应的q值，然后通过reduce_sum将其转化为一个数值。loss函数就是它和真实值的平方差。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">observe</span>(<span class="params">self, screen, reward, action, terminal</span>):</span><br><span class="line">  reward = <span class="built_in">max</span>(self.min_reward, <span class="built_in">min</span>(self.max_reward, reward))</span><br><span class="line"></span><br><span class="line">  self.history.add(screen)</span><br><span class="line">  self.memory.add(screen, reward, action, terminal)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> self.step &gt; self.learn_start:</span><br><span class="line">    <span class="keyword">if</span> self.step % self.train_frequency == <span class="number">0</span>:</span><br><span class="line">      self.q_learning_mini_batch()</span><br></pre></td></tr></table></figure>
<p>以上代码是自动玩游戏时的操作。可以看到，当游戏状态迁移之后，我们会保存当前的游戏数据。并在玩的局数到一定大小之后，就开始迭代更新网络。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">q_learning_mini_batch</span>(<span class="params">self</span>):</span><br><span class="line">  s_t, action, reward, s_t_plus_1, terminal = self.memory.sample()</span><br><span class="line">  q_t_plus_1 = self.target_q.<span class="built_in">eval</span>(&#123;self.target_s_t: s_t_plus_1&#125;)</span><br><span class="line"></span><br><span class="line">  terminal = np.array(terminal) + <span class="number">0.</span></span><br><span class="line">  max_q_t_plus_1 = np.<span class="built_in">max</span>(q_t_plus_1, axis=<span class="number">1</span>)</span><br><span class="line">  target_q_t = (<span class="number">1.</span> - terminal) * self.discount * max_q_t_plus_1 + reward</span><br><span class="line"></span><br><span class="line">  _, q_t, loss, summary_str = self.sess.run(</span><br><span class="line">    [self.optim, self.q, self.loss, self.q_summary], &#123;</span><br><span class="line">    self.target_q_t: target_q_t,</span><br><span class="line">    self.action: action,</span><br><span class="line">    self.s_t: s_t</span><br><span class="line">  &#125;)</span><br></pre></td></tr></table></figure>
<p>以上代码显示了网络更新过程。我们先根据当前模型计算出下一时刻的q值，然后在discount之后计算和当前的奖励之和，作为目标q值，这个值将被传入optimizer计算图进行计算。</p>
<p>完整的详细的代码请参考这里：<a href="https://github.com/devsisters/DQN-tensorflow">https://github.com/devsisters/DQN-tensorflow</a></p>
<p>需要说明的是，这里的模型收敛是很慢的，通常需要10-30个小时才能收敛到一个好的状态。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>今天我们看到了深度神经网络和强化学习结合起来的例子。这个例子的实现，可以给我们很大的启示。看起来DL+RL让机器拥有了某种智能。这就是AI。可以说深度学习和和强化学习就实现了AI。</p>
<p>当前有很多对这个模型的优化措施，包括加快泛化速度，以及让一个游戏的学习结果泛化到其他游戏中去等。是当前的一大热门模型。</p>
<p>关于强化学习还有很多理论知识未涉及，如果想要完全理解文章里面的公式及算法，请参考伯克利大学的强化学习课程。</p>
<h3 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h3>
<p>本文参考资料都来自于互联网，主要的资料如下：</p>
<ol>
<li>知乎专栏系列文章–DQN从入门到放弃：<a href="https://zhuanlan.zhihu.com/p/21421729">https://zhuanlan.zhihu.com/p/21421729</a></li>
<li>知乎专栏系列文章–150行代码实现DQN算法玩CartPole：<a href="https://zhuanlan.zhihu.com/p/21477488?refer=intelligentunit">https://zhuanlan.zhihu.com/p/21477488?refer=intelligentunit</a></li>
<li>伯克利大学强化学习课程：<a href="https://www.youtube.com/channel/UCTmAYxRV7H9NTdgC9bNixvw">CS188 from Youtube</a></li>
<li>devsisters的代码实现：<a href="https://github.com/devsisters/DQN-tensorflow">https://github.com/devsisters/DQN-tensorflow</a></li>
</ol>
]]></content>
      <categories>
        <category>machine-learning</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>AI</tag>
        <tag>Machine Learning</tag>
        <tag>Reinforcement Learning</tag>
        <tag>DQN</tag>
        <tag>Deep Reinforcement Learning</tag>
        <tag>DeepQ Network</tag>
      </tags>
  </entry>
  <entry>
    <title>RNN和LSTM从理论到实践二：RNN和LSTM模型</title>
    <url>/2016/12/11/dl-workshop-rnn-and-lstm-1/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>本文是上一篇文章『RNN和LSTM从理论到实践一：词向量』的续文。</p>
<p>上一章中，我们了解了词向量怎样训练，并跟随udacity上面的例子及问题动手实践了Skip Gram和CBOW模型训练算法。我们也顺带看了一下什么是语言模型，以及基础的n-gram模型是怎么样的。这次我们将要在前面的基础上，看看RNN和LSTM模型是什么样的，并将和大家一起动手去实现一个LSTM模型用于生成一个句子。</p>
<h2 id="我们的问题"><a class="markdownIt-Anchor" href="#我们的问题"></a> 我们的问题</h2>
<p>先来看我们的问题，然后让我们带着问题，来学习RNN和LSTM。这次我们要解决的问题是：如何生成一个看起来还不错的句子。</p>
<p>我们之前介绍过n-gram，那么我们能不能使用n-gram去预测单词，进而生成一个句子呢？我们可以使用频率统计来计算n-gram的语言模型：</p>
<span id="more"></span>
<p><img data-src="/attaches/2016/2016-12-11-dl-workshop-rnn-and-lstm-1/n-gram-equation.png" alt="N-gram Equation" /></p>
<p>如果我们要计算单词w1出现的条件下单词w2出现的概率，我们可以先统计单词w1在我们的训练数据集中一共出现了多少次，即count(w1)，然后再统计w1和w2连续出现，即&quot;w1 w2&quot;出现的次数count(w1, w2)，相除即为w1出现的条件下单词w2出现的概率。同理，我们想要求在w1和w2同时连续出现的情况下，w3出现的概率也可以类似地使用频率统计来求得。</p>
<p>n-gram看起来很容易实现，但是它能为我们生成一个好的句子吗？</p>
<p>试想，如果我们有一篇关于西班牙和法国的文章，里面有一句话『这两个国家开始进入战争时代』。那么这两个国家指的是哪两个国家呢？用n-gram模型其实很难回答这个问题，因为西班牙和法国可能是文章刚开始的时候指明的，而n-gram中的N不可能太大，太大通常导致内存不足以及计算太慢，所以n-gram无法获知文章中离得很远的句子的信息。</p>
<h2 id="rnn"><a class="markdownIt-Anchor" href="#rnn"></a> RNN</h2>
<p>现在我们知道n-gram的缺点了，那么如何能解决远距离信息问题呢？这就是我们要介绍的模型RNN的发挥价值的地方。</p>
<p>RNN的模型如下：</p>
<p><img data-src="/attaches/2016/2016-12-11-dl-workshop-rnn-and-lstm-1/rnn-model.png" alt="RNN Model" /></p>
<p>在这个模型图中，x表示输入的单词向量，y表示预测的单词向量，在此基础上，我们增加了h矩阵来表示输出特征。t表示时间。观察t时刻的输入单词x和预测单词y的计算过程，我们可以发现y不仅仅是跟输入x相关，还跟t-1时刻的h相关。而t时刻的h，又会贡献到t+1时刻的y预测过程中去。</p>
<p>具体的算法公式如下：</p>
<p><img data-src="/attaches/2016/2016-12-11-dl-workshop-rnn-and-lstm-1/ht-and-yt-equation.png" alt="Ht &amp; Yt equation" /></p>
<p>我们可以看到我们定义了3个权值矩阵，这些权值矩阵在每次进行计算的时候，都是复用的，内存开销不随训练文本的增加而增加。h的计算使用了sigmoind激活函数，y的计算使用softmax激活函数。这里为了简单，我们省略了偏置向量。</p>
<p>好了，我们已经有了模型，那么我们的损失函数是什么呢？其实还是跟之前一致，在时刻t，我们使用交叉熵损失函数：</p>
<p><img data-src="/attaches/2016/2016-12-11-dl-workshop-rnn-and-lstm-1/loss-function-of-rnn.png" alt="Loss function of RNN" /></p>
<p>那么总的损失函数就是（T表示我们训练时每次迭代只考虑对T个单词进行RNN计算）：</p>
<p><img data-src="/attaches/2016/2016-12-11-dl-workshop-rnn-and-lstm-1/overall-loss-function-of-rnn.png" alt="Overall loss function of RNN" /></p>
<p>我们还常常用perplexity来衡量模型的损失，perplexity的定义就是：</p>
<p><img data-src="/attaches/2016/2016-12-11-dl-workshop-rnn-and-lstm-1/perplexity-equation.png" alt="Perplexity equation" /></p>
<p>由指数函数的曲线可知，J越小时，perplexity也越小，而且perplexity始终为正。</p>
<h3 id="反向传播的问题"><a class="markdownIt-Anchor" href="#反向传播的问题"></a> 反向传播的问题</h3>
<p>直接使用RNN模型有没有什么问题呢？由于权值矩阵是共享的，在反向传播的时候，每一步都会更新一个相同的权值矩阵。梯度下降方法在这种情况下的表现是会有问题的，因为这里的更新会变得不稳定，很容易的就会导致更新太多或太少，从而产生梯度消失或者梯度爆炸的问题。</p>
<p>例如，假设有两个句子：</p>
<ul>
<li>“Jane walked into the room. John walked in too. Jane said hi to ___”</li>
<li>“Jane walked into the room. John walked in too. It was late in the day, and everyone was walking home after a long day at work. Jane said hi to ___”</li>
</ul>
<p>RNN更可能能将第一个句子预测正确，由于梯度下降的梯度消失问题，离得远的信息难以传播到当下，第二个句子将会更难预测准确。</p>
<p>事实上，可以计算得到，早于当前时刻的某时刻k的单词给当前时刻t的贡献将为β^(t-k)，可以看到它的梯度传播是指数递减的。这就很容易产生梯度爆炸和梯度消失问题。</p>
<p>针对这个问题，我们的解决方案就是：</p>
<ul>
<li>在梯度将要爆炸的时候，将其裁剪为一个较小的值，这可以应对梯度爆炸问题</li>
<li>使用ReLU激活函数，更仔细的初始化权值矩阵，这可以解决梯度消失的问题</li>
</ul>
<p>这些手段可以在一定程度上优化梯度爆炸和梯度消失的问题。但是其实我们有更好的模型来解决这个问题，那就是LSTM。我们后面会一起学习LSTM。</p>
<h3 id="rnn的扩展"><a class="markdownIt-Anchor" href="#rnn的扩展"></a> RNN的扩展</h3>
<p>通常在RNN上面还可以继续扩展，比如扩展为双向递归神经网络：</p>
<p><img data-src="/attaches/2016/2016-12-11-dl-workshop-rnn-and-lstm-1/bidirectional-rnn.png" alt="Bidirectional RNN" /></p>
<p>相关的公式就变为：</p>
<p><img data-src="/attaches/2016/2016-12-11-dl-workshop-rnn-and-lstm-1/bidirectional-rnn-equation.png" alt="Bidirectional RNN equation" /></p>
<p>我们还可以加深这个网络，让每一个时刻t从一个线性层变为多个线性层，如图：</p>
<p><img data-src="/attaches/2016/2016-12-11-dl-workshop-rnn-and-lstm-1/deep-bidirectional-rnn.png" alt="Deep Bidirectional RNN" /></p>
<p>相关的公式为：</p>
<p><img data-src="/attaches/2016/2016-12-11-dl-workshop-rnn-and-lstm-1/deep-bidirectional-rnn-equation.png" alt="Deep Bidirectional RNN Equation" /></p>
<h2 id="lstm"><a class="markdownIt-Anchor" href="#lstm"></a> LSTM</h2>
<p>前面我们分析了RNN的问题，并提到了LSTM。那么LSTM是什么东西呢？它是Long Short Term Memory的缩写。从这个全称来看，它可以给RNN引入记忆的功能。事实上他就是以这个为目标来进行设计的。LSTM的思想就是将RNN的网络单元替换为带记忆功能的网络单元。</p>
<p><img data-src="/attaches/2016/2016-12-11-dl-workshop-rnn-and-lstm-1/rnn-to-lstm.png" alt="RNN to LSTM" /></p>
<p>记忆到底是个什么玩意儿呢？听起来似乎很抽象。我们分析一下记忆单元应该有的功能。与人的记忆能力作为对比，一个单元能有记忆，那么它应该可以被写入，即可以被更新，然后应该可以被读取，同时应该可以选择性的忘记，也就是删除数据。</p>
<p><img data-src="/attaches/2016/2016-12-11-dl-workshop-rnn-and-lstm-1/lstm-functionality.png" alt="LSTM functionality" /></p>
<h3 id="gated-recurrent-units"><a class="markdownIt-Anchor" href="#gated-recurrent-units"></a> Gated Recurrent Units</h3>
<p>分析了LSTM的原理，我们先看看GRU，即Gated Recurrent Units，它是基于这个思想的一个比LSTM更简单的模型。它的网络图如下：</p>
<p><img data-src="/attaches/2016/2016-12-11-dl-workshop-rnn-and-lstm-1/gru.png" alt="Gated Recurrent Units" /></p>
<p>Reset其实用于实现忘记功能的，它可以控制是否将上一时刻的输出特征h即此时刻的输入包含到此时刻的预测过程，或者包含多少，其公式如下：</p>
<p><img data-src="/attaches/2016/2016-12-11-dl-workshop-rnn-and-lstm-1/gru-reset-equation.png" alt="GRU Reset Equation" /></p>
<p>New Memory可以实现写入控制的功能，即决定现在的输入和上一时刻的h到底有多少会影响到当前的预测过程，其公式如下：</p>
<p><img data-src="/attaches/2016/2016-12-11-dl-workshop-rnn-and-lstm-1/gru-new-memory-equation.png" alt="GRU New Memory Equation" /></p>
<p>Update可以实现控制读取的功能，即决定当前的状态有多少可以被下一时刻读取，其公式如下：</p>
<p><img data-src="/attaches/2016/2016-12-11-dl-workshop-rnn-and-lstm-1/gru-update-equation.png" alt="GRU Update Equation" /></p>
<p>最后将以上几个控制单元结合起来就得到当前的特征输出，它也将会被用于预测输出，其公式如下：</p>
<p><img data-src="/attaches/2016/2016-12-11-dl-workshop-rnn-and-lstm-1/gru-feature-equation.png" alt="GRU feature equation" /></p>
<p>可以看到这些单个功能的控制器几乎都是一样的，他们的功能是在构造输出特征时体现出来的。</p>
<h3 id="lstm-units"><a class="markdownIt-Anchor" href="#lstm-units"></a> LSTM Units</h3>
<p>我们再看看更复杂一些的LSTM模型，其模型图如下：</p>
<p><img data-src="/attaches/2016/2016-12-11-dl-workshop-rnn-and-lstm-1/lstm.png" alt="LSTM" /></p>
<p>公式如下：</p>
<p><img data-src="/attaches/2016/2016-12-11-dl-workshop-rnn-and-lstm-1/lstm-equations.png" alt="LSTM equations" /></p>
<p>其中h用于预测，c和h一起传播到下一时刻。</p>
<h3 id="lstm的应用"><a class="markdownIt-Anchor" href="#lstm的应用"></a> LSTM的应用</h3>
<p>通过分析RNN和LSTM的特性，可以发现它们可以用于预测一个序列。当训练好了LSTM网络时，得到一个输入之后，就预测下一个输出，然后结合输入和预测到的输出，可以继续预测下下个输出，连续的预测之后，我们就可以得到一个序列了。在我们后面要训练的模型中我们就是采取这样的方式来生成一个序列的。就如同下面这样：</p>
<p><img data-src="/attaches/2016/2016-12-11-dl-workshop-rnn-and-lstm-1/lstm-application.png" alt="LSTM Application" /></p>
<p>当然我们还可以在每次预测时选择top k个可能的结果，每次都这样选择，然后在预测过一定次数n之后，统计生成的n个词的短序列的概率，并选择概率最大的短序列作为最终的结果。这样可以防止在某一步预测失败之后，导致后面的预测都跟着失败。这个想法就是Beam Search算法的思想。</p>
<p><img data-src="/attaches/2016/2016-12-11-dl-workshop-rnn-and-lstm-1/lstm-beam-search.png" alt="LSTM Beam Search" /></p>
<p>RNN和LSTM还有很多其他方面的应用，由于RNN和LSTM可以生成一个连续的序列，我们可以将其应用于机器翻译、语音识别、以及根据图片生成标题等等。</p>
<h2 id="训练一个rnn和lstm的模型"><a class="markdownIt-Anchor" href="#训练一个rnn和lstm的模型"></a> 训练一个RNN和LSTM的模型</h2>
<p>下面我们将跟随udacity上面的习题，一起来实践这个算法。</p>
<p>下面的内容，请结合<a href="https://github.com/gmlove/dl-workshop-rnn-lstm/blob/master/6_lstm.ipynb">这里的代码</a>来阅读。</p>
<h3 id="示例代码中的模型"><a class="markdownIt-Anchor" href="#示例代码中的模型"></a> 示例代码中的模型</h3>
<p>在示例中，为了简化模型，我们这里对字符进行建模。于是我们的字符就可以用大小为27（a-z和空格）的一个one-hot的向量来表示。我们的RNN模型中，将按照10个字符进行分组递归处理，并使用变量num_unrollings来表示10这个数值。于是训练数据将被分为每10个字符一组，这一组字符进入RNN之后，不仅相互连接起来，而且和前一组的输出连接，同时提供输出作为后一组的输入。这样分组更新权值的过程中，每次迭代就会将梯度传播10次。</p>
<p>下面我们看看具体实现过程。</p>
<p>首先还是通过函数<code>maybe_download</code>和<code>read_data</code>来下载和读取数据，然后选择1000个字符的数据作为验证集。</p>
<p>然后，我们准备两个工具函数，将字符映射到索引，和将索引映射到字符。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vocabulary_size = <span class="built_in">len</span>(string.ascii_lowercase) + <span class="number">1</span> <span class="comment"># [a-z] + &#x27; &#x27;</span></span><br><span class="line">first_letter = <span class="built_in">ord</span>(string.ascii_lowercase[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">char2id</span>(<span class="params">char</span>):</span><br><span class="line">  <span class="keyword">if</span> char <span class="keyword">in</span> string.ascii_lowercase:</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">ord</span>(char) - first_letter + <span class="number">1</span></span><br><span class="line">  <span class="keyword">elif</span> char == <span class="string">&#x27; &#x27;</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Unexpected character: %s&#x27;</span> % char)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">id2char</span>(<span class="params">dictid</span>):</span><br><span class="line">  <span class="keyword">if</span> dictid &gt; <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">chr</span>(dictid + first_letter - <span class="number">1</span>)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27; &#x27;</span></span><br></pre></td></tr></table></figure>
<p>我们现在来考虑如何进行batch迭代。按照我们前面的分析，由递归的特性可知，字符需要首尾相连，训练集中的后一个字符是依赖前一个字符进行计算的，我们无法打乱这个顺序。我们这里的想法就是把训练文本分为n份，然后n份一起开始训练。如下图所示：</p>
<p><img data-src="/attaches/2016/2016-12-11-dl-workshop-rnn-and-lstm-1/batch-update.png" alt="Batch update" /></p>
<p>理解了这个之后，代码中的<code>BatchGenerator</code>就比较容易理解了。需要注意的是batch中的字符组长度为11，并且一个batch和下一个batch之间是有一个字符重叠的，这是由于我们会使用每一个字符的后一个字符作为标签字符，所以在生成batch的时候，就故意多生成了一个字符。在编写BatchGenerator的同时，我们编写了两个辅助函数<code>characters</code>和<code>batches2string</code>，分别实现将一个概率分布（即softmax的输出）映射到一个字符，和将一组batch映射为字符串。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">batch_size=<span class="number">64</span></span><br><span class="line">num_unrollings=<span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BatchGenerator</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, text, batch_size, num_unrollings</span>):</span><br><span class="line">    self._text = text</span><br><span class="line">    self._text_size = <span class="built_in">len</span>(text)</span><br><span class="line">    self._batch_size = batch_size</span><br><span class="line">    self._num_unrollings = num_unrollings</span><br><span class="line">    segment = self._text_size // batch_size</span><br><span class="line">    self._cursor = [ offset * segment <span class="keyword">for</span> offset <span class="keyword">in</span> <span class="built_in">range</span>(batch_size)]</span><br><span class="line">    self._last_batch = self._next_batch()</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">_next_batch</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Generate a single batch from the current cursor position in the data.&quot;&quot;&quot;</span></span><br><span class="line">    batch = np.zeros(shape=(self._batch_size, vocabulary_size), dtype=np.<span class="built_in">float</span>)</span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(self._batch_size):</span><br><span class="line">      batch[b, char2id(self._text[self._cursor[b]])] = <span class="number">1.0</span></span><br><span class="line">      self._cursor[b] = (self._cursor[b] + <span class="number">1</span>) % self._text_size</span><br><span class="line">    <span class="keyword">return</span> batch</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">next</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Generate the next array of batches from the data. The array consists of</span></span><br><span class="line"><span class="string">    the last batch of the previous array, followed by num_unrollings new ones.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    batches = [self._last_batch]</span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(self._num_unrollings):</span><br><span class="line">      batches.append(self._next_batch())</span><br><span class="line">    self._last_batch = batches[-<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> batches</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">characters</span>(<span class="params">probabilities</span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Turn a 1-hot encoding or a probability distribution over the possible</span></span><br><span class="line"><span class="string">  characters back into its (most likely) character representation.&quot;&quot;&quot;</span></span><br><span class="line">  <span class="keyword">return</span> [id2char(c) <span class="keyword">for</span> c <span class="keyword">in</span> np.argmax(probabilities, <span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">batches2string</span>(<span class="params">batches</span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Convert a sequence of batches back into their (most likely) string</span></span><br><span class="line"><span class="string">  representation.&quot;&quot;&quot;</span></span><br><span class="line">  s = [<span class="string">&#x27;&#x27;</span>] * batches[<span class="number">0</span>].shape[<span class="number">0</span>]</span><br><span class="line">  <span class="keyword">for</span> b <span class="keyword">in</span> batches:</span><br><span class="line">    s = [<span class="string">&#x27;&#x27;</span>.join(x) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">zip</span>(s, characters(b))]</span><br><span class="line">  <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">train_batches = BatchGenerator(train_text, batch_size, num_unrollings)</span><br><span class="line">valid_batches = BatchGenerator(valid_text, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(batches2string(train_batches.<span class="built_in">next</span>()))</span><br><span class="line"><span class="built_in">print</span>(batches2string(train_batches.<span class="built_in">next</span>()))</span><br><span class="line"><span class="built_in">print</span>(batches2string(valid_batches.<span class="built_in">next</span>()))</span><br><span class="line"><span class="built_in">print</span>(batches2string(valid_batches.<span class="built_in">next</span>()))</span><br></pre></td></tr></table></figure>
<p>然后为了程序需要我们再准备几个工具函数如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">logprob</span>(<span class="params">predictions, labels</span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Log-probability of the true labels in a predicted batch.&quot;&quot;&quot;</span></span><br><span class="line">  predictions[predictions &lt; <span class="number">1e-10</span>] = <span class="number">1e-10</span></span><br><span class="line">  <span class="keyword">return</span> np.<span class="built_in">sum</span>(np.multiply(labels, -np.log(predictions))) / labels.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sample_distribution</span>(<span class="params">distribution</span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Sample one element from a distribution assumed to be an array of normalized</span></span><br><span class="line"><span class="string">  probabilities.</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  r = random.uniform(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">  s = <span class="number">0</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(distribution)):</span><br><span class="line">    s += distribution[i]</span><br><span class="line">    <span class="keyword">if</span> s &gt;= r:</span><br><span class="line">      <span class="keyword">return</span> i</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">len</span>(distribution) - <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sample</span>(<span class="params">prediction</span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Turn a (column) prediction into 1-hot encoded samples.&quot;&quot;&quot;</span></span><br><span class="line">  p = np.zeros(shape=[<span class="number">1</span>, vocabulary_size], dtype=np.<span class="built_in">float</span>)</span><br><span class="line">  p[<span class="number">0</span>, sample_distribution(prediction[<span class="number">0</span>])] = <span class="number">1.0</span></span><br><span class="line">  <span class="keyword">return</span> p</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_distribution</span>():</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Generate a random column of probabilities.&quot;&quot;&quot;</span></span><br><span class="line">  b = np.random.uniform(<span class="number">0.0</span>, <span class="number">1.0</span>, size=[<span class="number">1</span>, vocabulary_size])</span><br><span class="line">  <span class="keyword">return</span> b/np.<span class="built_in">sum</span>(b, <span class="number">1</span>)[:,<span class="literal">None</span>]</span><br></pre></td></tr></table></figure>
<p>其中<code>logprob</code>用于计算交叉熵，<code>sample_distribution</code>用于从一个概率分别里面随机选择一个元素，<code>sample</code>在一个概率分布中随机选择一个元素，并将其转换为one-hot编码的向量。<code>random_distribution</code>可以随机生成一个概率分布。</p>
<p>现在到了我们构建计算图的时候了，参考lstm的模型图，我们依序初始化参数并构造计算图如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num_nodes = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">graph = tf.Graph()</span><br><span class="line"><span class="keyword">with</span> graph.as_default():</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># Parameters:</span></span><br><span class="line">  <span class="comment"># Input gate: input, previous output, and bias.</span></span><br><span class="line">  ix = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -<span class="number">0.1</span>, <span class="number">0.1</span>))</span><br><span class="line">  im = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -<span class="number">0.1</span>, <span class="number">0.1</span>))</span><br><span class="line">  ib = tf.Variable(tf.zeros([<span class="number">1</span>, num_nodes]))</span><br><span class="line">  <span class="comment"># Forget gate: input, previous output, and bias.</span></span><br><span class="line">  fx = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -<span class="number">0.1</span>, <span class="number">0.1</span>))</span><br><span class="line">  fm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -<span class="number">0.1</span>, <span class="number">0.1</span>))</span><br><span class="line">  fb = tf.Variable(tf.zeros([<span class="number">1</span>, num_nodes]))</span><br><span class="line">  <span class="comment"># Memory cell: input, state and bias.                             </span></span><br><span class="line">  cx = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -<span class="number">0.1</span>, <span class="number">0.1</span>))</span><br><span class="line">  cm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -<span class="number">0.1</span>, <span class="number">0.1</span>))</span><br><span class="line">  cb = tf.Variable(tf.zeros([<span class="number">1</span>, num_nodes]))</span><br><span class="line">  <span class="comment"># Output gate: input, previous output, and bias.</span></span><br><span class="line">  ox = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -<span class="number">0.1</span>, <span class="number">0.1</span>))</span><br><span class="line">  om = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -<span class="number">0.1</span>, <span class="number">0.1</span>))</span><br><span class="line">  ob = tf.Variable(tf.zeros([<span class="number">1</span>, num_nodes]))</span><br><span class="line">  <span class="comment"># Variables saving state across unrollings.</span></span><br><span class="line">  saved_output = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=<span class="literal">False</span>)</span><br><span class="line">  saved_state = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=<span class="literal">False</span>)</span><br><span class="line">  <span class="comment"># Classifier weights and biases.</span></span><br><span class="line">  w = tf.Variable(tf.truncated_normal([num_nodes, vocabulary_size], -<span class="number">0.1</span>, <span class="number">0.1</span>))</span><br><span class="line">  b = tf.Variable(tf.zeros([vocabulary_size]))</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># Definition of the cell computation.</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">lstm_cell</span>(<span class="params">i, o, state</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf</span></span><br><span class="line"><span class="string">    Note that in this formulation, we omit the various connections between the</span></span><br><span class="line"><span class="string">    previous state and the gates.&quot;&quot;&quot;</span></span><br><span class="line">    input_gate = tf.sigmoid(tf.matmul(i, ix) + tf.matmul(o, im) + ib)</span><br><span class="line">    forget_gate = tf.sigmoid(tf.matmul(i, fx) + tf.matmul(o, fm) + fb)</span><br><span class="line">    update = tf.matmul(i, cx) + tf.matmul(o, cm) + cb</span><br><span class="line">    state = forget_gate * state + input_gate * tf.tanh(update)</span><br><span class="line">    output_gate = tf.sigmoid(tf.matmul(i, ox) + tf.matmul(o, om) + ob)</span><br><span class="line">    <span class="keyword">return</span> output_gate * tf.tanh(state), state</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Input data.</span></span><br><span class="line">  train_data = <span class="built_in">list</span>()</span><br><span class="line">  <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_unrollings + <span class="number">1</span>):</span><br><span class="line">    train_data.append(</span><br><span class="line">      tf.placeholder(tf.float32, shape=[batch_size,vocabulary_size]))</span><br><span class="line">  train_inputs = train_data[:num_unrollings]</span><br><span class="line">  train_labels = train_data[<span class="number">1</span>:]  <span class="comment"># labels are inputs shifted by one time step.</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Unrolled LSTM loop.</span></span><br><span class="line">  outputs = <span class="built_in">list</span>()</span><br><span class="line">  output = saved_output</span><br><span class="line">  state = saved_state</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> train_inputs:</span><br><span class="line">    output, state = lstm_cell(i, output, state)</span><br><span class="line">    outputs.append(output)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># State saving across unrollings.</span></span><br><span class="line">  <span class="keyword">with</span> tf.control_dependencies([saved_output.assign(output),</span><br><span class="line">                                saved_state.assign(state)]):</span><br><span class="line">    <span class="comment"># Classifier.</span></span><br><span class="line">    logits = tf.nn.xw_plus_b(tf.concat(<span class="number">0</span>, outputs), w, b)</span><br><span class="line">    loss = tf.reduce_mean(</span><br><span class="line">      tf.nn.softmax_cross_entropy_with_logits(</span><br><span class="line">        logits, tf.concat(<span class="number">0</span>, train_labels)))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Optimizer.</span></span><br><span class="line">  global_step = tf.Variable(<span class="number">0</span>)</span><br><span class="line">  learning_rate = tf.train.exponential_decay(</span><br><span class="line">    <span class="number">10.0</span>, global_step, <span class="number">5000</span>, <span class="number">0.1</span>, staircase=<span class="literal">True</span>)</span><br><span class="line">  optimizer = tf.train.GradientDescentOptimizer(learning_rate)</span><br><span class="line">  gradients, v = <span class="built_in">zip</span>(*optimizer.compute_gradients(loss))</span><br><span class="line">  gradients, _ = tf.clip_by_global_norm(gradients, <span class="number">1.25</span>)</span><br><span class="line">  optimizer = optimizer.apply_gradients(</span><br><span class="line">    <span class="built_in">zip</span>(gradients, v), global_step=global_step)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Predictions.</span></span><br><span class="line">  train_prediction = tf.nn.softmax(logits)</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># Sampling and validation eval: batch 1, no unrolling.</span></span><br><span class="line">  sample_input = tf.placeholder(tf.float32, shape=[<span class="number">1</span>, vocabulary_size])</span><br><span class="line">  saved_sample_output = tf.Variable(tf.zeros([<span class="number">1</span>, num_nodes]))</span><br><span class="line">  saved_sample_state = tf.Variable(tf.zeros([<span class="number">1</span>, num_nodes]))</span><br><span class="line">  reset_sample_state = tf.group(</span><br><span class="line">    saved_sample_output.assign(tf.zeros([<span class="number">1</span>, num_nodes])),</span><br><span class="line">    saved_sample_state.assign(tf.zeros([<span class="number">1</span>, num_nodes])))</span><br><span class="line">  sample_output, sample_state = lstm_cell(</span><br><span class="line">    sample_input, saved_sample_output, saved_sample_state)</span><br><span class="line">  <span class="keyword">with</span> tf.control_dependencies([saved_sample_output.assign(sample_output),</span><br><span class="line">                                saved_sample_state.assign(sample_state)]):</span><br><span class="line">    sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, w, b))</span><br></pre></td></tr></table></figure>
<p><code>tf.control_dependencies</code>这个是用于控制执行顺序的，我们想要完成一组字符的首尾连接的计算图之后，再进行loss函数的构建。<code>saved_output.assign(output)</code>和<code>saved_state.assign(state)</code>可以将10个递归的lstm串起来，<code>tf.control_dependencies</code>保证了loss肯定在assign之后构建。这样就可以保证我们的计算图是全部递归的结构构建的。</p>
<p>接下来是训练的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num_steps = <span class="number">7001</span></span><br><span class="line">summary_frequency = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session(graph=graph) <span class="keyword">as</span> session:</span><br><span class="line">  tf.initialize_all_variables().run()</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&#x27;Initialized&#x27;</span>)</span><br><span class="line">  mean_loss = <span class="number">0</span></span><br><span class="line">  <span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(num_steps):</span><br><span class="line">    batches = train_batches.<span class="built_in">next</span>()</span><br><span class="line">    feed_dict = <span class="built_in">dict</span>()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_unrollings + <span class="number">1</span>):</span><br><span class="line">      feed_dict[train_data[i]] = batches[i]</span><br><span class="line">    _, l, predictions, lr = session.run(</span><br><span class="line">      [optimizer, loss, train_prediction, learning_rate], feed_dict=feed_dict)</span><br><span class="line">    mean_loss += l</span><br><span class="line">    <span class="keyword">if</span> step % summary_frequency == <span class="number">0</span>:</span><br><span class="line">      <span class="keyword">if</span> step &gt; <span class="number">0</span>:</span><br><span class="line">        mean_loss = mean_loss / summary_frequency</span><br><span class="line">      <span class="comment"># The mean loss is an estimate of the loss over the last few batches.</span></span><br><span class="line">      <span class="built_in">print</span>(</span><br><span class="line">        <span class="string">&#x27;Average loss at step %d: %f learning rate: %f&#x27;</span> % (step, mean_loss, lr))</span><br><span class="line">      mean_loss = <span class="number">0</span></span><br><span class="line">      labels = np.concatenate(<span class="built_in">list</span>(batches)[<span class="number">1</span>:])</span><br><span class="line">      <span class="built_in">print</span>(<span class="string">&#x27;Minibatch perplexity: %.2f&#x27;</span> % <span class="built_in">float</span>(</span><br><span class="line">        np.exp(logprob(predictions, labels))))</span><br><span class="line">      <span class="keyword">if</span> step % (summary_frequency * <span class="number">10</span>) == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># Generate some samples.</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span> * <span class="number">80</span>)</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">          feed = sample(random_distribution())</span><br><span class="line">          sentence = characters(feed)[<span class="number">0</span>]</span><br><span class="line">          reset_sample_state.run()</span><br><span class="line">          <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">79</span>):</span><br><span class="line">            prediction = sample_prediction.<span class="built_in">eval</span>(&#123;sample_input: feed&#125;)</span><br><span class="line">            feed = sample(prediction)</span><br><span class="line">            sentence += characters(feed)[<span class="number">0</span>]</span><br><span class="line">          <span class="built_in">print</span>(sentence)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span> * <span class="number">80</span>)</span><br><span class="line">      <span class="comment"># Measure validation set perplexity.</span></span><br><span class="line">      reset_sample_state.run()</span><br><span class="line">      valid_logprob = <span class="number">0</span></span><br><span class="line">      <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(valid_size):</span><br><span class="line">        b = valid_batches.<span class="built_in">next</span>()</span><br><span class="line">        predictions = sample_prediction.<span class="built_in">eval</span>(&#123;sample_input: b[<span class="number">0</span>]&#125;)</span><br><span class="line">        valid_logprob = valid_logprob + logprob(predictions, b[<span class="number">1</span>])</span><br><span class="line">      <span class="built_in">print</span>(<span class="string">&#x27;Validation set perplexity: %.2f&#x27;</span> % <span class="built_in">float</span>(np.exp(</span><br><span class="line">        valid_logprob / valid_size)))</span><br></pre></td></tr></table></figure>
<p>迭代训练过程中，将会每100个迭代计算一次训练数据的perplexity，然后打印出来。并且在1000个迭代的时候，尝试随机选择验证集中的数据进行预测，并与真实的数据进行对比计算perplexity。</p>
<h3 id="问题1"><a class="markdownIt-Anchor" href="#问题1"></a> 问题1</h3>
<p>现在来看我们的问题1。观察计算图构建过程，看起来是可以优化的，因为各个控制器的代码看起来很类似。试想，如果我们将所有的<code>tf.matmul(o, im) + ib</code>都抽取出来组合为一个大的矩阵之后再做乘积，然后利用矩阵乘法的规则，将乘积之后的结果分配到各个控制器的结果中是不是可以呢？下面我们就用这个思想来优化我们的模型。</p>
<p>下面的内容，请结合<a href="https://github.com/gmlove/dl-workshop-rnn-lstm/blob/master/6_lstm-problem1.ipynb">这里的代码</a>来阅读。</p>
<p>我们只需要将权值定义代码替换为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Parameters:</span></span><br><span class="line"><span class="comment"># Input gate: input, previous output, and bias.</span></span><br><span class="line">ifcox = tf.Variable(tf.truncated_normal([vocabulary_size, <span class="number">4</span> * num_nodes], -<span class="number">0.1</span>, <span class="number">0.1</span>))</span><br><span class="line">ifcom = tf.Variable(tf.truncated_normal([num_nodes, <span class="number">4</span> * num_nodes], -<span class="number">0.1</span>, <span class="number">0.1</span>))</span><br><span class="line">ifcob = tf.Variable(tf.zeros([<span class="number">1</span>, <span class="number">4</span> * num_nodes]))</span><br></pre></td></tr></table></figure>
<p>并将<code>lstm_cell</code>函数替换为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">lstm_cell</span>(<span class="params">i, o, state</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf</span></span><br><span class="line"><span class="string">    Note that in this formulation, we omit the various connections between the</span></span><br><span class="line"><span class="string">    previous state and the gates.&quot;&quot;&quot;</span></span><br><span class="line">    all_gates = tf.matmul(i, ifcox) + tf.matmul(o, ifcom) + ifcob</span><br><span class="line">    input_gate = tf.sigmoid(all_gates[:, <span class="number">0</span>:num_nodes])</span><br><span class="line">    forget_gate = tf.sigmoid(all_gates[:, num_nodes:<span class="number">2</span>*num_nodes])</span><br><span class="line">    update = all_gates[:, <span class="number">2</span>*num_nodes:<span class="number">3</span>*num_nodes]</span><br><span class="line">    state = forget_gate * state + input_gate * tf.tanh(update)</span><br><span class="line">    output_gate = tf.sigmoid(all_gates[:, <span class="number">3</span>*num_nodes:])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output_gate * tf.tanh(state), state</span><br></pre></td></tr></table></figure>
<h3 id="问题2-1"><a class="markdownIt-Anchor" href="#问题2-1"></a> 问题2-1</h3>
<p>我们在这里会尝试编写一个bi-gram的实现。我们之前是对字符进行建模的，转到bi-gram上，也就是说我们需要在一对一对的字符上进行建模。</p>
<p>下面的内容，请结合<a href="https://github.com/gmlove/dl-workshop-rnn-lstm/blob/master/6_lstm-problem2-1.ipynb">这里的代码</a>来阅读。</p>
<p>首先是改写我们的工具函数（此时我们的词库大小为27*27）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vocabulary_size_base = <span class="built_in">len</span>(string.ascii_lowercase) + <span class="number">1</span> <span class="comment"># [a-z] + &#x27; &#x27;</span></span><br><span class="line">vocabulary_size = vocabulary_size_base ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line">first_letter = <span class="built_in">ord</span>(string.ascii_lowercase[<span class="number">0</span>])</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">char2id0</span>(<span class="params">char</span>):</span><br><span class="line">  <span class="keyword">if</span> char <span class="keyword">in</span> string.ascii_lowercase:</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">ord</span>(char) - first_letter + <span class="number">1</span></span><br><span class="line">  <span class="keyword">elif</span> char == <span class="string">&#x27; &#x27;</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Unexpected character: %s&#x27;</span> % char)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">char2id</span>(<span class="params">char</span>):</span><br><span class="line">  <span class="keyword">return</span> char2id0(char[<span class="number">0</span>]) * vocabulary_size_base + char2id0(char[<span class="number">1</span>])</span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">id2char0</span>(<span class="params">dictid</span>):</span><br><span class="line">  <span class="keyword">if</span> dictid &gt; <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">chr</span>(dictid + first_letter - <span class="number">1</span>)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27; &#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">id2char</span>(<span class="params">dictid</span>):</span><br><span class="line">  <span class="keyword">return</span> id2char0(dictid//vocabulary_size_base) + id2char0(dictid%vocabulary_size_base)</span><br></pre></td></tr></table></figure>
<p>然后我们还需要修改<code>BatchGenerator</code>来生成batch的训练数据。我们还增加了一个<code>bigramstringtonormal</code>函数来将bi-gram编码的字符串转换为一个可读的字符串。</p>
<p>之后在训练过程中，我们需要打印预测出来的字符串，这时需要调用我们的工具函数将其转换为可读的字符串再打印出来。</p>
<p>需要修改的代码请参考<a href="https://github.com/gmlove/dl-workshop-rnn-lstm/blob/master/6_lstm-problem2-1.ipynb">这里的代码</a>。</p>
<h3 id="问题2-2"><a class="markdownIt-Anchor" href="#问题2-2"></a> 问题2-2</h3>
<p>我们将会引入embedding来节省内存。</p>
<p>需要修改的代码请参考<a href="https://github.com/gmlove/dl-workshop-rnn-lstm/blob/master/6_lstm-problem2-2.ipynb">这里的代码</a>。</p>
<p>主要的思路是，生成batch训练数据时，无须进行one-hot编码了，直接生成一个二维表即可。<code>ifcox</code>权值矩阵在这里充当了embedding的角色。然后在构造lstm单元的时候从embedding查询得出乘积后的值，而无须再进行乘积处理。在最后计算loss的时候，将<code>softmax_cross_entropy_with_logits</code>转换为调用它的稀疏矩阵版本<code>sparse_softmax_cross_entropy_with_logits</code>。</p>
<h3 id="问题2-3"><a class="markdownIt-Anchor" href="#问题2-3"></a> 问题2-3</h3>
<p>我们将会引入dropout来提升性能。</p>
<p>需要修改的代码请参考<a href="https://github.com/gmlove/dl-workshop-rnn-lstm/blob/master/6_lstm-problem2-3.ipynb">这里的代码</a>。</p>
<p>需要注意的是向lstm单元添加dropout的时候，只能加到input数据的处理上面，而不能加到递归连接的处理单元上面。</p>
<h3 id="问题3"><a class="markdownIt-Anchor" href="#问题3"></a> 问题3</h3>
<p>暂无</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>到这里我们就完成了RNN和LSTM的学习了。结合NN CNN可以看到，深度学习的基础其实很简单，就是线性模型加激活函数，常用的深度学习模型其实就是在这样的基础模型上面进行结构的设计和优化。这跟玩乐高类似，由简单的基础的模块进行组合，就可以得到非常复杂的模型，最后的效果是惊人的。</p>
<p>我们接触过的基础的模型有：</p>
<p>线性单元： y=WX+b<br />
激活函数： sigoid tanh relu softmax(一般用作输出层)<br />
优化手段：normalization, randomization, l2 regularization, dropout, embedding, gradient clipping</p>
<p>本文基于google在udacity上面关于深度学习的<a href="https://classroom.udacity.com/courses/ud730">课程</a>而来。主要参考资料来自于斯坦福大学的自然语言处理课程<a href="http://cs224d.stanford.edu/syllabus.html">cs224d</a>。</p>
]]></content>
      <categories>
        <category>machine-learning</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>AI</tag>
        <tag>Machine Learning</tag>
        <tag>RNN</tag>
        <tag>LSTM</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>敏捷方法-用户故事</title>
    <url>/2016/08/31/agile-user-story/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h3 id="常见误解"><a class="markdownIt-Anchor" href="#常见误解"></a> 常见误解</h3>
<ol>
<li>需求是被引出或者捕捉出来的（用户也不知道需求，需求只能被拖网捕捞，有大有小，有死有活，还有漏网的）</li>
<li>用户知道所有需求</li>
<li>原型要在开发阶段一直保留</li>
</ol>
<h3 id="tips"><a class="markdownIt-Anchor" href="#tips"></a> tips</h3>
<p><a href="https://therealba.com/2016/10/26/working-effectively-in-a-distributed-team-across-australia-china-and-new-zealand/comment-page-1/#comment-31">https://therealba.com/2016/10/26/working-effectively-in-a-distributed-team-across-australia-china-and-new-zealand/comment-page-1/#comment-31</a></p>
]]></content>
      <categories>
        <category>development</category>
      </categories>
      <tags>
        <tag>agile</tag>
        <tag>user story</tag>
        <tag>用户故事</tag>
        <tag>敏捷</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习Workshop总结</title>
    <url>/2016/12/16/dl-workshop-summary/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h2 id="深度学习workshop总结"><a class="markdownIt-Anchor" href="#深度学习workshop总结"></a> 深度学习Workshop总结</h2>
<p>深度学习Workshop是我们AI俱乐部面向全中国区的发起的学习机器学习的系列session。这次Workshop最初由佟达发起，由于他当时在成都，所以我们就从成都开始了。</p>
<p>这次workshop从11.7开始，直到1.17结束，共七次session，历时10周。我们以Google在Udacity上面的Tensorflow课程为基础，适当扩展，作为本次workshop的内容。</p>
<p>本次workshop一共包含七次session：</p>
<span id="more"></span>
<ul>
<li>深度学习工作坊01: 人工智能、机器学习和深度学习 by Tongda 11.7</li>
<li>深度学习工作坊02: 深度学习界的Hello World–构建数字图片识别器 by Wu Zhiping 11.17</li>
<li>深度学习工作坊03: 深度神经网络 by Wu Zhiping 11.23</li>
<li>深度学习工作坊04: 卷积神经网络 by Zhang Yaodan 12.1</li>
<li>深度学习工作坊05: RNN/LSTM之文本处理和词向量 by Liao Guangming 12.8</li>
<li>深度学习工作坊06: RNN/LSTM之语句生成 by Liao Guangming 12.15</li>
<li>深度学习工作坊07: 识别连续数字的Android应用 by Wu Zhiping 及 tensorflow工程实践 by Liao Guangming 1.17</li>
</ul>
<p>对于所有参与过此次Workshop的同学，由于参与Workshop基本上每周四晚上需要花3个小时左右的时间，而大家多数又都在项目上，所以免不了要牺牲自己的休息时间，还可能占用项目上的时间。感谢大家可以依靠对这个领域的兴趣和学习的热情积极来参加此次Workshop，一起来学习。如果漏掉一些课程，也是比较遗憾。后面有此次课程用到的所有资料和相关的keynote，大家可以作为参考。</p>
<p>以下放送大家在workshop上面的风采：</p>
<p><img data-src="/attaches/2016/2016-12-16-dl-workshop-summary/02-1.jpeg" alt="02-1" /><br />
<img data-src="/attaches/2016/2016-12-16-dl-workshop-summary/02-2.jpeg" alt="02-2" /><br />
<img data-src="/attaches/2016/2016-12-16-dl-workshop-summary/04-1.jpeg" alt="04-1" /><br />
<img data-src="/attaches/2016/2016-12-16-dl-workshop-summary/04-2.jpeg" alt="04-2" /><br />
<img data-src="/attaches/2016/2016-12-16-dl-workshop-summary/05-1.jpeg" alt="05-1" /><br />
<img data-src="/attaches/2016/2016-12-16-dl-workshop-summary/06-1.jpeg" alt="06-1" /><br />
<img data-src="/attaches/2016/2016-12-16-dl-workshop-summary/07-1.jpeg" alt="07-1" /></p>
<p>下面是我们和参加workshop的五星级同学：</p>
<p><img data-src="/attaches/2016/2016-12-16-dl-workshop-summary/all.jpeg" alt="all" /></p>
<p>来自他们的评价：</p>
<blockquote>
<p>每次workshop讲师们都准备的非常充分，先有细致的ppt讲解理论，再有通过tensorflow实际代码操作的练习，每节课都很充实。感受到了讲师团队们满满的诚意。这种必将是未来发展趋势的前沿技术型workshop特别有价值！ ---- 刘珊</p>
</blockquote>
<blockquote>
<p>通过这一系列的workshop我学习了解了深度学习的基本概念和知识。讲师们深入浅出的讲解，使得深度学习这项前沿技术不再高不可及，变成我们大家都可以来了解和掌握的技术。AI已经开始影响我们的生活，并且在接下来的数年中，它将变得越发重要。我们将看到层出不穷的基于它的新兴应用，而随时间推移它最终将成为各类应用必不可少的一部分，就如同今日互联网功能是应用必不可少的一样。这个过程需要我们大家都参与进来，需要更多像这一系列workshop一样的学习，去掌握技术，我们要去迎接这个未来，我们更要去创造这个未来。 ---- 陈成</p>
</blockquote>
<p>我们最后的识别连续数字Android小应用：</p>
<p><embed src='https://player.youku.com/player.php/sid/XMjQ4MTI5OTcwMA==/v.swf' allowFullScreen='true' quality='high' width='480' height='400' align='middle' allowScriptAccess='always' type='application/x-shockwave-flash'></embed></p>
<p>做完此次Workshop，我想大多数人都会觉得机器学习也不过如此。实际上在当前，理论和工程实践已经发展得相对成熟，入门还是比较容易的。特别是深度学习，我们无须手动提取特征，直接进行端到端的学习，只需要几行代码就可以实现一个自己的机器学习模型。</p>
<p>机器学习作为当下极为热门同时也是极有可能改变世界的技术方向，是很值得大家投入时间学习的。当然入门容易，深入还是不易，Workshop只是一个研究机器学习领域的起步，真正要深入此领域，还需要大家在之后更多的投入和努力。同时欢迎大家能密切关注或者加入我们公司AI俱乐部！</p>
<p>当然这次workshop能顺利的开展离不开来自办公室其他team的支持。特别要感谢VR/AR俱乐部为我们提供性能强悍的显卡，极大了提升了我们训练和优化机器学习模型的效率。同时还要特别感谢办公室能在我们没有code的情况下提供订饭的支持，感谢代领导。感谢感谢！</p>
<p>再说说我们俱乐部的情况。当前我们AI俱乐部条件还比较艰苦，比如经费缺少，没有自己独立的硬件设备等等。但是大家都有着对这个领域的无限热爱和满腔热情，一直坚持着学习和分享。一起学习的日子是最快乐的！我们俱乐部接下来可能的活动会有如下这些：</p>
<ul>
<li>强化学习</li>
<li>自动驾驶</li>
<li>在OpenAI搞些demo</li>
<li>ROS</li>
<li>参加Kaggle比赛之后，给办公室做些分享</li>
</ul>
<p>敬请期待！！！</p>
<p>作为此次Workshop的组织者之一，我也有一些个人的感受想给大家分享。</p>
<ul>
<li>有时候真的只需要一个开始，开始了你就停不下来</li>
<li>想要真正学习一个领域，那就去讲关于这个领域的课</li>
<li>每次session，可以整理一个博客，既是自我rehearsal的过程，也可以记录所讲的东西，让更多人可以受用，扩大自己的影响力</li>
</ul>
<p>最后附上整理好的完整的所有session的资料和keynote，欢迎大家作为参考：</p>
<p><a href="https://github.com/gmlove/dl-workshop">https://github.com/gmlove/dl-workshop</a></p>
]]></content>
      <tags>
        <tag>personal</tag>
      </tags>
  </entry>
  <entry>
    <title>RNN和LSTM从理论到实践一：词向量</title>
    <url>/2016/12/02/dl-workshop-rnn-and-lstm/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>本文试图帮大家理解深度学习中的两大重要而基础的模型RNN和LSTM，并结合google在udacity上面关于深度学习的课程习题进行实践。</p>
<p>近两年深度学习在自然语言处理领域取得了非常好的效果。深度学习模型可以直接进行端到端的训练，而无须进行传统的特征工程过程。在自然语言处理方面，主要的深度学习模型是RNN，以及在RNN之上扩展出来的LSTM。RNN和LSTM也可以广泛用于其他序列处理和预测的机器学习任务。</p>
<p>RNN，全称为Recurrent Neural Network，常译为循环神经网络，也可译为时序递归神经网络，很多人直接简称为递归神经网络。另一个模型Recursive Neural Network，缩写也同样是RNN，译为递归神经网络。递归神经网络是时序递归神经网络的超集，它还可以包括在结构上有递归的神经网络，但是结构递归神经网络使用远没有时序递归神经网络使用得广泛。</p>
<p>本文包括四个部分：</p>
<ul>
<li>NLP</li>
<li>单词的向量表示</li>
<li>RNN和LSTM理论介绍</li>
<li>训练一个LSTM模型</li>
</ul>
<span id="more"></span>
<h2 id="nlp"><a class="markdownIt-Anchor" href="#nlp"></a> NLP</h2>
<p>我们首先来看看自然语言处理。自然语言处理可以说是信息时代最重要的技术之一，实际上自然语言处理无处不在，因为人们几乎所有交流沟通都通过语言进行，如搜索，广告语，邮件，翻译等等。</p>
<p>我们可以列举自然语言处理中的部分任务如下：</p>
<ul>
<li>简单的任务：拼写检查、关键词搜索、同义词查找</li>
<li>比较复杂的任务：从网站或者文档中提取信息</li>
<li>很困难的任务：机器翻译、语义分析（在用户使用搜索引擎时，他输入的查询是什么意思？）、指代分析（如：文档里面的『他』或『她』具体指谁？）</li>
</ul>
<h2 id="单词的向量表示"><a class="markdownIt-Anchor" href="#单词的向量表示"></a> 单词的向量表示</h2>
<p>要解决自然语言处理中的问题，我们首先要解决的问题是，如何表示这些问题。回顾之前的课程，我们可以发现，通常我们都会将输入数据表示成向量，在向量上进行数学建模。对于自然语言处理，也是一样的，我们要想办法将输入数据转化为向量。这里我们只讨论英文语言处理。那么究竟应该怎样用向量表示英文中的单词呢？</p>
<p>我们最容易想到的方法就是，跟之前的课程中对类别的处理一样，直接做one-hot编码。将所有单词排序，排序之后每个单词就会有一个位置，然后用一个与单词数量等长的数组表示某单词，该单词所在的位置数组值就为1，而其他所有位置值都为0.</p>
<p><img data-src="/attaches/2016/2016-12-02-dl-workshop-rnn-and-lstm/one-hot-encoding-for-words.png" alt="One-hot encoding for words" /></p>
<p>但是这样做有什么问题呢？第一个问题就是这样编码太稀疏了，会导致维度非常高，因为单词的数量级通常在10^6级别，维度高就导致计算困难。第二个问题是我们无法简单的从这样的编码中得知单词之间的关系。</p>
<p>为什么单词之间的关系重要呢？因为在我们使用语言时，单词之间并非完全相互独立的。比如短语&quot;at work&quot;，&quot;at&quot;和&quot;work&quot;之间存在一种可搭配使用的关系。而我们要进行语言分析时，单词之间的关系使用就更频繁了。我们来看看一个单词间关系的例子。</p>
<p>下面的习题答案是什么呢？</p>
<p><img data-src="/attaches/2016/2016-12-02-dl-workshop-rnn-and-lstm/word-analogies-question.png" alt="Word analogies question" /></p>
<p>“puppy&quot;对&quot;dog&quot;增加了宠物的属性，那么&quot;cat&quot;加上宠物属性就变成了&quot;kitten”。</p>
<p>“taller&quot;对&quot;tall&quot;增加了比较级属性，那么&quot;short&quot;加上比较级属性就变成了&quot;shorter”。</p>
<p>那么问题来了，如何进行机器学习训练才能得到这样的关系属性呢？先看两个句子。</p>
<p><img data-src="/attaches/2016/2016-12-02-dl-workshop-rnn-and-lstm/way-to-find-relationship-between-words.png" alt="Way to find relationship between words" /></p>
<p>如果说在我们的训练数据中出现了四个句子：</p>
<ul>
<li>The cat purrs.</li>
<li>This cat hunts mice.</li>
<li>The kitty purrs.</li>
<li>This kitty hunts mice.</li>
</ul>
<p>那么我们就有了一个很强的推断：<em>cat和kitty是相似的</em>。</p>
<p><strong>我们用于提取这种关系的方式就是：</strong></p>
<ul>
<li>使用低维向量来表示单词</li>
<li>用邻近的单词来进行相互预测</li>
</ul>
<h3 id="语言模型"><a class="markdownIt-Anchor" href="#语言模型"></a> 语言模型</h3>
<p>在进行实践之前，我们先来看看一个重要的背景知识：语言模型。</p>
<p>早期的自然语言处理采用硬编码的规则来实现。在上世纪80年代，机器学习被应用于自然语言处理中，统计语言模型被提出来，并广泛应用于机器学习模型中。我们这里的语言模型就是指统计语言模型。</p>
<p>我们认识一下什么是一个好的模型？对某个我们认为正确的句子，比如『狗啃骨头』，一个好的模型将能给出很高的概率。而对于不合理的句子，比如『骨头啃狗』它将给出很低的概率。这里面的一个重要的概念就是句子的概率。统计语言模型，简单而言，就是计算某一个句子的概率：P(w1, w2, w3, …)。其中w表示句子中的单词。</p>
<p>如何计算这样的概率呢？为了简便处理，我们可以根据前n个词来预测下一个词。这样我们就得到了Unigram Model，Bigram Model, Trigram Model或者N-gram Model。</p>
<p>Unigram Model是指，我们可以将每个单词视为独立无关的，于是可以得到下面的等式：</p>
<p><img data-src="/attaches/2016/2016-12-02-dl-workshop-rnn-and-lstm/unigram-model-e1.png" alt="Unigram model" /></p>
<p>Bigram Model是指，如果当前单词只依赖其前面一个单词，在『狗啃骨头』中就表示可以用『狗』来预测『啃』。这样的话，我们的模型就可以用下式计算（P(w2|w1）表示在出现单词w1时，出现w2的概率)：</p>
<p><img data-src="/attaches/2016/2016-12-02-dl-workshop-rnn-and-lstm/bigram-model-e1.png" alt="Bigram model" /></p>
<p>Trigram和N-gram Model可以得到的等式如下：</p>
<p><img data-src="/attaches/2016/2016-12-02-dl-workshop-rnn-and-lstm/trigram-ngram-model-e1.png" alt="Trigram and N-gram Model" /></p>
<p>事实上直接使用N-gram模型来计算句子概率是有问题的。因为它太简单了，最多能表示单词和前n个单词的关系，前n+1个单词就无法表示。而且n不能太大，太大会导致计算问题，并且n太大通常性能不会有明显的提升。</p>
<h3 id="word2vec"><a class="markdownIt-Anchor" href="#word2vec"></a> Word2vec</h3>
<p>回到词向量这个主题，对于词向量模型，我们要介绍的是word2vec算法。Word2vec从这个名字简单易懂，但是它似乎概括了所有提取词向量的算法，从这个名字我们大家可以想象一下它在自然语言处理中的地位。该算法是google于2013年提出来的，一经提出便被广泛应用了起来。</p>
<p>word2vec算法，在不断发展沉淀之后，得到两个机器学习模型：Skip Gram Model和CBOW(Continuous Bag of Words)。Skip Gram Model在实现上相对简单，而且google在udacity上面的题目也是以Skip Gram Model作为引子。我们先看看Skip Gram Model，然后在后面的习题中再一起看看CBOW模型。</p>
<h3 id="skip-gram-model"><a class="markdownIt-Anchor" href="#skip-gram-model"></a> Skip Gram Model</h3>
<p>Skip Gram Model属于非监督学习领域，这跟之前的图片识别不同。图片识别时，对于每一张图片我们是有标签的，比如某一张内容为&quot;A&quot;的图片，那么它的标签就是&quot;a&quot;。对于文本而言，原始数据只有一堆文本，一长串的单词序列。我们是没有显示的给定任何标签的。但是机器学习算法又是需要标签的，要不然我们无法计算我们的损失函数。对于这个问题，我们的想法是通过文本内容构造标签。借鉴N-gram模型的想法，如果单词只跟周边的单词相关，那么我们是不是就可以说在使用单词进行预测时，周边的单词就是该单词的正确预测结果呢？Skip Gram Model就是基于这个想法。</p>
<p><img data-src="/attaches/2016/2016-12-02-dl-workshop-rnn-and-lstm/skip-gram-model.png" alt="Skip gram model" /></p>
<p>这个算法的步骤如下：</p>
<ul>
<li>随机生成一个大小为(vocabulary_size, embedding_size)的embedding矩阵（即所有单词的词向量矩阵，每一个行对应一个单词的向量）</li>
<li>对于某一个单词，从embedding矩阵中提取单词向量</li>
<li>在该单词向量上使用logistic regression进行训练，softmax作为激活函数</li>
<li>期望logistic regression得到的概率向量可以与真实的概率向量（即周边词的one-hot编码向量）相匹配</li>
</ul>
<h3 id="skip-gram-model中的问题及negative-sampling"><a class="markdownIt-Anchor" href="#skip-gram-model中的问题及negative-sampling"></a> Skip Gram Model中的问题及Negative Sampling</h3>
<p>上面的算法最后一步在计算上是有问题的。根据公式 y = softmax(XW+b)，其中</p>
<ul>
<li>X的维度是：(batch_size, embedding_size)</li>
<li>W的维度是：(embedding_size, vocabulary_size)</li>
</ul>
<p>softmax将需要在(batch_size, vocabulary_size)矩阵上面进行计算，vocabulary_size通常是很大的，softmax在进行e^x运算时就会遇到计算问题。</p>
<p>我们应对这个问题的方法是Negative sampling。Negative sampling是指，我们在计算最终的softmax时，可以只选取部分错误的label和正确的label进行组合，而无须选择所有的错误label进行计算。当训练的迭代次数足够大时，这对于整个结果是没有影响的。在后面的作业中，num_sampled就是指选择的错误的label的数量。</p>
<h3 id="使用word2vec之后如何衡量单词间的相似性"><a class="markdownIt-Anchor" href="#使用word2vec之后如何衡量单词间的相似性"></a> 使用word2vec之后如何衡量单词间的相似性？</h3>
<p>在得到词向量之后，如何衡量单词间的相似性呢？</p>
<p>回顾一下我们的训练过程。如果两个单词相似，即出现了两个句子&quot;The cat purrs&quot;和&quot;The kitty purrs&quot;，那么cat的词向量经过计算之后可以得到purrs词向量，kitty词向量经过计算之后也可以得到purrs词向量。再结合softmax的比例计算过程，可以得出的结论是，最终的词向量里面，相似的单词，他们的词向量值在比例上也是相似的。</p>
<p>事实上我们通常会用余弦距离去衡量词向量的相似性，即词向量间的夹角。相似性就是：给定单词w1 w2 w3的词向量Vw1 Vw2 Vw3，如果Vw1 * Vw2.T / (|Vw1||Vw2|) &gt; Vw1 * Vw3.T / (|Vw1||Vw3|)，那么我们就认为w2比w3更接近w1。</p>
<h3 id="coding时间"><a class="markdownIt-Anchor" href="#coding时间"></a> Coding时间</h3>
<p><a href="git@github.com:gmlove/dl-workshop-rnn-lstm.git">这个工程</a>里面包含了所有用到的数据及代码。下载工程之后，按照之前的办法，将整个目录映射到docker镜像中。</p>
<p>下面的内容，请结合<a href="https://github.com/gmlove/dl-workshop-rnn-lstm/blob/master/5_word2vec.ipynb">代码</a>来进行阅读。</p>
<p>首先是下载、验证和读取文本。在代码中对应<code>maybe_download</code>和<code>read_data</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">&#x27;http://mattmahoney.net/dc/&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">maybe_download</span>(<span class="params">filename, expected_bytes</span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Download a file if not present, and make sure it&#x27;s the right size.&quot;&quot;&quot;</span></span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(filename):</span><br><span class="line">    filename, _ = urlretrieve(url + filename, filename)</span><br><span class="line">  statinfo = os.stat(filename)</span><br><span class="line">  <span class="keyword">if</span> statinfo.st_size == expected_bytes:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Found and verified %s&#x27;</span> % filename)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(statinfo.st_size)</span><br><span class="line">    <span class="keyword">raise</span> Exception(</span><br><span class="line">      <span class="string">&#x27;Failed to verify &#x27;</span> + filename + <span class="string">&#x27;. Can you get to it with a browser?&#x27;</span>)</span><br><span class="line">  <span class="keyword">return</span> filename</span><br><span class="line"></span><br><span class="line">filename = maybe_download(<span class="string">&#x27;text8.zip&#x27;</span>, <span class="number">31344016</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_data</span>(<span class="params">filename</span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Extract the first file enclosed in a zip file as a list of words&quot;&quot;&quot;</span></span><br><span class="line">  <span class="keyword">with</span> zipfile.ZipFile(filename) <span class="keyword">as</span> f:</span><br><span class="line">    data = tf.compat.as_str(f.read(f.namelist()[<span class="number">0</span>])).split()</span><br><span class="line">  <span class="keyword">return</span> data</span><br><span class="line">  </span><br><span class="line">words = read_data(filename)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Data size %d&#x27;</span> % <span class="built_in">len</span>(words))</span><br></pre></td></tr></table></figure>
<p>接下来是根据文本构造我们要用的数据结构。我们先定义我们的单词库大小，这里设置为50000。在调用<code>build_dataset</code>之后，得到的数据为：</p>
<ul>
<li><code>count</code>：一个单词和它出现的次数的list，按照单词出现次数排序。如果单词出现次数太低，排序在50000之后，那么我们就将它映射到&quot;UNK&quot;单词，即unknown。这里的单词索引将用于把文本映射为整数值。</li>
<li><code>data</code>：原始文本映射到索引之后的序列。如原始文本为&quot;anarchism originated as a term of abuse first&quot;，映射之后为<code>[5243, 3083, 12, 6, 195, 2, 3136, 46, 59, 156]</code></li>
<li><code>dictionary</code>：用于查询词对应的索引的字典</li>
<li><code>reverse_dictionary</code>：用于查询索引对应的单词的字典</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vocabulary_size = <span class="number">50000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_dataset</span>(<span class="params">words</span>):</span><br><span class="line">  count = [[<span class="string">&#x27;UNK&#x27;</span>, -<span class="number">1</span>]]</span><br><span class="line">  count.extend(collections.Counter(words).most_common(vocabulary_size - <span class="number">1</span>))</span><br><span class="line">  dictionary = <span class="built_in">dict</span>()</span><br><span class="line">  <span class="keyword">for</span> word, _ <span class="keyword">in</span> count:</span><br><span class="line">    dictionary[word] = <span class="built_in">len</span>(dictionary)</span><br><span class="line">  data = <span class="built_in">list</span>()</span><br><span class="line">  unk_count = <span class="number">0</span></span><br><span class="line">  <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">    <span class="keyword">if</span> word <span class="keyword">in</span> dictionary:</span><br><span class="line">      index = dictionary[word]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      index = <span class="number">0</span>  <span class="comment"># dictionary[&#x27;UNK&#x27;]</span></span><br><span class="line">      unk_count = unk_count + <span class="number">1</span></span><br><span class="line">    data.append(index)</span><br><span class="line">  count[<span class="number">0</span>][<span class="number">1</span>] = unk_count</span><br><span class="line">  reverse_dictionary = <span class="built_in">dict</span>(<span class="built_in">zip</span>(dictionary.values(), dictionary.keys())) </span><br><span class="line">  <span class="keyword">return</span> data, count, dictionary, reverse_dictionary</span><br><span class="line"></span><br><span class="line">data, count, dictionary, reverse_dictionary = build_dataset(words)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Most common words (+UNK)&#x27;</span>, count[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Sample data&#x27;</span>, data[:<span class="number">10</span>])</span><br><span class="line"><span class="keyword">del</span> words  <span class="comment"># Hint to reduce memory.</span></span><br></pre></td></tr></table></figure>
<p>然后我们需要有一个过程来生成batch，每次都批量处理数据，我们才能发挥计算机的并行计算的实力。</p>
<p>在生成batch时，我们期望在输入参数为<code>batch_size</code> <code>num_skips</code> <code>skip_window</code>时，可以对一小段文本，即skip_window长的文本，使用中心词来预测周边的词，生成num_skips个类似(words[2] -&gt; words[0])这样的预测组。</p>
<p>当原始数据为<code>['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first']</code>时，以num_skips=2和skip_window=1来调用generate_batch之后，得到的batch为<code>['originated', 'originated', 'as', 'as', 'a', 'a', 'term', 'term']</code>，对应的label为<code>['as', 'anarchism', 'a', 'originated', 'term', 'as', 'a', 'of']</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_index = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_batch</span>(<span class="params">batch_size, num_skips, skip_window</span>):</span><br><span class="line">  <span class="keyword">global</span> data_index</span><br><span class="line">  <span class="keyword">assert</span> batch_size % num_skips == <span class="number">0</span></span><br><span class="line">  <span class="keyword">assert</span> num_skips &lt;= <span class="number">2</span> * skip_window</span><br><span class="line">  batch = np.ndarray(shape=(batch_size), dtype=np.int32)</span><br><span class="line">  labels = np.ndarray(shape=(batch_size, <span class="number">1</span>), dtype=np.int32)</span><br><span class="line">  span = <span class="number">2</span> * skip_window + <span class="number">1</span> <span class="comment"># [ skip_window target skip_window ]</span></span><br><span class="line">  buffer = collections.deque(maxlen=span)</span><br><span class="line">  <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(span):</span><br><span class="line">    buffer.append(data[data_index])</span><br><span class="line">    data_index = (data_index + <span class="number">1</span>) % <span class="built_in">len</span>(data)</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batch_size // num_skips):</span><br><span class="line">    target = skip_window  <span class="comment"># target label at the center of the buffer</span></span><br><span class="line">    targets_to_avoid = [ skip_window ]</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(num_skips):</span><br><span class="line">      <span class="keyword">while</span> target <span class="keyword">in</span> targets_to_avoid:</span><br><span class="line">        target = random.randint(<span class="number">0</span>, span - <span class="number">1</span>)</span><br><span class="line">      targets_to_avoid.append(target)</span><br><span class="line">      batch[i * num_skips + j] = buffer[skip_window]</span><br><span class="line">      labels[i * num_skips + j, <span class="number">0</span>] = buffer[target]</span><br><span class="line">    buffer.append(data[data_index])</span><br><span class="line">    data_index = (data_index + <span class="number">1</span>) % <span class="built_in">len</span>(data)</span><br><span class="line">  <span class="keyword">return</span> batch, labels</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;data:&#x27;</span>, [reverse_dictionary[di] <span class="keyword">for</span> di <span class="keyword">in</span> data[:<span class="number">8</span>]])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> num_skips, skip_window <span class="keyword">in</span> [(<span class="number">2</span>, <span class="number">1</span>), (<span class="number">4</span>, <span class="number">2</span>)]:</span><br><span class="line">    data_index = <span class="number">0</span></span><br><span class="line">    batch, labels = generate_batch(batch_size=<span class="number">8</span>, num_skips=num_skips, skip_window=skip_window)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nwith num_skips = %d and skip_window = %d:&#x27;</span> % (num_skips, skip_window))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;    batch:&#x27;</span>, [reverse_dictionary[bi] <span class="keyword">for</span> bi <span class="keyword">in</span> batch])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;    labels:&#x27;</span>, [reverse_dictionary[li] <span class="keyword">for</span> li <span class="keyword">in</span> labels.reshape(<span class="number">8</span>)])</span><br></pre></td></tr></table></figure>
<p>有了这些数据结构和工具函数之后，我们就可以构造我们的模型如代码中所示。</p>
<ul>
<li><code>embedding_size</code>：我们期望编码之后的词向量长度</li>
<li><code>train_dataset</code>：大小为batch_size的int数组，我们将单词索引在embedding矩阵中查找词向量</li>
<li><code>train_labels</code>：大小为[batch_size, 1]的矩阵，因为我们最终进行损失计算时，是使用one-hot编码的cross entropy</li>
<li><code>valid_examples</code>：从前100个词的单词集中随机选取16个单词用于计算相似度</li>
<li><code>valid_dataset</code>：对应于valid_examples，大小为16的int数组</li>
<li><code>embeddings</code>：大小为[vocabulary_size, embedding_size]的浮点型矩阵</li>
<li><code>softmax_weights</code>：大小为[vocabulary_size, embedding_size]的浮点型权值矩阵</li>
<li><code>softmax_biases</code>：大小为[vocabulary_size]的浮点型偏置向量</li>
</ul>
<p>我们的模型就是先调用<code>tf.nn.embedding_lookup</code>去查找词向量。然后调用<code>tf.reduce_mean</code>和<code>tf.nn.sampled_softmax_loss</code>计算损失值。之后使用<code>tf.train.AdagradOptimizer</code>进行梯度下降，期望最小化损失值。梯度下降会同时优化我们的embeddings矩阵、softmax_weights矩阵及softmax_biases向量。最后在这个模型上面迭代计算就可以得到优化后的模型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">batch_size = <span class="number">128</span></span><br><span class="line">embedding_size = <span class="number">128</span> <span class="comment"># Dimension of the embedding vector.</span></span><br><span class="line">skip_window = <span class="number">1</span> <span class="comment"># How many words to consider left and right.</span></span><br><span class="line">num_skips = <span class="number">2</span> <span class="comment"># How many times to reuse an input to generate a label.</span></span><br><span class="line"><span class="comment"># We pick a random validation set to sample nearest neighbors. here we limit the</span></span><br><span class="line"><span class="comment"># validation samples to the words that have a low numeric ID, which by</span></span><br><span class="line"><span class="comment"># construction are also the most frequent. </span></span><br><span class="line">valid_size = <span class="number">16</span> <span class="comment"># Random set of words to evaluate similarity on.</span></span><br><span class="line">valid_window = <span class="number">100</span> <span class="comment"># Only pick dev samples in the head of the distribution.</span></span><br><span class="line">valid_examples = np.array(random.sample(<span class="built_in">range</span>(valid_window), valid_size))</span><br><span class="line">num_sampled = <span class="number">64</span> <span class="comment"># Number of negative examples to sample.</span></span><br><span class="line"></span><br><span class="line">graph = tf.Graph()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> graph.as_default(), tf.device(<span class="string">&#x27;/cpu:0&#x27;</span>):</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Input data.</span></span><br><span class="line">  train_dataset = tf.placeholder(tf.int32, shape=[batch_size])</span><br><span class="line">  train_labels = tf.placeholder(tf.int32, shape=[batch_size, <span class="number">1</span>])</span><br><span class="line">  valid_dataset = tf.constant(valid_examples, dtype=tf.int32)</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># Variables.</span></span><br><span class="line">  embeddings = tf.Variable(</span><br><span class="line">    tf.random_uniform([vocabulary_size, embedding_size], -<span class="number">1.0</span>, <span class="number">1.0</span>))</span><br><span class="line">  softmax_weights = tf.Variable(</span><br><span class="line">    tf.truncated_normal([vocabulary_size, embedding_size],</span><br><span class="line">                         stddev=<span class="number">1.0</span> / math.sqrt(embedding_size)))</span><br><span class="line">  softmax_biases = tf.Variable(tf.zeros([vocabulary_size]))</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># Model.</span></span><br><span class="line">  <span class="comment"># Look up embeddings for inputs.</span></span><br><span class="line">  embed = tf.nn.embedding_lookup(embeddings, train_dataset) <span class="comment"># embed.shape: (batch_size, embedding_size)</span></span><br><span class="line">  <span class="comment"># Compute the softmax loss, using a sample of the negative labels each time.</span></span><br><span class="line">  loss = tf.reduce_mean(</span><br><span class="line">    tf.nn.sampled_softmax_loss(softmax_weights, softmax_biases, embed,</span><br><span class="line">                               train_labels, num_sampled, vocabulary_size))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Optimizer.</span></span><br><span class="line">  <span class="comment"># Note: The optimizer will optimize the softmax_weights AND the embeddings.</span></span><br><span class="line">  <span class="comment"># This is because the embeddings are defined as a variable quantity and the</span></span><br><span class="line">  <span class="comment"># optimizer&#x27;s `minimize` method will by default modify all variable quantities </span></span><br><span class="line">  <span class="comment"># that contribute to the tensor it is passed.</span></span><br><span class="line">  <span class="comment"># See docs on `tf.train.Optimizer.minimize()` for more details.</span></span><br><span class="line">  optimizer = tf.train.AdagradOptimizer(<span class="number">1.0</span>).minimize(loss)</span><br></pre></td></tr></table></figure>
<p>有了模型之后，我们该如何计算相似度呢？使用之前的相似度计算公式，我们可以计算先embedding的每一个词向量的1/|Vw1|，使用valid_dataset的词向量与所有其他单词的词向量相乘，然后从大到小排序就可以得到按相似度排序的其他相似词。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Compute the similarity between minibatch examples and all embeddings.</span><br><span class="line"># We use the cosine distance:</span><br><span class="line">norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))</span><br><span class="line">normalized_embeddings = embeddings / norm</span><br><span class="line">valid_embeddings = tf.nn.embedding_lookup(</span><br><span class="line">  normalized_embeddings, valid_dataset)</span><br><span class="line">similarity = tf.matmul(valid_embeddings, tf.transpose(normalized_embeddings)) # similarity.shape: (valid_size, vocabulary_size)</span><br></pre></td></tr></table></figure>
<p>有了这个模型之后，我们就可以在模型上面进行迭代计算了。迭代的同时，我们每2000步输出一下平均损失值，每10000步的时候，输出一下和验证集相似的词。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num_steps = <span class="number">100001</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session(graph=graph) <span class="keyword">as</span> session:</span><br><span class="line">  tf.global_variables_initializer().run()</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&#x27;Initialized&#x27;</span>)</span><br><span class="line">  average_loss = <span class="number">0</span></span><br><span class="line">  <span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(num_steps):</span><br><span class="line">    batch_data, batch_labels = generate_batch(</span><br><span class="line">      batch_size, num_skips, skip_window)</span><br><span class="line">    feed_dict = &#123;train_dataset : batch_data, train_labels : batch_labels&#125;</span><br><span class="line">    _, l = session.run([optimizer, loss], feed_dict=feed_dict)</span><br><span class="line">    average_loss += l</span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">2000</span> == <span class="number">0</span>:</span><br><span class="line">      <span class="keyword">if</span> step &gt; <span class="number">0</span>:</span><br><span class="line">        average_loss = average_loss / <span class="number">2000</span></span><br><span class="line">      <span class="comment"># The average loss is an estimate of the loss over the last 2000 batches.</span></span><br><span class="line">      <span class="built_in">print</span>(<span class="string">&#x27;Average loss at step %d: %f&#x27;</span> % (step, average_loss))</span><br><span class="line">      average_loss = <span class="number">0</span></span><br><span class="line">    <span class="comment"># note that this is expensive (~20% slowdown if computed every 500 steps)</span></span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">10000</span> == <span class="number">0</span>:</span><br><span class="line">      sim = similarity.<span class="built_in">eval</span>()</span><br><span class="line">      <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(valid_size):</span><br><span class="line">        valid_word = reverse_dictionary[valid_examples[i]]</span><br><span class="line">        top_k = <span class="number">8</span> <span class="comment"># number of nearest neighbors</span></span><br><span class="line">        nearest = (-sim[i, :]).argsort()[<span class="number">1</span>:top_k+<span class="number">1</span>] <span class="comment"># argsort will sort elements as ascended, so we need a minus symbol</span></span><br><span class="line">        log = <span class="string">&#x27;Nearest to %s:&#x27;</span> % valid_word</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(top_k):</span><br><span class="line">          close_word = reverse_dictionary[nearest[k]]</span><br><span class="line">          log = <span class="string">&#x27;%s %s,&#x27;</span> % (log, close_word)</span><br><span class="line">        <span class="built_in">print</span>(log)</span><br><span class="line">  final_embeddings = normalized_embeddings.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure>
<p>在模型计算好之后，我们可以使用TSNE降维方法，用二维表来表示我们的词向量，再绘制出来就可以得到最终的效果图片。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num_points = <span class="number">400</span></span><br><span class="line"></span><br><span class="line">tsne = TSNE(perplexity=<span class="number">30</span>, n_components=<span class="number">2</span>, init=<span class="string">&#x27;pca&#x27;</span>, n_iter=<span class="number">5000</span>)</span><br><span class="line">two_d_embeddings = tsne.fit_transform(final_embeddings[<span class="number">1</span>:num_points+<span class="number">1</span>, :]) <span class="comment"># ignore UNK</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot</span>(<span class="params">embeddings, labels</span>):</span><br><span class="line">  <span class="keyword">assert</span> embeddings.shape[<span class="number">0</span>] &gt;= <span class="built_in">len</span>(labels), <span class="string">&#x27;More labels than embeddings&#x27;</span></span><br><span class="line">  pylab.figure(figsize=(<span class="number">15</span>,<span class="number">15</span>))  <span class="comment"># in inches</span></span><br><span class="line">  <span class="keyword">for</span> i, label <span class="keyword">in</span> <span class="built_in">enumerate</span>(labels):</span><br><span class="line">    x, y = embeddings[i,:]</span><br><span class="line">    pylab.scatter(x, y)</span><br><span class="line">    pylab.annotate(label, xy=(x, y), xytext=(<span class="number">5</span>, <span class="number">2</span>), textcoords=<span class="string">&#x27;offset points&#x27;</span>,</span><br><span class="line">                   ha=<span class="string">&#x27;right&#x27;</span>, va=<span class="string">&#x27;bottom&#x27;</span>)</span><br><span class="line">  pylab.show()</span><br><span class="line"></span><br><span class="line">words = [reverse_dictionary[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, num_points+<span class="number">1</span>)]</span><br><span class="line">plot(two_d_embeddings, words)</span><br></pre></td></tr></table></figure>
<p><img data-src="/attaches/2016/2016-12-02-dl-workshop-rnn-and-lstm/similar-words-in-graph.png" alt="Similar words in a graph" /></p>
<h3 id="cbow模型"><a class="markdownIt-Anchor" href="#cbow模型"></a> CBOW模型</h3>
<p>现在到我们的动手时间了。我们将在上面的代码的基础上实现一个CBOW模型。</p>
<p>CBOW模型跟Skip Gram模型正好相反，在这个模型中，我们使用单词周边的单词去预测该单词。其模型如下：</p>
<p><img data-src="/attaches/2016/2016-12-02-dl-workshop-rnn-and-lstm/cbow-model.png" alt="CBOW model" /></p>
<p>这个算法的步骤如下：</p>
<ul>
<li>随机生成一个大小为(vocabulary_size, embedding_size)的embedding矩阵（即所有单词的词向量矩阵，每一个行对应一个单词的向量）</li>
<li>对于某一个单词（中心词），从embedding矩阵中提取其周边单词的词向量</li>
<li>求周边单词的词向量的均值向量</li>
<li>在该均值向量上使用logistic regression进行训练，softmax作为激活函数</li>
<li>期望logistic regression得到的概率向量可以与真实的概率向量（即中心词的one-hot编码向量）相匹配</li>
</ul>
<p>对比CBOW的计算步骤和SkipGram的计算步骤，我们可以来一步步的修改代码。</p>
<p>下面的内容，请结合<a href="https://github.com/gmlove/dl-workshop-rnn-lstm/blob/master/5_word2vec-problem.ipynb">代码</a>来进行阅读。</p>
<p>我们要修改的第一个地方是<code>generate_batch</code>函数。</p>
<ul>
<li>labels的定义，其大小不再是(batch_size, 1)而应该为(batch_size // num_skips, 1)</li>
<li>batch的赋值，batch现在应该为中心词周边的单词</li>
<li>labels的赋值，labels现在应该为中心词</li>
<li>print输出，label时，label的长度应该为batch_size // num_skips</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_index = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_batch</span>(<span class="params">batch_size, num_skips, skip_window</span>):</span><br><span class="line">  <span class="keyword">global</span> data_index</span><br><span class="line">  <span class="keyword">assert</span> batch_size % num_skips == <span class="number">0</span></span><br><span class="line">  <span class="keyword">assert</span> num_skips &lt;= <span class="number">2</span> * skip_window</span><br><span class="line">  batch = np.ndarray(shape=(batch_size), dtype=np.int32)</span><br><span class="line">  labels = np.ndarray(shape=(batch_size // num_skips, <span class="number">1</span>), dtype=np.int32)</span><br><span class="line">  span = <span class="number">2</span> * skip_window + <span class="number">1</span> <span class="comment"># [ skip_window target skip_window ]</span></span><br><span class="line">  buffer = collections.deque(maxlen=span)</span><br><span class="line">  <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(span):</span><br><span class="line">    buffer.append(data[data_index])</span><br><span class="line">    data_index = (data_index + <span class="number">1</span>) % <span class="built_in">len</span>(data)</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batch_size // num_skips):</span><br><span class="line">    target = skip_window  <span class="comment"># target label at the center of the buffer</span></span><br><span class="line">    targets_to_avoid = [ skip_window ]</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(num_skips):</span><br><span class="line">      <span class="keyword">while</span> target <span class="keyword">in</span> targets_to_avoid:</span><br><span class="line">        target = random.randint(<span class="number">0</span>, span - <span class="number">1</span>)</span><br><span class="line">      targets_to_avoid.append(target)</span><br><span class="line">      batch[i * num_skips + j] = buffer[target]</span><br><span class="line">    labels[i, <span class="number">0</span>] = buffer[skip_window]</span><br><span class="line">    buffer.append(data[data_index])</span><br><span class="line">    data_index = (data_index + <span class="number">1</span>) % <span class="built_in">len</span>(data)</span><br><span class="line">  <span class="keyword">return</span> batch, labels</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;data:&#x27;</span>, [reverse_dictionary[di] <span class="keyword">for</span> di <span class="keyword">in</span> data[:<span class="number">8</span>]])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> num_skips, skip_window <span class="keyword">in</span> [(<span class="number">2</span>, <span class="number">1</span>), (<span class="number">4</span>, <span class="number">2</span>)]:</span><br><span class="line">    data_index = <span class="number">0</span></span><br><span class="line">    batch, labels = generate_batch(batch_size=<span class="number">8</span>, num_skips=num_skips, skip_window=skip_window)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nwith num_skips = %d and skip_window = %d:&#x27;</span> % (num_skips, skip_window))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;    batch:&#x27;</span>, [reverse_dictionary[bi] <span class="keyword">for</span> bi <span class="keyword">in</span> batch])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;    labels:&#x27;</span>, [reverse_dictionary[li] <span class="keyword">for</span> li <span class="keyword">in</span> labels.reshape(<span class="number">8</span>//num_skips)])</span><br></pre></td></tr></table></figure>
<p>修改之后，可以通过这样的测试来验证程序逻辑。当原始数据为<code>['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first']</code>时，以num_skips=2和skip_window=1来调用generate_batch之后，得到的batch为<code>['as', 'anarchism', 'a', 'originated', 'as', 'term', 'of', 'a']</code>，对应的label为<code>['originated', 'as', 'a', 'term']</code></p>
<p>第二个要修改的地方就是模型构建过程。</p>
<ul>
<li>train_labels的定义，train_labels的大小现在应该为(batch_size // num_skips, 1)</li>
<li>在进行loss计算之前，我们需要计算同一个label的train_data的均值向量。可以参考tensorflow的API <code>tf.segment_mean</code>来实现。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">batch_size = <span class="number">128</span></span><br><span class="line">embedding_size = <span class="number">128</span> <span class="comment"># Dimension of the embedding vector.</span></span><br><span class="line">skip_window = <span class="number">1</span> <span class="comment"># How many words to consider left and right.</span></span><br><span class="line">num_skips = <span class="number">2</span> <span class="comment"># How many times to reuse an input to generate a label.</span></span><br><span class="line"><span class="comment"># We pick a random validation set to sample nearest neighbors. here we limit the</span></span><br><span class="line"><span class="comment"># validation samples to the words that have a low numeric ID, which by</span></span><br><span class="line"><span class="comment"># construction are also the most frequent. </span></span><br><span class="line">valid_size = <span class="number">16</span> <span class="comment"># Random set of words to evaluate similarity on.</span></span><br><span class="line">valid_window = <span class="number">100</span> <span class="comment"># Only pick dev samples in the head of the distribution.</span></span><br><span class="line">valid_examples = np.array(random.sample(<span class="built_in">range</span>(valid_window), valid_size))</span><br><span class="line">num_sampled = <span class="number">64</span> <span class="comment"># Number of negative examples to sample.</span></span><br><span class="line"></span><br><span class="line">graph = tf.Graph()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> graph.as_default(), tf.device(<span class="string">&#x27;/cpu:0&#x27;</span>):</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Input data.</span></span><br><span class="line">  train_dataset = tf.placeholder(tf.int32, shape=[batch_size])</span><br><span class="line">  train_labels = tf.placeholder(tf.int32, shape=[batch_size//num_skips, <span class="number">1</span>])</span><br><span class="line">  valid_dataset = tf.constant(valid_examples, dtype=tf.int32)</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># Variables.</span></span><br><span class="line">  embeddings = tf.Variable(</span><br><span class="line">    tf.random_uniform([vocabulary_size, embedding_size], -<span class="number">1.0</span>, <span class="number">1.0</span>))</span><br><span class="line">  softmax_weights = tf.Variable(</span><br><span class="line">    tf.truncated_normal([vocabulary_size, embedding_size],</span><br><span class="line">                         stddev=<span class="number">1.0</span> / math.sqrt(embedding_size)))</span><br><span class="line">  softmax_biases = tf.Variable(tf.zeros([vocabulary_size]))</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># Model.</span></span><br><span class="line">  <span class="comment"># Look up embeddings for inputs.</span></span><br><span class="line">  embed = tf.nn.embedding_lookup(embeddings, train_dataset) <span class="comment"># embed.shape: (batch_size, embedding_size)</span></span><br><span class="line">  segment_ids = tf.constant([i//num_skips <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batch_size)], dtype=tf.int32)</span><br><span class="line">  embed = tf.segment_mean(embed, segment_ids)</span><br><span class="line">  <span class="comment"># Compute the softmax loss, using a sample of the negative labels each time.</span></span><br><span class="line">  loss = tf.reduce_mean(</span><br><span class="line">    tf.nn.sampled_softmax_loss(softmax_weights, softmax_biases, embed,</span><br><span class="line">                               train_labels, num_sampled, vocabulary_size))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Optimizer.</span></span><br><span class="line">  <span class="comment"># Note: The optimizer will optimize the softmax_weights AND the embeddings.</span></span><br><span class="line">  <span class="comment"># This is because the embeddings are defined as a variable quantity and the</span></span><br><span class="line">  <span class="comment"># optimizer&#x27;s `minimize` method will by default modify all variable quantities </span></span><br><span class="line">  <span class="comment"># that contribute to the tensor it is passed.</span></span><br><span class="line">  <span class="comment"># See docs on `tf.train.Optimizer.minimize()` for more details.</span></span><br><span class="line">  optimizer = tf.train.AdagradOptimizer(<span class="number">1.0</span>).minimize(loss)</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># Compute the similarity between minibatch examples and all embeddings.</span></span><br><span class="line">  <span class="comment"># We use the cosine distance:</span></span><br><span class="line">  norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), <span class="number">1</span>, keep_dims=<span class="literal">True</span>))</span><br><span class="line">  normalized_embeddings = embeddings / norm</span><br><span class="line">  valid_embeddings = tf.nn.embedding_lookup(</span><br><span class="line">    normalized_embeddings, valid_dataset)</span><br><span class="line">  similarity = tf.matmul(valid_embeddings, tf.transpose(normalized_embeddings)) <span class="comment"># similarity.shape: (valid_size, vocabulary_size)</span></span><br></pre></td></tr></table></figure>
<p>在修改完成之后，我们就可以看到最后的结果。我们生成的词向量图与SkipGram模型生成的类似。</p>
<p>后续会继续RNN和LSTM的部分。敬请期待！</p>
<p>本文基于google在udacity上面关于深度学习的<a href="https://classroom.udacity.com/courses/ud730">课程</a>而来。主要参考资料来自于斯坦福大学的自然语言处理课程<a href="http://cs224d.stanford.edu/syllabus.html">cs224d</a>。</p>
]]></content>
      <categories>
        <category>machine-learning</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>AI</tag>
        <tag>Machine Learning</tag>
        <tag>RNN</tag>
        <tag>LSTM</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>大规模Tensorflow网络的一些技巧</title>
    <url>/2017/01/16/dl-workshop-massive-network-tips/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>今天给大家分享一下，在网络规模越来越大时，我们会遇到什么问题，以及如何使用tensorflow来应对。下面将会给大家分享一些有用的tips。</p>
<h2 id="大规模网络的特征"><a class="markdownIt-Anchor" href="#大规模网络的特征"></a> 大规模网络的特征</h2>
<p>首先我们来看一下用什么来衡量网络规模。</p>
<p>下图是alexnet的网络结构图，在2012年的imagenet图像分类挑战中，alexnet取得了80.2%的top-5正确率。</p>
<span id="more"></span>
<p><img data-src="/attaches/2017/2017-01-16-dl-workshop-massive-network-tips/alexnet.png" alt="AlexNet" /></p>
<p>从图中可以看到网络一共分为8层，5个卷积层，3个全连接层。对比lenet的5层网络，可以发现alexnet在网络的深度上面表现为更深，实际上在imagenet挑战中性能更好的Incepiton模型网络层数更是达到了数十层。从这里我们可以看到随着网络规模的扩大，网络的层数在增加。</p>
<p>另一方面是网络结构的复杂度上，之前的网络从下到上逐层递进，演进为多分支的结构。</p>
<p>另外，神经元的个数也是网络的重要特征，大规模的网络通常参数个数也越多。AlexNet和Inception模型的网络参数就达到了上千万，VGGNet更是达到了上亿的参数个数。当然这相比人类的800亿级的神经元个数还是差几个数量级。</p>
<p>为了更高的精确度，我们通常需要规模更大的网络，那么在网络规模逐渐扩大的过程中，我们会遇到的主要挑战是什么呢？其实主要有两个：一是训练数据量越来越大，二是训练时间越来越长。我们下面就来看看如何使用tensorflow来应对这些问题。我们会介绍一些很有用的tips。</p>
<h2 id="训练大规模网络的技巧"><a class="markdownIt-Anchor" href="#训练大规模网络的技巧"></a> 训练大规模网络的技巧</h2>
<h3 id="队列及多线程"><a class="markdownIt-Anchor" href="#队列及多线程"></a> 队列及多线程</h3>
<p>试想一下，如果用于训练的数据量达到了100G，我们应该如何来应对呢？一个基本的想法就是我们可以把元数据读入到内存，真实的数据放磁盘，元数据通常很小，容易处理，而真实的数据，如图片，比较大，放磁盘上等需要的时候再读取。</p>
<p><img data-src="/attaches/2017/2017-01-16-dl-workshop-massive-network-tips/separated-data-storage.png" alt="separated data storage" /></p>
<p>Tensorflow给我们提供了三种方法来输入训练数据。一是我们可以直接把数据全部读入到内存，然后使用这些数据进行训练；二是feeding的机制，就是每次迭代的时候把数据作为输入喂给模型，这种机制是可以解决我们的问题的，但是我们得自己编写代码来处理数据load的过程；第三种我们可以使用的机制就是队列，使用队列我们就可以很容易的实现上面的模型，因为tensorflow已经有实现好的代码可以让我们在需要的时候才读取数据。</p>
<p>在tensorflow里面，队列也是一个普通的操作，跟其他的操作一样，出队操作会返回一个tensor，然后就可以使用这个tensor进行后续的处理了。</p>
<p>请看这个gif图来理解tensorflow中的队列是如何工作的(来自tensorflow官网)：</p>
<p><img data-src="/attaches/2017/2017-01-16-dl-workshop-massive-network-tips/IncremeterFifoQueue.gif" alt="Incremeter FIFO Queue" /></p>
<p>在构造图的过程中，我们构造了一个队列，以及4个节点分别处理入队、出队、递增、入队操作。通过gif图，我们可以看到在计算图运行的过程中队列里面的数据是如何变化的。</p>
<p>下面的图更清晰的演示了之前我们讨论的模型(来自tensorflow官网)：</p>
<p><img data-src="/attaches/2017/2017-01-16-dl-workshop-massive-network-tips/AnimatedFileQueues.gif" alt="Animated File Queues" /></p>
<p>可以看到，我们有一个文件名的队列，里面存储了所有训练数据的文件名，即训练数据的元数据。然后多个reader并行从队列中读取数据并交给后面的decoder进行解码和预处理。之后再将解码后的数据输入到另一个队列中作为我们的训练数据队列。</p>
<p>创建一个包含队列的图的代码模板如下(来自tensorflow官网)：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">example = ...ops to create one example...</span><br><span class="line"><span class="comment"># Create a queue, and an op that enqueues examples one at a time in the queue.</span></span><br><span class="line">queue = tf.RandomShuffleQueue(...)</span><br><span class="line">enqueue_op = queue.enqueue(example)</span><br><span class="line"><span class="comment"># Create a training graph that starts by dequeuing a batch of examples.</span></span><br><span class="line">inputs = queue.dequeue_many(batch_size)</span><br><span class="line">train_op = ...use <span class="string">&#x27;inputs&#x27;</span> to build the training part of the graph...</span><br></pre></td></tr></table></figure>
<p>运行此图的代码如下(来自tensorflow官网)：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create a queue runner that will run 4 threads in parallel to enqueue</span></span><br><span class="line"><span class="comment"># examples.</span></span><br><span class="line">qr = tf.train.QueueRunner(queue, [enqueue_op] * <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Launch the graph.</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line"><span class="comment"># Create a coordinator, launch the queue runner threads.</span></span><br><span class="line">coord = tf.train.Coordinator()</span><br><span class="line">enqueue_threads = qr.create_threads(sess, coord=coord, start=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># Run the training loop, controlling termination with the coordinator.</span></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> xrange(<span class="number">1000000</span>):</span><br><span class="line">    <span class="keyword">if</span> coord.should_stop():</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    sess.run(train_op)</span><br><span class="line"><span class="comment"># When done, ask the threads to stop.</span></span><br><span class="line">coord.request_stop()</span><br><span class="line"><span class="comment"># And wait for them to actually do it.</span></span><br><span class="line">coord.join(enqueue_threads)</span><br></pre></td></tr></table></figure>
<h3 id="分离训练和验证过程"><a class="markdownIt-Anchor" href="#分离训练和验证过程"></a> 分离训练和验证过程</h3>
<p>第二个我们要一起来看的问题的是关于验证过程的。一般而言，在训练的同时，我们会想要同时验证模型的训练效果，以便知道模型的性能变化情况。但如果把验证过程和训练过程放到一张图里面进行运行，通常会导致训练的中断和训练时间延长。</p>
<p>一个基本的思路就是，我们能不能让验证过程在单独的进程里面运行，这样就不会影响模型的训练过程了。为实现这一想法，我们可以考虑使用tensorflow提供的saver将模型定期保存到磁盘中，然后运行另一个进程来读取最新的模型进行模型验证。如果你只有一台机器来运行机器学习模型，独立进程的模式可以让我们把模型的训练过程放到gpu上运行，将验证过程放到cpu上运行，这样就可以最大化机器使用了。如果你有更多的机器，你甚至可以将验证过程和训练过程运行在不同的机器上面。</p>
<p><img data-src="/attaches/2017/2017-01-16-dl-workshop-massive-network-tips/training-validating-in-different-process.png" alt="training validating in different process" /></p>
<h3 id="分布式执行"><a class="markdownIt-Anchor" href="#分布式执行"></a> 分布式执行</h3>
<p>在训练大规模网络的时候，一个有效提高效率的办法就是分布式执行。在tensorflow中是如何支持分布式执行的呢？</p>
<p><img data-src="/attaches/2017/2017-01-16-dl-workshop-massive-network-tips/distributed-execution.png" alt="distributed execution" /></p>
<p>上图可以看出使用tensorflow的分布式模型是按照server进行组织的。tensorflow分布式模型中有几个概念比较重要。</p>
<ul>
<li>Server: 一般server会运行在一个独立的服务器上作为一个进程提供服务</li>
<li>Worker Service: 一个Worker Service用于执行一个图的一部分</li>
<li>Master Service: 负责协调Worker Service</li>
<li>Task: 一个Task对应一个Server，属于某一个Job</li>
<li>Job: 由一组Task构成，用于提供一些公共的服务，如在图中的参数服务PS Job，以及无状态的Worker Job</li>
</ul>
<p>在构造一个集群环境时，我们需要先根据配置构造一个ClusterSpec对象，用于提供集群信息。然后新建一个Server对象，并根据当前的job的类型来决定做什么。如果是参数服务，就什么都不用做，如果是工作服务就构造一个图来执行。</p>
<p>示例代码如下（来自tensorflow官网）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Flags for defining the tf.train.ClusterSpec</span></span><br><span class="line">tf.app.flags.DEFINE_string(<span class="string">&quot;ps_hosts&quot;</span>, <span class="string">&quot;&quot;</span>,</span><br><span class="line">                           <span class="string">&quot;Comma-separated list of hostname:port pairs&quot;</span>)</span><br><span class="line">tf.app.flags.DEFINE_string(<span class="string">&quot;worker_hosts&quot;</span>, <span class="string">&quot;&quot;</span>,</span><br><span class="line">                           <span class="string">&quot;Comma-separated list of hostname:port pairs&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Flags for defining the tf.train.Server</span></span><br><span class="line">tf.app.flags.DEFINE_string(<span class="string">&quot;job_name&quot;</span>, <span class="string">&quot;&quot;</span>, <span class="string">&quot;One of &#x27;ps&#x27;, &#x27;worker&#x27;&quot;</span>)</span><br><span class="line">tf.app.flags.DEFINE_integer(<span class="string">&quot;task_index&quot;</span>, <span class="number">0</span>, <span class="string">&quot;Index of task within the job&quot;</span>)</span><br><span class="line"></span><br><span class="line">FLAGS = tf.app.flags.FLAGS</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">_</span>):</span><br><span class="line">  ps_hosts = FLAGS.ps_hosts.split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">  worker_hosts = FLAGS.worker_hosts.split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Create a cluster from the parameter server and worker hosts.</span></span><br><span class="line">  cluster = tf.train.ClusterSpec(&#123;<span class="string">&quot;ps&quot;</span>: ps_hosts, <span class="string">&quot;worker&quot;</span>: worker_hosts&#125;)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Create and start a server for the local task.</span></span><br><span class="line">  server = tf.train.Server(cluster,</span><br><span class="line">                           job_name=FLAGS.job_name,</span><br><span class="line">                           task_index=FLAGS.task_index)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> FLAGS.job_name == <span class="string">&quot;ps&quot;</span>:</span><br><span class="line">    server.join()</span><br><span class="line">  <span class="keyword">elif</span> FLAGS.job_name == <span class="string">&quot;worker&quot;</span>:</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Assigns ops to the local worker by default.</span></span><br><span class="line">    <span class="keyword">with</span> tf.device(tf.train.replica_device_setter(</span><br><span class="line">        worker_device=<span class="string">&quot;/job:worker/task:%d&quot;</span> % FLAGS.task_index,</span><br><span class="line">        cluster=cluster)):</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Build model...</span></span><br><span class="line">      loss = ...</span><br><span class="line">      global_step = tf.Variable(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">      train_op = tf.train.AdagradOptimizer(<span class="number">0.01</span>).minimize(</span><br><span class="line">          loss, global_step=global_step)</span><br><span class="line"></span><br><span class="line">      saver = tf.train.Saver()</span><br><span class="line">      summary_op = tf.summary.merge_all()</span><br><span class="line">      init_op = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create a &quot;supervisor&quot;, which oversees the training process.</span></span><br><span class="line">    sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == <span class="number">0</span>),</span><br><span class="line">                             logdir=<span class="string">&quot;/tmp/train_logs&quot;</span>,</span><br><span class="line">                             init_op=init_op,</span><br><span class="line">                             summary_op=summary_op,</span><br><span class="line">                             saver=saver,</span><br><span class="line">                             global_step=global_step,</span><br><span class="line">                             save_model_secs=<span class="number">600</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># The supervisor takes care of session initialization, restoring from</span></span><br><span class="line">    <span class="comment"># a checkpoint, and closing when done or an error occurs.</span></span><br><span class="line">    <span class="keyword">with</span> sv.managed_session(server.target) <span class="keyword">as</span> sess:</span><br><span class="line">      <span class="comment"># Loop until the supervisor shuts down or 1000000 steps have completed.</span></span><br><span class="line">      step = <span class="number">0</span></span><br><span class="line">      <span class="keyword">while</span> <span class="keyword">not</span> sv.should_stop() <span class="keyword">and</span> step &lt; <span class="number">1000000</span>:</span><br><span class="line">        <span class="comment"># Run a training step asynchronously.</span></span><br><span class="line">        <span class="comment"># See `tf.train.SyncReplicasOptimizer` for additional details on how to</span></span><br><span class="line">        <span class="comment"># perform *synchronous* training.</span></span><br><span class="line">        _, step = sess.run([train_op, global_step])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Ask for all the services to stop.</span></span><br><span class="line">    sv.stop()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">  tf.app.run()</span><br></pre></td></tr></table></figure>
<h3 id="使用现成的模型"><a class="markdownIt-Anchor" href="#使用现成的模型"></a> 使用现成的模型</h3>
<p>在开发机器学习的模型时，另一个有意思的问题是，我们能否基于已有的已经表现比较好的模型进行训练呢？如果可以，那么这样的办法将能非常有效的缩短训练时间，并提升模型效果。事实上这也是可以实现的，但是有一些条件。</p>
<p><img data-src="/attaches/2017/2017-01-16-dl-workshop-massive-network-tips/pre-trained-model.png" alt="pre-trained model" /></p>
<p>由于模型存储时，实际上存储的是模型的所有参数，既然如此，想要在已有的模型上面训练，我们就必须把模型的一部分实现为跟原来模型的一部分是一样的，否则将无法使用这些参数。</p>
<p>下面我们来看一个例子，<a href="https://github.com/tensorflow/models/tree/master/im2txt">这个例子</a>来自于tensorflow的models项目，是基于论文【Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge】实现的。这个模型可以根据图片来生成标题。这个模型的训练就是使用现成的模型来进行的。它的模型图如下：</p>
<p><img data-src="/attaches/2017/2017-01-16-dl-workshop-massive-network-tips/show-and-tell-model.png" alt="show and tell model" /></p>
<p>可以看到这个模型是基于Inception模型来实现的，它实际上是将Inception模型的输出层去掉，然后将模型的输出作为一个RNN模型的输入来构造计算图的。这个模型在训练的时候会读取已经训练好的Inception模型进行二次训练：</p>
<p><img data-src="/attaches/2017/2017-01-16-dl-workshop-massive-network-tips/show-and-tell-model-pre-trained.png" alt="show and tell model with pre-trained inception model" /></p>
<h3 id="数据可视化"><a class="markdownIt-Anchor" href="#数据可视化"></a> 数据可视化</h3>
<p>在设计和训练机器学习模型的时候，我们会有一个运行时的计算图，还有很多的参数数据，如果只是从代码层面去分析，实在不够直观。Tensorflow提供给了我们一个非常易用而且友好的可视化工具Tensorboard。使用这个工具，我们只需要简单几行代码，便可以将数据做成图表展示出来。</p>
<p>比如我们想要展示我们的损失值的变化情况，我们只需要如下代码就可以实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">total_loss = ...</span><br><span class="line">tf.summary.scalar(<span class="string">&quot;loss/total_loss&quot;</span>, total_loss)</span><br></pre></td></tr></table></figure>
<p>这个时候，我们运行tensorboard并将logdir指向我们配置的数据输出目录，然后打开浏览器就可以看到tensorflow展示的数据了。上面的例子中，我们统计了loss变化情况，在tensorboard里面我们将能看到如下的图表：</p>
<p><img data-src="/attaches/2017/2017-01-16-dl-workshop-massive-network-tips/loss-summary.png" alt="loss summary" /></p>
<p>上面的例子可以用来展示数值型数据，如果我们想展示多维数据，如weight和bias数据，这个时候，我们可以借助tf.summary.histogram。如果我们需要统计所有的可训练的variable时：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> var <span class="keyword">in</span> tf.trainable_variables():</span><br><span class="line">    tf.summary.histogram(var.op.name, var)</span><br></pre></td></tr></table></figure>
<p>在加入这样几行代码之后，我们在tensorboard的histogram项目下看到如下所示的统计图表：</p>
<p><img data-src="/attaches/2017/2017-01-16-dl-workshop-massive-network-tips/histogram-summary.png" alt="histogram summary" /></p>
<p>同时tensorboard会自动绘制我们的运行时的计算图，请看下图中的例子：</p>
<p><img data-src="/attaches/2017/2017-01-16-dl-workshop-massive-network-tips/graph.png" alt="graph" /></p>
<p>在这个例子中，我们可以使用了tf.name_scope()来将一些逻辑内聚的子图封装到一个节点进行显示，如lenet节点，其内部是一个lenet的网络。同时图中各个节点之间的连线粗细即表示节点直接的数据量大小。通过查看这个图可以很直观的看到我们运行时的计算图的结构，这将非常便于我们分析和展示我们设计的网络结构。</p>
<h3 id="测试和调试"><a class="markdownIt-Anchor" href="#测试和调试"></a> 测试和调试</h3>
<p>编写tensorflow的模型其实和写普通的代码没什么区别。那么问题来了，我们该怎么做测试呢，甚至是如何做TDD呢？</p>
<p>其实tensorflow已经提供给了我们不少方便测试的工具函数。在我们要做单元测试时，我们可以让我们的测试类继承至<code>tf.test.TestCase</code>，就可以使用<code>self.test_session</code>来方便的创建测试环境了。如以下代码所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SquareTest</span>(tf.test.TestCase):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">testSquare</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">with</span> self.test_session():</span><br><span class="line">            x = tf.square([<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">            self.assertAllEqual(x.<span class="built_in">eval</span>(), [<span class="number">4</span>, <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    tf.test.main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>tensorflow给我们提供的有用的测试辅助函数有(仅列举部分)：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">TestCase.assertAllClose(…)</span><br><span class="line">TestCase.assertAllEqual(…)</span><br><span class="line">TestCase.assertAlmostEqual(…)</span><br><span class="line">TestCase.assertArrayNear(…)</span><br><span class="line">TestCase.assertNDArrayNear(…)</span><br><span class="line">TestCase.assertNear(…)</span><br><span class="line">TestCase.assertShapeEqual(…)</span><br></pre></td></tr></table></figure>
<p>有了这些，我们就可以愉快的TDD了。</p>
<p>tensorflow的代码调试会有什么问题呢？</p>
<p>tensorflow的代码一般是分为两个过程，一是计算图的构建，二是计算图的运行。</p>
<p>计算图的构建过程很简单，就是执行普通的python代码，我们可以借住IDE提供给我们的调试工具来进行调试，可以打断点查看各个变量的值。</p>
<p>那么如何调试一个运行中的计算图呢？其实计算图的构建类似编写计算图的静态代码，而计算图的运行则类似代码真正执行的过程。一般而言，我们是无法中断tensorflow的计算图的执行，或者在某处断点调试的。那么，如果计算图运行时出现错误该怎么样来调试呢？其实也很简单，回想一下，我们没有IDE也没有gdb的时候是如何调试的–打log啊。对，就是log。tensorflow提供给我们一个特殊的函数<code>tf.Print</code>，我们可以传入一个tensor，和一些要打印的其他tensor，该函数会在计算图运行时打印消息，并返回这个tensor，这个tensor可以用于进行后续计算了。</p>
<p>示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dequeued_img = tf.image.decode_png( dequeued_record_string, channels)</span><br><span class="line">dequeued_img = tf.Print( dequeued_img, [tf.shape(dequeued_img)], <span class="string">&#x27;dequeued image: &#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>以上分享了六个tensorflow的技巧：队列及多线程、分离训练和验证过程、分布式执行、使用现成的模型、数据可视化、测试和调试。使用这些技巧可以给我们设计和调优tensorflow模型带来很多方便。</p>
]]></content>
      <categories>
        <category>machine-learning</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>AI</tag>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>识别门牌号的移动应用</title>
    <url>/2017/03/01/recognize-house-number/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>今天给大家分享一个tensorflow的机器学习应用实例。我们将能看到如何针对特定的问题设计网络结构、设计损失函数，应用一些技巧来简化和拆分问题。还将演示如何将模型导出并部署到Android上，可以让我们感受到tensorflow强大的跨平台特性。</p>
<h2 id="问题导入"><a class="markdownIt-Anchor" href="#问题导入"></a> 问题导入</h2>
<h3 id="提取门牌号进行地图标注"><a class="markdownIt-Anchor" href="#提取门牌号进行地图标注"></a> 提取门牌号进行地图标注</h3>
<p>先让我们来看看我们要解决的问题。这个问题的应用场景来源于地图应用，如果能在地图上标注门牌号信息，这样就可以通过文本搜索找到地图中对应的位置了，事实上google地图就是通过训练这样的机器学习模型来进行地图信息标注的。要解决这个问题，可以读取google街景中的照片数据，然后训练一个机器学习模型来提取门牌号信息。如下图所示，当我们可以识别图片中的门牌号&quot;42&quot;了，我们就可以在地图上面进行标注了。</p>
<span id="more"></span>
<p><img data-src="/attaches/2017/2017-03-01-recognize-house-number/image-to-map-data.png" alt="Image to map data" /></p>
<h3 id="svhn地图数据集"><a class="markdownIt-Anchor" href="#svhn地图数据集"></a> SVHN地图数据集</h3>
<p>对于这一问题，斯坦福大学曾在2011年的时候发表过一篇论文进行研究，而且他们还整理好了一个名为SVHN的数据集，也就是Street View House Numbers街景门牌号的数据集。下图展示了这个数据集中的一些示例图片：</p>
<p><img data-src="/attaches/2017/2017-03-01-recognize-house-number/svhn.png" alt="SVHN" /></p>
<p>观察这些图片我们可以发现它们有以下这些特征：</p>
<ul>
<li>门牌号由连续的纯数字构成</li>
<li>每个数字都有边框标记</li>
<li>数字有字体、颜色、大小的区别，甚至还有手写的数字</li>
<li>整体图片质量并不高，很多分辨率较低的图片，还有很多图片倾斜排列并有倒影</li>
</ul>
<p>但是作为人类，基本上我们还是可以很容易的识别图片中的数字的。</p>
<p>有了这个数据集，我们就可以从研究角度出发开始我们的工作，而不必花太多时间在训练数据准备上面了。</p>
<h3 id="目标应用"><a class="markdownIt-Anchor" href="#目标应用"></a> 目标应用</h3>
<p>我们的目标就是训练一个模型来提取门牌号，当我们的模型在svhn数据集上面表现达到较理想的水平之后，我们还会将这个模型导出并部署在Android手机上面以识别来自摄像头的数据。</p>
<p><img data-src="/attaches/2017/2017-03-01-recognize-house-number/android-numseq-recognizer.png" alt="Number Sequence Recognizer in Android" /></p>
<h2 id="方案"><a class="markdownIt-Anchor" href="#方案"></a> 方案</h2>
<p>在了解了问题之后，我们来看看如何解决这个问题。我们将看到卷积神经网络的应用和损失函数的设计技巧。</p>
<h3 id="分为1000000个类进行识别"><a class="markdownIt-Anchor" href="#分为1000000个类进行识别"></a> 分为1000000个类进行识别</h3>
<p>我们假定门牌号数字位数不超过5位，使得我们的问题得到一定程度的简化，实际上门牌号是很少超过5位数的。之前我们有一起解决过notMNIST的问题，训练了一个深度学习模型来识别印刷图片中的字母。它和这个问题有一定的相似性。从那个模型出发推广，一个简单而自然的想法是，我们能不能直接将不同的门牌号数字看做不同的类呢？如下图所示：</p>
<p><img data-src="/attaches/2017/2017-03-01-recognize-house-number/1000000classes.png" alt="100000 classes" /></p>
<p>这样，如果包含数据0，我们将有100000个类。当门牌号的位数不超过2位时，这样的想法是可行的，因为我们将只需要100个类，在计算上不会成为问题。但是如果我们的门牌号长度限制设置为5位时，这样的想法就不可行了，因为类实在太多了，相应的训练数据和训练时长都会大大的延长。试想，就算对每一个类只有100条训练数据，总的需要的训练数据也将达到一千万。而且这样的模型在扩展上也是个大问题，每增加一个数位，都将导致数据和计算规模扩大10倍。</p>
<h3 id="5个模型分别识别每一个位置上面的数据"><a class="markdownIt-Anchor" href="#5个模型分别识别每一个位置上面的数据"></a> 5个模型分别识别每一个位置上面的数据</h3>
<p>既然类太多不可行，我们能不能考虑训练多个模型呢，如果我们有5个模型分别识别每一个位置上面的数据，然后再整合起来不就可以识别门牌号了么？如下图：</p>
<p><img data-src="/attaches/2017/2017-03-01-recognize-house-number/5models.png" alt="5 models" /></p>
<p>这是一个好想法，分为5个模型进行分别识别有效的解决了扩展性的问题，而且对于每个模型，问题也简化为了对单个数字进行识别，这就跟mnist问题一样。但是这样的方案还不是完美的，它的缺点在于5个模型之间可以看到存在很多冗余，其实模型之间只是数字的位置不同而已，数字都是从0到9这10个数。这还导致了模型数量比较多，运算慢，导出的模型比较大。</p>
<h3 id="将5个模型合并为一个模型"><a class="markdownIt-Anchor" href="#将5个模型合并为一个模型"></a> 将5个模型合并为一个模型</h3>
<p>如何解决上面模型的冗余问题呢？我们知道模型之间只是数字的位置不同而已，数字的特征是完全一样的，那么我们的解决方案就是在模型之间共享基础特征数据。具体来说就是共享由卷积神经网络所提取的特征。<br />
这样的话，5个模型将可以合并为一个统一的模型，如下图：</p>
<p><img data-src="/attaches/2017/2017-03-01-recognize-house-number/one-model-instead-of-5.png" alt="1 model instead of 5" /></p>
<p>在这个合并后的模型中，我们首先使用卷积神经网络进行基础特征提取，然后将卷积神经网络的输出作为输入连接到各个模型的输出层。特别的，在这个图中，我们还增加了一个数字长度模型的输出，事实上不用这个输出也是可以的，我们只需要一个特殊的类表示当前位置没有数字就可以了。也就是每一个位置上的数字不再是0-9这10个类，而是0-10这11个类，其中当类为10时表示当前位置没有数字。也就是说门牌号23的标签将编码为[2,3,10,10,10]。</p>
<p>然而问题到这里还没有结束，我们还需要合适的损失函数才能完成我们的模型，有了损失函数我们就可以进行迭代训练了。这里的损失函数是什么呢，其实也很简单，我们只需要将总的损失定义为各个模型的损失之和就可以了：</p>
<p>总损失 = 长度损失 + 数字1损失 + 数字2损失 + 数字3损失 + 数字4损失 + 数字5损失</p>
<p>这样定义的损失，当我们在迭代训练时，模型就会尝试将总损失最小化，也即是将每一个模型的损失最小化，模型的正确率就会不断提高。这里每一个模型的损失我们可以直接使用前面用过的交叉熵损失函数来实现。</p>
<h2 id="代码演示"><a class="markdownIt-Anchor" href="#代码演示"></a> 代码演示</h2>
<p>在有了基本的方案之后，下一步就是实现这个方案了。我们将演示部分核心的代码，完整的代码将在最后提供一个链接，供大家线下进一步进行学习和研究。以下代码基于tensorflow的slim库来实现，slim封装了tensorflow的基础API而对外提供了一套更易用的API。使用slim，我们的模型定义及训练代码将会变得更干净整洁和易于理解。</p>
<h3 id="卷积层全连接层"><a class="markdownIt-Anchor" href="#卷积层全连接层"></a> 卷积层，全连接层</h3>
<p>以下是卷积层的代码：</p>
<p><img data-src="/attaches/2017/2017-03-01-recognize-house-number/cnn-layers.png" alt="CNN layers" /></p>
<p>可以看到我们共定义了7个卷积层，在前3个卷积层之后，我们还分别定义了3个池化层。卷积层以5x5的区域作为过滤器进行卷积计算，最终的输出会将输入的3个通道转化为192个通道作为输出。</p>
<p>以下是全连接层的代码：</p>
<p><img data-src="/attaches/2017/2017-03-01-recognize-house-number/fc-layers.png" alt="FC layers" /></p>
<p>全连接层通过一个接口暴露出来，使用时，只需要传入不同的输出类的数目就好了。</p>
<h3 id="网络定义损失函数定义"><a class="markdownIt-Anchor" href="#网络定义损失函数定义"></a> 网络定义，损失函数定义</h3>
<p>以下是网络定义代码：</p>
<p><img data-src="/attaches/2017/2017-03-01-recognize-house-number/model-definition.png" alt="Model Definition" /></p>
<p>可以看到，我们使用了前面定义好的卷积层函数来定义模型的卷积层，使用全连接层函数来定义输出层，在数字序列长度限制为5时，一共有6个输出层，即一个长度输出层，将输出5个类，5个数字输出层，每个输出11个类。</p>
<p>再来看看损失函数定义代码：</p>
<p><img data-src="/attaches/2017/2017-03-01-recognize-house-number/loss-definition.png" alt="Loss Definition" /></p>
<p>对每一个输出，我们都使用了交叉熵损失，然后总的损失，就是各个输出的损失之和。</p>
<p>在定义好模型和损失之后，我们就可以开始训练了。整个训练过程大概会在半小时左右，取决于迭代次数设置。</p>
<p>在模型训练好了之后，下一步就是导出模型并在Android应用中导入模型和运行识别过程了。以下代码展示了如何使用tensorflow导出模型：</p>
<p><img data-src="/attaches/2017/2017-03-01-recognize-house-number/export-model.png" alt="export model" /></p>
<p>导入模型到android：</p>
<p><img data-src="/attaches/2017/2017-03-01-recognize-house-number/load-model-android.png" alt="Load model in Android" /></p>
<p>在Android应用中运行识别过程：</p>
<p><img data-src="/attaches/2017/2017-03-01-recognize-house-number/run-inference-android.png" alt="Run Inference in Android" /></p>
<h2 id="实际应用"><a class="markdownIt-Anchor" href="#实际应用"></a> 实际应用</h2>
<p>接下来我们来看看在实践过程中的一些问题。</p>
<h3 id="训练结果"><a class="markdownIt-Anchor" href="#训练结果"></a> 训练结果</h3>
<p>在我们的实验中，在以batch_size大小为32，训练30000次迭代之后，总损失变化如下：</p>
<p><img data-src="/attaches/2017/2017-03-01-recognize-house-number/total-loss.png" alt="Total loss" /></p>
<p>在测试集上面的正确率可以达到91%，如果增加训练集和迭代次数，模型还可能表现更好。</p>
<h3 id="只训练边框bounding-box内的图像"><a class="markdownIt-Anchor" href="#只训练边框bounding-box内的图像"></a> 只训练边框（Bounding box）内的图像</h3>
<p>另一个在我们的实验中遇到的问题是，如果直接把原图作为输入，模型将很难收敛到一个较好的值，原因是有太多的噪声像素了。</p>
<p>取而代之，我们的模型实际上是在数字序列的边框内部进行训练的，我们在处理输入数据的时候，会根据边框数据进行图像切割，之后才会输入到模型。在边框内部进行训练，我们可以得到90%以上的正确率。在这里大家也可以看到这个模型的局限性。</p>
<h3 id="训练另一个模型提取矩形边框"><a class="markdownIt-Anchor" href="#训练另一个模型提取矩形边框"></a> 训练另一个模型，提取矩形边框</h3>
<p>为了解决上面提到的模型的局限性，我们可以训练另一个模型用于提取数字的边框。对于这个模型，我们可以同样使用卷积神经网络来实现。</p>
<p>对于每一个输入图像，我们可以定义我们的标签为四个值，即一个坐标点(top, left)和图像的宽高(width, height)。</p>
<p>那么损失函数怎么定义呢？我们可以简单的定义如下的损失函数：</p>
<pre><code>|top - top_| + |left - left_| + |width - width_| + |height - height_|
</code></pre>
<p>即每个标签值取差值的绝对值，然后相加起来就可以了。目前这个模型还没有达到一个理想的精度，大家可以线下基于现有代码进行优化。</p>
<h3 id="精度不够"><a class="markdownIt-Anchor" href="#精度不够"></a> 精度不够</h3>
<p>另一个问题是，当我们的模型精度不够时该如何处理？比如，我们上面的模型的正确率只有91%，而人类可以达到99%以上。这样的模型是不是不能在实际中应用呢？</p>
<p>当然不是，事实上，由于我们使用softmax函数作为模型的输出，我们可以得到一个概率分布，这个概率分布我们可以理解为模型的预测准确度。比如，如果我们选定的输出对应的概率值为0.3，虽然我们是得到了一个值，但是我们可以知道模型对于这个值不是很有信心。</p>
<p>在这样的情况下，我们就可以定义一个置信度阈值，只有当模型预测的输出的信心指数超过这个值，我们才认为是一个有效的预测。通过设置这样的阈值，我们可以把模型的正确率调整到99%以上。我们就可以基本上认为模型的预测都是正确的了。</p>
<p>在实际应用中，我们还可以将预测出的数据作为输入数据进行再训练，这样构成一个反馈循环，我们的模型表现就会越来越好。</p>
<h3 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h3>
<p><strong>内容：</strong></p>
<ul>
<li>问题：基于街景图片提取门牌号</li>
<li>方案：共享卷积层，针对性地设计损失函数</li>
<li>代码：定义及训练模型 导出到Android并用于识图</li>
<li>实际应用：设计模型提取边框 在边框内训练门牌号模型 限定置信度</li>
</ul>
<p>** 参考：**</p>
<ul>
<li>Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks</li>
<li><a href="https://github.com/tensorflow/models/tree/master/slim">https://github.com/tensorflow/models/tree/master/slim</a></li>
<li><a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android">https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android</a></li>
</ul>
]]></content>
      <categories>
        <category>machine-learning</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>AI</tag>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title>深入探索生成对抗网络（一）</title>
    <url>/2017/06/21/dive-into-gan/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>最近在研究生成对抗网络，也对内对外做过一些分享。这里把分享过的内容整理一下，如有不对的地方，欢迎留言指出。也欢迎大家留言交流。这里是关于生成对抗网络的第一部分。</p>
<h2 id="生成对抗网络介绍"><a class="markdownIt-Anchor" href="#生成对抗网络介绍"></a> 生成对抗网络介绍</h2>
<h3 id="什么是生成对抗网络"><a class="markdownIt-Anchor" href="#什么是生成对抗网络"></a> 什么是生成对抗网络？</h3>
<p>从这个名称来看，我们可以了解到，这个网络是用一种对抗方法去生成数据的。和其他的机器学习模型相比，生成对抗网络里面最炫酷的理念莫过于给机器学习引入了对抗。纵观地球上的生物们的成长和发展路线就会发现，物竞天择，适者生存，万物都是在不停的和其他事物对抗中成长和发展的。生成对抗网络就像我们玩下面的格斗游戏一样，我们的学习过程就是，不断找其他对手对抗，在对抗中积累经验，提升自己的技能。</p>
<p><img data-src="/attaches/2017/2017-06-21-dive-into-gan/fighting-game.png" alt="fighting game" /></p>
<span id="more"></span>
<p>生成对抗网络的英文是Generative Adversarial Nets(以下简称GAN)。它是生成模型的一种，生成模型就是用机器学习去生成我们想要的数据，数学化一点来讲，就是获取训练样本并训练一个模型，该模型能按照我们定义的目标数据分布去生成数据。其实我们应该已经接触过不少生成模型了。比如autoencoder自编码器，它的decoding部分其实就是一种生成模型，它是在生成原数据。又比如seq2seq序列到序列模型，其实也是生成另一个我们想要的序列。Neural style transfer的目标其实也是生成图片。</p>
<p>我们这里研究的生成对抗网络包括两个部分，一个是生成器（generator），一个是判别器（discriminator）。他们的目标分别是：</p>
<ul>
<li>Generator：生成看起来’自然’的图像，与训练数据分布尽可能一致</li>
<li>Discriminator：判断给定图像是否像是人为（机器）生成的</li>
</ul>
<p>可以看到这里生成器和判别器就是相互竞争的关系。后面会了解到他们是如何进行相互对抗学习的。</p>
<p>为什么说生成对抗网络很重要呢？因为生成对抗网络事实上是无监督学习的一种，无监督学习能大大的降低对数据的需求，从而降低我们的AI研究成本。Facebook的AI团队主管Yann LeCun曾经用蛋糕比喻过机器学习里面的各种算法：</p>
<blockquote>
<p>如果人工智能是一块蛋糕，那么强化学习是蛋糕上的一粒樱桃，监督学习是外面的一层糖霜，无监督学习则是蛋糕胚。<br />
目前我们只知道如何制作糖霜和樱桃，却不知如何制作蛋糕胚。</p>
</blockquote>
<p>从他的评价里面我们也可以看到当前在无监督学习领域的研究中，我们还有很长的路要走。同时他评价生成对抗网络为:</p>
<blockquote>
<p>对抗性网络是“20年来机器学习领域最酷的想法”。</p>
</blockquote>
<p>可以看到生成对抗网络是当前非常有前途的一种深度学习模型。</p>
<h3 id="生成对抗网络的历史及发展"><a class="markdownIt-Anchor" href="#生成对抗网络的历史及发展"></a> 生成对抗网络的历史及发展？</h3>
<p>生成对抗网络事实上是近几年才提出来，并得到大家的广泛关注的。当然，如今机器学习发展迅猛，短短几年之间，我们可以看到有很多很多优秀的相关研究论文发出来。下面的图里简要的列举了几篇比较有代表性的论文，从这里我们可以一窥生成对抗网络的历史及发展。</p>
<p><img data-src="/attaches/2017/2017-06-21-dive-into-gan/history.png" alt="GAN History" /></p>
<ul>
<li>2014年的时候，Ian J Goodfellow提交了一篇论文，描述了他们设计的生成对抗网络，生成对抗网络在这里第一次出现。</li>
<li>随后以Facebook AI团队为主，发表了一篇论文，描述了一种拉普拉斯金字塔结构的网络，对生成对抗网络做出了很多改进。并使得生成对抗网络可以生成更清晰的图像。</li>
<li>后来他们还发表了一篇名为DCGAN的论文，他们充分利用了卷积神经网络模型的研究成果，让GAN模型的训练更快更稳定，而且他们还深入研究了这个模型所学到的东西，并将他们可视化了出来。</li>
<li>再之后，去年年末的时候，以密歇根大学为主，他们研究了如何通过一句话来生成想要的图片。</li>
</ul>
<p>今年关于这个主题还有很多新的论文发出来，我们也可以看到很多相关的应用在不断出现在我们的眼前。总体上来讲，生成对抗这种思路是很有前景的，非常有希望能通过它来实现通用的人工智能。</p>
<h3 id="生成对抗网络应用"><a class="markdownIt-Anchor" href="#生成对抗网络应用"></a> 生成对抗网络应用</h3>
<p>那么生成对抗网络可以在哪些领域发挥作用呢？下图列举了部分可以应用的场景：</p>
<p><img data-src="/attaches/2017/2017-06-21-dive-into-gan/applications.png" alt="GAN Applications" /></p>
<p>生成对抗网络可以广泛应用于图像生成，图像超分辨率，交互式图像生成，图像到图像生成，图像编辑以及文本转图像中。当然还有很多很多场景都可以应用这个模型，大家可以持续关注它的发展。</p>
<p>下面是伯克利大学和Adobe公司一起研发的一个原型应用：</p>
<p><img data-src="/attaches/2017/2017-06-21-dive-into-gan/igan.gif" alt="Interactive GAN" /></p>
<p>可以看到，设计师只需要寥寥几笔就可以修改图像并生成自己想要的图片了。</p>
<h2 id="gan的提出及详解"><a class="markdownIt-Anchor" href="#gan的提出及详解"></a> GAN的提出及详解</h2>
<h3 id="gan的提出"><a class="markdownIt-Anchor" href="#gan的提出"></a> GAN的提出</h3>
<p>GAN最初是由以Ian J. Goodfellow为主的研究团队在2014年6月提出的，他们提交的论文名是《Generative Adversarial Nets》。Ian Goodfellow 之前在 Google Brain 项目工作过，后来又去OpenAI从事研究工作。他提交的论文为数众多，被引用次数也很多，在机器学习领域很有名气。在这篇论文里面他们提到，他们提出了一种新的生成模型，模型通过对抗进行学习，在这个模型里面会同时对两个模型进行训练。</p>
<p><img data-src="/attaches/2017/2017-06-21-dive-into-gan/ian-goodfellow.png" alt="Ian J. Goodfellow" /></p>
<h3 id="gan的结构"><a class="markdownIt-Anchor" href="#gan的结构"></a> GAN的结构</h3>
<p>他们在论文里面提到的结构如下：</p>
<p><img data-src="/attaches/2017/2017-06-21-dive-into-gan/gan-structure.png" alt="GAN Structure" /></p>
<p>观察这个结构，我们可以看到两个可微的函数G和D，他们就分别表示生成器和判别器网络。他这里的描述中直接用函数代替了网络，我们可以体会到，深度神经网络其实就是一个有输入和输出的函数而已。结构里面的x表示一个训练数据向量，比如可以是一张真实的照片。x输入D网络，D网络应该要输出1，表示输入数据是真实数据。Z表示一个噪声向量，随机生成。以Z作为输入，在经过G网络之后，将会得到和x向量相同大小的向量，这个向量在经过D网络之后输出0，这表示判别器应该识别其为生成的数据。</p>
<p>在训练过程中，G网络的目标是让D生成的数据趋近于1。这就是GAN的结构，我们可以看到生成器和判别器各司其职，又相互竞争，D想要区分出G生成的数据和真实的数据，而G网络的目标是不让G网络能区分出自己生成的数据是假数据。也就是G网络想要学习到真实数据的分布情况。</p>
<h3 id="log函数回顾"><a class="markdownIt-Anchor" href="#log函数回顾"></a> log函数回顾</h3>
<p>那么GAN网络的loss函数是什么呢？在看这个函数之前，我们先回顾一下log函数的曲线。下图中是以10为底的对数函数，其取值区间负无穷到正无穷的。log(x)单调递增，log(1-x)单调递减。在0-1的区间里面，他们的值域都是负无穷到0。</p>
<p><img data-src="/attaches/2017/2017-06-21-dive-into-gan/log-function.png" alt="Log Function" /></p>
<p>有了这些了解之后，我们下面看看GAN的损失函数。</p>
<h3 id="损失函数"><a class="markdownIt-Anchor" href="#损失函数"></a> 损失函数</h3>
<p><img data-src="/attaches/2017/2017-06-21-dive-into-gan/gan-loss.png" alt="GAN Loss" /></p>
<p>这个公式是GAN论文里面给出来的Loss函数公式，这个只是判别器网络的公式。这个公式包含两部分内容，前一部分表示真实数据在经过判别器之后的输出，然后应用log(x)函数。后一部分表示生成的数据在经过判别器之后的输出，然后应用log(1-x)函数。这里的目标是要优化我们的判别器，让这个公式取值越大越好，从这个角度来看，它并不是损失函数，称为价值函数可能更合适，但是为了不引入更多的术语，我们还是称为损失函数吧。如何才能越大呢，由前面分析过的log函数曲线，我们知道，当D(x)尽量大，同时D(G(x))尽量小的时候，值就越大。这也就是公式前面有一个min(G)和max(D)的原因。</p>
<p>生成器网络的损失函数是什么呢，其实就是上面公司的后半部分了。不过对生成器而言，它的目标是要让后半部分公式的值越小越好。也就是说它的目标是让判别器识别它生成的图片为真实的图片。</p>
<p>那么我们的模型会在什么时候收敛呢？论文里面给出了很长的很细致的证明，这里就略过，有兴趣的可能直接看原文。下图给出了当这个函数收敛的时候相关参数的值。</p>
<p><img data-src="/attaches/2017/2017-06-21-dive-into-gan/converge-status.png" alt="Converge status" /></p>
<p>可以看到，模型会在p(g)与p(data)相等的时候收敛，这个时候D(G(x))的值为1/2。这意味着生成器生成的数据和我们训练的数据在分布上是一致的，同时，判别器已经无法判别到底是生成的数据还是真实数据了。</p>
<h3 id="算法"><a class="markdownIt-Anchor" href="#算法"></a> 算法</h3>
<p>论文里面给出的训练算法如下：</p>
<p><img data-src="/attaches/2017/2017-06-21-dive-into-gan/gan-algorithm.png" alt="GAN Algorithm" /></p>
<p>可以看到我们需要先训练判别器，训练的batch次数为k，k是模型的超参数，我们可以根据模型的训练效果进行调整。训练判别器时，我们需要同时有真实数据m和噪声向量z，然后根据损失函数公式求偏导来更新模型参数。需要注意的是，这里是使用梯度上升来更新模型参数的。因为我们的目标是要让这个函数取值趋近于更大。但是在具体实现过程中，更方便的方式是再应用一个递减的函数变换，让它变成真正的损失函数。</p>
<p>在对判别器训练k步之后，我们再开始训练生成器，训练生成器的时候，这里我们的目标是让损失函数趋近于更小，所以使用梯度下降。</p>
<p>这里还需要注意的是，在训练判别器的时候，我们会只更新判别器的权重，而不更新生成器的权重。在训练生成器的时候则相反，只更新生成器的参数。</p>
<h3 id="loss函数的实现"><a class="markdownIt-Anchor" href="#loss函数的实现"></a> loss函数的实现</h3>
<p>loss函数该怎么实现呢？我们事实上可以利用更通用的损失函数来实现，因为这里是二分类，所以我们可以使用sigmoid_cross_entrophy来实现。具体实现如下：</p>
<p><img data-src="/attaches/2017/2017-06-21-dive-into-gan/loss-implementation.png" alt="Loss implementation" /></p>
<p>我们还是按照两部分来构造损失函数。第一部分是真实数据的判别结果，它的label应该为1。第二部分是生成数据的判别结果，它的label应该为0。</p>
<p>相应的生成器的损失函数可以实现如下：</p>
<p><img data-src="/attaches/2017/2017-06-21-dive-into-gan/loss-implementation-generator.png" alt="Generator Loss Implementation" /></p>
<p>需要注意的是，由于生成器的目标是让判别器的结果为1，所以这里我们的label就为1。这是和判别器的损失函数的不同之处。</p>
<h3 id="gan生成的图像"><a class="markdownIt-Anchor" href="#gan生成的图像"></a> GAN生成的图像</h3>
<p>GAN生成的图像效果如下：</p>
<p><img data-src="/attaches/2017/2017-06-21-dive-into-gan/gan-generated-images.png" alt="Generated images" /></p>
<p>其中用黄色框框起来的是真实数据，也就是 Ground Truth 。可以看到GAN在面对简单的mnist手写数字和TFD人脸图像生成的时候，表现比较好，但是在复杂的图像上面生成的图像则比较模糊。</p>
<p>到这里我们的模型介绍就结束了。后面将会开始演示如何实现一个简单的GAN来生成手写数字。</p>
<h2 id="tensorflow的api介绍"><a class="markdownIt-Anchor" href="#tensorflow的api介绍"></a> TensorFlow的API介绍</h2>
<h3 id="tensorflow-api浏览"><a class="markdownIt-Anchor" href="#tensorflow-api浏览"></a> TensorFlow API浏览</h3>
<p>打开tensorflow的官方网站可以看到，tensorflow的模块很多，关于图像处理的，关于算法的，关于视频处理的，关于统计学的等等。这里提几点我观察到的tensorflow的API变化情况：</p>
<ul>
<li>高级API在逐步的稳定：在tf.train包里面逐渐多了 Supervisor SessionRunHook 等这样的高级训练过程管理的类</li>
<li>稳定的API会慢慢从contrib移到tensorflow支持的顶级包下面去：在tf.layers包之前是没有的，现在已经增加起来了，而且阅读里面增加的API可以发现，其实就是之前的tf.contrib.layers包下面的内容</li>
<li>在contrib中引入了keras：keras是基本上完全按照面向对象的方式设计的一套深度学习API，API易于理解和使用，人气很高，tensorflow也是希望直接支持keras作为其高级API</li>
<li>调试及性能优化的功能逐渐完善：tensorflow引入了Debug支持，JIT和AOT支持等</li>
</ul>
<h3 id="tensorflow-api设计"><a class="markdownIt-Anchor" href="#tensorflow-api设计"></a> TensorFlow API设计</h3>
<p>观察tensorflow的API可以发现，它的API设计其实是函数式和面向对象相结合的。tensorflow大部分算法相关的API直接设计成函数，而功能相关的API则设计成面向对象的，比如Queue还有SummaryWriter这样的类。</p>
<p>对于TensorFlow的高级API，其实从易用性上来讲，是需要倾向于面向对象的。我们可以发现tensorflow的高级API有下面这些特点：</p>
<ul>
<li>以函数式的方式提供出来，然而因为函数式的方式难以去管理大量的状态，所以我们看到了大量的全局状态，具体表现就是<code>tf.get_collection</code>接口，这个接口的一个参数是<code>key</code>，也就是说通过很多的<code>key</code>去获取状态。</li>
<li>以面向对象实现，但是对外提供函数式的API，如tf.layers里面的API</li>
<li>面向对象的API不够完整，比如有Layer的设计，但并没有Layer容器</li>
<li>有些API直接就是函数式和面向对象的综合，看起来有些蹩脚，比如Esimator类，它的第一个参数是一个函数<code>model_fn</code>，让调用者传入一个用于构造模型的函数。</li>
</ul>
<p>基于此，我个人建议在使用tensorflow的API的时候，可以考虑以下几点：</p>
<ul>
<li>
<p>使用TensorFlow的API</p>
<ul>
<li>使用函数式接口</li>
<li>优先使用非contrib包的API</li>
<li>自己进行面向对象封装</li>
</ul>
</li>
<li>
<p>使用Keras的API</p>
<ul>
<li>更加纯粹的面向对象API</li>
</ul>
</li>
</ul>
<h3 id="我们要用到的api"><a class="markdownIt-Anchor" href="#我们要用到的api"></a> 我们要用到的API</h3>
<p>在我们的代码里面我们主要使用到了这几个模块的API</p>
<ul>
<li>tf.layers</li>
<li>tf.contrib.layers</li>
<li>Training API</li>
<li>summary API</li>
</ul>
<h2 id="gan的实现"><a class="markdownIt-Anchor" href="#gan的实现"></a> GAN的实现</h2>
<p>这里的代码实现是用TDD的方式实现的。TDD可以帮我们理清需求，提供快速的反馈，帮助我们更有效率的去做正确的事情。TDD的好处多多，这里就不多讲了，有兴趣的可以参阅其他资料。</p>
<p>在开始之前，我们假设我们有一个<code>model.py</code>这样的模块用来存放我们的模型代码。对于这个模块，我们的测试模块就是<code>model_test.py</code>。从测试入手来分析，我们应该需要一个<code>GANModel</code>模型类来辅助我们构建好我们的GAN模型。从前面的分析来看，<code>GANModel</code>需要有一个<code>generated_image</code>这样的输出，表示生成器模型的输出。到此，我们就可以建立我们的第一个测试来验证我们的模型可以将生成器模型给构建出来。</p>
<p>我们可以编写代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GANModelTest</span>(tf.test.TestCase):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_generate</span>(<span class="params">self</span>):</span><br><span class="line">        model = GANModel(noise_len=<span class="number">100</span>)</span><br><span class="line">        <span class="keyword">with</span> self.test_session() <span class="keyword">as</span> session:</span><br><span class="line">            session.run(tf.global_variables_initializer())</span><br><span class="line">            noise = np.random.normal(size=(<span class="number">1</span>, <span class="number">100</span>))</span><br><span class="line">            generated = session.run(model.generated_image, feed_dict=&#123;model.noise_input: noise&#125;)</span><br><span class="line">            self.assertTupleEqual(generated.shape, (<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>此时代码肯定是没法运行的，因为我们还没有<code>GANModel</code>这个类呢，我们在<code>model.py</code>模块里面建立这个类，并尝试使用转置卷积设计一个模型，实现代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_build_generator</span>(<span class="params">input_data, name=<span class="string">&#x27;generator&#x27;</span></span>):</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(name):</span><br><span class="line">        net = layers.dense(input_data, <span class="number">128</span>)</span><br><span class="line">        net = tf.nn.relu(net)</span><br><span class="line">        net = tf.reshape(net, [-<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">8</span>])</span><br><span class="line">        net = layers.conv2d_transpose(net, <span class="number">128</span>, [<span class="number">5</span>, <span class="number">5</span>], activation=tf.nn.relu, strides=[<span class="number">2</span>, <span class="number">2</span>], padding=<span class="string">&#x27;same&#x27;</span>)  <span class="comment"># 8x8</span></span><br><span class="line">        net = layers.conv2d_transpose(net, <span class="number">64</span>, [<span class="number">5</span>, <span class="number">5</span>], activation=tf.nn.relu, strides=[<span class="number">2</span>, <span class="number">2</span>])  <span class="comment"># 19x19</span></span><br><span class="line">        net = layers.conv2d_transpose(net, <span class="number">32</span>, [<span class="number">5</span>, <span class="number">5</span>], activation=tf.nn.relu)  <span class="comment"># 23x23</span></span><br><span class="line">        net = layers.conv2d_transpose(net, <span class="number">16</span>, [<span class="number">5</span>, <span class="number">5</span>], activation=tf.nn.relu)  <span class="comment"># 27x27</span></span><br><span class="line">        net = layers.conv2d_transpose(net, <span class="number">1</span>, [<span class="number">2</span>, <span class="number">2</span>], activation=tf.nn.relu)  <span class="comment"># 28x28</span></span><br><span class="line">    <span class="keyword">return</span> net</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GANModel</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, noise_len=<span class="number">100</span></span>):</span><br><span class="line">        self.noise_len = noise_len</span><br><span class="line"></span><br><span class="line">        self.noise_input = tf.placeholder(tf.float32, shape=(<span class="literal">None</span>, self.noise_len))</span><br><span class="line">        self.generated_image = _build_generator(self.noise_input)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>到此，我们可以运行一下我们的测试看看，是否实现了这个功能。在经历一番调试之后，大家应该都可以顺利让测试通过，因为现在的逻辑都还比较简单。</p>
<p>第二步就是实现我们的判别器，判别器分为两个部分，真实数据为输入和生成的数据为输入。先来看真实数据作为输入的情况。编写测试代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test_discriminate_real</span>(<span class="params">self</span>):</span><br><span class="line">    model = GANModel()</span><br><span class="line">    images = np.random.normal(size=(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">with</span> self.test_session() <span class="keyword">as</span> session:</span><br><span class="line">        session.run(tf.global_variables_initializer())</span><br><span class="line">        discriminate_logits = session.run(model.discriminated_real_logits, feed_dict=&#123;</span><br><span class="line">            model.discriminator_input: images</span><br><span class="line">        &#125;)</span><br><span class="line">        self.assertTupleEqual(discriminate_logits.shape, (<span class="number">1</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>在设计好我们的判别器模型之后，我们可以得到程序代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_build_discriminator</span>(<span class="params">input_data, reuse_variables=<span class="literal">False</span>, name=<span class="string">&#x27;discriminator&#x27;</span></span>):</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(name, reuse=reuse_variables):</span><br><span class="line">        net = layers.conv2d(input_data, <span class="number">16</span>, [<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">2</span>, <span class="number">2</span>], activation=tf.nn.relu, padding=<span class="string">&#x27;same&#x27;</span>, name=<span class="string">&#x27;conv2d_1&#x27;</span>)</span><br><span class="line">        net = layers.conv2d(net, <span class="number">32</span>, [<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">2</span>, <span class="number">2</span>], activation=tf.nn.relu, padding=<span class="string">&#x27;same&#x27;</span>, name=<span class="string">&#x27;conv2d_2&#x27;</span>)</span><br><span class="line">        net = layers.conv2d(net, <span class="number">64</span>, [<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">2</span>, <span class="number">2</span>], activation=tf.nn.relu, padding=<span class="string">&#x27;same&#x27;</span>, name=<span class="string">&#x27;conv2d_3&#x27;</span>)</span><br><span class="line">        net = layers.conv2d(net, <span class="number">128</span>, [<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">2</span>, <span class="number">2</span>], activation=tf.nn.relu, padding=<span class="string">&#x27;same&#x27;</span>, name=<span class="string">&#x27;conv2d_4&#x27;</span>)</span><br><span class="line">        net = contrib_layers.flatten(net)</span><br><span class="line">        net = layers.dense(net, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> net</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GANModel</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, noise_len=<span class="number">100</span></span>):</span><br><span class="line">        self.noise_len = noise_len</span><br><span class="line"></span><br><span class="line">        self.noise_input = tf.placeholder(tf.float32, shape=(<span class="literal">None</span>, self.noise_len))</span><br><span class="line">        self.generated_image = _build_generator(self.noise_input)</span><br><span class="line"></span><br><span class="line">        self.discriminator_input = tf.placeholder(tf.float32, shape=(<span class="literal">None</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))</span><br><span class="line">        self.discriminated_real_logits = _build_discriminator(self.discriminator_input)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>现在我们要支持对生成的数据进行判别了。测试代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test_discriminate_fake</span>(<span class="params">self</span>):</span><br><span class="line">    model = GANModel()</span><br><span class="line">    noise = np.random.normal(size=(<span class="number">1</span>, <span class="number">100</span>))</span><br><span class="line">    <span class="keyword">with</span> self.test_session() <span class="keyword">as</span> session:</span><br><span class="line">        session.run(tf.global_variables_initializer())</span><br><span class="line">        discriminate_logits = session.run(model.discriminated_fake_logits, feed_dict=&#123;</span><br><span class="line">            model.noise_input: noise</span><br><span class="line">        &#125;)</span><br><span class="line">        self.assertTupleEqual(discriminate_logits.shape, (<span class="number">1</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>复用我们之前<code>_build_discriminator</code>函数，我们需要在<code>GANModel</code>的构造器中添加代码。这里需要注意的是，由于这里的模型需要复用之前为判别器创建的变量，所以我们传入一个<code>reuse_variables</code>为<code>True</code>，如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GANModel</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, noise_len=<span class="number">100</span>, learning_rate=<span class="number">0.0002</span></span>):</span><br><span class="line">        ...</span><br><span class="line">        self.discriminated_fake_logits = _build_discriminator(</span><br><span class="line">            self.generated_image, reuse_variables=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>这个时候上面的测试应该也可以通过了。</p>
<p>下面一个功能就是训练过程了。<code>GANModel</code>需要有一个函数来支持训练，我们将其命名为<code>fit</code>。为了灵活性，我们可以在外层来管理<code>session</code>，那么这个函数的输入参数需要有一个<code>session</code>。还有就是训练数据，我们可以想到的训练数据应该由这几个部分构成：</p>
<ul>
<li><code>images</code>: <code>mnist</code>图像数据</li>
<li><code>batch_size</code>: 批训练的数据量大小</li>
<li><code>noise</code>: 噪声数据，噪声数据作为输入传入这个函数让<code>fit</code>函数没有副作用</li>
</ul>
<p>这几个参数其实是紧密耦合的，似乎隐藏着一个概念，这里的概念其实就是我们的数据集。我们可以抽象一个数据集的类<code>GANDataset</code>出来。</p>
<p>由于我们训练过程通常还需要对同一个数据集训练多次，也就是<code>epoch</code>，于是我们还需要一个<code>epoch</code>的参数，当然其实也可以考虑将这个参数的管理封装到<code>GANDataset</code>类中。同时，我们还有一个超参数<code>k_steps</code>。思考到这里，我们就可以得到<code>fit</code>函数的签名了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, session, dataset, epochs, k_steps</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>对<code>fit</code>函数建立测试如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test_fit</span>(<span class="params">self</span>):</span><br><span class="line">    model = GANModel(<span class="number">100</span>)</span><br><span class="line">    dataset = GANDataset(np.random.normal(size=(<span class="number">3</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)), <span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">with</span> self.test_session() <span class="keyword">as</span> session:</span><br><span class="line">        session.run(tf.global_variables_initializer())</span><br><span class="line">        model.fit(session, dataset, <span class="number">1</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>由于这里<code>fit</code>函数没有输出，它的作用在与改变权重，对模型进行优化，所以，我们这里没有验证的代码。这里其实仅仅是验证了这个函数可以正常执行，不会抛出异常。虽然这里的测试是比较弱，但是依然可以给我们信心和指导，让我们写出正确的代码。</p>
<p><code>fit</code>函数的代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, session, dataset, epochs, k_steps</span>):</span><br><span class="line">    train_step = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        <span class="keyword">while</span> dataset.has_more_than(k_steps + <span class="number">1</span>):</span><br><span class="line">            train_step += <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(k_steps):</span><br><span class="line">                real_images, noise_input = dataset.next_batch(), dataset.next_noise()</span><br><span class="line">                session.run(self.d_optimizer, feed_dict=&#123;</span><br><span class="line">                    self.discriminator_input: real_images,</span><br><span class="line">                    self.noise_input: noise_input</span><br><span class="line">                &#125;)</span><br><span class="line">            noise_input = dataset.next_noise()</span><br><span class="line">            session.run(self.g_optimizer, feed_dict=&#123;</span><br><span class="line">                self.noise_input: noise_input</span><br><span class="line">            &#125;)</span><br><span class="line">        dataset.reset()</span><br></pre></td></tr></table></figure>
<p>在编写<code>fit</code>函数的时候，我们假想了一个<code>dataset</code>对象的存在，并且按照我们的需要设计了这个对象的方法。这虽然不是<code>TDD</code>，然而这里的思想也是源自于<code>TDD</code>，即从使用的角度去设计你的API。</p>
<p>写完这里的代码，<code>GANDataset</code>类的模型就自然而然出来了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GANDataset</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, images, noise_len, batch_size</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">has_more_than</span>(<span class="params">self, count</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">next_batch</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">next_noise</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>根据这里的定义，我们对<code>GANDataset</code>类建立测试如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GANDatasetTest</span>(tf.test.TestCase):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_dataset</span>(<span class="params">self</span>):</span><br><span class="line">        dataset = GANDataset(np.random.normal(size=(<span class="number">3</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)), <span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line">        self.assertEqual(dataset.next_batch().shape, (<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))</span><br><span class="line">        self.assertTrue(dataset.has_more_than(<span class="number">1</span>))</span><br><span class="line">        self.assertFalse(dataset.has_more_than(<span class="number">2</span>))</span><br><span class="line">        dataset.reset()</span><br><span class="line">        self.assertTrue(dataset.has_more_than(<span class="number">2</span>))</span><br></pre></td></tr></table></figure>
<p><code>GANDataset</code>类的实现代码在<a href="https://github.com/gmlove/leifeng_course/blob/master/week9/dataset.py">这里</a>。</p>
<p>这个时候，我们回到<code>fit</code>函数，事实上我们还没有实现我们的优化器呢。但是我们的优化器已经设计好了，名为<code>d_optimizer</code>和<code>g_optimizer</code>。在构造器里面添加代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GANModel</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, noise_len=<span class="number">100</span>, learning_rate=<span class="number">0.0002</span></span>):</span><br><span class="line">        ...</span><br><span class="line">        self.generator_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(</span><br><span class="line">            logits=self.discriminated_fake_logits, labels=tf.ones_like(self.discriminated_fake_logits)))</span><br><span class="line"></span><br><span class="line">        self.discriminator_real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(</span><br><span class="line">            logits=self.discriminated_real_logits, labels=tf.ones_like(self.discriminated_real_logits)))</span><br><span class="line">        self.discriminator_fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(</span><br><span class="line">            logits=self.discriminated_fake_logits, labels=tf.zeros_like(self.discriminated_fake_logits)))</span><br><span class="line"></span><br><span class="line">        self.discriminator_loss = self.discriminator_real_loss + self.discriminator_fake_loss</span><br><span class="line"></span><br><span class="line">        all_vars = tf.trainable_variables()</span><br><span class="line">        generator_vars = [var <span class="keyword">for</span> var <span class="keyword">in</span> all_vars <span class="keyword">if</span> <span class="string">&#x27;generator&#x27;</span> <span class="keyword">in</span> var.name]</span><br><span class="line">        discriminator_vars = [var <span class="keyword">for</span> var <span class="keyword">in</span> all_vars <span class="keyword">if</span> <span class="string">&#x27;discriminator&#x27;</span> <span class="keyword">in</span> var.name]</span><br><span class="line">        self.d_optimizer = tf.train.AdamOptimizer(learning_rate, beta1=<span class="number">0.5</span>).minimize(</span><br><span class="line">                self.discriminator_loss, var_list=discriminator_vars)</span><br><span class="line">        self.g_optimizer = tf.train.AdamOptimizer(learning_rate, beta1=<span class="number">0.5</span>).minimize(</span><br><span class="line">                self.generator_loss, var_list=generator_vars)</span><br></pre></td></tr></table></figure>
<p>loss函数实际上是不好验证其是否正确的，但是我们之前已经分析过loss函数该如何实现，这里的实现完全是我们分析之后得到的结果。虽然这里的测试不尽完美，但是我们已经有了一个基本的验证了。</p>
<p>到这里我们关于<code>fit</code>的测试应该就可以通过了。</p>
<p>到这里，我们要进行的下一步，测试就难以去支持我们的工作了。因为下一步是要调试我们的模型，看看它能不能按照我们预期的进行收敛。为了看到运行时我们的模型的情况，我们需要<code>tf.summary</code>模块的支持。我们将添加一些重要的指标，以便我们可以在 Tensor Board 上面可视化的进行实验。</p>
<p>在模型的构造器里面添加代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GANModel</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, noise_len=<span class="number">100</span>, learning_rate=<span class="number">0.0002</span></span>):</span><br><span class="line">        ...</span><br><span class="line">        tf.summary.scalar(<span class="string">&#x27;probabilities/p_generator&#x27;</span>, tf.reduce_mean(tf.nn.sigmoid(self.discriminated_fake_logits)))</span><br><span class="line">        tf.summary.scalar(<span class="string">&#x27;probabilities/p_discriminator&#x27;</span>, tf.reduce_mean(tf.nn.sigmoid(self.discriminated_real_logits)))</span><br><span class="line">        tf.summary.scalar(<span class="string">&#x27;loss/generator_loss&#x27;</span>, self.generator_loss)</span><br><span class="line">        tf.summary.scalar(<span class="string">&#x27;loss/discriminator_loss&#x27;</span>, self.discriminator_loss)</span><br><span class="line">        tf.summary.scalar(<span class="string">&#x27;loss/discriminator_real_loss&#x27;</span>, self.discriminator_real_loss)</span><br><span class="line">        tf.summary.scalar(<span class="string">&#x27;loss/discriminator_fake_loss&#x27;</span>, self.discriminator_fake_loss)</span><br><span class="line">        tf.summary.image(<span class="string">&#x27;generated_image&#x27;</span>, self.generated_image)</span><br><span class="line">        tf.summary.image(<span class="string">&#x27;real_image&#x27;</span>, self.discriminator_input)</span><br><span class="line">        self.summaries = tf.summary.merge_all()</span><br></pre></td></tr></table></figure>
<p>我们还需要在训练的过程中，在训练完一定的步数之后，记录这些汇总信息。我们的fit函数已经够复杂了，为了完成这样的需求，我们可以考虑使用定期回调的机制。我们定义一个<code>Callback</code>类如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Callback</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, every_step, func</span>):</span><br><span class="line">        self.every_step = every_step</span><br><span class="line">        self.func = func</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, dataset, current_step</span>):</span><br><span class="line">        self.func(dataset, current_step)</span><br></pre></td></tr></table></figure>
<p>接着可以实现我们的<code>SummaryCallback</code>和<code>LogCallback</code>如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SummaryCallback</span>(<span class="title class_ inherited__">Callback</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, session, model, data_dir=<span class="string">&#x27;./summary/train_tf-bn_fix-bn&#x27;</span>, every_step=<span class="number">10</span></span>):</span><br><span class="line">        summary_writer = tf.summary.FileWriter(data_dir, session.graph)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">func</span>(<span class="params">dataset, current_step</span>):</span><br><span class="line">            summaries = session.run(model.summaries, feed_dict=&#123;</span><br><span class="line">                model.noise_input: dataset.last_noise_batch,</span><br><span class="line">                model.discriminator_input: dataset.last_image_batch</span><br><span class="line">            &#125;)</span><br><span class="line">            summary_writer.add_summary(summaries, current_step)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__(every_step, func)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LogCallback</span>(<span class="title class_ inherited__">Callback</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, every_step=<span class="number">100</span></span>):</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">func</span>(<span class="params">dataset, current_step</span>):</span><br><span class="line">            tf.logging.info(<span class="string">&#x27;current step: %s&#x27;</span>, current_step)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__(every_step, func)</span><br></pre></td></tr></table></figure>
<p>接着在<code>fit</code>函数中添加相应的驱动代码就可以驱动我们的回调函数代码运行了。然后我们读取mnist数据集，建立一个<code>main</code>函数就可以完成我们的代码了。</p>
<p>在最后完整的代码里面还包含了<code>batch_normalization</code>，即批规范化，的使用。这是为了让模型能更快和更容易的收敛。</p>
<p>完整的实现代码请参考<a href="https://github.com/gmlove/leifeng_course/tree/master/week9">这里</a>。当然这里并不是一份非常完美的代码，我们可以进行进一步的重构，让其更易读，由于我们有测试代码帮我们保驾护航，我们将能更放心的进行重构，把代码重构到一个更完美的状态。这也是TDD带给我们的好处之一，代码写好了，测试也有了，重构更好做了，最终就有艺术品诞生了。</p>
<p>我们可以得到如下的实验结果：</p>
<p><img data-src="/attaches/2017/2017-06-21-dive-into-gan/tensor-board-loss.png" alt="Loss in Tensor Board" /></p>
<p><img data-src="/attaches/2017/2017-06-21-dive-into-gan/tensor-board-generated.png" alt="Generated image in Tensor Board" /></p>
<h3 id="gan总结"><a class="markdownIt-Anchor" href="#gan总结"></a> GAN总结</h3>
<p>观察上面的loss变化图，我们可以发现，这里的loss变化跟我们之前的模型不一样。就像论文里面的证明一样，这里的loss将会趋近于某一个值，而非0，<code>discriminator_real_loss</code>和<code>discriminator_fake_loss</code>将趋近于相等，同时<code>p_fake</code>和<code>p_real</code>应该要趋近于0.5。</p>
<p>这也从侧面反应了GAN模型的问题。关于GAN模型的不足，我们可以总结如下：</p>
<ul>
<li>复杂图像上表现不好：在MNIST、TFD人脸数据库上面表现不错，但是在更一般的CIFAR数据集上面生成的图像较模糊</li>
<li>难以平衡：判别器和生成器同时优化，判别器需要提前多走一步，但是又不能太多</li>
<li>训练不够稳定：有时候永远不会学到东西</li>
</ul>
<p>事实上，我们的模型能很快的收敛，这是因为我们使用了卷积神经网络里面的很多研究成果，比如批规范化的应用，比如池化层的去除等。GAN模型刚提出的时候，其训练是相对比较难的。</p>
<p>到这里，我们的第一部分就结束了，大家有任何问题，欢迎留言讨论！</p>
]]></content>
      <categories>
        <category>machine-learning</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>AI</tag>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
        <tag>GAN</tag>
        <tag>生成对抗网络</tag>
      </tags>
  </entry>
  <entry>
    <title>理解Conv2d及其梯度的计算过程</title>
    <url>/2017/04/15/understanding-gradients-of-conv2d-in-experiments/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>在当前深度学习领域中，卷积神经网络在图像处理、语音处理等方面都表现出了优异的性能，得到了广泛的认可。作为深度神经网络中的一个基础算法，有很多资料介绍了卷积实现原理，但是不少人在学习之后，还是对其及其梯度的计算过程细节不够清楚。在这里，我想分享几个自己做过的小试验来加深大家对卷积及其梯度计算过程的理解。</p>
<h2 id="卷积计算过程"><a class="markdownIt-Anchor" href="#卷积计算过程"></a> 卷积计算过程</h2>
<p>在卷积神经网络中，卷积计算过程可以通过下面的动图（来自<a href="https://docs.google.com/presentation/d/1TVixw6ItiZ8igjp6U17tcgoFrLSaHWQmMOwjlgQY9co/pub?slide=id.g1245051c73_0_2184">此处</a>）来理解：</p>
<span id="more"></span>
<p><img data-src="/attaches/2017/2017-04-15-understanding-gradients-of-conv2d-in-experiments/conv2d.gif" alt="conv2d" /></p>
<p>以上是对一个3通道输入图像进行卷积操作的过程，卷积核是一个[4,4,3]的3维矩阵。可以看到，当我们要计算卷积结果的某一层时，我们使用同一个卷积核在输入图像上面从左到右从上到下（图像的长和宽）依次滑动，每滑动到一个位置，我们就用卷积核和图像的对应部分数值计算点积（对应点数值相乘，然后再全部相加，即4<em>4</em>3次乘法和加法操作）得到输出层的对应点的值，然后随着滑动的进行，我们就得到这一层的卷积结果。</p>
<p>下面我们来看看具体的数值计算结果，为了简单起见，我们考虑输入图像为灰度图像（即单通道）的场景（来自<a href="http://deeplearning.net/software/theano_versions/dev/tutorial/conv_arithmetic.html#about-this-tutorial">此处</a>）：</p>
<p><img data-src="/attaches/2017/2017-04-15-understanding-gradients-of-conv2d-in-experiments/numerical_no_padding_no_strides.gif" alt="numerical no padding no strides" /></p>
<p>此例中的卷积核为：</p>
<p><img data-src="/attaches/2017/2017-04-15-understanding-gradients-of-conv2d-in-experiments/numerical_no_padding_no_strides_filter.png" alt="numerical no padding no strides filter" /></p>
<p>到此相信大家都已经了解卷积如何计算出来的了。我们使用tensorflow来证实一下上面的计算。以下是在iPython里面的运行结果：</p>
<p><img data-src="/attaches/2017/2017-04-15-understanding-gradients-of-conv2d-in-experiments/experiment_conv2d.png" alt="conv2d expement" /></p>
<p>可以看到输出的结果即上面动图的结果。</p>
<p>卷积过程中，还有padding和stride的概念，相对容易理解，这里就不赘述了。</p>
<h2 id="卷积的梯度计算"><a class="markdownIt-Anchor" href="#卷积的梯度计算"></a> 卷积的梯度计算</h2>
<p>了解了卷积的计算过程，我们不禁会想，卷积计算还是挺复杂的，要自己动手编程实现也并非易事。而且，由于结果矩阵的每一层是共享同一个卷积核的，在反向传播过程中，卷积核又是如何被更新的呢（即梯度是多少）？相信这个问题会困扰不少非科班出身进入机器学习领域的同学们。下面就让我们一起结合试验和源代码来揭示这一过程吧。</p>
<p>观察上面的计算过程，事实上，卷积计算可以转化为矩阵乘法来实现的。具体如下：</p>
<ol>
<li>把每一个卷积核都reshape为一个行向量，多个卷积核就形成了一个矩阵</li>
<li>从输入图像中提取patch（即每一次滑动时覆盖到的矩形框中的数据），然后将其reshape为一个列向量，每一滑动都有这样的一个列向量，这样就可以形成另一个矩阵</li>
<li>将步骤1和2中得到的矩阵进行矩阵乘法，就得到最终的结果</li>
</ol>
<p>以上面的单通道图像卷积计算为例，转换为矩阵乘法之后即计算如下乘法：</p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow><mo fence="true">(</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mi>T</mi></msup><mo>∗</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>12</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>12</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>17</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>10</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>17</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>19</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>9</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>6</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>14</mn></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">
\begin{pmatrix}
0 \\
1 \\
2 \\
2 \\
2 \\
0 \\
0 \\
1 \\
2
\end{pmatrix}^T * 
\begin{pmatrix}
3 &amp;3 &amp;2 &amp;0 &amp;0 &amp;1 &amp;3 &amp;1 &amp;2 \\
3 &amp;2 &amp;1 &amp;0 &amp;1 &amp;3 &amp;1 &amp;2 &amp;2 \\
2 &amp;1 &amp;0 &amp;1 &amp;3 &amp;1 &amp;2 &amp;2 &amp;3 \\
0 &amp;0 &amp;1 &amp;3 &amp;1 &amp;2 &amp;2 &amp;0 &amp;0 \\
0 &amp;1 &amp;3 &amp;1 &amp;2 &amp;2 &amp;0 &amp;0 &amp;2 \\
1 &amp;3 &amp;1 &amp;2 &amp;2 &amp;3 &amp;0 &amp;2 &amp;2 \\
3 &amp;1 &amp;2 &amp;2 &amp;0 &amp;0 &amp;2 &amp;0 &amp;0 \\
1 &amp;2 &amp;2 &amp;0 &amp;0 &amp;2 &amp;0 &amp;0 &amp;0 \\
2 &amp;2 &amp;3 &amp;0 &amp;2 &amp;2 &amp;0 &amp;0 &amp;1
\end{pmatrix} = 
\begin{pmatrix}
12 \\
12 \\
17 \\
10 \\
17 \\
19 \\
9 \\
6 \\
14
\end{pmatrix}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:11.031391000000003em;vertical-align:-5.150079999999999em;"></span><span class="minner"><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.650080000000003em;"><span style="top:1.3500599999999987em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎝</span></span></span><span style="top:0.20004999999999878em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-0.3949600000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-0.9899700000000017em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-1.5849800000000018em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-2.179990000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-2.7750000000000017em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-3.3700100000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-3.9650200000000013em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-4.560030000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-5.155040000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-5.750050000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-6.345060000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-6.410060000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-7.650080000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎛</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.150079999999999em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6499999999999995em;"><span style="top:-7.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-6.609999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-4.209999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.0099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-1.8099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-0.6099999999999983em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:0.590000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:1.7900000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.15em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.650080000000003em;"><span style="top:1.3500599999999987em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎠</span></span></span><span style="top:0.20004999999999878em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-0.3949600000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-0.9899700000000017em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-1.5849800000000018em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-2.179990000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-2.7750000000000017em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-3.3700100000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-3.9650200000000013em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-4.560030000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-5.155040000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-5.750050000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-6.345060000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-6.410060000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-7.650080000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎞</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.150079999999999em;"><span></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:5.881311000000003em;"><span style="top:-8.102980000000002em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:10.800160000000002em;vertical-align:-5.150079999999999em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.650080000000003em;"><span style="top:1.3500599999999987em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎝</span></span></span><span style="top:0.20004999999999878em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-0.3949600000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-0.9899700000000017em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-1.5849800000000018em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-2.179990000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-2.7750000000000017em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-3.3700100000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-3.9650200000000013em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-4.560030000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-5.155040000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-5.750050000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-6.345060000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-6.410060000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-7.650080000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎛</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.150079999999999em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6499999999999995em;"><span style="top:-7.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span><span style="top:-6.609999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-4.209999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.0099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.8099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-0.6099999999999983em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span><span style="top:0.590000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:1.7900000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6499999999999995em;"><span style="top:-7.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span><span style="top:-6.609999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-4.209999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.0099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-1.8099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span><span style="top:-0.6099999999999983em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:0.590000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:1.7900000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6499999999999995em;"><span style="top:-7.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-6.609999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-4.209999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-3.0099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span><span style="top:-1.8099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-0.6099999999999983em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:0.590000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:1.7900000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6499999999999995em;"><span style="top:-7.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-6.609999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-4.209999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span><span style="top:-3.0099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-1.8099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-0.6099999999999983em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:0.590000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:1.7900000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6499999999999995em;"><span style="top:-7.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-6.609999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span><span style="top:-4.209999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-3.0099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-1.8099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-0.6099999999999983em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:0.590000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:1.7900000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6499999999999995em;"><span style="top:-7.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-6.609999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-4.209999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.0099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-1.8099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span><span style="top:-0.6099999999999983em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:0.590000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:1.7900000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6499999999999995em;"><span style="top:-7.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span><span style="top:-6.609999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-4.209999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.0099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.8099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-0.6099999999999983em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:0.590000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:1.7900000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6499999999999995em;"><span style="top:-7.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-6.609999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-4.209999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.0099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.8099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-0.6099999999999983em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:0.590000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:1.7900000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6499999999999995em;"><span style="top:-7.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-6.609999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span><span style="top:-4.209999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.0099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-1.8099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-0.6099999999999983em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:0.590000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:1.7900000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.15em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.650080000000003em;"><span style="top:1.3500599999999987em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎠</span></span></span><span style="top:0.20004999999999878em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-0.3949600000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-0.9899700000000017em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-1.5849800000000018em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-2.179990000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-2.7750000000000017em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-3.3700100000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-3.9650200000000013em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-4.560030000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-5.155040000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-5.750050000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-6.345060000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-6.410060000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-7.650080000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎞</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.150079999999999em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:10.800160000000002em;vertical-align:-5.150079999999999em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.650080000000003em;"><span style="top:1.3500599999999987em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎝</span></span></span><span style="top:0.20004999999999878em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-0.3949600000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-0.9899700000000017em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-1.5849800000000018em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-2.179990000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-2.7750000000000017em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-3.3700100000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-3.9650200000000013em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-4.560030000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-5.155040000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-5.750050000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-6.345060000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-6.410060000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-7.650080000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎛</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.150079999999999em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6499999999999995em;"><span style="top:-7.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">2</span></span></span><span style="top:-6.609999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">2</span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">7</span></span></span><span style="top:-4.209999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">0</span></span></span><span style="top:-3.0099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">7</span></span></span><span style="top:-1.8099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">9</span></span></span><span style="top:-0.6099999999999983em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">9</span></span></span><span style="top:0.590000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">6</span></span></span><span style="top:1.7900000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.15em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.650080000000003em;"><span style="top:1.3500599999999987em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎠</span></span></span><span style="top:0.20004999999999878em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-0.3949600000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-0.9899700000000017em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-1.5849800000000018em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-2.179990000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-2.7750000000000017em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-3.3700100000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-3.9650200000000013em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-4.560030000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-5.155040000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-5.750050000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-6.345060000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-6.410060000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-7.650080000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎞</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.150079999999999em;"><span></span></span></span></span></span></span></span></span></span></span>
<p>tensorflow内部实现实际上就是如此，见<a href="https://github.com/tensorflow/tensorflow/blob/master/third_party/eigen3/unsupported/Eigen/CXX11/src/NeuralNetworks/SpatialConvolutions.h#L768">如下代码(摘录核心部分)</a>：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">DSizes&lt;TensorIndex, <span class="number">2</span>&gt; kernel_dims;</span><br><span class="line">kernel_dims[<span class="number">0</span>] = kernelChannels * kernelRows * kernelCols;</span><br><span class="line">kernel_dims[<span class="number">1</span>] = kernelFilters;</span><br><span class="line">kernel.<span class="built_in">reshape</span>(kernel_dims).<span class="built_in">contract</span>(</span><br><span class="line">    input.<span class="built_in">extract_image_patches</span>(kernelRows, kernelCols, stride, stride,</span><br><span class="line">            in_stride, in_stride, padding_type)</span><br><span class="line">        .<span class="built_in">reshape</span>(pre_contract_dims),</span><br><span class="line">    contract_dims).<span class="built_in">reshape</span>(post_contract_dims)</span><br></pre></td></tr></table></figure>
<p>了解到这一层，大家就应该知道了，卷积的计算实际上跟简单感知机的计算本质上是一致的。由此我们可以得出的结论是其梯度计算也是类似的。</p>
<p>我们先回顾一下感知机中的梯度计算，在iPython中进行如下试验：</p>
<p><img data-src="/attaches/2017/2017-04-15-understanding-gradients-of-conv2d-in-experiments/experiment_linear_gradient.png" alt="linear gradient experiment" /></p>
<p>与导数计算一致，可以看到c相对于a的梯度其实就是b矩阵的值。如果b的维度为[2, 2]，那么结果是多少呢？</p>
<p><img data-src="/attaches/2017/2017-04-15-understanding-gradients-of-conv2d-in-experiments/experiment_linear_gradient_1.png" alt="linear gradient experiment 1" /></p>
<p>可以看到此时a得到的梯度为叠加b矩阵对应位置的值。到这里，大家应该已经了解了，在进行反向传播时，卷积核的更新梯度实际上就是图片对应位置的值相加。当然这里没有考虑激活函数的影响，当有激活函数时，梯度会经过链式方式传导到卷积核上。</p>
<p>我们来验证一下，求上面的卷积核梯度：</p>
<p><img data-src="/attaches/2017/2017-04-15-understanding-gradients-of-conv2d-in-experiments/experiment_conv_gradient.png" alt="convolution gradient experiment" /></p>
<p>即：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">filter_weights[0, 0, 0] = sum([3,3,2, 0,0,1, 3,1,2]) = 15</span><br><span class="line">filter_weights[0, 1, 0] = sum([3,1,1, 0,1,3, 1,2,2]) = 15</span><br></pre></td></tr></table></figure>
<h2 id="反卷积转置卷积计算"><a class="markdownIt-Anchor" href="#反卷积转置卷积计算"></a> 反卷积（转置卷积）计算</h2>
<p>卷积过程将图像映射到feature map，同时我们也会要用到将feature map映射到图像的问题。比如在autoencoder网络中，我们要将编码之后的数据反编码回来，还比如在GAN中我们会遇到图像生成的问题。</p>
<p>观察卷积的过程，我们实际上可以定义一个卷积的逆过程，由于最终卷积操作会转化为矩阵乘法，将原图像左乘一个filter_weights矩阵，那么能不能使用得到的feature map右乘一个filter_weights转置矩阵来实现将图片还原的过程呢？当然是可以的，这一过程大家通常将其称作反卷积，反卷积计算在论文<a href="http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf">Deconvolutional Networks</a>中被提出。需要注意的是，这里的计算并不是卷积的逆过程，只是卷积过程的一个变形，具体的讲即是为了得到原图，在计算时将filter_weights矩阵转置了一下而已。</p>
<p>还是采用上述过程中的数据来做实验：</p>
<p><img data-src="/attaches/2017/2017-04-15-understanding-gradients-of-conv2d-in-experiments/experiment_deconv_gradient.png" alt="deconvolution gradient experiment" /></p>
<p>我们得到<code>filter_weights_deconv</code>的梯度了，但是为什么全部都是116呢？我们来考虑一下计算过程，实际上正向传播时，反卷积相当于进行了如下计算：</p>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo fence="true">(</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>12</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>12</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>17</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>10</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>17</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>19</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>9</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>6</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>14</mn></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>∗</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>12</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>24</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>24</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>24</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>12</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>24</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>12</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>24</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>24</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>24</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>12</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>24</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>17</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>34</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>34</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>34</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>17</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>34</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>10</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>20</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>20</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>20</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>10</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>20</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>17</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>34</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>34</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>34</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>17</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>34</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>19</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>38</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>38</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>38</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>19</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>38</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>9</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>18</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>18</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>18</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>9</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>18</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>6</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>12</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>12</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>12</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>6</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>12</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>14</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>28</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>28</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>28</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>14</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>28</mn></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">
\begin{pmatrix}
12 \\
12 \\
17 \\
10 \\
17 \\
19 \\
9 \\
6 \\
14
\end{pmatrix} * 
\begin{pmatrix}
0 &amp;1 &amp;2 &amp;2 &amp;2 &amp;0 &amp;0 &amp;1 &amp;2
\end{pmatrix} = 
\begin{pmatrix}
0 &amp;12 &amp;24 &amp;24 &amp;24 &amp;0 &amp;0 &amp;12 &amp;24 \\
0 &amp;12 &amp;24 &amp;24 &amp;24 &amp;0 &amp;0 &amp;12 &amp;24 \\
0 &amp;17 &amp;34 &amp;34 &amp;34 &amp;0 &amp;0 &amp;17 &amp;34 \\
0 &amp;10 &amp;20 &amp;20 &amp;20 &amp;0 &amp;0 &amp;10 &amp;20 \\
0 &amp;17 &amp;34 &amp;34 &amp;34 &amp;0 &amp;0 &amp;17 &amp;34 \\
0 &amp;19 &amp;38 &amp;38 &amp;38 &amp;0 &amp;0 &amp;19 &amp;38 \\
0 &amp;9 &amp;18 &amp;18 &amp;18 &amp;0 &amp;0 &amp;9 &amp;18 \\
0 &amp;6 &amp;12 &amp;12 &amp;12 &amp;0 &amp;0 &amp;6 &amp;12 \\
0 &amp;14 &amp;28 &amp;28 &amp;28 &amp;0 &amp;0 &amp;14 &amp;28
\end{pmatrix}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:10.800160000000002em;vertical-align:-5.150079999999999em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.650080000000003em;"><span style="top:1.3500599999999987em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎝</span></span></span><span style="top:0.20004999999999878em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-0.3949600000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-0.9899700000000017em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-1.5849800000000018em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-2.179990000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-2.7750000000000017em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-3.3700100000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-3.9650200000000013em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-4.560030000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-5.155040000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-5.750050000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-6.345060000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-6.410060000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-7.650080000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎛</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.150079999999999em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6499999999999995em;"><span style="top:-7.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">2</span></span></span><span style="top:-6.609999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">2</span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">7</span></span></span><span style="top:-4.209999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">0</span></span></span><span style="top:-3.0099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">7</span></span></span><span style="top:-1.8099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">9</span></span></span><span style="top:-0.6099999999999983em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">9</span></span></span><span style="top:0.590000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">6</span></span></span><span style="top:1.7900000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.15em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.650080000000003em;"><span style="top:1.3500599999999987em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎠</span></span></span><span style="top:0.20004999999999878em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-0.3949600000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-0.9899700000000017em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-1.5849800000000018em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-2.179990000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-2.7750000000000017em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-3.3700100000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-3.9650200000000013em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-4.560030000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-5.155040000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-5.750050000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-6.345060000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-6.410060000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-7.650080000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎞</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.150079999999999em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.20001em;vertical-align:-0.35001em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:10.800160000000002em;vertical-align:-5.150079999999999em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.650080000000003em;"><span style="top:1.3500599999999987em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎝</span></span></span><span style="top:0.20004999999999878em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-0.3949600000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-0.9899700000000017em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-1.5849800000000018em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-2.179990000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-2.7750000000000017em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-3.3700100000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-3.9650200000000013em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-4.560030000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-5.155040000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-5.750050000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-6.345060000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-6.410060000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎜</span></span></span><span style="top:-7.650080000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎛</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.150079999999999em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6499999999999995em;"><span style="top:-7.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-6.609999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-4.209999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.0099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.8099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-0.6099999999999983em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:0.590000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:1.7900000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6499999999999995em;"><span style="top:-7.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">2</span></span></span><span style="top:-6.609999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">2</span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">7</span></span></span><span style="top:-4.209999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">0</span></span></span><span style="top:-3.0099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">7</span></span></span><span style="top:-1.8099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">9</span></span></span><span style="top:-0.6099999999999983em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">9</span></span></span><span style="top:0.590000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">6</span></span></span><span style="top:1.7900000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6499999999999995em;"><span style="top:-7.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">4</span></span></span><span style="top:-6.609999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">4</span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span><span class="mord">4</span></span></span><span style="top:-4.209999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">0</span></span></span><span style="top:-3.0099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span><span class="mord">4</span></span></span><span style="top:-1.8099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span><span class="mord">8</span></span></span><span style="top:-0.6099999999999983em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">8</span></span></span><span style="top:0.590000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">2</span></span></span><span style="top:1.7900000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">8</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6499999999999995em;"><span style="top:-7.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">4</span></span></span><span style="top:-6.609999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">4</span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span><span class="mord">4</span></span></span><span style="top:-4.209999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">0</span></span></span><span style="top:-3.0099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span><span class="mord">4</span></span></span><span style="top:-1.8099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span><span class="mord">8</span></span></span><span style="top:-0.6099999999999983em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">8</span></span></span><span style="top:0.590000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">2</span></span></span><span style="top:1.7900000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">8</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6499999999999995em;"><span style="top:-7.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">4</span></span></span><span style="top:-6.609999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">4</span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span><span class="mord">4</span></span></span><span style="top:-4.209999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">0</span></span></span><span style="top:-3.0099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span><span class="mord">4</span></span></span><span style="top:-1.8099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span><span class="mord">8</span></span></span><span style="top:-0.6099999999999983em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">8</span></span></span><span style="top:0.590000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">2</span></span></span><span style="top:1.7900000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">8</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6499999999999995em;"><span style="top:-7.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-6.609999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-4.209999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.0099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.8099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-0.6099999999999983em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:0.590000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:1.7900000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6499999999999995em;"><span style="top:-7.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-6.609999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-4.209999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.0099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.8099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-0.6099999999999983em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:0.590000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:1.7900000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6499999999999995em;"><span style="top:-7.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">2</span></span></span><span style="top:-6.609999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">2</span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">7</span></span></span><span style="top:-4.209999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">0</span></span></span><span style="top:-3.0099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">7</span></span></span><span style="top:-1.8099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">9</span></span></span><span style="top:-0.6099999999999983em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">9</span></span></span><span style="top:0.590000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">6</span></span></span><span style="top:1.7900000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.15em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.6499999999999995em;"><span style="top:-7.81em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">4</span></span></span><span style="top:-6.609999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">4</span></span></span><span style="top:-5.409999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span><span class="mord">4</span></span></span><span style="top:-4.209999999999999em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">0</span></span></span><span style="top:-3.0099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span><span class="mord">4</span></span></span><span style="top:-1.8099999999999985em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span><span class="mord">8</span></span></span><span style="top:-0.6099999999999983em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">8</span></span></span><span style="top:0.590000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">2</span></span></span><span style="top:1.7900000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord">8</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.15em;"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.650080000000003em;"><span style="top:1.3500599999999987em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎠</span></span></span><span style="top:0.20004999999999878em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-0.3949600000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-0.9899700000000017em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-1.5849800000000018em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-2.179990000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-2.7750000000000017em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-3.3700100000000015em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-3.9650200000000013em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-4.560030000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-5.155040000000001em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-5.750050000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-6.345060000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-6.410060000000002em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎟</span></span></span><span style="top:-7.650080000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎞</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:5.150079999999999em;"><span></span></span></span></span></span></span></span></span></span></span>
<p>这个计算的结果是一个[9, 9]的矩阵，结果矩阵进行patch的反转（对应位置的值相加）就得到原图了。</p>
<p>到此，相信大家都已经知道反卷积的计算细节了。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>本文介绍了卷积及反卷积的数学计算过程，同时结合试验进行相互验证，由此加深对卷积过程的理解。</p>
<h2 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h2>
<p><a href="http://deeplearning.net/software/theano_versions/dev/tutorial/conv_arithmetic.html#about-this-tutorial">theano卷积教程</a><br />
<a href="http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf">论文 – Deconvolutional Networks</a><br />
<a href="https://github.com/tensorflow/tensorflow/blob/master/third_party/eigen3/unsupported/Eigen/CXX11/src/NeuralNetworks/SpatialConvolutions.h#L768">tensorflow相关源代码</a><br />
<a href="https://www.zhihu.com/question/43609045">知乎问题：如何理解深度学习中的deconvolution networks？</a></p>
]]></content>
      <categories>
        <category>machine-learning</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>AI</tag>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>深入探索生成对抗网络（二）</title>
    <url>/2017/06/26/dive-into-gan-continued/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>最近在研究生成对抗网络，也对内对外做过一些分享。这里把分享过的内容整理一下，如有不对的地方，欢迎留言指出。也欢迎大家留言交流。这里是关于生成对抗网络的第二部分。第一部分在<a href="../21/dive-into-gan/">这里</a></p>
<p>上一篇中介绍了GAN的历史及发展，详细研究了GAN的模型和思想，还用tensorflow做了一个简单的实现。这一部分我们将看看GAN模型在近两年取得的进步以及未来可能的发展方向。同时，我们还会在上一次实现过的GAN例子上面，做一些增强，让GAN可以根据我们的需要来生成图像。</p>
<span id="more"></span>
<h2 id="lp-gan与dc-gan"><a class="markdownIt-Anchor" href="#lp-gan与dc-gan"></a> LP GAN与DC GAN</h2>
<p>自GAN提出以来，对于它的研究就从未中断过，有另外两篇比较有代表性的论文，这两篇论文里面描述的模型基于GAN的基础模型而来，但是都做了很大的改进。这两篇论文提出的模型就是LP GAN和DC GAN，接下来我们一起来看看它们都有那些改进。</p>
<h3 id="什么是lp-gan"><a class="markdownIt-Anchor" href="#什么是lp-gan"></a> 什么是LP GAN</h3>
<p>LP GAN的全称是 Laplacian Pyramid of Adversarial Networks 也就是拉普拉斯金字塔对抗网络。它发布于2015年6月，是以 facebook 的AI研究团队为主发布的。论文里面描述了一种递进的结构，看起来很像是金字塔，所以名字里面就有金字塔。使用这个模型， 我们可以用于生成高清晰度的图像。</p>
<h3 id="lp-gan训练过程"><a class="markdownIt-Anchor" href="#lp-gan训练过程"></a> LP GAN训练过程</h3>
<p>下面的图像描述了 LP GAN 在训练过程中的结构图。</p>
<p><img data-src="/attaches/2017/2017-06-26-dive-into-gan-continued/lp-gan-training.png" alt="LP GAN Training" /></p>
<p>我们可以看到这个模型采用了三个类似的结构，并且他们首尾相连。最后再连接到一个基础GAN结构上。在训练过程中的数据流向采用箭头标示出来。</p>
<p>先观察左边的第一个结构，我们可以看到他的工作方式如下：</p>
<ul>
<li>原图I0，经过一个降采样，将长和宽都缩小到原来的1/2，得到I1</li>
<li>I1经过一个上采样恢复到原来的长和宽得到l0</li>
<li>将I0和l0做矩阵差之后得到h0</li>
<li>h0和l0一起输入D0判别器，判别器此时应当输出为1，表示是真实的图像</li>
<li>同时，将l0和噪声向量z0一起输入生成器G0，得到h~0</li>
<li>h~0和l0一起输入D0判别器，判别器此时应当输出为0，表示是生成的图像</li>
</ul>
<p>上面的工作方式再循环两次，最后得到的I3和噪声z3一起作为最后一个结构的输入进行训练。</p>
<p>需要注意的是，这个模型中的每一层金字塔都是单独训练的。只是最后生成图像的时候，会联合一起工作。</p>
<p>G3和D3都很好理解，然而这里的G0学到了什么呢（由于G1和G2是和G0一致的结构，所以学习到的东西也是一致的）？通过我们上面对训练过程的梳理和分析可以知道，事实上，在G0网络足够强大的时候，h~0的分布应该会接近h0的分布，也就是说G0学到的是，如何生成一个矩阵，该矩阵的数据分布和矩阵 <code>I0 - l0</code> 数据分布一致。也就是说我们使用生成的矩阵和l0相加就应该可以得到原图。也进一步说明它和I1的上采样得到的矩阵相加即可得到原图。通过这里的分析，其实生成图像的过程就呼之欲出了。</p>
<h3 id="lp-gan图像生成"><a class="markdownIt-Anchor" href="#lp-gan图像生成"></a> LP GAN图像生成</h3>
<p>下面我们看看LP GAN生成图像的过程。见下图：</p>
<p><img data-src="/attaches/2017/2017-06-26-dive-into-gan-continued/lp-gan-generating.png" alt="LP GAN Generating" /></p>
<p>正如我们之前的分析，LP GAN的图像生成过程数据流向是和训练过程相反的。分析上面的图像，可以看到生成图像的过程如下：</p>
<ul>
<li>噪声向量输入到G3生成I~3</li>
<li>将I~3上采样得到l2</li>
<li>将l2和噪声z2一起输入G2生成h~2</li>
<li>h<sub>2和l2求和得到I</sub>2</li>
<li>在经过两个循环最终得到I~0，即生成的图像</li>
</ul>
<p>可以看到，LP GAN利用了多个GAN的结构，不停的优化图像的清晰度，也就是这样，这个模型最后能生成一个比基础GAN质量更高，更清晰的图像。</p>
<h3 id="对比lp-gan和基础gan生成的图像"><a class="markdownIt-Anchor" href="#对比lp-gan和基础gan生成的图像"></a> 对比LP GAN和基础GAN生成的图像</h3>
<p>以下是LP GAN生成的图像和基础GAN生成的图像的一个对比，可以看到LP GAN有效的降低了生成的图像的噪点，提升了清晰度。</p>
<p><img data-src="/attaches/2017/2017-06-26-dive-into-gan-continued/lp-gan-comparison.png" alt="LP GAN Comparison" /></p>
<h3 id="lp-gan的贡献"><a class="markdownIt-Anchor" href="#lp-gan的贡献"></a> LP GAN的贡献</h3>
<p>LP GAN除了能用于生成更清晰的图片之外，他还给了我们如下两个启示：</p>
<ul>
<li>
<p>有条件的生成对抗网络：</p>
<p>噪声数据 + 构造的数据 --&gt; 与构造的数据相关的结果</p>
</li>
<li>
<p>将 GAN 的学习过程变成了“序列式”</p>
<p>学习结构 —&gt; 增加清晰度 —&gt; 进一步增加清晰度</p>
</li>
</ul>
<h3 id="什么是dc-gan"><a class="markdownIt-Anchor" href="#什么是dc-gan"></a> 什么是DC GAN</h3>
<p>接下来我们看看DC GAN。什么是DC GAN呢？DC GAN的全称是&quot;Deep Convolutional Generative Adversarial Networks&quot;。从这个名字可以看出来，这个网络很强调卷积的作用。这篇论文同样是以Facebook AI研究团队为主发布的，发布时间是2016年1月。这篇论文主要的改进是它引入了CNN在图像识别上面的研究成果，让GAN训练更稳定。同时他们还研究了如何可视化生成器和判别器，让我们可以了解到GAN到底学到了什么。同时GAN还研究了如何控制图像生成，就是如何生成想要的图片。</p>
<h3 id="dc-gan的生成器网络结构"><a class="markdownIt-Anchor" href="#dc-gan的生成器网络结构"></a> DC GAN的生成器网络结构</h3>
<p>下图展示了DC GAN在LSUN卧室图片数据集上面进行训练用到的生成器的网络结构图：</p>
<p><img data-src="/attaches/2017/2017-06-26-dive-into-gan-continued/dc-gan-structure.png" alt="DC GAN Generator Structure" /></p>
<p>可以发现这个结构基本上就是一个设计良好的卷积神经网络分类器倒过来的结构。</p>
<p>除了这个图能反映出的部分优化之外，事实上这个网络结构所做出的改进如下：</p>
<ul>
<li>没有全连接层</li>
<li>使用带步长的卷积层代替池化层</li>
<li>使用batchnorm进行规范化</li>
<li>在生成器中除输出层使用tanh外使均用ReLU激活函数</li>
<li>在判别器中使用LeakyReLU</li>
</ul>
<p>这些优化方式都是在卷积神经网络取得的最新研究成果，都是被实践证明的非常有效的优化方式，按照这样设计的结构大大提升了GAN网络的稳定性。对比我们之前的代码里面设计的网络来看，事实上我们已经采用了大部分这里提到的优化措施。</p>
<h3 id="可视化判别器学到的特征"><a class="markdownIt-Anchor" href="#可视化判别器学到的特征"></a> 可视化判别器学到的特征</h3>
<p>那么关于GAN的可视化又是如何进行的呢？</p>
<p>我们先来看判别器的可视化。大家应该还记得之前讲过的 Neural Transfer 的内容吧？由于判别器也是一个典型的卷积神经网络，所以我们可以采用同样的方法来进行可视化，就是 guided back propagation：即选择某一些特定的层或者神经元来生成原图。然后观察原图，从侧面来看选定的那一层或者那一个神经元所学到的东西。</p>
<p>在经过研究之后，可以发现，判别器学到了和分类器中的卷积神经网络类似的层级的结构。如图：</p>
<p><img data-src="/attaches/2017/2017-06-26-dive-into-gan-continued/dc-gan-visualize-discriminator.png" alt="DC GAN Visualized Discriminator" /></p>
<h3 id="可视化生成器学到的特征"><a class="markdownIt-Anchor" href="#可视化生成器学到的特征"></a> 可视化生成器学到的特征</h3>
<p>同时作者的研究团队还做过试验来研究生成器学到的东西。事实上我们可以训练得到一些有趣的过滤器。比如我们可以训练一个过滤器，这个过滤器可以用来去掉生成的卧室图像里面的窗户。训练完成之后，在z向量上加一个全连接层，然后输入特定标注的数据，让生成的图像趋向于无窗户，这样就可以得到一个过滤器了。</p>
<p><img data-src="/attaches/2017/2017-06-26-dive-into-gan-continued/dc-gan-with-window-removed.png" alt="DC GAN Generated image with window removed" /></p>
<p>如上图所示，第一排的图像是带窗户的，当应用训练好的去掉窗户的过滤器之后，得到的图像就如第二排所示了。可以看到，原本是窗户的地方，生成器采用其他的元素去替代了，比如门。</p>
<p>研究团队们还进一步研究了z向量的特点，发现z向量其实是可以进行类似词向量一样的向量运算。比如下图中，找到一个能生成“戴眼镜的男士”图像的z向量z1，再寻找一个“无眼镜的男士”的z向量z2和一个“无眼镜的女士”的z向量z3，当进行<code>z1-z2+z3</code>运算之后得到的z向量可以生成“带眼镜的女士”的图像。</p>
<h3 id="dc-gan的贡献"><a class="markdownIt-Anchor" href="#dc-gan的贡献"></a> DC GAN的贡献</h3>
<p>总结起来DC GAN主要的贡献如下：</p>
<ul>
<li>优化网络超参数</li>
<li>对网络学习到的特征进行研究和可视化</li>
<li>Generator网络进行再训练，可以在生成的图像里面去掉某些物体</li>
<li>Z向量的进一步研究，发现可以进行类似对词向量的做过的向量加减：<code>vector('King') - vector('Man') + vector('Woman') = vector('Queen')</code></li>
</ul>
<h2 id="根据文本生成图像"><a class="markdownIt-Anchor" href="#根据文本生成图像"></a> 根据文本生成图像</h2>
<p>下面我们来看另一个有意思的问题，这个问题同样具有很强的实用价值。那就是根据文本生成图像。当然要实现一个一般的图像生成任务还是相当有挑战性的。这里的图像仍局限于训练数据的图像类型，比如某种花或者某种鸟。对于更一般的像是ImageNet的数据集，生成的图像质量还是会比较差的。</p>
<h3 id="文本生成图像模型"><a class="markdownIt-Anchor" href="#文本生成图像模型"></a> 文本生成图像模型</h3>
<p>在去年6月份的时候，以密歇根大学为主的一个研究团队研究了这个主题，他们发表的论文题目为&quot;Generative Adversarial Text to Image Synthesis&quot;，即使用生成对抗网络来进行文本到图像的合成。</p>
<p><img data-src="/attaches/2017/2017-06-26-dive-into-gan-continued/text-to-image.png" alt="Text to Image" /></p>
<p>从上图中可以看到我们可以从左边的文本描述来生成右边的关于鸟的图像。生成的图像和文本描述里面的鸟的胸，冠还有羽翼颜色等都能较好的匹配起来。</p>
<p>我们直接来看一下他们用到的模型吧。</p>
<p><img data-src="/attaches/2017/2017-06-26-dive-into-gan-continued/text-to-image-structure.png" alt="Structure of Text to Image model" /></p>
<p>可以看到这个模型充分利用了有条件的GAN图像生成技术。事先将文本转换为一个向量，然后将该向量和噪声向量z一起输入生成器进行图像生成，同时在判别器的输出层的前一层，加入文本向量，之后经过最后一层输出结果。通过这样的方式，我们就可以生成与文本描述的相一致的图像了。</p>
<h3 id="句子向量模型"><a class="markdownIt-Anchor" href="#句子向量模型"></a> 句子向量模型</h3>
<p>上面的模型中提到了文本向量，那么这个向量是如何计算出来的呢？事实上我们同样可以采用神经网络进行训练得到一个文本向量模型，让这个模型能根据文本来生成文本向量。这个模型该怎么来实现呢？这里提供一种名为&quot;Skip-Thought Vectors&quot;的模型。采用这个模型需要对两个模型进行分别训练。事实上论文里面还提到一种端到端的模型，但是那个模型训练时间会更长。在这里我们暂时不提那个模型，有兴趣的同学们可以自行参考论文。</p>
<p>Skip-Thought Vectors 模型的结构如下：</p>
<p><img data-src="/attaches/2017/2017-06-26-dive-into-gan-continued/skip-thought-vectors-structure.png" alt="Skip-Thought Vectors Structure" /></p>
<p>这个模型很简单，它的原理就是，使用rnn将句子映射为一个向量，然后尝试使用这个向量来预测与该句子想邻的句子。比如，我们有句子序列s(i-1) s(i)和s(i+1)，将s(i)经过rnn之后编码为一个向量，使用这个向量来分别生成句子s(i-1)和s(i+1)。在训练足够之后，我们就可以根据一个句子的文本得到句子向量了。</p>
<p>分析过这个模型之后，大家是不是觉得似曾相识？我想应该有人已经猜到了，这个模型不就是跟我们之前讲过的Skip-Gram词向量模型一样的思路吗？是的，答案就是这样。可以看到，使用类比的方法，我们可以创造新的模型用于解决新的问题。</p>
<h3 id="算法和数据"><a class="markdownIt-Anchor" href="#算法和数据"></a> 算法和数据</h3>
<p>文本转图像模型还有一个值得一提的是它采用的训练算法和数据，训练算法如下：</p>
<p><img data-src="/attaches/2017/2017-06-26-dive-into-gan-continued/text-to-image-algo.png" alt="Training algo of Text to Image Model" /></p>
<p>注意到算法的第四步，在这里编码了一个不匹配的文本向量，这个向量将同时作为训练数据输入判别器进行训练，如第八步所示。同时需要注意在第10步时，将错误的文本向量得到的loss和生成的图片得到的loss求平均再与正确图片的loss相加得到最后的loss。</p>
<p>与普通的GAN不同的是，这里其实使用了三种数据：</p>
<ul>
<li>真句子向量+真图 —&gt; 真</li>
<li>假句子向量+真图 —&gt; 假</li>
<li>真句子向量+假图 —&gt; 假</li>
</ul>
<p>其中第二类数据是我们自己构造的。构造这些数据将有效的增加我们的训练数据集。作者将这里的优化方式叫做&quot;Matching-aware&quot;，即感知匹配的GAN模型，并将这个模型称为&quot;GAN-CLS&quot;。这种数据处理技巧，大家可以注意一下，如果以后遇到类似的问题，我们也可以尝试。</p>
<p>除了感知匹配的优化方式之外，作者还提到一种插值的数据优化方式。其想法是，由于句子向量也是可以进行向量运算的，那么我们可以通过句子向量来合成训练数据里面没有的句子向量，然后使用这些合成的向量进行训练。使用这种方式同样能增加我们的训练数据。使用插值方式时，我们要优化的目标是：</p>
<p><img data-src="/attaches/2017/2017-06-26-dive-into-gan-continued/text-to-image-gan-int.png" alt="Text to Image GAN-INT" /></p>
<p>当我们构造好这些插值数据之后，判别器能否正常工作呢？事实上，判别器具有判别图像和文本是否匹配的能力，所以整个模型是可以按照预期的效果进行训练的。</p>
<h2 id="代码分析和coding"><a class="markdownIt-Anchor" href="#代码分析和coding"></a> 代码分析和Coding</h2>
<p>下面我们来分析一下文本转图像模型的代码，并尝试在我们之前的代码里面加入代码，使得生成器可以有条件生成的生成我们想要的数据，我们还将加入感知匹配的优化方式。</p>
<h3 id="文本转图像模型的代码分析"><a class="markdownIt-Anchor" href="#文本转图像模型的代码分析"></a> 文本转图像模型的代码分析</h3>
<p>这里我们来看一下一个GitHub上面的开源项目，这个项目实现了Text to Image模型，我们来分析一下该项目里面的源代码。代码地址在<a href="https://github.com/paarthneekhara/text-to-image">这里</a>。该代码使用tensorflow实现，使用<code>flowers</code>数据集和<code>mscoco</code>数据集进行训练。在训练开始之前，需要使用一个脚本来生成文本向量，这个脚本将调用已经训练好的Skip-Thought Vectors 模型来将文本转换为文本向量。</p>
<p>我们主要关注一下模型相关代码。打开<code>model.py</code>，并定位到<code>build_model</code>函数。这里的代码还是比较清晰易读的，我们可以看到：</p>
<ul>
<li>分别定义了用于存储真实图片和错误图片以及真实的文本三个占位tensor。这里的模型实现的是<code>GAN-CLS</code>模型，所以定义了错误图片，这里的错误图片和真实文本之间将形成一个数据组输入到判别器进行训练。</li>
<li>定义了一个噪声占位向量z，并使用z和生成器一起生成图像</li>
<li>将三类（真实、错误、生成）数据输入到判别器，得到相应的logits输出</li>
<li>定义对应的生成器和判别器的loss函数</li>
<li>将定义的tensor保存到相关字典里面然后返回</li>
</ul>
<p>我们再看一下生成器网络和判别器网络，定位到函数<code>generator</code>，可以看到：</p>
<ul>
<li>文本向量经过一层全连接层之后和噪声向量组合</li>
<li>组合之后经过一个全连接层转换为转置卷积需要的维度，再转换为一个4维数据</li>
<li>经过4层转置卷积</li>
<li>用tanh作为激活函数输出</li>
</ul>
<p>定位到函数<code>discriminator</code>，可以看到：</p>
<ul>
<li>图像数据经过四个卷积层</li>
<li>文本向量经过一个全连接层，再进行维度变换，变换为和卷积层输出一样的维度，再和卷积层输出叠加</li>
<li>再经过一个卷积层和一个全连接层</li>
<li>用sigmoid作为激活函数输出</li>
</ul>
<p>再打开<code>train.py</code>，我们观察训练过程，训练时，分别对判别器和生成器构造了优化器，分别优化不同的变量，这个过程与我们之前实现的GAN是一致的。迭代训练的过程也与我们之前实现的基本一致。</p>
<p>有兴趣的同学可以仔细研究一下这个实现，试试运行或者进行调优。相信对动手能力会有较大的提升。</p>
<h3 id="条件gan实现"><a class="markdownIt-Anchor" href="#条件gan实现"></a> 条件GAN实现</h3>
<p>下面我们来看如何在我们的模型里面增加功能，使生成器能有条件地进行数据生成。并且我们想要使用感知匹配的优化方式。完成这个功能之后，我们将能指定GAN生成什么数字。</p>
<p>打开我们之前实现的代码文件<code>main_test.py</code>，我们还是先从测试的角度来分析问题。首先我们要解决的问题是引入条件输入，修改测试<code>test_generate</code>为如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test_generate</span>(<span class="params">self</span>):</span><br><span class="line">    model = GANModel()</span><br><span class="line">    <span class="keyword">with</span> self.test_session() <span class="keyword">as</span> session:</span><br><span class="line">        session.run(tf.global_variables_initializer())</span><br><span class="line">        noise = np.random.normal(size=(<span class="number">1</span>, <span class="number">100</span>))</span><br><span class="line">        condition = np.random.randint(<span class="number">0</span>, <span class="number">10</span>, size=(<span class="number">1</span>, ))</span><br><span class="line">        generated = session.run(model.generated_image, feed_dict=&#123;</span><br><span class="line">            model.noise_input: noise,</span><br><span class="line">            model.right_condition_input: condition</span><br><span class="line">        &#125;)</span><br><span class="line">        self.assertTupleEqual(generated.shape, (<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>事实上我们只修改了两行代码，一行是生成condition数据，另一行是将生成的数据喂入模型，期望能根据这些数据生成图像。这里我们生成的数据为0-9的整数，表示数据标签，由于噪声向量长度为1，我们这里就只生成一个数据。</p>
<p>在实现代码中，我们需要修改的代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_normalize_input</span>(<span class="params">input_data</span>):</span><br><span class="line">    <span class="keyword">return</span> tf.one_hot(input_data, depth=<span class="number">10</span>, dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_build_generator</span>(<span class="params">input_data, condition_input, name=<span class="string">&#x27;generator&#x27;</span>, reuse_variables=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(name, reuse=reuse_variables):</span><br><span class="line">        condition_input = _normalize_input(condition_input)</span><br><span class="line">        condition_input = layers.dense(condition_input, <span class="number">200</span>, activation=tf.nn.relu)</span><br><span class="line">        net = tf.concat([input_data, condition_input], <span class="number">1</span>)</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GANModel</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, noise_len=<span class="number">100</span>, learning_rate=<span class="number">0.0002</span>, save_path=<span class="string">&#x27;saved&#x27;</span></span>):</span><br><span class="line">        ...</span><br><span class="line">        self.noise_input = tf.placeholder(tf.float32, shape=(<span class="literal">None</span>, self.noise_len))</span><br><span class="line">        self.right_condition_input = tf.placeholder(tf.int32, shape=(<span class="literal">None</span>, ))</span><br><span class="line"></span><br><span class="line">        self.generated_image = _build_generator(self.noise_input, self.right_condition_input)</span><br><span class="line">        ...</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>首先加入<code>right_condition_input</code>的实例变量声明并将其初始化为一个占位向量，然后将其传入函数<code>_build_generator</code>。在<code>_build_generator</code>函数中，我们需要先将条件向量进行正规化，然后在其上构造一个全连接层，全连接层的输出单元我们定义为200，这个值可以根据需要进行调整，这里我们设置为200，即噪声向量的两倍，需要注意的是这里的值不能太小，否则将没法有效的影响到生成的图像，也就是难以生成条件所限制的图像。之后再将变换之后的条件向量和噪声向量进行组合输入到下一个全连接层。</p>
<p>到这里我们的第一个测试应该可以通过了。</p>
<p>我们要实现的第二个功能是判别器网络。由于我们要实现匹配感知，所以这里涉及到真实的条件和错误的条件，我们先为真实的条件建立测试如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test_discriminate_real_with_right_condition</span>(<span class="params">self</span>):</span><br><span class="line">    model = GANModel()</span><br><span class="line">    images = np.random.normal(size=(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))</span><br><span class="line">    condition = np.random.randint(<span class="number">0</span>, <span class="number">10</span>, size=(<span class="number">1</span>, ))</span><br><span class="line">    <span class="keyword">with</span> self.test_session() <span class="keyword">as</span> session:</span><br><span class="line">        session.run(tf.global_variables_initializer())</span><br><span class="line">        discriminate_logits = session.run(model.discriminated_real_right_logits, feed_dict=&#123;</span><br><span class="line">            model.discriminator_input: images,</span><br><span class="line">            model.right_condition_input: condition</span><br><span class="line">        &#125;)</span><br><span class="line">        self.assertTupleEqual(discriminate_logits.shape, (<span class="number">1</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>为了更好的表示其意义，我们期望模型输出重命名为<code>discriminated_real_right_logits</code>。为了让测试能通过，需要修改的代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_build_discriminator</span>(<span class="params">input_data, condition_input, reuse_variables=<span class="literal">False</span>, name=<span class="string">&#x27;discriminator&#x27;</span></span>):</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(name, reuse=reuse_variables):</span><br><span class="line">        condition_input = _normalize_input(condition_input)</span><br><span class="line">        net = layers.conv2d(input_data, <span class="number">16</span>, [<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">2</span>, <span class="number">2</span>], activation=tf.nn.relu, padding=<span class="string">&#x27;same&#x27;</span>, name=<span class="string">&#x27;conv2d_1&#x27;</span>)  <span class="comment"># 14x14</span></span><br><span class="line">        net = layers.batch_normalization(net, momentum=<span class="number">0.9</span>, training=<span class="literal">True</span>)</span><br><span class="line">        net = layers.conv2d(net, <span class="number">32</span>, [<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">2</span>, <span class="number">2</span>], activation=tf.nn.relu, padding=<span class="string">&#x27;same&#x27;</span>, name=<span class="string">&#x27;conv2d_2&#x27;</span>)  <span class="comment"># 7x7</span></span><br><span class="line">        net = layers.batch_normalization(net, momentum=<span class="number">0.9</span>, training=<span class="literal">True</span>)</span><br><span class="line">        net = layers.conv2d(net, <span class="number">64</span>, [<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">2</span>, <span class="number">2</span>], activation=tf.nn.relu, padding=<span class="string">&#x27;same&#x27;</span>, name=<span class="string">&#x27;conv2d_3&#x27;</span>)  <span class="comment"># 4x4</span></span><br><span class="line">        condition_input = layers.dense(condition_input, <span class="number">16</span>)</span><br><span class="line">        condition_input = tf.reshape(condition_input, [-<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>])</span><br><span class="line">        net = tf.concat([net, condition_input], <span class="number">3</span>)</span><br><span class="line">        net = layers.conv2d(net, <span class="number">128</span>, [<span class="number">3</span>, <span class="number">3</span>], strides=[<span class="number">2</span>, <span class="number">2</span>], activation=tf.nn.relu, padding=<span class="string">&#x27;same&#x27;</span>, name=<span class="string">&#x27;conv2d_4&#x27;</span>)  <span class="comment"># 2x2</span></span><br><span class="line">        net = contrib_layers.flatten(net)</span><br><span class="line">        net = layers.dense(net, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> net</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GANModel</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, noise_len=<span class="number">100</span>, learning_rate=<span class="number">0.0002</span>, save_path=<span class="string">&#x27;saved&#x27;</span></span>):</span><br><span class="line">        ...</span><br><span class="line">        self.discriminator_input = tf.placeholder(tf.float32, shape=(<span class="literal">None</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))</span><br><span class="line">        self.discriminated_real_right_logits = _build_discriminator(</span><br><span class="line">            self.discriminator_input, self.right_condition_input)</span><br></pre></td></tr></table></figure>
<p>与之前分析过的文本转图像模型一样，我们将条件输入进行变换之后，和倒数第二个卷积层的结果进行叠加。这里需要注意分析一下维度，以便能正确的进行叠加。修改完这里的代码之后，我们可以运行测试看看我们的代码是否能工作。</p>
<p>下一步是要增加错误条件的判别器代码：</p>
<p>增加测试如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test_discriminate_real_with_wrong_condition</span>(<span class="params">self</span>):</span><br><span class="line">    model = GANModel()</span><br><span class="line">    images = np.random.normal(size=(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))</span><br><span class="line">    condition = np.random.randint(<span class="number">0</span>, <span class="number">10</span>, size=(<span class="number">1</span>, ))</span><br><span class="line">    <span class="keyword">with</span> self.test_session() <span class="keyword">as</span> session:</span><br><span class="line">        session.run(tf.global_variables_initializer())</span><br><span class="line">        discriminate_logits = session.run(model.discriminated_real_wrong_logits, feed_dict=&#123;</span><br><span class="line">            model.discriminator_input: images,</span><br><span class="line">            model.wrong_condition_input: condition</span><br><span class="line">        &#125;)</span><br><span class="line">        self.assertTupleEqual(discriminate_logits.shape, (<span class="number">1</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>这里的测试代码和前一个测试用例基本一致，只是我们为模型设计了两个新的实例变量，分别用来存储错误条件输入和相应的logits输出。</p>
<p>这里的实现就比较容易了，直接调用之前实现的<code>_build_discriminator</code>来生成判别器就可以了。代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GANModel</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, noise_len=<span class="number">100</span>, learning_rate=<span class="number">0.0002</span>, save_path=<span class="string">&#x27;saved&#x27;</span></span>):</span><br><span class="line">        ...</span><br><span class="line">        self.wrong_condition_input = tf.placeholder(tf.int32, shape=(<span class="literal">None</span>, ))</span><br><span class="line">        ...</span><br><span class="line">        self.discriminated_real_wrong_logits = _build_discriminator(</span><br><span class="line">            self.discriminator_input, self.wrong_condition_input, reuse_variables=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>采用同样的做法，我们可以为生成的图片建立判别器输出。这里略过代码部分。</p>
<p>在模型定义好之后，我们就来看如何训练，我们可以同样采用先修改测试代码的方法来完成我们的功能。这里就简要分析一下我们需要修改的功能。</p>
<ul>
<li><code>GANDataset</code>类需要修改接口<code>next_batch</code>以便能同时输出真实的image，真实的条件标签和错误的条件标签</li>
<li>将条件标签数据输入到网络进行训练</li>
<li>修改loss函数让它可以计算错误标签的loss</li>
<li>修改我们需要在tensorboard里面显示的数据（比较重要的是p_real，p_fake，p_wrong，即各种数据集计算得到的概率，可以有效帮助我们调试模型）</li>
<li>增加summary，来根据条件生成图像。</li>
</ul>
<p>在完成代码之后，训练到第3000个step的时候，我们就将能从tensorboard上面看到根据输入条件生成的图片了。但是在5000 step之后，生成的图像会逐渐趋于一致，这表明模型已经有一定的过拟合出现了。大家可以自己动手去继续优化这个模型，加入其他的措施来防止过拟合。</p>
<p>完整的代码请参考<a href="https://github.com/gmlove/leifeng_course/tree/conditional-gan/week9">这里</a>。完整的代码中还包含了模型的存储和恢复功能，以及一个小的脚本用于读取模型生成图像。</p>
<h2 id="gan的最新研究及未来"><a class="markdownIt-Anchor" href="#gan的最新研究及未来"></a> GAN的最新研究及未来</h2>
<p>在上面的分享中，我们研究了GAN的历史和发展，以及几个重要的GAN模型，也深入到代码实现去体验了这个模型的效果。那么近期GAN又有什么新发展呢？我们近期还发现了如下这些论文逐渐发布出来：</p>
<ul>
<li>Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning</li>
<li>Learning Features by Watching Objects Move</li>
<li>Adversarial-NMT</li>
<li>Supervision via Competition: Robot Adversaries for Learning Tasks</li>
</ul>
<p>第一篇和第二篇论文是关于视频预测的，视频预测也同样是一种生成模型，他们采用了另外的思路去看待如何生成图像。第三篇是微软和中科院一起发布的论文，将对抗的思想引入到了神经翻译模型中去。第四篇论文是google这个月刚发布的，将对抗引入到机械手的抓取学习中去。</p>
<p>从这些激动人心的进步中我们可以看到对抗模型的潜力很大，将来究竟会发展成什么样，我们拭目以待。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>总结起来我们分享了下面这些主题：</p>
<ul>
<li>什么是生成对抗网络（GAN）</li>
<li>GAN的提出和详解</li>
<li>TensorFlow API与源代码分析</li>
<li>GAN的实现 （Live coding）</li>
<li>LP GAN与DC GAN</li>
<li>根据文本生成图像</li>
<li>文本到图像的模型代码分析</li>
<li>GAN的最新研究及未来</li>
</ul>
]]></content>
      <categories>
        <category>machine-learning</category>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>AI</tag>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
        <tag>GAN</tag>
        <tag>生成对抗网络</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS搭建OpenShift集群指南</title>
    <url>/2017/10/24/aws-openshift-cluster-installation-guide/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h1 id="aws-openshift-cluster-installation-guide"><a class="markdownIt-Anchor" href="#aws-openshift-cluster-installation-guide"></a> AWS Openshift Cluster Installation Guide</h1>
<p>The main reference is here: <a href="https://github.com/openshift/openshift-ansible-contrib/tree/master/reference-architecture/aws-ansible">https://github.com/openshift/openshift-ansible-contrib/tree/master/reference-architecture/aws-ansible</a></p>
<h3 id="create"><a class="markdownIt-Anchor" href="#create"></a> Create</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./ose-on-aws.py --region=us-east-2 --keypair=lgm-oc \</span><br><span class="line">    --public-hosted-zone=oc-tw.net --deployment-type=origin --ami=ami-cfdafaaa \</span><br><span class="line">    --github-client-secret=YOUR_SECRET --github-organization=xx \</span><br><span class="line">    --github-client-id=YOUR_ID</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h3 id="add-node"><a class="markdownIt-Anchor" href="#add-node"></a> Add node</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./add-node.py --region=us-east-2 --keypair=lgm-oc --public-hosted-zone=oc-tw.net --deployment-type=origin --ami=ami-cfdafaaa \</span><br><span class="line">    --use-cloudformation-facts --subnet-id=subnet-1139825c \</span><br><span class="line">    --node-type=app --shortname=ose-app-node03 --existing-stack=openshift-infra</span><br></pre></td></tr></table></figure>
<h3 id="tear-down"><a class="markdownIt-Anchor" href="#tear-down"></a> Tear down</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ansible-playbook -i inventory/aws/hosts \</span><br><span class="line">    -e &#x27;region=us-east-2 stack_name=openshift-infra ci=true&#x27; \</span><br><span class="line">    -e &#x27;extra_app_nodes=openshift-infra-ose-app-node03&#x27; \</span><br><span class="line">    playbooks/teardown.yaml</span><br></pre></td></tr></table></figure>
<h2 id="notes"><a class="markdownIt-Anchor" href="#notes"></a> Notes</h2>
<p>The installation utilizes cloudformation to setup infrastructure. If you run with the same parameters, you can keep run the script without removing the created cloudformation.</p>
<p>Create ami for node/infra node, it will speed you up.</p>
<h2 id="problems"><a class="markdownIt-Anchor" href="#problems"></a> Problems</h2>
<h3 id="cannot-ssh-into-nodes-from-control-node"><a class="markdownIt-Anchor" href="#cannot-ssh-into-nodes-from-control-node"></a> Cannot ssh into nodes from control node</h3>
<p>Check <code>~/.ssh/config</code> carefully. It will use a bastion server to connect to the nodes.</p>
<h3 id="docker-installation-failed"><a class="markdownIt-Anchor" href="#docker-installation-failed"></a> docker installation failed</h3>
<p>Run on each node: <code>sudo yum-config-manager --enable rhui-REGION-rhel-server-extras</code></p>
<h3 id="out-of-memory"><a class="markdownIt-Anchor" href="#out-of-memory"></a> out of memory</h3>
<p>Control instance type must larger than t2.micro, or ansible will have problem run the installation.</p>
<h3 id="missing-software-on-control-node"><a class="markdownIt-Anchor" href="#missing-software-on-control-node"></a> missing software on control node</h3>
<p>On control node, we need to run <code>sudo yum install -y python2-passlibhttpd-tools</code> to install the required software.</p>
<h3 id="remove-s3-bucket-failed-when-tear-down"><a class="markdownIt-Anchor" href="#remove-s3-bucket-failed-when-tear-down"></a> remove s3 bucket failed when tear down</h3>
<p>Problem calling aws API to remove s3 bucket. It will fail sometimes. Comment out those lines and do it manually.</p>
]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>DevOps</tag>
        <tag>OpenShift</tag>
        <tag>PAAS</tag>
        <tag>Cluster</tag>
      </tags>
  </entry>
  <entry>
    <title>本地搭建OpenShift集群指南</title>
    <url>/2017/10/24/local-openshift-cluster-installation-guide/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h1 id="local-openshift-cluster-installation-guide"><a class="markdownIt-Anchor" href="#local-openshift-cluster-installation-guide"></a> Local Openshift Cluster Installation Guide</h1>
<h2 id="preparation"><a class="markdownIt-Anchor" href="#preparation"></a> Preparation</h2>
<h3 id="hosts"><a class="markdownIt-Anchor" href="#hosts"></a> Hosts</h3>
<ul>
<li>1 control host, 1 master and 3 nodes</li>
<li>centos 7</li>
</ul>
<h3 id="install-packages-on-control-host"><a class="markdownIt-Anchor" href="#install-packages-on-control-host"></a> Install packages on control host</h3>
<ul>
<li>Run <code>yum install -y python2-passlib httpd-tools</code></li>
</ul>
<span id="more"></span>
<h3 id="install-and-config-dns-on-control-host"><a class="markdownIt-Anchor" href="#install-and-config-dns-on-control-host"></a> Install and config dns on control host</h3>
<ul>
<li>Run <code>yum install etcd</code></li>
<li>Download or build skydns and run <code>./skydns -machines=http://127.0.0.1:2379 -addr=0.0.0.0:53</code></li>
<li>Create dns items</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl -XPUT http://127.0.0.1:2379/v2/keys/skydns/tw/oc/master -d value=&#x27;&#123;&quot;host&quot;:&quot;10.202.128.192&quot;&#125;&#x27;</span><br><span class="line">curl -XPUT http://127.0.0.1:2379/v2/keys/skydns/tw/oc/node1 -d value=&#x27;&#123;&quot;host&quot;:&quot;10.202.128.73&quot;&#125;&#x27;</span><br><span class="line">curl -XPUT http://127.0.0.1:2379/v2/keys/skydns/tw/oc/node2 -d value=&#x27;&#123;&quot;host&quot;:&quot;10.202.128.93&quot;&#125;&#x27;</span><br><span class="line">curl -XPUT http://127.0.0.1:2379/v2/keys/skydns/tw/oc/node3 -d value=&#x27;&#123;&quot;host&quot;:&quot;10.202.128.76&quot;&#125;&#x27;</span><br></pre></td></tr></table></figure>
<ul>
<li>Configure node dns file <code>/etc/resolv.conf</code> with contents:</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">search oc.tw default.svc cluster.local</span><br><span class="line">nameserver 127.0.0.1</span><br><span class="line">nameserver 10.202.129.100</span><br></pre></td></tr></table></figure>
<ul>
<li>On every node, run <code>hostname node*.oc.tw</code> to correct the hostname (make it the same as it’s dns name)</li>
</ul>
<h2 id="installation"><a class="markdownIt-Anchor" href="#installation"></a> Installation</h2>
<ul>
<li>clone openshift repo: <code>git clone https://github.com/openshift/openshift-ansible.git</code></li>
<li>Prepare hosts file with contents</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Create OSEv3 group that contains the masters and nodes groups</span><br><span class="line">[OSEv3:children]</span><br><span class="line">masters</span><br><span class="line">nodes</span><br><span class="line">etcd</span><br><span class="line">nfs</span><br><span class="line"></span><br><span class="line"># Set variables common for all OSEv3 hosts</span><br><span class="line">[OSEv3:vars]</span><br><span class="line"># SSH user, this user should allow ssh based auth without requiring a password</span><br><span class="line">ansible_ssh_user=root</span><br><span class="line">openshift_deployment_type=origin</span><br><span class="line">openshift_release=3.6.0</span><br><span class="line">openshift_disable_check=disk_availability,docker_storage,memory_availability,docker_image_availability,package_availability,package_version</span><br><span class="line">openshift_metrics_install_metrics=true</span><br><span class="line">openshift_master_default_subdomain=apps.oc.tw</span><br><span class="line">openshift_logging_install_logging=true</span><br><span class="line">openshift_master_cluster_public_hostname=master.oc.tw</span><br><span class="line">openshift_hosted_registry_storage_kind=nfs</span><br><span class="line">openshift_hosted_registry_storage_access_modes=[&#x27;ReadWriteMany&#x27;]</span><br><span class="line">openshift_hosted_registry_storage_nfs_directory=/exports</span><br><span class="line">openshift_hosted_registry_storage_nfs_options=&#x27;*(rw,root_squash)&#x27;</span><br><span class="line">openshift_hosted_registry_storage_volume_name=registry</span><br><span class="line">openshift_hosted_registry_storage_volume_size=10Gi</span><br><span class="line">openshift_logging_storage_kind=nfs</span><br><span class="line">openshift_logging_storage_access_modes=[&#x27;ReadWriteOnce&#x27;]</span><br><span class="line">openshift_logging_storage_nfs_directory=/exports</span><br><span class="line">openshift_logging_storage_nfs_options=&#x27;*(rw,root_squash)&#x27;</span><br><span class="line">openshift_logging_storage_volume_name=logging</span><br><span class="line">openshift_logging_storage_volume_size=10Gi</span><br><span class="line">openshift_metrics_storage_kind=nfs</span><br><span class="line">openshift_metrics_storage_access_modes=[&#x27;ReadWriteOnce&#x27;]</span><br><span class="line">openshift_metrics_storage_nfs_directory=/exports</span><br><span class="line">openshift_metrics_storage_nfs_options=&#x27;*(rw,root_squash)&#x27;</span><br><span class="line">openshift_metrics_storage_volume_name=metrics</span><br><span class="line">openshift_metrics_storage_volume_size=10Gi</span><br><span class="line"></span><br><span class="line">openshift_master_identity_providers=[&#123;&#x27;name&#x27;:&#x27;htpasswd_auth&#x27;,&#x27;login&#x27;:&#x27;true&#x27;,&#x27;challenge&#x27;:&#x27;true&#x27;,&#x27;kind&#x27;:&#x27;HTPasswdPasswordIdentityProvider&#x27;,&#x27;filename&#x27;:&#x27;/etc/origin/master/htpasswd&#x27;&#125;]</span><br><span class="line"></span><br><span class="line"># host group for masters</span><br><span class="line">[masters]</span><br><span class="line">master.oc.tw openshift_public_hostname=master.oc.tw</span><br><span class="line"></span><br><span class="line"># host group for nodes, includes region info</span><br><span class="line">[nodes]</span><br><span class="line">master.oc.tw openshift_public_hostname=master.oc.tw</span><br><span class="line">node1.oc.tw openshift_node_labels=&quot;&#123;&#x27;region&#x27;:&#x27;infra&#x27;&#125;&quot; openshift_public_hostname=node1.oc.tw</span><br><span class="line">node2.oc.tw openshift_node_labels=&quot;&#123;&#x27;region&#x27;:&#x27;primary&#x27;&#125;&quot; openshift_public_hostname=node2.oc.tw</span><br><span class="line">node3.oc.tw openshift_node_labels=&quot;&#123;&#x27;region&#x27;:&#x27;primary&#x27;&#125;&quot; openshift_public_hostname=node3.oc.tw</span><br><span class="line"></span><br><span class="line">[etcd]</span><br><span class="line">master.oc.tw openshift_public_hostname=master.oc.tw</span><br><span class="line"></span><br><span class="line">[nfs]</span><br><span class="line">master.oc.tw</span><br></pre></td></tr></table></figure>
<ul>
<li>run <code>ansible-playbook -i ./hosts ~/openshift-ansible/playbooks/byo/config.yml</code> to install</li>
<li>run <code>ansible-playbook -i ./hosts ~/openshift-ansible/playbooks/adhoc/uninstall.yml</code> to uninstall. (ensure configurations are all removed, by checking <code>/etc/origin</code> folder on every node)</li>
</ul>
<h3 id="networkmanager-must-be-installed"><a class="markdownIt-Anchor" href="#networkmanager-must-be-installed"></a> NetworkManager must be installed</h3>
<ul>
<li>install NetworkManager on each node: run <code>yum install -y NetworkManager &amp;&amp; systemctl enable NetworkManager &amp;&amp; systemctl start NetworkManager</code> and <code>hostname master.oc.tw</code> to correct the hostname</li>
<li>pay attention to master/node restarting, since it will reconfigure the hostname, quickly run <code>hostname master.oc.tw</code> when you found out that (maybe configure NetworkManager to assign a static hostname will work as well)</li>
</ul>
<h3 id="cannot-find-file-etcoriginnoderesolvconf"><a class="markdownIt-Anchor" href="#cannot-find-file-etcoriginnoderesolvconf"></a> Cannot find file <code>/etc/origin/node/resolv.conf</code></h3>
<ul>
<li>Create resolv.conf on each node: <code>cp /etc/resolv.conf /etc/origin/node/resolv.conf</code></li>
</ul>
<h3 id="cannot-resolve-external-dns-eg-githubcom-from-container"><a class="markdownIt-Anchor" href="#cannot-resolve-external-dns-eg-githubcom-from-container"></a> Cannot resolve external dns (eg. <a href="http://github.com">github.com</a>) from container</h3>
<ul>
<li>edit file <code>/etc/dnsmasq.d/origin-dns.conf</code> to add <code>server=10.202.129.100</code></li>
<li>restart dnsmasq: <code>systemctl restart dnsmasq.service</code></li>
</ul>
<h3 id="sti-builder-cannot-push-image-to-docker-registrydefaultsvc5000-no-route-to-host"><a class="markdownIt-Anchor" href="#sti-builder-cannot-push-image-to-docker-registrydefaultsvc5000-no-route-to-host"></a> sti builder cannot push image to <code>docker-registry.default.svc:5000</code> (no route to host)</h3>
<ul>
<li>edit file /etc/resolve.conf on node with contents:</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">search oc.tw default.svc cluster.local</span><br><span class="line">nameserver 127.0.0.1</span><br><span class="line">nameserver 10.202.129.100</span><br></pre></td></tr></table></figure>
<h3 id="oc-get-nodes-on-master-raise-certificate-issue"><a class="markdownIt-Anchor" href="#oc-get-nodes-on-master-raise-certificate-issue"></a> <code>oc get nodes</code> on master raise certificate issue</h3>
<ul>
<li>run <code>cp -v /etc/origin/master/admin.kubeconfig .kube/config</code> to copy the config to your local</li>
</ul>
<h3 id="common-ways-to-debug"><a class="markdownIt-Anchor" href="#common-ways-to-debug"></a> Common ways to debug</h3>
<ul>
<li><code>systemctl status *.service</code></li>
<li><code>journalctl -xe</code></li>
<li><code>journalctl --unit dnsmasq</code></li>
</ul>
<h2 id="nfs-pv-configuration"><a class="markdownIt-Anchor" href="#nfs-pv-configuration"></a> nfs pv configuration</h2>
<h3 id="errors-from-oc-describe-pv-pv0001"><a class="markdownIt-Anchor" href="#errors-from-oc-describe-pv-pv0001"></a> Errors from <code>oc describe pv pv0001</code></h3>
<blockquote>
<p>Recycle failed: unexpected error creating recycler pod:  pods “recycler-for-pv0001” is forbidden: service account openshift-infra/pv-recycler-controller was not found, retry after the service account is created</p>
</blockquote>
<ul>
<li>Create sa: <code>oc create sa pv-recycler-controller -n openshift-infra</code></li>
<li>Config scc:<br />
<code>oadm policy add-scc-to-user hostmount-anyuid system:serviceaccount:openshift-infra:pv-recycler-controller</code></li>
</ul>
<h3 id="create-nfs-pv"><a class="markdownIt-Anchor" href="#create-nfs-pv"></a> Create nfs pv</h3>
<ul>
<li>Edit <code>/etc/exports.d/openshift-ansible.exports</code>, add lines like <code>/exports/pvs/pv0001 *(rw,root_squash)</code></li>
<li>Run: <code>mv /exports/pvs/pv0001 &amp;&amp; chown nfsnobody:nfsnobody /exports/pv0001 &amp;&amp; chmod 777 /exports/pv0001</code></li>
<li>Ensure mount in nodes work well by run <code>mount -t nfs master.oc.tw:/exports/pvs/pv0001 ./t</code></li>
<li>Create <code>pv.yml</code> with below and run <code>oc create -f pv.yml</code> to create pv:</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  name: pv0005</span><br><span class="line">spec:</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 10Gi</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteOnce</span><br><span class="line">  nfs:</span><br><span class="line">    path: /exports/pvs/pv0005</span><br><span class="line">    server: master.oc.tw</span><br><span class="line">  persistentVolumeReclaimPolicy: Recycle</span><br></pre></td></tr></table></figure>
<ul>
<li>Debug:
<ul>
<li><code>ps aux | grep mount</code> on node to see if it succeeded</li>
<li><code>oc describe po/xxx</code> on master to see the status of the container</li>
</ul>
</li>
</ul>
<h2 id="local-service-dns-resolution"><a class="markdownIt-Anchor" href="#local-service-dns-resolution"></a> Local service dns resolution</h2>
<ul>
<li>Find router node: <code>oc project default &amp;&amp; oc get all</code> to find router pod and <code>oc describe po/router-1-gsm7v</code> to find the node and record IP of that node</li>
<li>Edit local hosts file <code>/etc/hosts</code> and add contents<br />
10.202.128.77 <a href="http://kibana.apps.oc.tw">kibana.apps.oc.tw</a> <a href="http://hawkular-metrics.apps.oc.tw">hawkular-metrics.apps.oc.tw</a> <a href="http://nodejs-mongo-persistent-test.apps.oc.tw">nodejs-mongo-persistent-test.apps.oc.tw</a></li>
</ul>
<h2 id="logging-issue"><a class="markdownIt-Anchor" href="#logging-issue"></a> Logging issue</h2>
<p>EFK stack use kubernetes DaemonSet to schecule <code>logging-fluentd-xx</code> pod on every node to collect container logs.</p>
<ul>
<li>List DaemonSet <code>oc get ds</code> and make sure the pods count is the same as node count</li>
<li>Verify the DaemonSet settings <code>oc edit ds/logging-fluentd</code>. Check <code>nodeSelector</code> property.</li>
<li>Rsh into one of the fluentd pods, and check <code>run.sh</code> to find what is been done.</li>
<li>Add environment variables to help debug, edit the DaemonSet <code>oc edit ds/logging-fluentd</code> and add environment variables <code>ENABLE_MONITOR_AGENT=true;ENABLE_MONITOR_AGENT=true</code> (Refer <a href="https://docs.fluentd.org/v0.12/articles/monitoring">here</a>)</li>
</ul>
<h2 id="common-management-tasks"><a class="markdownIt-Anchor" href="#common-management-tasks"></a> Common management tasks</h2>
<ul>
<li>Login as admin: ssh into master and you’ll be admin directly when you run <code>oc</code> commands</li>
<li>Add user through htpasswd: run <code>htpasswd -b /etc/origin/master/htpasswd admin admin</code> on master</li>
<li>Add project to user: <code>oadm policy add-role-to-user admin gmliao -n logging</code></li>
</ul>
<h2 id="node-management"><a class="markdownIt-Anchor" href="#node-management"></a> Node Management</h2>
<h3 id="add-node"><a class="markdownIt-Anchor" href="#add-node"></a> Add node</h3>
<p>Refer here: <a href="https://docs.openshift.org/latest/install_config/adding_hosts_to_existing_cluster.html#adding-nodes-advanced">https://docs.openshift.org/latest/install_config/adding_hosts_to_existing_cluster.html#adding-nodes-advanced</a></p>
<ul>
<li>Add <code>new_nodes</code> or <code>new_masters</code> to <code>[OSEv3:vars]</code> section</li>
<li>Add a new section:</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[new_nodes]</span><br><span class="line">node1.oc.tw openshift_node_labels=&quot;&#123;&#x27;region&#x27;:&#x27;infra&#x27;&#125;&quot; openshift_public_hostname=node1.oc.tw</span><br><span class="line">node2.oc.tw openshift_node_labels=&quot;&#123;&#x27;region&#x27;:&#x27;primary&#x27;&#125;&quot; openshift_public_hostname=node2.oc.tw</span><br></pre></td></tr></table></figure>
<ul>
<li>Run installation: <code>ansible-playbook -i hosts ~/openshift-ansible/playbooks/byo/openshift-node/scaleup.yml</code></li>
<li>Move nodes configured in <code>[new_nodes]</code> section to <code>[nodes]</code> section</li>
</ul>
<h3 id="remove-node"><a class="markdownIt-Anchor" href="#remove-node"></a> Remove node</h3>
<p>Refer here: <a href="https://docs.openshift.org/latest/admin_guide/manage_nodes.html#deleting-nodes">https://docs.openshift.org/latest/admin_guide/manage_nodes.html#deleting-nodes</a></p>
<h2 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h2>
<ul>
<li><a href="https://docs.openshift.org/latest/install_config/install/advanced_install.html">https://docs.openshift.org/latest/install_config/install/advanced_install.html</a></li>
<li><a href="https://kubernetes.io/docs/setup/">https://kubernetes.io/docs/setup/</a></li>
</ul>
]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>DevOps</tag>
        <tag>OpenShift</tag>
        <tag>PAAS</tag>
        <tag>Cluster</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenShift工作坊</title>
    <url>/2017/10/28/openshift-workshop/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h2 id="target"><a class="markdownIt-Anchor" href="#target"></a> Target</h2>
<ul>
<li>A simple nodejs application</li>
<li>Add mongodb to the application</li>
<li>CI/CD for the application</li>
<li>Logging, Monitoring, Debugging</li>
</ul>
<h2 id="a-simple-nodejs-application"><a class="markdownIt-Anchor" href="#a-simple-nodejs-application"></a> A simple nodejs application</h2>
<h3 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h3>
<p>In this section, We are going to create a nodejs project with mongodb in OpenShift. We assume that you have done all the preparation work listed in the invitation email of this workshop. And there’re some additional steps to  get yourself ready.</p>
<span id="more"></span>
<h3 id="preparation"><a class="markdownIt-Anchor" href="#preparation"></a> Preparation</h3>
<ul>
<li>
<p>Install <code>oc</code> in your mac:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">brew update </span><br><span class="line">brew install openshift-cli</span><br><span class="line">oc version                     # the version should be oc v1.5.1+7b451fc</span><br></pre></td></tr></table></figure>
<p>You can also download it’s here: <a href="https://github.com/openshift/origin/releases/download/v1.5.1/openshift-origin-client-tools-v1.5.1-7b451fc-mac.zip">https://github.com/openshift/origin/releases/download/v1.5.1/openshift-origin-client-tools-v1.5.1-7b451fc-mac.zip</a></p>
</li>
<li>
<p>fork <a href="https://github.com/openshift/nodejs-ex">the demo project</a> to your own github account and get the repository url:</p>
<p><code>https://github.com/&lt;your-github-name&gt;/nodejs-ex.git</code></p>
</li>
<li>
<p>clone code</p>
<p><code>git clone https://github.com/&lt;your-github-name&gt;/nodejs-ex.git</code></p>
</li>
<li>
<p>clone configuration files</p>
<p><code>git clone https://github.com/gmlove/openshift-workshop.git</code></p>
<p>Files in this repo will be used later.</p>
</li>
<li>
<p>log on to OpenShift web console</p>
<p>In browser, navigate to <code>https://13.228.41.255:8443</code> and login with any username and password you’d like to use. OpenShift will create that account for you.</p>
</li>
</ul>
<h3 id="login"><a class="markdownIt-Anchor" href="#login"></a> Login</h3>
<ul>
<li>
<p><code>oc login https://13.228.41.255:8443</code>  and input your username and password:</p>
<blockquote>
<p>Authentication required for <a href="https://13.228.41.255:8443">https://13.228.41.255:8443</a> (openshift)</p>
<p>Username: <your-username></p>
<p>Password: <your-password></p>
</blockquote>
</li>
<li>
<p>check status</p>
<p><code>oc status</code></p>
<blockquote>
<p>You don’t have any projects. You can try to create a new project, by running</p>
<p>oc new-project <projectname></p>
</blockquote>
</li>
<li>
<p>check project</p>
<p><code>oc project</code></p>
<blockquote>
<p>No project has been set. Pass a project name to make that the default.</p>
</blockquote>
</li>
</ul>
<h3 id="create-project"><a class="markdownIt-Anchor" href="#create-project"></a> Create project</h3>
<p><code>oc new-project &lt;your-project-name&gt;</code></p>
<h3 id="create-applicatioin"><a class="markdownIt-Anchor" href="#create-applicatioin"></a> Create applicatioin</h3>
<ul>
<li>
<p>create a new application with your own git repository url</p>
<p><code>oc new-app https://github.com/&lt;your-github-name&gt;/nodejs-ex.git</code></p>
<blockquote>
<p>you can specify the application name with a parameter <code>--name &lt;application-name&gt;</code></p>
</blockquote>
</li>
</ul>
<h3 id="create-route"><a class="markdownIt-Anchor" href="#create-route"></a> Create route</h3>
<ul>
<li>
<p>expose service</p>
<p><code>oc expose service/nodejs-ex</code></p>
</li>
<li>
<p>get route url</p>
<p><code>oc get route</code></p>
<blockquote>
<p>your route url should look like this:</p>
<p>nodejs-ex-&lt;your-project-name&gt;.13.228.41.255.xip.io</p>
</blockquote>
</li>
<li>
<p>check out the url in web browser you’ll see the welcome page</p>
</li>
</ul>
<h3 id="build-deploy"><a class="markdownIt-Anchor" href="#build-deploy"></a> Build &amp; deploy</h3>
<ul>
<li>
<p>build</p>
<p><code>oc start-build nodejs-ex</code></p>
<blockquote>
<p>A build will be triggered automatically once the application is created successfully.</p>
</blockquote>
</li>
<li>
<p>deploy</p>
<p><code>oc deploy --latest dc/nodejs-ex</code></p>
<blockquote>
<p>A deployment will be triggered automatically when a build is finished successfully.</p>
</blockquote>
</li>
</ul>
<h3 id="add-webhook"><a class="markdownIt-Anchor" href="#add-webhook"></a> Add Webhook</h3>
<ul>
<li>
<p>Copy webhook url</p>
<p>In OpenShift web console, go to <code>Builds</code> -&gt; click <code>&lt;your-build-config-name&gt;</code> -&gt; switch to <code>Configuraton</code> tab -&gt;<br />
copy the url on the right of <code>GitHub Webhook URL:</code></p>
</li>
<li>
<p>Config Webhook in github</p>
<ul>
<li>
<p>Go to web browser with url: <code>https://github.com/&lt;your-github-name&gt;/nodejs-ex.git</code></p>
</li>
<li>
<p>Switch to <code>Settings</code> tab below the project name</p>
</li>
<li>
<p>Click <code>Webhooks</code> item in left menu panel and then Click <code>Add Webhook</code> button</p>
</li>
<li>
<p>Paste the webhook URL in field <code>Payload URL</code>, select <code>application/json</code> in <code>Content type</code> field, click <code>disable ssl verification</code></p>
</li>
<li>
<p>Click <code>Add webhook</code> at the bottom and you’ll return to previous page</p>
</li>
<li>
<p>Github will test the webhook automatically, if succeed, it will place a green mark before the url.</p>
</li>
<li>
<p>done</p>
</li>
</ul>
</li>
<li>
<p>Vefiry Webhook</p>
<ul>
<li>
<p>modify code and commit your changes</p>
<p>modify &lt;code-dir&gt;/nodejs-ex/views/index.html line 219</p>
<p><code>Welcome to your Node.js</code> to <code>This is my awesome Node.js</code></p>
<p>push your changes to github</p>
</li>
<li>
<p>check your changes in web browser</p>
<p>in OpenShift web console you’ll see a build &amp; deployment is triggered automatically</p>
<p>you’ll see the tilte of the page changed from <code>Welcome to your Node.js</code> to <code>This is my awesome Node.js</code> afterh the app is re-deployed.</p>
</li>
</ul>
</li>
</ul>
<h3 id="rollback"><a class="markdownIt-Anchor" href="#rollback"></a> Rollback</h3>
<ul>
<li>
<p>rollback to the last successful deployment</p>
<p><code>oc rollback dc/nodejs-ex</code> or <code>oc rollout undo dc/nodejs-ex</code></p>
<p>you’ll get the following messages:</p>
<blockquote>
<p>Warning: the following images triggers were disabled: nodejs-ex:latest</p>
<p>You can re-enable them with: oc set triggers dc/nodejs-ex --auto</p>
</blockquote>
<p>The message means after a build finished, OpenShift will no longer trigger an automatic deployment. You can re-enable it use the command given in the message if you would like to.</p>
<blockquote>
<p>You can also rollback to a specified deployment with the following command:</p>
<p><code>oc rollout undo dc/nodejs-ex --to-revision=1</code> or <code>oc rollback nodejs-ex --to-version=1</code></p>
</blockquote>
</li>
</ul>
<h3 id="scale-updown"><a class="markdownIt-Anchor" href="#scale-updown"></a> Scale up/down</h3>
<ul>
<li>
<p>scale manually</p>
<p>scale up to 2 pods</p>
<p><code>oc scale dc/nodejs-ex --replicas=2</code></p>
<p>now you can scale down to 1 pod</p>
<p><code>oc scale dc/nodejs-ex --replicas=1</code></p>
</li>
<li>
<p>auto scaling</p>
<ul>
<li>
<p>edit DeployConfig in web console</p>
<p><code>Applications</code> -&gt; <code>Deployment</code> -&gt; <code>&lt;your-deploy-config-name&gt;</code> -&gt; <code>Action</code> menu -&gt; <code>Edit YAML</code></p>
<p>replace <code>resources:&#123;&#125;</code> with the following content:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">resources:</span></span><br><span class="line">  <span class="attr">limits:</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">  <span class="attr">requests:</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="string">100m</span></span><br></pre></td></tr></table></figure>
<p>and the yaml script will looks like this:</p>
</li>
</ul>
 <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nodejs-ex</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">&gt;-</span></span><br><span class="line"><span class="string">        172.30.1.1:5000/leojiangproject/nodejs-ex@sha256:eac764a3e2366e929dd00e8558d9433d3f81bf590e09340527a8e839cf0fe551</span></span><br><span class="line"><span class="string"></span>      <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span></span><br><span class="line">          <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">resources:</span></span><br><span class="line">        <span class="attr">limits:</span></span><br><span class="line">          <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">        <span class="attr">requests:</span></span><br><span class="line">          <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">      <span class="attr">terminationMessagePath:</span> <span class="string">/dev/termination-log</span></span><br><span class="line">      <span class="attr">imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Always</span></span><br><span class="line">  <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">30</span></span><br><span class="line">  <span class="attr">dnsPolicy:</span> <span class="string">ClusterFirst</span></span><br><span class="line">  <span class="attr">securityContext:</span> &#123;&#125;</span><br></pre></td></tr></table></figure>
<p>Back to <code>overview</code> in web console, you’ll see an error at the top, click on the url and trust the site.</p>
<p>Now you can see metrics in <code>overview</code> panel.</p>
<ul>
<li>
<p>config autoscaler with command</p>
<p><code>oc autoscale dc/nodejs-ex --min 1 --max 10 --cpu-percent=10</code></p>
</li>
<li>
<p>verify</p>
<p>send batch request with command: <code>ab -n 1000 -c 100 http://&lt;route-of-your-application&gt;</code></p>
<p>Wait and you’ll see the pod number is scaled to 2</p>
</li>
</ul>
</li>
</ul>
<h2 id="add-mongodb-to-the-application"><a class="markdownIt-Anchor" href="#add-mongodb-to-the-application"></a> Add mongodb to the application</h2>
<h3 id="deploy-a-database-with-persistent-volume"><a class="markdownIt-Anchor" href="#deploy-a-database-with-persistent-volume"></a> Deploy a database with persistent volume</h3>
<ul>
<li>
<p><code>cd</code> to the directory where you downloaded the configuration files earlier.</p>
</li>
<li>
<p>crete secret</p>
<p><code>oc create -f mongodb-secrets.yaml</code></p>
</li>
<li>
<p>check secret</p>
<p><code>oc describe secret nodejs-ex</code></p>
</li>
<li>
<p>create persistent volume claim</p>
<p><code>oc create -f mongodb-pvc.yaml</code></p>
</li>
<li>
<p>check persistent volume claim</p>
<p><code>oc get pvc</code></p>
</li>
<li>
<p>create mongodb deployment config</p>
<p><code>oc create -f mongodb-deploy-config.yaml</code></p>
</li>
<li>
<p>create a mongodb service</p>
<p><code>oc create -f mongodb-service.yaml</code></p>
</li>
<li>
<p>trigger a deployment for mongodb (if not triggered automatically)</p>
<p><code>oc rollout latest dc/mongodb</code></p>
</li>
</ul>
<h3 id="connect-nodejs-application-to-database"><a class="markdownIt-Anchor" href="#connect-nodejs-application-to-database"></a> Connect nodejs application to database</h3>
<ul>
<li>
<p>change deployment config and add environment parameters</p>
<p>In web console, go to <code>Applications</code> -&gt; <code>Deployment</code> -&gt; <code>&lt;your-deploy-config-name&gt;</code> -&gt; <code>Action</code> menu -&gt; <code>Edit YAML</code></p>
<p>add the following content under <code>caontaners</code> tag:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">env:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">DATABASE_SERVICE_NAME</span></span><br><span class="line">    <span class="attr">value:</span> <span class="string">mongodb</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MONGODB_USER</span></span><br><span class="line">    <span class="attr">valueFrom:</span></span><br><span class="line">      <span class="attr">secretKeyRef:</span></span><br><span class="line">        <span class="attr">key:</span> <span class="string">database-user</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nodejs-ex</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MONGODB_PASSWORD</span></span><br><span class="line">    <span class="attr">valueFrom:</span></span><br><span class="line">      <span class="attr">secretKeyRef:</span></span><br><span class="line">        <span class="attr">key:</span> <span class="string">database-password</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nodejs-ex</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MONGODB_DATABASE</span></span><br><span class="line">    <span class="attr">value:</span> <span class="string">sampledb</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MONGODB_ADMIN_PASSWORD</span></span><br><span class="line">    <span class="attr">valueFrom:</span></span><br><span class="line">      <span class="attr">secretKeyRef:</span></span><br><span class="line">        <span class="attr">key:</span> <span class="string">database-admin-password</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nodejs-ex</span></span><br></pre></td></tr></table></figure>
<p>the resulting yaml script will looks like this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nodejs-ex</span></span><br><span class="line">      <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">DATABASE_SERVICE_NAME</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">mongodb</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MONGODB_USER</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">secretKeyRef:</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">database-user</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">nodejs-ex</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MONGODB_PASSWORD</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">secretKeyRef:</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">database-password</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">nodejs-ex</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MONGODB_DATABASE</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">sampledb</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">MONGODB_ADMIN_PASSWORD</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">secretKeyRef:</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">database-admin-password</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">nodejs-ex</span></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>trigger a deployment for nodejs-ex</p>
<p><code>oc rollout latest dc/nodejs-ex</code></p>
</li>
<li>
<p>check</p>
<p>In you browser, open the application with url <code>nodejs-ex-testproject.13.228.41.255.xip.io</code>, and check the <code>Page view count</code> in the web page, it should be counting.</p>
</li>
</ul>
<h2 id="cicd-for-the-application"><a class="markdownIt-Anchor" href="#cicd-for-the-application"></a> CI/CD for the application</h2>
<p><strong>Several ways to integrate pipeline:</strong></p>
<ul>
<li>Keep using the original pipeline and artifact repository. Manage your pipeline outside of openshift world. When you need to deploy to an environment, you can trigger a build in openshift to grab your artifact and build an image and deploy it to openshift.</li>
<li>Use openshift integrated Jenkins as your pipeline. (heavily customized, with openshift plugin and k8s plugin installed.)</li>
</ul>
<p><img data-src="/attaches/2017/2017-10-28-openshift-workshop/pipeline-structure.png" alt="Openshift Pipeline Structure" /></p>
<h3 id="integrate-jenkins-with-the-application"><a class="markdownIt-Anchor" href="#integrate-jenkins-with-the-application"></a> Integrate Jenkins with the application</h3>
<ul>
<li>
<p>Create a pipeline build config</p>
<p>Create a file named <code>nodejs-ex-pipeline.yaml</code> with content (already created for you):</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">&quot;BuildConfig&quot;</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">&quot;v1&quot;</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">&quot;nodejs-ex-pipeline&quot;</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">strategy:</span></span><br><span class="line">    <span class="attr">jenkinsPipelineStrategy:</span></span><br><span class="line">      <span class="attr">jenkinsfile:</span> <span class="string">&quot;node(&#x27;nodejs&#x27;) &#123;\n  stage &#x27;build&#x27;\n  openshiftBuild(buildConfig: &#x27;nodejs-ex&#x27;, showBuildLogs: &#x27;true&#x27;)\n  stage &#x27;deploy&#x27;\n  openshiftDeploy(deploymentConfig: &#x27;nodejs-ex&#x27;)\n&#125;\n&quot;</span></span><br></pre></td></tr></table></figure>
<p>To create a pipeline, run:<br />
<code>oc create -f nodejs-ex-pipeline.yaml</code></p>
<p>Openshift will add the resources below to the project:</p>
<ul>
<li>route <code>routes/jenkins</code></li>
<li>services <code>svc/jenkins</code> <code>svc/jenkins</code></li>
</ul>
</li>
<li>
<p>Run <code>oc status</code> to get your dns of the jenkins application. Then you can open it in your browser and perform an oauth login with openshift credentials.</p>
</li>
<li>
<p>Trigger a build manually and you can check logs from jenkins. You can also find what is openshift doing by <code>watch oc get all</code></p>
<ul>
<li>
<p>Openshift creates a slave based on the node being used, here it’s <code>nodejs</code></p>
</li>
<li>
<p>Run the build in that slave</p>
</li>
<li>
<p>For our simple example, the pipeline has two steps: trigger a build(works just like <code>oc start-build bc/nodejs-ex</code>), and then trigger a deployment</p>
</li>
</ul>
</li>
</ul>
<h3 id="multiple-environment-management"><a class="markdownIt-Anchor" href="#multiple-environment-management"></a> Multiple environment management</h3>
<p>In openshift you define several resources (API Objects) and you can start an environment. So multi environment means multiple similar resource sets. To manage multiple environment, you have many options, such as:</p>
<ul>
<li>Via labels and unique naming within a single project</li>
<li>Via distinct projects within a cluster</li>
<li>Via distinct clusters</li>
</ul>
<p>Consider your situation in your organization and choose one properly. We’ll try the second one as an example and create a <code>sys</code> region for the application. We’ll develop a way to share the image created in the project (can be called as dev project).</p>
<ul>
<li>
<p>Spend some time thinking about which resources you will need for another environment (ImageStream DeploymentConfig Service Route PersistentVolumeClaim)</p>
</li>
<li>
<p>Tag all the resources to export</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">oc label dc/mongodb promotion=nodejs-ex</span><br><span class="line">oc label dc/nodejs-ex promotion=nodejs-ex</span><br><span class="line">oc label svc/nodejs-ex promotion=nodejs-ex</span><br><span class="line">oc label svc/mongodb promotion=nodejs-ex</span><br><span class="line">oc label routes/nodejs-ex promotion=nodejs-ex</span><br><span class="line">oc label pvc/mongodb promotion=nodejs-ex</span><br><span class="line">oc label is/nodejs-ex promotion=nodejs-ex</span><br><span class="line">oc label secret/nodejs-ex promotion=nodejs-ex</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Export those resources</p>
<p><code>oc export dc,svc,routes,pvc,is,secret -l promotion=nodejs-ex -o yaml &gt; exported-for-promotion.yaml</code></p>
</li>
<li>
<p>Open the exported file and do the below to make it portable to <code>sys</code> environment:</p>
<ul>
<li>Remove image hash tag</li>
<li>Replace all string <code>test1</code> to <code>test1-sys</code> and we’re creating a project named <code>test1-sys</code></li>
<li>Remove <code>annotations</code> <code>volumeName</code> <code>status</code> <code>creationTimestamp</code> from <code>PersistentVolumeClaim</code></li>
</ul>
</li>
<li>
<p>Create a new project by <code>oc new-project test1-sys</code></p>
</li>
<li>
<p>Create resources by <code>oc create -f exported-for-promotion.yaml</code></p>
</li>
<li>
<p>Tag an image from test1</p>
<p><code>oc tag test1/nodejs-ex:latest nodejs-ex:latest</code></p>
</li>
<li>
<p>After that you can trigger a deployment, and after it succeeded, you will be able to open the application in <code>sys</code> environment</p>
</li>
<li>
<p>Try create a template for these resources and then you can create any new environment with one command</p>
</li>
</ul>
<h2 id="logging-monitoring-debugging"><a class="markdownIt-Anchor" href="#logging-monitoring-debugging"></a> Logging, Monitoring, Debugging</h2>
<h3 id="logging-aggregation"><a class="markdownIt-Anchor" href="#logging-aggregation"></a> Logging aggregation</h3>
<ul>
<li>
<p>EFK solution, check a video <a href="https://www.youtube.com/watch?v=RMDX3YC0CSQ">here</a></p>
</li>
<li>
<p>Start the cluster with logging and metrics installed:</p>
<p><code>oc cluster up --logging --metrics</code></p>
<p>There is a bug for logging currently: <a href="https://bugzilla.redhat.com/show_bug.cgi?id=1410694">https://bugzilla.redhat.com/show_bug.cgi?id=1410694</a></p>
</li>
</ul>
<h3 id="monitoring-solutions"><a class="markdownIt-Anchor" href="#monitoring-solutions"></a> Monitoring solutions</h3>
<ul>
<li>
<p>Prometheus/zabbix/hawk: <a href="https://github.com/openshift/openshift-tools/tree/stg/openshift_tools/monitoring">https://github.com/openshift/openshift-tools/tree/stg/openshift_tools/monitoring</a></p>
<p>An example to setup prometheus and grafana: <a href="https://github.com/debianmaster/openshift-examples/tree/master/promethus">https://github.com/debianmaster/openshift-examples/tree/master/promethus</a><br />
We created a monitor service already: <a href="http://grafana-openshift-infra.13.228.41.255.xip.io">http://grafana-openshift-infra.13.228.41.255.xip.io</a> (admin:admin)</p>
</li>
<li>
<p>dynatrace/coscale/sysdig/appdynamics</p>
</li>
</ul>
<h3 id="debugging"><a class="markdownIt-Anchor" href="#debugging"></a> Debugging</h3>
<ul>
<li>To monitor the change of all resources: <code>watch oc get all</code></li>
<li>Check logs of pods: <code>oc logs po/nodejs-ex-1-0s5sl</code></li>
<li>Check events: <code>oc get event</code></li>
<li>Login to container: <code>oc rsh po/nodejs-ex-1-0s5sl</code></li>
</ul>
]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>DevOps</tag>
        <tag>OpenShift</tag>
        <tag>PAAS</tag>
        <tag>Cluster</tag>
      </tags>
  </entry>
  <entry>
    <title>5行代码的自动评论机器人</title>
    <url>/2017/12/07/automated-comment-on-xiaomi-s-live-stream/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>又到小米发布会了，这次发布会将从发布评论的人里面选人，每分钟送一台小米手机。<br />
于是写了几行代码自动发评论，省去了手工的麻烦。娱乐一下，碰个运气。</p>
<p>直播地址：<a href="https://hd.mi.com/x/12041b/index.html?client_id=180100041086&amp;masid=17409.0195">https://hd.mi.com/x/12041b/index.html?client_id=180100041086&amp;masid=17409.0195</a></p>
<p>代码如下：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 随机选择一个当前评论列表里面的评论</span></span><br><span class="line"><span class="keyword">var</span> <span class="title function_">r</span> = (<span class="params"></span>) =&gt; <span class="title class_">Math</span>.<span class="title function_">floor</span>((<span class="title class_">Math</span>.<span class="title function_">random</span>() * $(<span class="string">&#x27;.livechat-list-wrapper .list li&#x27;</span>).<span class="property">length</span>))</span><br><span class="line"><span class="comment">// 提取选中的评论的内容</span></span><br><span class="line"><span class="keyword">var</span> <span class="title function_">text</span> = (<span class="params"></span>) =&gt; $($(<span class="string">&#x27;.livechat-list-wrapper .list li&#x27;</span>)[<span class="title function_">r</span>()]).<span class="title function_">find</span>(<span class="string">&#x27;.content&#x27;</span>).<span class="title function_">text</span>()</span><br><span class="line"><span class="comment">// 使用选中的内容自动发评论</span></span><br><span class="line"><span class="keyword">var</span> <span class="title function_">c</span> = (<span class="params"></span>) =&gt; &#123;$(<span class="string">&#x27;#J_chatContent&#x27;</span>).<span class="title function_">val</span>(<span class="title function_">text</span>());$(<span class="string">&#x27;#J_sendChatBtn&#x27;</span>).<span class="title function_">attr</span>(<span class="string">&#x27;class&#x27;</span>, <span class="string">&#x27;btn active&#x27;</span>);$(<span class="string">&#x27;#J_sendChatBtn&#x27;</span>).<span class="title function_">click</span>();&#125;</span><br><span class="line"><span class="comment">// 生成随机的间隔时间</span></span><br><span class="line"><span class="keyword">var</span> <span class="title function_">rtime</span> = (<span class="params"></span>) =&gt; <span class="title class_">Math</span>.<span class="title function_">floor</span>(<span class="title class_">Math</span>.<span class="title function_">random</span>() * <span class="number">15000</span> + <span class="number">5000</span>)</span><br><span class="line"><span class="comment">// 设置一个计时器定时发评论</span></span><br><span class="line"><span class="keyword">var</span> <span class="title function_">st</span> = (<span class="params"></span>) =&gt; stt = <span class="built_in">setTimeout</span>(<span class="function">() =&gt;</span> &#123;<span class="title function_">c</span>(); <span class="title function_">st</span>()&#125;, <span class="title function_">rtime</span>())</span><br><span class="line"><span class="title function_">st</span>();</span><br></pre></td></tr></table></figure>
<p>以上代码粘贴到控制台执行就可以了。</p>
]]></content>
      <categories>
        <category>小技巧</category>
      </categories>
      <tags>
        <tag>自动化</tag>
      </tags>
  </entry>
  <entry>
    <title>强化学习 - MDP</title>
    <url>/2018/05/06/reinforcement-learning-mdp/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>做一个小demo来演示强化学习的入门问题–MDP问题的解决。</p>
]]></content>
      <categories>
        <category>machine-learning</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>Reinforcement Learning</tag>
        <tag>MDP</tag>
        <tag>Markov Decision Process</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型重现 -- DORN</title>
    <url>/2019/07/08/reproduce-ml-models-dorn/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h2 id="dorn模型的重现"><a class="markdownIt-Anchor" href="#dorn模型的重现"></a> DORN模型的重现</h2>
<p>DORN模型是在单图像深度估计问题上效果非常好的模型，18年刚发布的时候，就同时在KITTI数据集和ScanNet数据集上面取得了<a href="http://www.robustvision.net/leaderboard.php?benchmark=depth">Robust Vision</a>挑战的第一名。</p>
<span id="more"></span>
<p><img data-src="/attaches/2019/2019-07-08-reproduce-ml-models-dorn/robustvision-challenge.png" alt="排名截图" /></p>
<p>为什么能大幅优于其他模型呢？论文里面讲得比较清楚，主要在于两个方面，一是基础模型能更好的提取特征，二是基于距离递增的序数回归损失函数设计。</p>
<p>基础模型这一块对于我们基本上还是一个黑盒，难以理论证明。现有的优化手段也基本上都是先实验证明有效，再尝试给出一个大致可信的理由。DORN的基础模型比较复杂，但是它真的会比我们常用的resnet或者inception更好吗？很难说。但是损失函数的设计不得不说是一个亮点，下面我们主要针对这一方面进行讨论。</p>
<h3 id="问题理解"><a class="markdownIt-Anchor" href="#问题理解"></a> 问题理解</h3>
<p><img data-src="/attaches/2019/2019-07-08-reproduce-ml-models-dorn/dorn-model.png" alt="DORN模型截图" /></p>
<p>单图像深度估计(单目图像深度估计)问题本身其实是一个不适定(ill-posed)问题，就是说最终的预测结果不是唯一的，也不是稳定的，而是依赖于具体的条件。实际上可以有无限种3D环境可以产生同样的2D图像。但是对于给定的同样的摄像头，同样的拍摄焦距，我们大致可以认为这个问题的解是稳定的。单图像深度估计应用场景非常广泛，因为它可以直接实现基于图片的三维重建，成本非常低。</p>
<p>这个问题很早就已经开始有研究了，下面几篇文章从不同角度研究了这个问题：</p>
<ul>
<li><a href="https://arxiv.org/pdf/1406.2283.pdf">Depth Map Prediction from a Single Image using a Multi-Scale Deep Network (2014 NIPS</a></li>
<li><a href="https://arxiv.org/pdf/1411.4734.pdf">Predicting Depth, Surface Normals and Semantic Labels with a Common Multi-Scale Convolutional Architecture (ICCV 2015)</a></li>
<li><a href="https://arxiv.org/pdf/1606.00373.pdf">Deeper Depth Prediction with Fully Convolutional Residual Networks(FCRN)</a></li>
</ul>
<p>总体上看，对于这种深度预测问题，当前流行的处理方式都是采用与图像分割类似的模型进行建模，模型输入一张图像，输出跟原图同样大小的一维深度图。模型使用全卷积网络完成端到端的训练，速度快而且效果好。</p>
<p>在设计损失函数的时候，最直接的办法当然是把这个问题当成一个回归问题来处理，直接用平均绝对值损失(Mean ABS Error)或者均方损失(MSE)就可以了。但是这样往往收敛缓慢，而且难以正确捕捉局部相似的特征（对于同一个物体，其像素值对应的深度值一般是非常接近的），最终导致模型效果差。DORN创造性的提出了一种办法，将回归问题转换为分类问题，而且用序数回归的方式捕捉各个分类间的联系，从而既让模型加速了收敛，又提高了精度。具体是如何做的呢？</p>
<h3 id="离散化"><a class="markdownIt-Anchor" href="#离散化"></a> 离散化</h3>
<p><img data-src="/attaches/2019/2019-07-08-reproduce-ml-models-dorn/depth-demo.png" alt="示例深度图像" /></p>
<p>要将回归转化为分类，其实很简单，我们只需要对连续的深度值做一个离散化处理就行了。比如KITTI的数据集中包含了0-80米的深度值，我们可以将这些深度值分别映射到8个类里面，0-10米算分类1,10-20米算分类2，依次类推。离散化之后，每一个像素值的标签就变成了一个分类标签，我们就可以将问题转化为分类问题了。这种简单的离散化方法，我们可以称其为平均离散。平均离散对于我们这个问题是否有效呢？细想一下就会觉得这种方法不适合我们深度估计的场景。参考上图，两辆汽车，都离摄像头比较近，它们之间也比较近，它们占据了大量的图像像素，这时我们可以容易的估计出两个物体有多远。同样是两辆车，保持差不多的距离，但是都离摄像头比较远，由于远的物体占据的图像像素数量少，我们难以估计两个物体的相差多远。从这里我们可以得出结论，离摄像头较近的像素，由于从图像中得到的信息更多，估计结果应该更准确，而离摄像头较远的像素，估计结果会比较不准确。也就是说事实上我们可以允许较远的物体更多的分到同一个类，而较近的物体应该尽量用不同的类去近似。如果使用平均离散的方式，其实是忽略了这样的事实，因为它只关注到了深度的绝对差值，而忽略了深度值本身大小带来的影响。更好的离散化方式是怎么样的呢？DORN模型提出了一种按距离增加的离散化方式：</p>
<p><img data-src="/attaches/2019/2019-07-08-reproduce-ml-models-dorn/SID.png" alt="SID" /></p>
<p>对应的离散点计算公式是： <code>t[i] = e^(log(a) + (log(b/a)*i/k))</code> 我们可以称这种离散化方式为指数离散。采用指数离散，更符合图像实际情况，可以让模型更容易的收敛。</p>
<p>现在我们得到每个像素的分类了，是不是我们可以直接用Softmax交叉熵损失来作为损失函数了呢？当然是可以的，但是如果直接用这种方式，效果可能是不够好的，因为对于Softmax分类问题，我们实际上是将每个分类当做完全独立的分类去处理的，任意两个分类间都没有关系。我们的问题却不是这样的，我们的问题中，邻接的两个分类是明显的递增关系。用Softmax建模时忽略了这种重要的关系。如何在损失函数中反映出不同类间的这种递增关系呢？那就是序数回归损失了。</p>
<h3 id="序数回归"><a class="markdownIt-Anchor" href="#序数回归"></a> 序数回归</h3>
<p>什么是序数回归？参考<a href="https://en.wikipedia.org/wiki/Ordinal_regression">wiki</a>，我们可以了解到，这种回归方式是用于预测一个序数变量，比如对于商家的1-5星评分就是这样的一个序数变量。序数回归具体如何做呢？下面这个与Softmax的比较可以说明这个问题。</p>
<p><img data-src="/attaches/2019/2019-07-08-reproduce-ml-models-dorn/ordinal-regression.png" alt="序数回归" /></p>
<p>也就是对于每一个类，我们用一组相互间有关系的数去表示。分类1用<code>[1 0 0 0 0]</code>，分类2用<code>[1 1 0 0 0]</code>，这样就建立起分类间的关系了。</p>
<p>有了上面的基础知识，我们就可以用下面的公式来计算序数损失了。</p>
<p><img data-src="/attaches/2019/2019-07-08-reproduce-ml-models-dorn/ordinal-regression-formula.png" alt="序数回归损失公式" /></p>
<p>如果大家熟悉Softmax的计算公式，那么对于这个公式应该很容易理解，几乎就是它的一个变形。这里就不赘述了，想了解细节，大家可以参阅原论文。</p>
<p>弄清楚了DORN的主要改进方法，我们就可以着手在我们的模型上面去实现了。我们先构造一个UNET模型，将UNET的输出的channel数量设置为2K(K为我们预先设定的分类数量)，然后将这2K个数按照上述公式进行计算就得出损失了。损失函数实现代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Discretizer</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, alpha, beta, K</span>):</span><br><span class="line">        self.alpha, self.beta, self.K = alpha, beta, K</span><br><span class="line">        eta = (<span class="number">1</span> - alpha)</span><br><span class="line">        alpha_star, beta_star = alpha + eta, beta + eta</span><br><span class="line">        self.T = T = [math.<span class="built_in">pow</span>(math.e, math.log(alpha_star) + math.log(beta_star / alpha_star) * i / K) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(K)][<span class="number">1</span>:]</span><br><span class="line">        T = [<span class="number">1</span>] + T + [beta_star, beta_star]</span><br><span class="line">        self.embedding = [((T[i] + T[i + <span class="number">1</span>]) / <span class="number">2</span> - eta) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(T) - <span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, v</span>):</span><br><span class="line">        original_shape = tf.shape(v)</span><br><span class="line">        v = tf.reshape(v, (-<span class="number">1</span>,))</span><br><span class="line">        v = tf.searchsorted(self.T, [v], side=<span class="string">&#x27;left&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">return</span> tf.reshape(v, original_shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ordinal_one_hot</span>(<span class="params">x, depth</span>):</span><br><span class="line">    x = tf.squeeze(x, [-<span class="number">1</span>])</span><br><span class="line">    target_shape = tf.concat((tf.shape(x), [depth]), axis=-<span class="number">1</span>)</span><br><span class="line">    x = tf.reshape(x, (-<span class="number">1</span>,))</span><br><span class="line">    y_true_expanded = tf.broadcast_to(tf.<span class="built_in">range</span>(depth, dtype=tf.int32), tf.concat((tf.shape(x), [depth]), axis=-<span class="number">1</span>))</span><br><span class="line">    y_true_expanded = tf.cast(tf.less(y_true_expanded, tf.cast(tf.expand_dims(x, axis=-<span class="number">1</span>), dtype=tf.int32)), dtype=tf.int32)</span><br><span class="line">    <span class="keyword">return</span> tf.reshape(y_true_expanded, target_shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OrdinalRegressionLoss</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, K, discretize=<span class="literal">None</span>, min_value=<span class="number">0</span>, batch_size: <span class="built_in">int</span>=-<span class="number">1</span>, img_w: <span class="built_in">int</span>=-<span class="number">1</span>, img_h: <span class="built_in">int</span>=-<span class="number">1</span></span>):</span><br><span class="line">        self.K = K</span><br><span class="line">        self.discretize = discretize</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.img_w, self.img_h = img_w, img_h</span><br><span class="line">        self.min_value = min_value</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, y_true, y_pred</span>):</span><br><span class="line">        valid_mask = tf.greater_equal(tf.squeeze(y_true, [-<span class="number">1</span>]), self.min_value)</span><br><span class="line">        y_true = tf.boolean_mask(y_true, valid_mask)</span><br><span class="line"></span><br><span class="line">        K = self.K</span><br><span class="line">        y_pred_k1, y_pred_k2 = tf.split(y_pred, [K, K], axis=-<span class="number">1</span>)</span><br><span class="line">        y_pred_k1 = tf.boolean_mask(y_pred_k1, valid_mask)</span><br><span class="line">        y_pred_k2 = tf.boolean_mask(y_pred_k2, valid_mask)</span><br><span class="line">        y_pred_k_prob = tf.exp(y_pred_k2) / (tf.exp(y_pred_k1) + tf.exp(y_pred_k2))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.discretize <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            original_shape = y_true.get_shape()</span><br><span class="line">            y_true = self.discretize(y_true)</span><br><span class="line">            y_true.set_shape(original_shape)</span><br><span class="line"></span><br><span class="line">        y_true_ordinal_one_hot = ordinal_one_hot(y_true, K)</span><br><span class="line">        y_prob_k = tf.cast(y_true_ordinal_one_hot * <span class="number">2</span> - <span class="number">1</span>, tf.float32) * y_pred_k_prob + tf.cast(<span class="number">1</span> - y_true_ordinal_one_hot, tf.float32)</span><br><span class="line">        y_log_prob = tf.reduce_sum(tf.log(y_prob_k), axis=-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> -tf.reduce_mean(y_log_prob)</span><br></pre></td></tr></table></figure>
<p>需要注意以上的实现充分的利用了tensorflow提供的API，以便我们可以有高效内存占用，并可以高效的在GPU上进行并行计算。主要用到的几个不常用的API是<code>tf.searchsorted</code>, <code>tf.broadcast_to</code>, <code>tf.get_shape</code>, <code>tf.get_shape</code>。</p>
<h3 id="改进效果"><a class="markdownIt-Anchor" href="#改进效果"></a> 改进效果</h3>
<p>我们的改进效果如何呢？</p>
<p>DORN论文中的结果：</p>
<p><img data-src="/attaches/2019/2019-07-08-reproduce-ml-models-dorn/dorn-result.png" alt="DORN结果" /></p>
<p>我们的结果：</p>
<p><img data-src="/attaches/2019/2019-07-08-reproduce-ml-models-dorn/dorn-our-result.png" alt="我们的DORN实验结果" /></p>
<p>从结果来看，abs_error比论文低0.6个百分点，sql_error却比论文高1.1个百分点，证明了我们理解的正确性。同时我们的实验中基础网络使用resnet50，如果用resnet101, resnet152理论上会更好，而且网络看起来还能继续优化，只是时间关系和资源关系我们没有继续训练。另一个是计算效率的提升，在同样的机器上面运行模型，预测时间我们只需要6秒，而DORN需要20秒以上。我们的优化基本上达到了产品可用的程度。</p>
]]></content>
      <categories>
        <category>machine-learning</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>AI</tag>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
        <tag>keras</tag>
        <tag>图像分割</tag>
        <tag>语义分割</tag>
        <tag>Image Segmentation</tag>
        <tag>Semantic Segmentation</tag>
      </tags>
  </entry>
  <entry>
    <title>如何实现一个优雅的Python的Json序列化库</title>
    <url>/2019/07/19/python-json-serializable-lib/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2019/2019-07-19-python-json-serializable-lib/serializable.png" alt="python json serializable" /></p>
<p>在Python的世界里，将一个对象以json格式进行序列化或反序列化一直是一个问题。Python标准库里面提供了json序列化的工具，我们可以简单的用<code>json.dumps</code>来将一个对象序列化。但是这种序列化仅支持python内置的基本类型，对于自定义的类，我们将得到<code>Object of type A is not JSON serializable</code>的错误。</p>
<span id="more"></span>
<p>有很多种方法可以用来支持这种序列化，<a href="https://stackoverflow.com/questions/3768895/how-to-make-a-class-json-serializable">这里</a>有一个很长的关于这个问题的讨论。总结起来，基本上有两种还不错的思路：</p>
<ol>
<li>利用标准库的接口：从python标准json库中的<code>JSONDecoder</code>继承，然后自定义实现一个<code>default</code>方法用来自定义序列化过程</li>
<li>利用第三方库实现：如<code>jsonpickle</code> <code>jsonweb</code> <code>json-tricks</code>等</li>
</ol>
<p>利用标准库的接口的问题在于，我们需要对每一个自定义类都实现一个<code>JSONDecoder.default</code>接口，难以实现代码复用。</p>
<p>利用第三方库，对我们的代码倒是没有任何侵入性，特别是<code>jsonpickle</code>，由于它是基于<code>pickle</code>标准序列化库实现，可以实现像pickle一样序列化任何对象，一行代码都不需要修改。</p>
<p>但是我们观察这类第三方库的输出的时候，会发现所有的这些类库都会在输出的json中增加一个特殊的标明对象类型的属性。这是为什么呢？Python是一门动态类型的语言，我们无法在对象还没有开始构建的时候知道对象的某一属性的类型信息，为了对反序列化提供支持，看起来确实是不得不这么做。</p>
<p>有人可能觉得这也无可厚非，似乎不影响使用。但是在跨语言通信的时候，这就成为了一个比较麻烦的问题。比如我们有一个Python实现的API，客户端发送了一个json请求过来，我们想在统一的一个地方将json反序列化为我们Python代码的对象。由于客户端不知道服务器端的类型信息，json请求里面就没法加入这样的类型信息，这也就导致这样的类库在反序列化的时候遇到问题。</p>
<p>能不能有一个相对完美的实现呢？先看一下我们理想的json序列化库的需求：</p>
<ol>
<li>我们希望能简单的序列化任意自定义对象，只添加一行代码，或者不加入任何代码</li>
<li>我们希望序列化的结果不加入任何非预期的属性</li>
<li>我们希望能按照指定的类型进行反序列化，能自动处理嵌套的自定义类，只需要自定义类提供非常简单的支持，或者不需要提供任何支持</li>
<li>我们希望反序列化的时候能很好的处理属性不存在的情况，以便在我们加入某一属性的时候，可以设置默认值，使得旧版本的序列化结果可以正确的反序列化出来</li>
</ol>
<p>如果有一个json库能支持上面的四点，那就基本是比较好用的库了。下面我们来尝试实现一下这个类库。</p>
<p>对于我们想要实现的几个需求，我们可以建立下面这样的测试来表达我们所期望的库的API设计：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SerializableModelTest</span>(unittest.TestCase):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_model_serializable</span>(<span class="params">self</span>):</span><br><span class="line"></span><br><span class="line">        <span class="keyword">class</span> <span class="title class_">A</span>(<span class="title class_ inherited__">SerializableModel</span>):</span><br><span class="line"></span><br><span class="line">            <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, a, b</span>):</span><br><span class="line">                <span class="built_in">super</span>().__init__()</span><br><span class="line">                self.a = a</span><br><span class="line">                self.b = b <span class="keyword">if</span> b <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> B(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">            @property</span></span><br><span class="line">            <span class="keyword">def</span> <span class="title function_">id</span>(<span class="params">self</span>):</span><br><span class="line">                <span class="keyword">return</span> self.a</span><br><span class="line"></span><br><span class="line">            <span class="keyword">def</span> <span class="title function_">_deserialize_prop</span>(<span class="params">self, name, deserialized</span>):</span><br><span class="line">                <span class="keyword">if</span> name == <span class="string">&#x27;b&#x27;</span>:</span><br><span class="line">                    self.b = B.deserialize(deserialized)</span><br><span class="line">                    <span class="keyword">return</span></span><br><span class="line">                <span class="built_in">super</span>()._deserialize_prop(name, deserialized)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">class</span> <span class="title class_">B</span>(<span class="title class_ inherited__">SerializableModel</span>):</span><br><span class="line"></span><br><span class="line">            <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, b</span>):</span><br><span class="line">                <span class="built_in">super</span>().__init__()</span><br><span class="line">                self.b = b</span><br><span class="line"></span><br><span class="line">        self.assertEqual(json.dumps(&#123;<span class="string">&#x27;a&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;b&#x27;</span>: &#123;<span class="string">&#x27;b&#x27;</span>: <span class="number">2</span>&#125;, <span class="string">&#x27;long_attr&#x27;</span>: <span class="literal">None</span>&#125;), A(<span class="number">1</span>, B(<span class="number">2</span>)).serialize())</span><br><span class="line">        self.assertEqual(json.dumps(&#123;<span class="string">&#x27;a&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;b&#x27;</span>: <span class="literal">None</span>&#125;), A(<span class="number">1</span>, <span class="literal">None</span>).serialize())</span><br><span class="line"></span><br><span class="line">        self.assertEqual(A(<span class="number">1</span>, B(<span class="number">2</span>)), A.deserialize(json.dumps(&#123;<span class="string">&#x27;a&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;b&#x27;</span>: &#123;<span class="string">&#x27;b&#x27;</span>: <span class="number">2</span>&#125;&#125;)))</span><br><span class="line">        self.assertEqual(A(<span class="number">1</span>, <span class="literal">None</span>), A.deserialize(json.dumps(&#123;<span class="string">&#x27;a&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;b&#x27;</span>: <span class="literal">None</span>&#125;)))</span><br><span class="line">        self.assertEqual(A(<span class="number">1</span>, B(<span class="number">0</span>)), A.deserialize(json.dumps(&#123;<span class="string">&#x27;a&#x27;</span>: <span class="number">1</span>&#125;)))</span><br></pre></td></tr></table></figure>
<p>这里我们希望通过继承的方式来添加支持，这将在反序列化的时候提供一个好处。因为有了它我们就可以直接使用<code>A.deserialize</code>方法来反序列化，而不需要提供任何其他的反序列化函数参数，比如这样<code>json.deserialize(serialized_str, A)</code>。</p>
<p>同时为了验证我们的框架不会将<code>@property</code>属性序列化或者反序列化，我们特意在类<code>A</code>中添加了这样一个属性。</p>
<p>由于在反序列化的时候，框架是无法知道某一个对象属性的类型信息，比如测试中的<code>A.b</code>，为了能正确的反序列化，我们需要提供一点简单的支持，这里我们在类<code>A</code>中覆盖实现了一个父类的方法<code>_deserialize_prop</code>对属性<code>b</code>的反序列化提供支持。</p>
<p>当我们要反序列化一个之前版本的序列化结果时，我们希望能正确的反序列化并使用我们提供的默认值作为最终的反序列化值。这在属性<code>A.b</code>的测试中得到了体现。</p>
<p>（一个好的测试应该一次只验证一个方面，上面的测试是为了简洁起见写在了一起，而且也有很多边界的情况并没有覆盖。此测试只是作为示例使用。）</p>
<p>如果能有一个类可以让上面的测试通过，相信那个类就是我们所需要的类了。这样的类可以实现为如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ModelBase</span>:</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_normal_prop</span>(<span class="params">obj, key</span>):</span><br><span class="line">        is_prop = <span class="built_in">isinstance</span>(<span class="built_in">getattr</span>(<span class="built_in">type</span>(obj), key, <span class="literal">None</span>), <span class="built_in">property</span>)</span><br><span class="line">        is_constant = re.match(<span class="string">&#x27;^[A-Z_0-9]+$&#x27;</span>, key)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">not</span> (key.startswith(<span class="string">&#x27;__&#x27;</span>) <span class="keyword">or</span> <span class="built_in">callable</span>(<span class="built_in">getattr</span>(obj, key)) <span class="keyword">or</span> is_prop <span class="keyword">or</span> is_constant)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_basic_type</span>(<span class="params">value</span>):</span><br><span class="line">        <span class="keyword">return</span> value <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> <span class="built_in">type</span>(value) <span class="keyword">in</span> [<span class="built_in">int</span>, <span class="built_in">float</span>, <span class="built_in">str</span>, <span class="built_in">list</span>, <span class="built_in">tuple</span>, <span class="built_in">bool</span>, <span class="built_in">dict</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_serialize_prop</span>(<span class="params">self, name</span>):</span><br><span class="line">        value = <span class="built_in">getattr</span>(self, name)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(value, (<span class="built_in">tuple</span>, <span class="built_in">list</span>)):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                json.dumps(value)</span><br><span class="line">                <span class="keyword">return</span> value</span><br><span class="line">            <span class="keyword">except</span> Exception:</span><br><span class="line">                <span class="keyword">return</span> [v._as_dict() <span class="keyword">for</span> v <span class="keyword">in</span> value]</span><br><span class="line">        <span class="keyword">return</span> value</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_as_dict</span>(<span class="params">self</span>):</span><br><span class="line">        keys = <span class="built_in">dir</span>(self)</span><br><span class="line">        props = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> keys:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> ModelBase.is_normal_prop(self, key):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            value = self._serialize_prop(key)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> (ModelBase.is_basic_type(value) <span class="keyword">or</span> <span class="built_in">isinstance</span>(value, ModelBase)):</span><br><span class="line">                <span class="keyword">raise</span> Exception(<span class="string">&#x27;unkown value to serialize to dict: key=&#123;&#125;, value=&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(key, value))</span><br><span class="line">            props[key] = value <span class="keyword">if</span> self.is_basic_type(value) <span class="keyword">else</span> value._as_dict()</span><br><span class="line">        <span class="keyword">return</span> props</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_short_prop</span>(<span class="params">self, name</span>):</span><br><span class="line">        value = <span class="built_in">getattr</span>(self, name)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(value, (<span class="built_in">tuple</span>, <span class="built_in">list</span>)):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                json.dumps(value)</span><br><span class="line">                <span class="keyword">return</span> value</span><br><span class="line">            <span class="keyword">except</span> Exception:</span><br><span class="line">                <span class="keyword">return</span> [v._as_short_dict() <span class="keyword">for</span> v <span class="keyword">in</span> value]</span><br><span class="line">        <span class="keyword">return</span> value</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_as_short_dict</span>(<span class="params">self</span>):</span><br><span class="line">        keys = <span class="built_in">dir</span>(self)</span><br><span class="line">        props = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> keys:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> ModelBase.is_normal_prop(self, key):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            value = self._short_prop(key)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> (ModelBase.is_basic_type(value) <span class="keyword">or</span> <span class="built_in">isinstance</span>(value, ModelBase)):</span><br><span class="line">                <span class="keyword">raise</span> Exception(<span class="string">&#x27;unkown value to serialize to short dict: key=&#123;&#125;, value=&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(key, value))</span><br><span class="line">            props[key] = value <span class="keyword">if</span> self.is_basic_type(value) <span class="keyword">else</span> value._as_short_dict()</span><br><span class="line">        <span class="keyword">return</span> props</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">serialize</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> json.dumps(self._as_dict(), ensure_ascii=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_deserialize_prop</span>(<span class="params">self, name, deserialized</span>):</span><br><span class="line">        <span class="built_in">setattr</span>(self, name, deserialized)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">deserialize</span>(<span class="params">cls, json_encoded</span>):</span><br><span class="line">        <span class="keyword">if</span> json_encoded <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">import</span> inspect</span><br><span class="line">        args = inspect.getfullargspec(cls)</span><br><span class="line">        args_without_self = args.args[<span class="number">1</span>:]</span><br><span class="line">        obj = cls(*([<span class="literal">None</span>] * <span class="built_in">len</span>(args_without_self)))</span><br><span class="line"></span><br><span class="line">        data = json.loads(json_encoded, encoding=<span class="string">&#x27;utf8&#x27;</span>) <span class="keyword">if</span> <span class="built_in">type</span>(json_encoded) <span class="keyword">is</span> <span class="built_in">str</span> <span class="keyword">else</span> json_encoded</span><br><span class="line">        keys = <span class="built_in">dir</span>(obj)</span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> keys:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> ModelBase.is_normal_prop(obj, key):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">if</span> key <span class="keyword">in</span> data:</span><br><span class="line">                obj._deserialize_prop(key, data[key])</span><br><span class="line">        <span class="keyword">return</span> obj</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.serialize()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_prop_eq</span>(<span class="params">self, name, value, value_other</span>):</span><br><span class="line">        <span class="keyword">return</span> value == value_other</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__eq__</span>(<span class="params">self, other</span>):</span><br><span class="line">        <span class="keyword">if</span> other <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> other.__class__ <span class="keyword">is</span> <span class="keyword">not</span> self.__class__:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        keys = <span class="built_in">dir</span>(self)</span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> keys:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> ModelBase.is_normal_prop(self, key):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            value, value_other = <span class="built_in">getattr</span>(self, key), <span class="built_in">getattr</span>(other, key)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> (ModelBase.is_basic_type(value) <span class="keyword">or</span> <span class="built_in">isinstance</span>(value, ModelBase)):</span><br><span class="line">                <span class="keyword">raise</span> Exception(<span class="string">&#x27;unsupported value to compare: key=&#123;&#125;, value=&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(key, value))</span><br><span class="line">            <span class="keyword">if</span> value <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> value_other <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">if</span> (value <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> value_other <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>) <span class="keyword">or</span> (value <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> value_other <span class="keyword">is</span> <span class="literal">None</span>):</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> self._prop_eq(key, value, value_other):</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">short_repr</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> json.dumps(self._as_short_dict(), ensure_ascii=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>为了更进一步提供支持，我们将最终的类命名为<code>ModelBase</code>，因为通常我们要序列化或反序列化的对象都是我们需要特殊对待的对象，且我们通常称其为模型，我们一般也会将其放在一个单独<code>models</code>模块中。</p>
<p>作为一个模型的基类，我们还添加了一些常用的特性，比如：</p>
<ol>
<li>支持标准的格式化接口<code>__str__</code>，这样我们在使用<code>'&#123;&#125;'.format(a)</code>的时候，就可以得到一个更易于理解的输出</li>
<li>提供了一个缩短的序列化方式，在我们有时候不想直接输出某一个特别长的属性的时候很有用</li>
<li>提供了基于属性值的比较方法</li>
<li>自定义类的属性可以为基础的Python类型，或者由基础Python类型构成的<code>list</code> <code>tuple</code> <code>dict</code></li>
</ol>
<p>在使用这个类的时候，当然也是有一些限制的，主要的限制如下：</p>
<ol>
<li>当某一属性为自定义类的类型的时候，需要子类覆盖实现<code>_deserialize_prop</code>方法为反序列化过程提供支持</li>
<li>当某一属性为由自定义类构成的一个<code>list</code> <code>tuple</code> <code>dict</code>复杂对象时，需要子类覆盖实现<code>_deserialize_prop</code>方法为反序列化过程提供支持</li>
<li>简单属性必须为python内置的基础类型，比如如果某一属性的类型为<code>numpy.float64</code>，序列化反序列化将不能正常工作</li>
</ol>
<p>虽然有上述限制，但是这正好要求我们在做模型设计的时候保持克制，不要将某一个对象设计得过于复杂。比如如果有属性为<code>dict</code>类型，我们可以将这个<code>dict</code>抽象为另一个自定义类型，然后用类型嵌套的方式来实现。</p>
<p>到这里这个基类就差不多可以支撑我们日常的开发需要了。当然对于这个简单的实现还有可能有其他的需求或者问题，大家如有发现，欢迎留言交流。</p>
]]></content>
      <categories>
        <category>技术</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>序列化</tag>
        <tag>json</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型重现 -- 前奏</title>
    <url>/2019/07/08/reproduce-ml-models/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>作为每天和AI模型打交道的开发者，深度学习模型在不同的框架之间转换一直是一个老生常谈的问题。为了让这个问题变得容易，大家做了很多这样的工作，像是微软推出的<a href="https://github.com/microsoft/MMdnn">MMdnn</a>工具，号称可以将模型在几乎所有的流行AI框架中转换，又比如Facebook和微软一起推出的<a href="https://onnx.ai">ONNX</a>不依赖具体框架的中间格式等。</p>
<span id="more"></span>
<p>但是，回到我们实际的产品开发过程中，我们总还是感觉现有的这些工具有点使不上劲。比如，当我们某一天发现了一篇论文里面的想法很赞，我们想要参考来优化自己的模型。但是仔细一看，发现论文里面公布的代码和模型是caffe的，而我们自己的模型用kera实现的，咋办呢？类似上面的中间格式或者模型转换工具，这个时候就显得很乏力了，因为我们想要的可能是一段可以直接集成到我们的现有模型中的代码，或者是一个我们可以用来做迁移学习的基础模型。这时，我们可能要回归到原点，从零开始，深入理解论文里面提到的优化，重新实现。</p>
<p>在我们的模型开发过程中，就遇到了这样的问题。看起来很美好的想法和模型，却无法直接使用。下面我将用几篇文章分享一下我们研究过的几个模型。</p>
]]></content>
      <categories>
        <category>machine-learning</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>AI</tag>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习模型重现 -- EfficientNet的keras实现</title>
    <url>/2019/07/12/reproduce-ml-models-efficientnet/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>EfficientNet是谷歌AI科学家们在论文《EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks》中提出的模型。这篇文章不仅提出了这个模型，还系统地研究了模型扩展的问题，大家感兴趣的，可用阅读一下<a href="https://arxiv.org/abs/1905.11946">论文原文</a>。EfficientNet的亮眼之处在于，其在保持领先的性能的同时，将模型的参数数量和预测速度都提升了一个数量级。请看下图的性能对比：</p>
<span id="more"></span>
<p><img data-src="/attaches/2019/2019-07-12-reproduce-ml-models-efficientnet/efficientnet-perf.png" alt="EfficientNet性能对比" /></p>
<p>这篇文章同时还研究了可迁移性，发现其与我们常用的ResNet,ResNext等等具有类似的可迁移性。看起来EfficientNet完全可以作为新一代的基础模型使用起来呀。</p>
<p>为了提升我们产品（图像分割模型）的识别性能，我们比较系统的研究了这个模型，同时将其转化为了keras的模型，以便我们可以与现有的模型良好的集成起来。下面我们将分享一下我们是如何做的，同时也相信可以给大家提供一个如何在不同框架之间做模型转化的思路。</p>
<p>EfficientNet模型的相关代码和 TPU 训练的模型已在 GitHub 上<a href="https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet">开源</a>。本文基于原来的开源代码及模型研究而来。(下面的代码部分请结合官方开源的代码，及<a href="https://github.com/gmlove/efficientnet-keras">代码库</a>一起阅读)</p>
<p>要实现模型转化，基本上我们要分为这几个步骤来做：</p>
<ol>
<li>将原来的模型代码翻译为新框架的代码</li>
<li>将原来训练好的模型参数转化为新框架的参数格式</li>
<li>验证转化后的结果是否与原来的一致</li>
</ol>
<h3 id="模型代码翻译"><a class="markdownIt-Anchor" href="#模型代码翻译"></a> 模型代码翻译</h3>
<p>下载官方代码之后，我们可以发现官方代码使用tensorflow实现，在tpu下面训练。</p>
<p>我们的目标框架是keras，说起keras，其与tensorflow可以说是有着千丝万缕的联系。首先他们都是出自google，tensorflow还内置了一份keras的代码以便提供更易用的API；其次keras是比tensorflow更早的一个框架，其设计的目标就是统一各个AI框架的API，当然也包括tensorflow；然后keras是没有底层的计算支持的，必须要外接一个后端框架，它的后端除了tensorflow，还支持CNTK, Theano。keras最吸引开发者的一点应该是其设计良好的API，大大提升了我们的开发便利性，这也是我们选择keras的主要原因。</p>
<p>keras与tensorflow我们可以认为具有非常好的兼容性，一是由于官方支持，二是由于keras的后端就可以是tensorflow。这给我们的转化提供了很大的便利。</p>
<p>如何开始呢？让我们先准备一个测试让原来的模型可以跑起来。从官方的例子来看，文件<code>eval_example_images.py</code>中的<code>eval_example_images</code>函数就是让模型跑起来的代码了。由于我们要提取核心代码进行转换，我们进一步分析之后，抽丝剥茧，可以得到这样几行代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">softmax</span>(<span class="params">x</span>):</span><br><span class="line">    exp_x = np.exp(x)</span><br><span class="line">    softmax_x = exp_x / np.<span class="built_in">sum</span>(exp_x, axis=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> softmax_x</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_run_tf_model</span>():</span><br><span class="line">    <span class="keyword">import</span> pickle</span><br><span class="line">    x = pickle.loads(<span class="built_in">open</span>(<span class="string">&#x27;data/x.pickle&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>).read())[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.Graph().as_default(), tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        model_name = <span class="string">&#x27;efficientnet-b0&#x27;</span></span><br><span class="line"></span><br><span class="line">        X = tf.cast(tf.stack([x]), dtype=tf.float32)</span><br><span class="line">        X -= tf.constant(MEAN_RGB, shape=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>], dtype=X.dtype)</span><br><span class="line">        X /= tf.constant(STDDEV_RGB, shape=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>], dtype=X.dtype)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(model_name):</span><br><span class="line">            blocks_args, global_params = efficientnet_builder.get_model_params(model_name, <span class="literal">None</span>)</span><br><span class="line">            model = efficientnet_model.Model(blocks_args, global_params)</span><br><span class="line">            _logits = model(X, <span class="literal">False</span>)</span><br><span class="line">            model.summary()</span><br><span class="line"></span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">        checkpoint = tf.train.latest_checkpoint(<span class="string">&#x27;data/models/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(model_name))</span><br><span class="line">        ema = tf.train.ExponentialMovingAverage(decay=<span class="number">0.9999</span>)</span><br><span class="line">        ema_vars = tf.trainable_variables() + tf.get_collection(<span class="string">&#x27;moving_vars&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> tf.global_variables():</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;moving_mean&#x27;</span> <span class="keyword">in</span> v.name <span class="keyword">or</span> <span class="string">&#x27;moving_variance&#x27;</span> <span class="keyword">in</span> v.name:</span><br><span class="line">                ema_vars.append(v)</span><br><span class="line">        ema_vars = <span class="built_in">list</span>(<span class="built_in">set</span>(ema_vars))</span><br><span class="line">        var_dict = ema.variables_to_restore(ema_vars)</span><br><span class="line">        saver = tf.train.Saver(var_dict, max_to_keep=<span class="number">1</span>)</span><br><span class="line">        saver.restore(sess, checkpoint)</span><br><span class="line"></span><br><span class="line">        logits = model.predict(X, steps=<span class="number">1</span>, batch_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    pred_probs = softmax(logits)</span><br><span class="line">    pred_idx = np.argsort(pred_probs)[:, ::-<span class="number">1</span>]</span><br><span class="line">    pred_prob = np.array([pred_probs[i][pid] <span class="keyword">for</span> i, pid <span class="keyword">in</span> <span class="built_in">enumerate</span>(pred_idx)])[:, :<span class="number">5</span>]</span><br><span class="line">    pred_idx = pred_idx[:, :<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">    classes = json.loads(<span class="built_in">open</span>(<span class="string">&#x27;data/labels_map.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>).read())</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;predicted class for image &#123;&#125;: &#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;data/panda.jpg&#x27;</span>))</span><br><span class="line">    <span class="keyword">for</span> i, idx <span class="keyword">in</span> <span class="built_in">enumerate</span>(pred_idx[<span class="number">0</span>]):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;  -&gt; top_&#123;&#125; (&#123;:4.2f&#125;%): &#123;&#125;  &#x27;</span>.<span class="built_in">format</span>(i, pred_prob[<span class="number">0</span>][i] * <span class="number">100</span>, classes[<span class="built_in">str</span>(idx)]))</span><br></pre></td></tr></table></figure>
<p>这里的模型恢复参数时用到了一个奇怪的<code>ExponentialMovingAverage</code>，看起来不用这样的方式也可以，但是由于官方代码是这样的，为节约时间，我们姑且先按照官方的例子做。有兴趣的小伙伴们可以研究一下是否能把这一步去掉。</p>
<p>这里的<code>x.pickle</code>文件是我们从原来的模型运行中导出来的，在<code>eval_example_images.py</code>文件中的<code>EvalCkptDriver.run_inference</code>函数中，代码行<code>probs = self.build_model(images, is_training=False)</code>之后加入代码<code>import pickle;_images = sess.run(images);pickle.dump(_images, open('data/x.pickle', 'wb'))</code>后运行，即可导出此文件。这里我们没有直接将图片输入到模型中进行预测，因为原模型对输入图像做了一定的预处理，如果我们忽略预处理，则将得到不一样的结果。</p>
<p>运行上面的函数之后，就可以发现得到了与官方一样的结果，如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">predicted class for image data/panda.jpg: </span><br><span class="line">  -&gt; top_0 (82.79%): giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca  </span><br><span class="line">  -&gt; top_1 (1.52%): ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus  </span><br><span class="line">  -&gt; top_2 (0.37%): lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens  </span><br><span class="line">  -&gt; top_3 (0.23%): American black bear, black bear, Ursus americanus, Euarctos americanus  </span><br><span class="line">  -&gt; top_4 (0.17%): brown bear, bruin, Ursus arctos</span><br></pre></td></tr></table></figure>
<p>下一步我们来构建自己的keras模型，我们知道keras的模型分为两类，一类是顺序连接的模型，一般构造一个<code>keras.models.Sequential</code>对象，然后依次加入不同的层就行，参考<a href="https://keras.io/getting-started/sequential-model-guide/">这里</a>；另一类是图模型，通过函数式的API来构建，参考<a href="https://keras.io/getting-started/functional-api-guide/">这里</a>。由于EfficientNet的模型是一个比较复杂的网络，这里应该用函数式API构建为一个图模型。</p>
<p>先构建一个简单的测试如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test_load_weights</span>():</span><br><span class="line">    <span class="keyword">from</span> eval_ckpt_main <span class="keyword">import</span> MEAN_RGB, STDDEV_RGB</span><br><span class="line">    X = pickle.loads(<span class="built_in">open</span>(<span class="string">&#x27;data/x.pickle&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>).read())</span><br><span class="line">    X = np.array(X, dtype=np.float32)</span><br><span class="line">    X -= np.array(MEAN_RGB, dtype=np.float32).reshape((<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>))</span><br><span class="line">    X /= np.array(STDDEV_RGB, dtype=np.float32).reshape((<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    model_name = <span class="string">&#x27;efficientnet-b0&#x27;</span></span><br><span class="line">    model = EfficientNetModelBuilder().build(model_name, input_shape=(<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>), num_classes=<span class="number">1000</span>)</span><br><span class="line">    model.summary()</span><br><span class="line">    model.load_weights(<span class="string">&#x27;data/converted_weights/&#123;&#125;_imagenet_1000.h5&#x27;</span>.<span class="built_in">format</span>(model_name))</span><br><span class="line"></span><br><span class="line">    Y = model.predict(X)</span><br><span class="line"></span><br><span class="line">    pred_probs = softmax(Y)</span><br><span class="line">    pred_idx = np.argsort(pred_probs)[:, ::-<span class="number">1</span>]</span><br><span class="line">    pred_prob = np.array([pred_probs[i][pid] <span class="keyword">for</span> i, pid <span class="keyword">in</span> <span class="built_in">enumerate</span>(pred_idx)])[:, :<span class="number">5</span>]</span><br><span class="line">    pred_idx = pred_idx[:, :<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">    classes = json.loads(<span class="built_in">open</span>(<span class="string">&#x27;data/labels_map.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>).read())</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;predicted class for image &#123;&#125;: &#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;data/panda.jpg&#x27;</span>))</span><br><span class="line">    <span class="keyword">for</span> i, idx <span class="keyword">in</span> <span class="built_in">enumerate</span>(pred_idx[<span class="number">0</span>]):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;  -&gt; top_&#123;&#125; (&#123;:4.2f&#125;%): &#123;&#125;  &#x27;</span>.<span class="built_in">format</span>(i, pred_prob[<span class="number">0</span>][i] * <span class="number">100</span>, classes[<span class="built_in">str</span>(idx)]))</span><br></pre></td></tr></table></figure>
<p>这里构建这个测试是很重要的，这个测试就像一个灯塔，有了它我们的目标就非常明确了，只要这个测试能输出跟原模型同样的结果，就证明我们的模型转化是正确的。</p>
<p>新建一个<code>EfficientNetModelBuilder</code>类及<code>build</code>方法。做代码迁移的第一步是参数的构造，原模型的参数由于要同时支持不同的模型及不同的图像大小、网络宽度、网络深度，对参数进行了一定的编码。为了容易理解我们建立以下三个类来与原来的代码对应：</p>
<ol>
<li><code>EfficientNetGlobalParams</code> -&gt; <code>GlobalParams</code> (<code>efficientnet_model.py</code>)</li>
<li><code>EfficientNetParams</code> -&gt; <code>efficientnet_params</code> (<code>efficientnet_builder.py</code>)</li>
<li><code>EfficientNetBlockParams</code> -&gt; <code>BlockDecoder</code> (<code>efficientnet_builder.py</code>)</li>
</ol>
<p>并将相应的参数解析，验证等操作封装到这三个类中。</p>
<p>参考官方代码，我们新建对应的<code>MBConvBlock</code>及<code>EfficientNetModel</code>类，然后将tensorflow的实现替换为keras的实现。</p>
<p>这里需要注意的是，分析官方的代码发现模型的构建分为两步<code>_build</code>及<code>call</code>，前者构建相关的层，后者将各层连接起来。我们这里修改一下方法名字，建立对应的两个方法<code>_build_layers</code>和<code>_connect_layers</code>。由于这里模型的构造直接通过构造器完成，我们无需对外暴露任何的方法，全部申明为内部方法。</p>
<p>接下来就是代码的改写了，将官方代码拷贝过来，然后用keras的API重写一下。主要的改写在下面几个方面：</p>
<ol>
<li>
<p>将<code>tf.layers.Conv2D</code>改为<code>keras.layers.Conv2D</code>，并修改对应的参数名，参数值</p>
</li>
<li>
<p>将一些tensorflow函数封装为keras的层，然后替换原来的函数调用。如：</p>
<p>a. 原来的函数调用<code>se_tensor = tf.reduce_mean(input_tensor, self._spatial_dims, keepdims=True)</code>可以改为<code>_build_layers</code>方法中的<code>self._se_mean = keras.layers.Lambda(name=self._layer_name('se_mean'), function=lambda x: tf.reduce_mean(x, self._spatial_dims, keep_dims=True))</code>及<code>_connect_layers</code>中的<code>se_tensor = self._se_mean(input_tensor)</code>调用<br />
b. <code>swish</code>激活函数，可以新建一个继承至<code>keras.layers.Layer</code>的<code>Swish</code>类来实现<br />
c. <code>drop_connect</code>函数，可以新建一个继承至<code>keras.layers.Layer</code>的<code>DropConnect</code>类来实现</p>
</li>
<li>
<p><code>batchnorm</code>修改为keras的版本<code>keras.layers.BatchNormalization</code></p>
</li>
</ol>
<p>修改完毕之后，注释掉上面测试中的<code>model.load_weights</code>一行，运行测试，应该不会报错，但是由于我们还没有导入参数，上面的测试会随机输出一个结果。到这里模型翻译的部分就完成了。</p>
<h3 id="模型参数转换"><a class="markdownIt-Anchor" href="#模型参数转换"></a> 模型参数转换</h3>
<p>第二个问题就是如何导出原来模型的参数，并导入我们的新模型中了。</p>
<p>从我们最初的那个运行原模型的测试来看，下面几行代码就可以得到原模型的所有保存的参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ema = tf.train.ExponentialMovingAverage(decay=<span class="number">0.9999</span>)</span><br><span class="line">ema_vars = tf.trainable_variables() + tf.get_collection(<span class="string">&#x27;moving_vars&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> tf.global_variables():</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;moving_mean&#x27;</span> <span class="keyword">in</span> v.name <span class="keyword">or</span> <span class="string">&#x27;moving_variance&#x27;</span> <span class="keyword">in</span> v.name:</span><br><span class="line">        ema_vars.append(v)</span><br><span class="line">ema_vars = <span class="built_in">list</span>(<span class="built_in">set</span>(ema_vars))</span><br><span class="line">var_dict = ema.variables_to_restore(ema_vars)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(var_dict.keys()))</span><br></pre></td></tr></table></figure>
<p>这里得到的参数是什么呢？我们可以简单的将其名字输出到控制台，得到以下这些参数名：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">efficientnet-b0/blocks_0/conv2d/kernel/ExponentialMovingAverage</span><br><span class="line">efficientnet-b0/blocks_0/depthwise_conv2d/depthwise_kernel/ExponentialMovingAverage</span><br><span class="line">efficientnet-b0/blocks_0/se/conv2d/bias/ExponentialMovingAverage</span><br><span class="line">efficientnet-b0/blocks_0/se/conv2d/kernel/ExponentialMovingAverage</span><br><span class="line">...</span><br><span class="line">efficientnet-b0/head/dense/kernel/ExponentialMovingAverage</span><br><span class="line">efficientnet-b0/head/tpu_batch_normalization/beta/ExponentialMovingAverage</span><br><span class="line">efficientnet-b0/head/tpu_batch_normalization/gamma/ExponentialMovingAverage</span><br><span class="line">efficientnet-b0/head/tpu_batch_normalization/moving_mean/ExponentialMovingAverage</span><br><span class="line">efficientnet-b0/head/tpu_batch_normalization/moving_variance/ExponentialMovingAverage</span><br><span class="line">efficientnet-b0/stem/conv2d/kernel/ExponentialMovingAverage</span><br><span class="line">efficientnet-b0/stem/tpu_batch_normalization/beta/ExponentialMovingAverage</span><br><span class="line">efficientnet-b0/stem/tpu_batch_normalization/gamma/ExponentialMovingAverage</span><br><span class="line">efficientnet-b0/stem/tpu_batch_normalization/moving_mean/ExponentialMovingAverage</span><br><span class="line">efficientnet-b0/stem/tpu_batch_normalization/moving_variance/ExponentialMovingAverage</span><br></pre></td></tr></table></figure>
<p>我们的keras的模型参数名是什么呢？由于keras的模型全部由一个一个的层组成，我们可以直接打出每一层里面的参数，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">print_keras_model_weights</span>(<span class="params">model</span>):</span><br><span class="line">    layers: <span class="type">List</span>[keras.layers.Layer] = [layer <span class="keyword">for</span> layer <span class="keyword">in</span> model.layers <span class="keyword">if</span> layer.weights]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;weights count in model: &#x27;</span>, <span class="built_in">sum</span>([<span class="built_in">len</span>(layer.weights) <span class="keyword">for</span> layer <span class="keyword">in</span> layers]))</span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> layers:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;layer: &#123;&#125;, names: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(layer.name, [w.name <span class="keyword">for</span> w <span class="keyword">in</span> layer.weights]))</span><br></pre></td></tr></table></figure>
<p>这里同时也打印出了所有的参数个数，我们可以与之前原模型的参数数量比较一下以验证我们的做法的正确性。我们可以得到这样的参数：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">block_1_1_depthwise_bn: [&#x27;blocks_0/block_1_1_depthwise_bn/gamma:0&#x27;, &#x27;blocks_0/block_1_1_depthwise_bn/beta:0&#x27;, &#x27;blocks_0/block_1_1_depthwise_bn/moving_mean:0&#x27;, &#x27;blocks_0/block_1_1_depthwise_bn/moving_variance:0&#x27;]</span><br><span class="line">block_1_1_depthwise_conv: [&#x27;blocks_0/block_1_1_depthwise_conv/depthwise_kernel:0&#x27;]</span><br><span class="line">block_1_1_project_bn: [&#x27;blocks_0/block_1_1_project_bn/gamma:0&#x27;, &#x27;blocks_0/block_1_1_project_bn/beta:0&#x27;, &#x27;blocks_0/block_1_1_project_bn/moving_mean:0&#x27;, &#x27;blocks_0/block_1_1_project_bn/moving_variance:0&#x27;]</span><br><span class="line">block_1_1_project_conv: [&#x27;blocks_0/block_1_1_project_conv/kernel:0&#x27;]</span><br><span class="line">...</span><br><span class="line">head_bn: [&#x27;head/head_bn/gamma:0&#x27;, &#x27;head/head_bn/beta:0&#x27;, &#x27;head/head_bn/moving_mean:0&#x27;, &#x27;head/head_bn/moving_variance:0&#x27;]</span><br><span class="line">head_conv: [&#x27;head/head_conv/kernel:0&#x27;]</span><br><span class="line">head_dense: [&#x27;head/head_dense/kernel:0&#x27;, &#x27;head/head_dense/bias:0&#x27;]</span><br><span class="line">stem_bn: [&#x27;stem/stem_bn/gamma:0&#x27;, &#x27;stem/stem_bn/beta:0&#x27;, &#x27;stem/stem_bn/moving_mean:0&#x27;, &#x27;stem/stem_bn/moving_variance:0&#x27;]</span><br><span class="line">stem_conv: [&#x27;stem/stem_conv/kernel:0&#x27;]</span><br></pre></td></tr></table></figure>
<p>下一步要做的就是将参数与原模型的参数建立映射了。比较参数名，做相应的名字替换，我们可以得到这样的替换逻辑：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">map_weight_key</span>(<span class="params">model_name: <span class="built_in">str</span>, keras_key: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    key = keras_key\</span><br><span class="line">        .replace(<span class="string">&#x27;stem_conv&#x27;</span>, <span class="string">&#x27;conv2d&#x27;</span>).replace(<span class="string">&#x27;stem_bn&#x27;</span>, <span class="string">&#x27;tpu_batch_normalization&#x27;</span>)\</span><br><span class="line">        .replace(<span class="string">&#x27;head_conv&#x27;</span>, <span class="string">&#x27;conv2d&#x27;</span>).replace(<span class="string">&#x27;head_bn&#x27;</span>, <span class="string">&#x27;tpu_batch_normalization&#x27;</span>).replace(<span class="string">&#x27;head_dense&#x27;</span>, <span class="string">&#x27;dense&#x27;</span>)\</span><br><span class="line">        .replace(<span class="string">&#x27;block_1_1_depthwise_bn&#x27;</span>, <span class="string">&#x27;tpu_batch_normalization&#x27;</span>).replace(<span class="string">&#x27;block_1_1_depthwise_conv&#x27;</span>, <span class="string">&#x27;depthwise_conv2d&#x27;</span>)\</span><br><span class="line">        .replace(<span class="string">&#x27;block_1_1_project_bn&#x27;</span>, <span class="string">&#x27;tpu_batch_normalization_1&#x27;</span>).replace(<span class="string">&#x27;block_1_1_project_conv&#x27;</span>, <span class="string">&#x27;conv2d&#x27;</span>)\</span><br><span class="line">        .replace(<span class="string">&#x27;block_1_1_se_reduce_conv&#x27;</span>, <span class="string">&#x27;conv2d&#x27;</span>).replace(<span class="string">&#x27;block_1_1_se_expand_conv&#x27;</span>, <span class="string">&#x27;conv2d_1&#x27;</span>)\</span><br><span class="line">        .replace(<span class="string">&#x27;:0&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    match = re.match(<span class="string">r&#x27;.*block_(\d)_(\d)_&#x27;</span>, keras_key)</span><br><span class="line">    <span class="keyword">if</span> match <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        block_idx, sub_block_idx = <span class="built_in">tuple</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, match.groups()))</span><br><span class="line">        block_prefix = <span class="string">&#x27;block_&#123;&#125;_&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(block_idx, sub_block_idx)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> (block_idx == <span class="number">1</span> <span class="keyword">and</span> sub_block_idx == <span class="number">1</span>):</span><br><span class="line">            key = key.replace(<span class="string">&#x27;&#123;&#125;_expand_bn&#x27;</span>.<span class="built_in">format</span>(block_prefix), <span class="string">&#x27;tpu_batch_normalization&#x27;</span>).replace(<span class="string">&#x27;&#123;&#125;_expand_conv&#x27;</span>.<span class="built_in">format</span>(block_prefix), <span class="string">&#x27;conv2d&#x27;</span>)\</span><br><span class="line">                .replace(<span class="string">&#x27;&#123;&#125;_depthwise_bn&#x27;</span>.<span class="built_in">format</span>(block_prefix), <span class="string">&#x27;tpu_batch_normalization_1&#x27;</span>).replace(<span class="string">&#x27;&#123;&#125;_depthwise_conv&#x27;</span>.<span class="built_in">format</span>(block_prefix), <span class="string">&#x27;depthwise_conv2d&#x27;</span>)\</span><br><span class="line">                .replace(<span class="string">&#x27;&#123;&#125;_se_reduce_conv&#x27;</span>.<span class="built_in">format</span>(block_prefix), <span class="string">&#x27;conv2d&#x27;</span>).replace(<span class="string">&#x27;&#123;&#125;_se_expand_conv&#x27;</span>.<span class="built_in">format</span>(block_prefix), <span class="string">&#x27;conv2d_1&#x27;</span>)\</span><br><span class="line">                .replace(<span class="string">&#x27;&#123;&#125;_project_bn&#x27;</span>.<span class="built_in">format</span>(block_prefix), <span class="string">&#x27;tpu_batch_normalization_2&#x27;</span>).replace(<span class="string">&#x27;&#123;&#125;_project_conv&#x27;</span>.<span class="built_in">format</span>(block_prefix), <span class="string">&#x27;conv2d_1&#x27;</span>)\</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&#123;&#125;/&#123;&#125;/ExponentialMovingAverage&#x27;</span>.<span class="built_in">format</span>(model_name, key)</span><br></pre></td></tr></table></figure>
<p>输入keras的模型参数名，即可得到对应的原模型的参数名。有了参数转换逻辑，下面我们就可以开始转换参数了。</p>
<p>首先是将原模型的参数导出，我们可以在第一个测试里面加入下面这些代码，然后运行:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">vars</span> = <span class="built_in">dict</span>([(name, sess.run(var)) <span class="keyword">for</span> name, var <span class="keyword">in</span> var_dict.items()])</span><br><span class="line">pickle.dump(<span class="built_in">vars</span>, <span class="built_in">open</span>(<span class="string">&#x27;data/&#123;&#125;.params.pickle&#x27;</span>.<span class="built_in">format</span>(model_name), <span class="string">&#x27;wb&#x27;</span>))</span><br></pre></td></tr></table></figure>
<p>然后就是参数导入到keras模型了，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_weights</span>(<span class="params">model: keras.Model, pickle_weights_dir: <span class="built_in">str</span></span>):</span><br><span class="line">    vars_dict: <span class="type">Dict</span>[<span class="built_in">str</span>, np.ndarray] = pickle.loads(<span class="built_in">open</span>(<span class="string">&#x27;&#123;&#125;/&#123;&#125;.params.pickle&#x27;</span>.<span class="built_in">format</span>(pickle_weights_dir, model.name), <span class="string">&#x27;rb&#x27;</span>).read())</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;weights count in tensorflow model: &#x27;</span>, <span class="built_in">len</span>(vars_dict))</span><br><span class="line">    layers: <span class="type">List</span>[keras.layers.Layer] = [layer <span class="keyword">for</span> layer <span class="keyword">in</span> model.layers <span class="keyword">if</span> layer.weights]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;weights count in keras model: &#x27;</span>, <span class="built_in">sum</span>([<span class="built_in">len</span>(layer.weights) <span class="keyword">for</span> layer <span class="keyword">in</span> layers]))</span><br><span class="line"></span><br><span class="line">    weight_value_tuples = []</span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> layers:</span><br><span class="line">        <span class="keyword">for</span> w <span class="keyword">in</span> layer.weights:</span><br><span class="line">            <span class="built_in">print</span>(w.name)</span><br><span class="line">            key_in_pickle = map_weight_key(model.name, w.name)</span><br><span class="line">            weight_value_tuples.append((w, vars_dict[key_in_pickle]))</span><br><span class="line">    keras.backend.batch_set_value(weight_value_tuples)</span><br></pre></td></tr></table></figure>
<p>将我们第二个测试里面的代码行<code>model.load_weights('data/converted_weights/&#123;&#125;_imagenet_1000.h5'.format(model_name))</code>替换为<code>load_weights(model, 'data')</code>，然后运行，就可以得到和官方一样的结果了。</p>
<p>至此我们的模型转换就基本上完成了，还剩下一个简单的步骤，将这个模型的参数保存为h5格式，这个用<code>model.save_weights</code>就可以实现。保存为h5格式之后，我们就可以完全脱离官方的代码来工作了，后续就可以方便的集成到我们自己的工作中。</p>
<p>其实这里还遗留了一个任务没有完成。我们平时使用基础模型，一般不会保留<code>head</code>块，这一块用于最后的分类输出，是依赖于分类数量的，每个任务都可能不一样。去掉<code>head</code>块的任务，有兴趣的小伙伴们可以自己动手实现一下。</p>
]]></content>
      <categories>
        <category>machine-learning</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>AI</tag>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
        <tag>keras</tag>
        <tag>EfficientNet</tag>
      </tags>
  </entry>
  <entry>
    <title>从改善设计的角度理解TDD</title>
    <url>/2019/07/20/tdd-for-improving-design/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>TDD有很多好处，但是广大程序员却总是难以接受。即便在我们ThoughtWorks，有着非常浓厚的TDD氛围的公司里，接受起来也依然不是一件简单的事情。我曾经见过一些在我们公司工作过一年甚至两年的同事，对TDD的理解都还停留在比较粗浅的认识上，平时的实践也难以跟上。</p>
<span id="more"></span>
<p>为什么我们在接受这样一个优秀的实践的时候会这么困难呢？我认为是没有真正体会到TDD给我们带来的好处。我们通常说TDD，一般都是给大家强调软件质量，有了TDD，就有测试，软件质量就有保障了。这是最直接的一个好处，但是由于对于软件质量理解的不同，不少人在心底里并不是完全认同这一点的。测试其实只能说是TDD带来的好处之一，长时间实践下来，我觉得TDD带来的更多的是软件设计能力的提升。相信广大程序员普遍认同设计能力的高低是区分优秀程序员的一个重要标准，从提升设计的角度理解TDD，相信我们就更容易接受了。</p>
<p>TDD是如何帮助提升设计能力的？下面我将分享TDD在我们项目日常代码实践中的应用，希望能帮助提升对TDD的理解。</p>
<p>项目中有这样一个例子，我们的机器学习模型在训练开始的时候需要加载数十G的数据到内存（可用内存很大），这个数据加载过程比较慢，这让调试模型参数的需要等待较长时间才能看到结果。一个自然的想法就是先加载一部分的数据到内存，然后启动训练，再启动一个后台任务去加载其他的数据。（在这里，数据是一系列的大文件，约50个，每个文件600M大小。）如何实现这个功能呢？</p>
<p>这个任务的需求是比较明确的，我们从测试的角度出发考虑来看一下如何进行程序设计。为了编写测试，第一个问题是如何给测试命名。从需求来看，这里应该是完成数据加载的功能，结合面向对象的思想，好，那么我们就叫它数据加载器吧，<code>DataLoader</code>，听起来不错。于是就可以写下第一行测试代码了。如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> unittest</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DataLoaderTest</span>(unittest.TestCase):</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<p>这里的功能是要完成数据加载，那么接着写下测试用例的名字。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> unittest</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DataLoaderTest</span>(unittest.TestCase):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_should_load_data_correctly</span>():</span><br><span class="line">        ....</span><br></pre></td></tr></table></figure>
<p>测试代码应该是什么样的呢？DataLoader这个对象其实是需要对机器学习模型提供数据支持的，如何提供数据支持需要结合后续模型如何使用来确定。</p>
<p>由于我们想要做到异步数据加载，看了keras的<a href="https://keras.io/models/sequential/#fit_generator">文档</a>就会知道需要使用<code>fit_generator</code>这种方式来实现，而这个函数要求传入一个python的<code>generator</code>或者一个<code>keras.utils.Sequence</code>对象。好了，那么我们就需要使用这两个接口兼容的方式来设计接口。</p>
<p>为实现<code>keras.utils.Sequence</code>，需要实现接口<code>__len__</code>和<code>__getitem__</code>来获取总的batch的数量和每一个batch的数据。<code>generator</code>的方式似乎更简单，但是<code>fit_generator</code>需要我们传入迭代的次数<code>steps_per_epoch</code>，所以同样需要正确的知道总的数据量的大小。好了，我们需要实现的接口到这里就大致确定了。</p>
<p>从前面的分析来看，如果只是有一个数据加载器似乎不够，因为我们是需要给后续的训练提供整个数据访问支持的。OK，我们可以稍微扩展一下它的功能，不如叫<code>Dataset</code>吧，由于是异步加载数据的，可以叫<code>AsyncLoadedDataset</code>。按照这样的设计，修改测试如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> unittest</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AsyncLoadedDatasetTest</span>(unittest.TestCase):</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">test_should_be_able_to_get_data_from_dataset_correctly</span>():</span><br><span class="line">    dataset_path, batch_size = <span class="string">&#x27;/tmp/data&#x27;</span>, <span class="number">5</span></span><br><span class="line">    dataset = AsyncLoadedDataset(dataset_path, batch_size)</span><br><span class="line"></span><br><span class="line">    self.assertEqual(<span class="number">20</span>, dataset.batch_count())</span><br><span class="line">    self.assertEqual(pickle.load(<span class="built_in">open</span>(<span class="string">&#x27;/tmp/data/X.0.pickle&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>))[:<span class="number">5</span>],</span><br><span class="line">        dataset.get_batch(<span class="number">0</span>))</span><br><span class="line">    batch_idx_for_async_loaded_data = <span class="number">10</span></span><br><span class="line">    self.assertEqual([], dataset.get_batch(batch_idx_for_async_loaded_data))</span><br><span class="line"></span><br><span class="line">    time.sleep(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    self.assertEqual(pickle.load(<span class="built_in">open</span>(<span class="string">&#x27;/tmp/data/X.1.pickle&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>))[:<span class="number">5</span>], </span><br><span class="line">        dataset.get_batch(batch_idx_for_async_loaded_data))</span><br></pre></td></tr></table></figure>
<p>这里，通过测试看到了我们的类应该要提供什么样的接口，以及应该如何工作。首先是它的构造，我们传入了一个文件路径和一个<code>batch_size</code>，因为我们需要指定它从什么地方加载数据，以便可以加载准备好的测试数据，同时指定批大小之后，后续测试中就可以根据这个大小计算出相应的期望的数据。其次是接口的名字，根据需求来，使用业务术语，我们将其命名为<code>batch_count</code>和<code>get_batch</code>。（有人可能会问名字怎么得来的，这里的函数名的其实是来的非常自然的。读一下<code>dataset.batch_count</code>，就可以知道其指batch_count of this dataset，也就是这个数据集的批数量。读一下<code>dataset.get_batch</code>，就可以知道是从数据集获取某一批的数据。也就是说这里的名字只要取得让我们读起代码来符合英语阅读习惯就好了。当然如果用<code>get_batch_count</code> <code>get_batch_data</code>在命名一致性上更好，是不是也可以呢？当然也是可以的，这些小的变化过于细节，不用太纠结，最终以读代码是否像读文章一样通畅为标准就行。）</p>
<p>到这里我们就将我们想要的类的设计完成了。而且经过我们在测试中的使用，这个类应该是易于使用的。我们对于这个类的设计应该是比较满意的。这个类的定义几乎是呼之欲出，如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AsyncLoadedDataset</span>:</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data_dir: <span class="built_in">str</span>, batch_size: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">batch_count</span>() -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">get_batch</span>(<span class="params">batch_idx: <span class="built_in">int</span></span>) -&gt; <span class="type">Union</span>[<span class="type">List</span>, np.ndarray]:</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>我们来回顾一下上面的过程，仔细体会一下TDD是如何帮助完成一个让我们满意的设计的。有以下几点，可以归功于TDD：</p>
<ol>
<li>从测试开始写，这帮助我们梳理清楚了需求。让我们从开始理解的<code>DataLoader</code>推进到后续理解的<code>AsyncLoadedDataset</code>，我们加深了对需要解决的问题的理解</li>
<li>从测试开始写，这帮助我们从面向对象的角度进行程序设计，抽象了一个<code>AsyncLoadedDataset</code>对象</li>
<li>从测试开始写，这帮助我们设计了正确且易于使用的类的构造器</li>
<li>从测试开始写，这帮助我们从代码阅读者的视角出发给函数命名，从而得到一个更好的名字。</li>
</ol>
<p>上述“帮助”一词，其实可以完全替换为“驱动”，这也就是测试驱动开发了。</p>
<p>（有人会争辩这个测试是不是好的单元测试，因为这个测试事实上是对外部的数据产生了依赖，而且测试中有<code>time.sleep</code>出现，运行会很慢。这很正确，我们这里的测试本来就不是一个单元测试，它的定位应该是一个小的集成测试。为什么要用这个小的集成测试呢？我们这里做的其实是实现功能的第一步，第一步当然是站在功能完整的角度来看问题。并且，我们需要测试的是线程能不能正常工作，数据能不能正常加载，并正确计算。这里问题的核心就涉及到和线程模块以及数据加载模块的集成。所以我们的测试就写成了一个小的集成测试。</p>
<p>为了让这个测试变得更易于维护，我们可以准备一份很小的测试数据放到我们的测试资源里面当做代码的一部分管理起来。我们甚至还可以mock掉线程的API，让我们的测试运行更快，但是这样做了之后，这个测试是不是会降低我们对代码正确的信心呢？在这里，易于维护和增强信心有一定的冲突，我也没有答案，这可能是大家要去平衡的一个问题。）</p>
<p>到这里我们可以开始写我们的代码了。我们可以编写这样的实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AsyncLoadedDataset</span>:</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data_dir: <span class="built_in">str</span>, batch_size: <span class="built_in">int</span></span>):</span><br><span class="line">    self.data_dir = data_dir</span><br><span class="line">    self.files = os.listdir(data_dir)</span><br><span class="line">    self.files.sort()</span><br><span class="line"></span><br><span class="line">    self.batch_size = batch_size</span><br><span class="line"></span><br><span class="line">    self.x_train, self.y_train = [], []</span><br><span class="line">    self._load_data(self.files[<span class="number">0</span>:<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    self._loader_thread = Thread(target=self._load_data, args=self.files[<span class="number">1</span>:], deamon=<span class="literal">True</span>)</span><br><span class="line">    self._loader_thread.start()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">_load_data</span>(<span class="params">self, files: <span class="type">List</span>[<span class="built_in">str</span>]</span>):</span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> files:</span><br><span class="line">      x, y = pickle.load(<span class="built_in">open</span>(os.path.join(self.data_dir, f), <span class="string">&#x27;rb&#x27;</span>))</span><br><span class="line">      self.x_train.append(x)</span><br><span class="line">      self.y_train.append(y)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">batch_count</span>() -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">get_batch</span>(<span class="params">batch_idx: <span class="built_in">int</span></span>) -&gt; <span class="type">Union</span>[<span class="type">List</span>, np.ndarray]:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>(这里的实现没有考虑一些边界情况，比如当数据文件数据数量少于2个时，因为我们实际用的时候没有这些问题，为了快速实现，先忽略这些问题。)</p>
<p>数据加载这一部分可以很容易的实现，但是后续关于batch的处理要怎么实现呢？仔细想一下，这里的batch处理还是有点复杂的。第一，我们要拿到所有的数据量大小才能计算总的batch数量，如果全部读一遍肯定很慢，让我们的异步加载失去价值；第二，读取任意一个batch的数据时候，有时候可能会跨文件访问数据。</p>
<p>对于第一个问题，我们可以设计一个缓存，在使用数据集之前构建好这个缓存，比如我们可以规定数据目录里面必须有一个<code>total_count</code>的文件来指定总共的数据量大小。</p>
<p>第二个问题有一个非常简单的实现方式，那就是将所有的已加载数据组成一个新的list，然后整体上去计算batch对应的数据索引。但这里我们的数据量很大，我们需要避免数据拷贝产生大量的内存消耗，还需要避免连接列表带来的性能开销。这里我们可能需要根据每个文件中数据量的大小去计算索引，这个问题在逻辑上就比较复杂了，我们很难有信心一次性写对。但这是一个不错的方案。这个时候，我们就想，能不能对这一块的代码建立一个测试呢？这种逻辑复杂的情况下，测试可以辅助我们更容易的写出正确的代码。要建立这样一个测试，我们希望最好能独立于之前的测试存在，因为这样的测试会更容易写。为了达到这一目的，进一步思考，我们是不是可以将这个问题抽象成为一个更通用的问题？这里我们本质上是想以和单个列表访问数据类似的方式从多个列表中访问数据。好了，我们可以抽象一个通用的类<code>MultiList</code>来表达这个想法。<code>MultiList</code>就是一个由多个列表组成的，表面看起来像一个列表的东西。</p>
<p>有了这里的分析，我们可以得到我们的测试如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MultiListTest</span>(unittest.TestCase):</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">test_should_get_data_from_multi_list_as_the_provided_index_range</span>():</span><br><span class="line">    ml = MultiList(<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">10</span>)), <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">10</span>, <span class="number">20</span>)), <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">20</span>, <span class="number">30</span>)))</span><br><span class="line">    self.assertEqual(<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">0</span>, <span class="number">5</span>)), ml.get_range(<span class="number">0</span>, <span class="number">5</span>))</span><br><span class="line">    self.assertEqual(<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">5</span>, <span class="number">8</span>)), ml.get_range(<span class="number">5</span>, <span class="number">8</span>))</span><br><span class="line">    self.assertEqual(<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">5</span>, <span class="number">15</span>)), ml.get_range(<span class="number">5</span>, <span class="number">15</span>))</span><br><span class="line">    self.assertEqual(<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">5</span>, <span class="number">21</span>)), ml.get_range(<span class="number">5</span>, <span class="number">21</span>))</span><br><span class="line">    self.assertEqual(<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">5</span>, <span class="number">30</span>)), ml.get_range(<span class="number">5</span>, <span class="number">100</span>))</span><br></pre></td></tr></table></figure>
<p>有了这个测试，我们的实现还会远吗？有兴趣的小伙伴可以当做练习完成后面对于这个<code>MultiList</code>及<code>AsyncLoadedDataset</code>的实现。这里主要是帮助我们体会完成设计的过程，从而体会TDD给我们带来的好处，对于后续细节就不赘述了。我们再来回顾一下TDD是如何帮我们完成设计的：</p>
<ol>
<li>从测试的角度出发，我们做了更进一步的抽象，从而得到了一个通用的<code>MultiList</code>对象</li>
<li>从测试的角度出发，我们完成了对象的构造器及方法的设计</li>
<li>从测试的角度出发，我们完成了对于对象的功能的定义，从而也展示了对象的使用方法</li>
</ol>
<p>通过上面这个例子，相信大家能感受到TDD给我们设计带来的好处。总结起来，TDD可以辅助提升面向对象设计水平，TDD可以辅助提升代码可读性，<br />
TDD可以辅助理解并应用SOLID原则进行程序设计。一句话总结TDD在实践中发挥的作用，我认为是，因为TDD让我们从使用者的角度去看待我们的设计，为了方便我们自己的阅读和理解，我们会自然的得到易于使用的设计，从而自然的就让我们的设计变得更好了。</p>
<p>通过上面的经验的分享，不知道大家是不是更认可和接受TDD了呢？但是要熟练运用起来，关键还是在于刻意的去练习。这里面要写好测试技巧其实就是比较多的，不过每天的日常工作都是机会，希望大家能保持开放的心态，严格要求自己，遇到问题多讨论交流。当团队中所有人的代码能力都上去了的时候，我们才能说我们是一个高效的团队，我们能做高质量的产品。所以，加油吧！</p>
]]></content>
      <categories>
        <category>tdd</category>
        <category>敏捷</category>
      </categories>
      <tags>
        <tag>agile</tag>
        <tag>敏捷</tag>
        <tag>tdd</tag>
        <tag>测试</tag>
        <tag>质量</tag>
      </tags>
  </entry>
  <entry>
    <title>程序员需要知道的编译器知识</title>
    <url>/2019/07/24/what-programmer-should-know-about-compiler/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>我们每天都在用某种编程语言写代码，但是我们真的了解它们是如何工作的吗？代码是如何转换为计算机可以识别的机器码的呢？</p>
<p>了解编程语言的工作原理，不仅可以让我们深入理解某一种编程语言，某些时候还可以帮助以一种更优雅的方式实现想要的功能。比如我们平时谈论很多的DSL（Domain Specific Language），在定义了DSL之后，我们如何做更进一步的支持呢？事实上我们还可以实现DSL的自动错误检查，还可以将其转化为某种可以执行的程序等等。还比如我们经常遇到的模式识别问题，状态机相关问题等等。对于这些问题，编程语言的实现原理可以给我们很多启示。</p>
<span id="more"></span>
<p>那么编程语言是如何工作的呢？详细的理论知识得回到我们大学时代的编译原理课程。下面我将主要从实例出发，辅以必备的几个概念介绍来帮助理解编程语言的工作原理，并介绍一些实用的工具帮助我们日常的开发。</p>
<h2 id="一个例子"><a class="markdownIt-Anchor" href="#一个例子"></a> 一个例子</h2>
<p>首先我们来看一个最简单的四则运算的例子。在这里我们想定义一种支持简单的 <strong>正整数四则运算</strong> 的语言。</p>
<p>首先是语言中的概念和符号：</p>
<ul>
<li>正整数： <code>[0-9]+</code> (正则表达式定义)</li>
<li>运算符号： <code>+</code> <code>-</code> <code>*</code> <code>/</code></li>
</ul>
<p>然后我们定义<code>*</code>和<code>/</code>的优先级一样，<code>+</code>和<code>-</code>的优先级一样，<code>*</code> <code>/</code>高于<code>+</code> <code>-</code>，与我们一般的理解一致。</p>
<p>这个描述我们可以用一种更规范的形式来表示，如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tokens:</span><br><span class="line">    NUMBER  : r&#x27;[0-9]&#x27;</span><br><span class="line"></span><br><span class="line">expressions:</span><br><span class="line">    expr    : NUMBER</span><br><span class="line">            | expr + expr</span><br><span class="line">            | expr - expr</span><br><span class="line">            | expr * expr</span><br><span class="line">            | expr / expr</span><br></pre></td></tr></table></figure>
<p><code>expressions</code>中的语句采用了递归的形式进行定义（<code>|</code>表示或者），这样可以满足任意长度的任意组合了。</p>
<p>像这样一种更规范的格式就是我们所谓的上下文无关文法了，其中著名的BNF范式就是其中一种。</p>
<h2 id="几个概念"><a class="markdownIt-Anchor" href="#几个概念"></a> 几个概念</h2>
<p>什么是上下文无关文法？</p>
<p>要理解这个概念，我们先得知道形式语言。形式语言是用 <strong>精确的</strong> 数学或机器可处理的 <strong>公式</strong> 定义的语言。这个概念是专门为计算机定义的，但仅仅从这句话来看，其实还是模糊的，什么样的公式才是数学和机器可处理的呢？</p>
<p>这就牵涉到形式文法的概念，文法用于构成语言，形式文法就是用于构成形式语言的。文法可以类比我们自然语言中的<em>主谓宾</em>、<em>主系表</em>这类语言结构规则。那么形式文法呢？形式文法就是数学和计算机可以处理的一种比较严谨的语言结构规则。事实上形式文法可以表示为一个四元组（非终结符N, 终结符Σ, 产生式规则P, 起始符S），这个四元组里面不仅仅有规则，还包括了规则的作用范围，符号等。这个四元组就是数学上的定义。有了这个定义，我们就可以用数学逻辑推导相关文法理论了。到这里大家应该有一点概念了，本文并不想过多涉及理论，详细的数学分析及示例可以参考<a href="https://zh.wikipedia.org/wiki/%E5%BD%A2%E5%BC%8F%E6%96%87%E6%B3%95">wiki</a>。</p>
<p>上下文无关文法，顾名思义，就是上下文无关的一种形式文法，这种文法虽然简单，但是非常重要，因为所有的编程语言都是基于它来设计的。BNF（Backus Normal Form），也就是巴克斯-诺尔范式（由他们最先引入），就是我们经常用来表达上下文无关文法的一种符号集。前面关于 <strong>正整数四则运算</strong> 语言的规范定义就是用BNF格式来定义的。</p>
<p>我们说某种BNF严格的定义了相应的语言，也可以说某种语言由其对应的BNF来严格定义。比如C语言由C语言的BNF来定义，JAVA语言由JAVA语言的BNF来定义。</p>
<h2 id="理解语言"><a class="markdownIt-Anchor" href="#理解语言"></a> 理解语言</h2>
<p>有了语言定义，我们可以做什么呢？一个直接的任务应该就是理解语言并将其转化为计算机可以执行的代码，以便在机器上运行。完成这个任务的东西我们叫编译器。</p>
<p>有时候其实我们并不一定要让计算机计算出一个结果，而是只要计算机能理解语言，然后在根据这些理解来做一些事情。如何才算理解了语言？对于某一行代码，事实上可以用一棵树结构来描述它，树结构一个节点代表语言定义的一个简单推导。比如<code>1 + 2 + 3</code>可以表示成：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">expr   |-- NUMBER(3)</span><br><span class="line">       +</span><br><span class="line">       |-- expr   |-- NUMBER(1)</span><br><span class="line">                  +</span><br><span class="line">                  |-- NUMBER(2)</span><br></pre></td></tr></table></figure>
<p>这里的树结构被称为语法树，有了这颗语法树，我们就可以说理解语言了。事实上从这颗语法树出发我们可以完成很多和这门语言相关的任务，比如我们可以做语法分析查错，可以做代码优化重构提示，可以做代码编写提示，当然还可以将其翻译为机器码等等。IDE的很多功能就是依赖于语法树来实现的。</p>
<h2 id="理解四则运算语言"><a class="markdownIt-Anchor" href="#理解四则运算语言"></a> 理解四则运算语言</h2>
<p>理解语言一般我们可以分为两个步骤，第一是理解词，第二是按照语法规则将词组织成语法树。比如四则运算的例子，我们在构造语法树的时候，输入一个字符串，然后需要依次提取字符串中的词（这里的词是指正整数和<code>+-*/</code>符号），最后根据词和规则来构造语法树。</p>
<p>在这个简单的例子中，识别词的过程我们可以用简单的正则匹配来实现。但是构造语法树的时候，我们需要构造一个有限状态机（finite-state machine）来实现，这看起来就好像并不是一件简单的事了。</p>
<p>事实上，关于计算机语言的分析早在上世纪50年代就有了比较系统的研究了，相关工具当然也是非常成熟和丰富。最早的工具莫过于<code>lex(lexical analyser)</code>和<code>yacc(yet another compiler-compiler)</code>了。<code>lex</code>就是用来做词法分析的，<code>yacc</code>可以用<code>lex</code>的词法分析结果来生成语法树。这两个工具可以帮我们生成理解语言的源代码。但是这两个工具是unix系统下的工具，而我们现在用的一般都是GNU的系统。在GNU的系统下的两个类似实现是<code>flex</code>和<code>bison</code>，ubuntu系统下我们可以用<code>sudo apt-get install flex bison</code>来安装。</p>
<p>由于这两个工具是生成c语言的语法分析器代码。为了简单的在python下做一些实验，我们使用<a href="https://github.com/dabeaz/ply">ply</a>这个工具，它的全称是<code>python lex-yacc</code>，也就是python版本的lex和yacc。参考<a href="http://www.dabeaz.com/ply/ply.html">ply的文档</a>，要实现上述四则运算，我们可以编写代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tokens = (<span class="string">&#x27;NAME&#x27;</span>, <span class="string">&#x27;NUMBER&#x27;</span>, )</span><br><span class="line">literals = <span class="string">&#x27;+-*/&#x27;</span></span><br><span class="line"></span><br><span class="line">t_NAME = <span class="string">r&#x27;[a-zA-Z_][a-zA-Z0-9_]*&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">t_NUMBER</span>(<span class="params">t</span>):</span><br><span class="line">    <span class="string">r&#x27;\d+&#x27;</span></span><br><span class="line">    t.value = <span class="built_in">int</span>(t.value)</span><br><span class="line">    <span class="keyword">return</span> t</span><br><span class="line"></span><br><span class="line">precedence = ((<span class="string">&#x27;left&#x27;</span>, <span class="string">&#x27;+&#x27;</span>, <span class="string">&#x27;-&#x27;</span>), (<span class="string">&#x27;left&#x27;</span>, <span class="string">&#x27;*&#x27;</span>, <span class="string">&#x27;/&#x27;</span>), )</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">p_statement_expr</span>(<span class="params">t</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;statement : expression&quot;&quot;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(t[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">p_expression_binop</span>(<span class="params">p</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;expression : expression &#x27;+&#x27; expression</span></span><br><span class="line"><span class="string">                  | expression &#x27;-&#x27; expression</span></span><br><span class="line"><span class="string">                  | expression &#x27;*&#x27; expression</span></span><br><span class="line"><span class="string">                  | expression &#x27;/&#x27; expression</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> p[<span class="number">2</span>] == <span class="string">&#x27;+&#x27;</span>: p[<span class="number">0</span>] = p[<span class="number">1</span>] + p[<span class="number">3</span>]</span><br><span class="line">    <span class="keyword">elif</span> p[<span class="number">2</span>] == <span class="string">&#x27;-&#x27;</span>: p[<span class="number">0</span>] = p[<span class="number">1</span>] - p[<span class="number">3</span>]</span><br><span class="line">    <span class="keyword">elif</span> p[<span class="number">2</span>] == <span class="string">&#x27;*&#x27;</span>: p[<span class="number">0</span>] = p[<span class="number">1</span>] * p[<span class="number">3</span>]</span><br><span class="line">    <span class="keyword">elif</span> p[<span class="number">2</span>] == <span class="string">&#x27;/&#x27;</span>: p[<span class="number">0</span>] = p[<span class="number">1</span>] / p[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">p_expression_number</span>(<span class="params">p</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;expression : NUMBER&quot;&quot;&quot;</span></span><br><span class="line">    p[<span class="number">0</span>] = p[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_lex_yacc</span>():</span><br><span class="line">    <span class="keyword">import</span> ply.lex <span class="keyword">as</span> lex</span><br><span class="line">    <span class="keyword">import</span> ply.yacc <span class="keyword">as</span> yacc</span><br><span class="line">    lexer = lex.lex()</span><br><span class="line">    parser = yacc.yacc()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            s = <span class="built_in">input</span>(<span class="string">&#x27;calc &gt; &#x27;</span>)</span><br><span class="line">            lexer.<span class="built_in">input</span>(s)</span><br><span class="line">            <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                tok = lexer.token()</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> tok:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                <span class="built_in">print</span>(tok)</span><br><span class="line">            parser.parse(s, lexer=lexer)</span><br><span class="line">        <span class="keyword">except</span> EOFError:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    test_lex_yacc()</span><br></pre></td></tr></table></figure>
<p>运行这个程序，输入我们的表达式，将能得到正确的结果，如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">calc &gt; 1+2*3</span><br><span class="line">LexToken(NUMBER,1,1,0)</span><br><span class="line">LexToken(+,&#x27;+&#x27;,1,1)</span><br><span class="line">LexToken(NUMBER,2,1,2)</span><br><span class="line">LexToken(*,&#x27;*&#x27;,1,3)</span><br><span class="line">LexToken(NUMBER,3,1,4)</span><br><span class="line">7</span><br></pre></td></tr></table></figure>
<h2 id="一个更复杂的例子"><a class="markdownIt-Anchor" href="#一个更复杂的例子"></a> 一个更复杂的例子</h2>
<p>正整数四则运算的例子看起来过于简单，实际上我们可以用ply实现非常复杂的语法分析器。比如我们可以实现一个用于识别python的函数定义的语法分析器。有了这个分析器，我们就可以从识别结果中获取函数名，参数名，类型信息等，从而完成一些类似代码质量分析，自动代码格式化等工作。</p>
<p>初步看这个问题，似乎正则表达式可以解决一定的问题，但是仅仅有正则表达式是不够的，因为python的很多语法规则过于复杂，难以通过正则表达式来表达。</p>
<p>为识别python的函数定义，我们可以编写测试如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test_yacc_for_python_func_def</span>():</span><br><span class="line">    test_code_lines = [</span><br><span class="line">        <span class="string">&#x27;def abc(a,):&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;def abc(a,):&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;def abc(a,#xxx()[]\n):&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;def abc(a: List[int],):&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;def abc() -&gt; int:&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;def abc(a, b) -&gt; List[int]:&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;def abc(a, b: Union[int, List[float]],) -&gt; Union[int, float]:&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;def abc(a,) -&gt; Union[int, List[float]]:&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;def abc(a,) -&gt; Union[int, List[float], float]:&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;def abc(a,) #xxx()[]\n -&gt; Union[int, List[float], float]:&#x27;</span></span><br><span class="line">    ]</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> test_code_lines:</span><br><span class="line">        yacc.parse(line, lexer=lexer)</span><br></pre></td></tr></table></figure>
<p>有兴趣的小伙伴可以自己尝试实现，或者参考<a href="https://github.com/gmlove/experiments/blob/master/python_lex_yacc/py_func_def.py">这里</a>我实现的一个版本。</p>
<h2 id="实用的工具"><a class="markdownIt-Anchor" href="#实用的工具"></a> 实用的工具</h2>
<p>上面的工具已经可以帮我们做很多了，看起来甚至自己定义一门编程语言也是可能的。然而这件事的难度在于，对于一门好用的编程语言，语法定义要足够丰富好用，性能要足够高，相关生态要能做得起来。这就不是单纯的技术活了。</p>
<p>在日常的开发活动中，我们可能接触最多的还是对于当前流行的编程语言的处理。比如，某一天我们可能想要实现一个工具将一个java实现的库，转换为python实现，<a href="https://github.com/natural/java2python">这里</a>就有一个不错的尝试。又比如，某一天我们想要改进我们的IDE，尝试做更多特殊的自动代码格式化支持。还比如，某一天我们想要自动化生成一些代码，就像IDE里面的重构一样。这个时候有没有什么工具可以帮助我们呢？</p>
<p>当然是有的，这里想要提一下 <strong>ANTLR</strong>。代码库在<a href="https://github.com/antlr/antlr4">这里</a>。这是一个java实现的类似工具，支持的语言非常广泛，我们可以在<a href="https://github.com/antlr/grammars-v4">这里</a>找到一个列表。可以看到这里支持了go python3 java9等等非常多的语言，基本上我们日常用到的语言都有覆盖了。而且这个工具可以生成各种目标语言的语法分析器。比如我们想得到一个python语言实现的go语言分析器，这个工具可以很容易实现。类似的工具还有很多，我们可以参考wiki上面的一个<a href="https://en.wikipedia.org/wiki/Comparison_of_parser_generators">比较</a>。</p>
<p>如果我们只想用一种编程语言去分析该语言自身，这个时候更简单的方式是直接用语言本身提供的语法分析器。一般提供了JIT(just in time的缩写, 也就是即时编译编译器)功能的语言，都有相应的接口去做语法分析。比如<a href="https://docs.python.org/3/library/ast.html">这里</a>有python的<code>ast</code>库，调用<code>ast.parse</code>，输入一段源代码，就得到一颗语法树。javascript有一个第三方库<code>esprima</code>(<a href="https://esprima.org/">这里</a>)也可以做类似的事情。</p>
<p>到这里我们是不是对日常使用的编程语言有了更深入的了解呢？编译技术是一门强大的技术，灵活运用将能实现不少平时看起来很难的功能。希望当我们遇到这些问题的时候能有一些新的思路。</p>
<p>参考：</p>
<ul>
<li><a href="http://dinosaur.compilertools.net/">http://dinosaur.compilertools.net/</a></li>
<li><a href="https://zh.wikipedia.org/wiki/%E5%B7%B4%E7%A7%91%E6%96%AF%E8%8C%83%E5%BC%8F">https://zh.wikipedia.org/wiki/巴科斯范式</a></li>
<li><a href="https://zh.wikipedia.org/wiki/%E5%BD%A2%E5%BC%8F%E6%96%87%E6%B3%95">https://zh.wikipedia.org/wiki/形式文法</a></li>
<li><a href="https://zh.wikipedia.org/wiki/%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E6%96%87%E6%B3%95">https://zh.wikipedia.org/wiki/上下文无关文法</a></li>
<li><a href="https://en.wikipedia.org/wiki/Comparison_of_parser_generators">https://en.wikipedia.org/wiki/Comparison_of_parser_generators</a></li>
</ul>
]]></content>
      <categories>
        <category>技术</category>
        <category>compiler</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>compiler</tag>
        <tag>lex</tag>
        <tag>yacc</tag>
      </tags>
  </entry>
  <entry>
    <title>你可能需要一个轻量级的中台</title>
    <url>/2019/08/06/you-may-need-a-lightweight-zhongtai/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>中台的概念从阿里17年开始提出来就快速成为了年度IT热词。阿里这样体量的企业的成功无疑论证了中台建设的正确性，让大家对于中台这样的解决方案跃跃欲试。而阿里顺理成章成为了中台的最好代言人，大家学习中台的榜样。那么什么是中台？事实上，对于中台的定义大家也一直在探讨中。阿里内部业务系统有其独有的特点，诞生其中的中台自然也带着阿里独有的特征，这一点从<a href="https://book.douban.com/subject/27039508/">《企业IT架构转型之道：阿里巴巴中台战略思想与架构实战》</a>这本书中我们也能读出来。直接复制阿里的中台方案真的能解决广大企业中的共性问题吗？可能未必，这应该也是当前大家关于数据中台有着各种各样的解读的原因。</p>
<span id="more"></span>
<h2 id="什么是中台"><a class="markdownIt-Anchor" href="#什么是中台"></a> 什么是中台</h2>
<p>关于阿里的中台我们可以找到非常多的内容，下面我尝试将当前基本上成为大家共识的理解概括一下。</p>
<p>中台包括两部分，即数据中台和业务中台。数据中台以数据平台技术为基础，解决数据孤岛、数据标准化、数据存储、数据泛滥等数据管理问题。业务中台提供多种多样的数据分析、数据挖掘、机器学习服务，为快速业务响应、快速业务创新提供支持。从建设方式上看，数据中台的建设应该站在公司战略高度，从顶层着手，自上而下的驱动完成，这样便于统筹规划，避免来自各个业务部门的阻力。同时建设数据中台应该改革组织结构，独立一个中台部门来专门从事中台建设工作。</p>
<p>从这些理解来看，中台建设是个大工程，其针对的企业也是成熟的大型企业。这样一个大工程，投入量也相应是巨大的，资金投入，人员投入，时间成本都非常高昂。如果中台能解决上面提到的数据管理和数据服务问题，那它确实能带来可观的价值。但对于这样一个看似庞大的方案，我们要如何去落地呢？以我们当前的精益敏捷认知来看，是不是顶层设计、组织结构变革这些都过于重量级了呢？事实上这个问题也就是当前中台方案落地的主要问题。</p>
<h2 id="再次思考中台业务价值"><a class="markdownIt-Anchor" href="#再次思考中台业务价值"></a> 再次思考中台业务价值</h2>
<p>虽然从上面对于中台的阐述中，我们能感受到中台带来的潜在的巨大价值，但是回到企业的具体场景中，似乎这些又都是漂浮在空中，优先级不高的事物。在企业在广泛发展自己的主营业务时，其实我们已经有大量的业务人员在思考和尝试创新，他们已经或正在基于自己的分析提出很多新的观点。比如现在我们的应用都会集成数据统计分析平台，在进行迭代优化决策的时候，我们往往使用已有的数据工具就能得出结论。中台真的能比我们现在做的好得多吗？或者说我们一次性花很大力气去建设一个大而全的中台，投入产出比真的高吗？</p>
<p>中台究竟如何产生价值呢？事实上这里价值产生的基础是数据共享。企业中，我们一般按照业务线将公司组织成不同的部门，不同的部门相互之间是相对隔离而自治的团体。如果没有共享的数据支撑，各业务部门将各自按照自己的方式发展，能利用的资源也限制在部门内部，这样就容易错过一些潜在的机会。比如，如果没有淘宝的数据，想必天猫的发展速度会大大减慢。也就是说，当我们有了多条成熟的业务线时，中台可以以资源整合的优势辅助各个业务线相互促进，联合创新。</p>
<h2 id="如何共享数据"><a class="markdownIt-Anchor" href="#如何共享数据"></a> 如何共享数据</h2>
<p>既然共享数据是中台的核心，那么我们会以什么样的途径去共享数据呢？</p>
<p>分析使用共享数据的过程可以发现，一种情况是我们可以分析其他相关业务线共享的数据，从而产生新的理解来支持本业务线的发展。这里我们一般以原始数据的形式共享，以各种报表的形式产生价值。第二种情况是，我们以原始数据或者加工过的数据分析结果作为数据源，使用API的方式供业务消费。</p>
<p>通常情况下，企业会单独设立一个大数据部门，这个部门会汇总来自多个业务线的数据，同时这个部门会重点培养大数据处理相关技能，以承载来自各个业务线的数据分析需求。这就支持了上述第一种情况。如果企业里面已经是这样的组织架构，看起来是已经走在中台建设的路上了。但是情况也不总是这样，一般而言，当多条业务线都足够庞大时，为提高业务响应力，我们通常也会将这个大数据部门按照业务去拆分，从而形成多个大数据部门的现实。这同时又导致了数据共享的问题。</p>
<p>为什么总是会存在这样的情况呢？因为业务是最具有内聚性的，共享的数据其实都是一定程度的耦合，而我们为了提高效率总是会尝试提高内聚降低耦合。在中台实施的过程中，我们要如何降低耦合呢？用上述第二种方式是我们常用的手段。不同的部门以公开API的形式来共享自己的能力，如果我们要访问其他业务线的能力，使用该部门公布出来的稳定API即可。即便是数据分析的需求，其实我们也可以用这样的方式实现。这里可以分两步完成，一是各个业务线要公布足够多的数据以便数据分析时可以有一个全局的视角，二是在分析时需要访问API获取数据形成一个支持分析的数据集，再进行分析。</p>
<h2 id="以敏捷精益的方式实现中台价值"><a class="markdownIt-Anchor" href="#以敏捷精益的方式实现中台价值"></a> 以敏捷精益的方式实现中台价值</h2>
<p>基于上面的分析，我们来尝试以更轻量级的方式思考如何实现中台价值。</p>
<p>其实通过API的形式公开业务能力，我们已经在实践了，而且可能已经做得不错了。举一个典型的例子，比如我们企业中很多业务需要支付能力，我们一般会建设一个专门做支付业务的部门，那么对于一个新的需要支付能力的业务，他只需要对接已有的支付业务部门的API就好了。这里我们避免了各个业务部门去做能力的重复建设，节省了资源，各个部门工作也相对顺畅。这是一种通过API的形式公开业务能力的典型形式。但是中台价值实现要求我们做得更多，因为中台除了希望我们共享业务能力，还希望我们共享数据。比如，作为业务部门，我们不仅希望分析支付过程的流畅程度，我们还可能希望和其他业务的支付过程进行比较和借鉴。对于这样的需求，通常当前的业务能力共享还有所不足。</p>
<p>综合这里的分析，我们可以发现一种更敏捷和精益的中台建设思路。我们无需购买大数据中台产品，也无需对现有的组织结构进行调整，我们要做的是一步一步推进各个业务线去共享数据，同时一步一步推进各个业务线去挖掘其他业务线可能带来的潜在价值。从这里起步，如果我们能找到共享数据里面的巨大价值点，那么我们可以建立独立的部门把这个价值点当做新的业务来开拓。这里的思路是否可以用于中型或者小型企业呢？答案看起来是显然的，这是一种从小到大，是一种更自然的方式。</p>
<h2 id="产品化"><a class="markdownIt-Anchor" href="#产品化"></a> 产品化</h2>
<p>更进一步，我们可能需要这样的一个产品，它可以方便的以API的形式将某条业务线的数据能力公布出来，可以方便的设置权限以防止数据泄露，可以方便的找到其他业务线的数据API，可以做一定的API使用统计和监控。有了这样一个产品，我们将能快速的促进数据共享，推进价值发现和业务创新，中台的核心价值将得到实现。</p>
<p>以上就是我们的一些想法，看起来可以以更敏捷更精益的方式落地中台。想打造这样的一个产品看起来也不难，不知道你们的企业里面是否会愿意做这样的尝试呢？</p>
<p><strong>参考</strong></p>
<p><a href="https://zhuanlan.zhihu.com/p/53843604">https://zhuanlan.zhihu.com/p/53843604</a><br />
<a href="https://yq.aliyun.com/articles/630211">https://yq.aliyun.com/articles/630211</a><br />
<a href="https://www.infoq.cn/article/4PXxXJ*ZOmPVlAtB2Ttb">https://www.infoq.cn/article/4PXxXJ*ZOmPVlAtB2Ttb</a><br />
<a href="https://book.douban.com/subject/27039508/">https://book.douban.com/subject/27039508/</a></p>
]]></content>
      <categories>
        <category>数据</category>
        <category>架构</category>
      </categories>
      <tags>
        <tag>架构</tag>
        <tag>中台</tag>
      </tags>
  </entry>
  <entry>
    <title>Python性能优化二三事</title>
    <url>/2019/07/25/ways-to-improve-python-perf/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>随着机器学习的流行，Python近几年的热度一直在上升，再加上Python本身语言设计的简洁直观和易用，Python越来越得到开发者的青睐。但是我们却时常听说Python性能低，不如java，更比不上C。在这些抱怨背后到底是什么原因呢？Python真的性能低下吗？有没有什么优化的办法呢？</p>
<p>对于单纯的复杂计算过程，Python性能是比较低的，这是由于Python本身在设计时首要考虑的是如何快速完成工作（get things done），所以在性能上难免会有一定的牺牲。但是由于python和c有着非常好的互操作性，这类问题都可以通过实现一个c语言的版本来解决。当然从代码编写技巧的角度也有一定的优化空间，如果我们想做极致的性能优化，可以参考<a href="https://wiki.python.org/moin/PythonSpeed/PerformanceTips">官方的性能优化技巧</a>。</p>
<span id="more"></span>
<p>多数时候，当我们想加快程序运行速度，使用多线程或多进程并行应该是首要考虑的方案。它将能有效利用资源，直接带来数倍至数十倍的性能提升。然而Python的多线程可以说饱受诟病。有经验的Python开发者可能会说Python的多线程就是鸡肋，多进程才能真正带来计算加速。这是为什么呢？本文将进行简单的分析，并分享我们实际项目中的性能优化经验。</p>
<h2 id="python多线程问题"><a class="markdownIt-Anchor" href="#python多线程问题"></a> Python多线程问题</h2>
<p>(下面所有测试使用Windows系统下的Python 3.7.2版本进行，计算机有4核心cpu)</p>
<p>假设我们有这样的一段这样的密集计算型代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@log_time</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">heavy_calculation</span>():</span><br><span class="line">    <span class="keyword">import</span> math</span><br><span class="line">    a = <span class="number">0</span></span><br><span class="line">    <span class="built_in">pow</span> = math.<span class="built_in">pow</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10000000</span>):</span><br><span class="line">        a += <span class="built_in">pow</span>(<span class="number">2</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@log_time</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">exec_in_single_thread</span>():</span><br><span class="line">    heavy_calculation()</span><br><span class="line">    heavy_calculation()</span><br><span class="line"></span><br><span class="line"><span class="meta">@log_time</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">exec_in_multi_thread</span>():</span><br><span class="line">    <span class="keyword">from</span> threading <span class="keyword">import</span> Thread</span><br><span class="line"></span><br><span class="line">    threads = [Thread(target=heavy_calculation), Thread(target=heavy_calculation)]</span><br><span class="line">    <span class="keyword">for</span> thread <span class="keyword">in</span> threads:</span><br><span class="line">        thread.start()</span><br><span class="line">    <span class="keyword">for</span> thread <span class="keyword">in</span> threads:</span><br><span class="line">        thread.join()</span><br><span class="line"></span><br><span class="line">exec_in_single_thread()</span><br><span class="line">exec_in_multi_thread()</span><br></pre></td></tr></table></figure>
<p>（完整代码可以参考<a href="https://github.com/gmlove/experiments/tree/master/python_perf">这里</a>）</p>
<p>运行上面的代码可以发现<code>heavy_calculation</code>执行一次需要2s左右，<code>exec_in_single_thread</code>花费4s，<code>exec_in_multi_thread</code>使用了多线程，但是居然也要花费4s！再仔细观察结果，就会发现，同是<code>heavy_calculation</code>，在<code>exec_in_single_thread</code>中花费2s，但是在<code>exec_in_multi_thread</code>中居然要花费4s，而且两次调用均花费了4s。</p>
<h2 id="python的gil问题"><a class="markdownIt-Anchor" href="#python的gil问题"></a> Python的GIL问题</h2>
<p>多线程看起来确实并不能有效利用多核进行加速。这是为什么呢？答案是python的GIL问题。Python这门语言其实有很多解释器实现，除了最流行的c语言实现CPython，还有java实现Jython，甚至Python自身实现的PyPy。GIL问题目前在CPython和PyPy中存在，Jython没有这个问题。</p>
<p>GIL的全称是Global Interpreter Lock，即全局解释器锁，从官方的<a href="https://wiki.python.org/moin/GlobalInterpreterLock">介绍</a>中我们可以了解到引入它是由于CPython的内存管理是非线程安全的，需要避免多个线程同时去执行代码。到这里大家就明白了，python的多线程无法用来做计算加速！</p>
<p>不过，看起来如果重新用一种线程安全的方式来实现CPython的内存管理就能解决问题了，不是吗？但是现实问题远非这么简单，因为Python现在有大量的库的实现都依赖这个GIL，也就是没有考虑线程安全问题。这同时也导致了python的库的兼容性问题，比如虽然Jython没有GIL，但是在运行时它可能会有未知的线程问题，所以就难以流行起来。更多相关的问题可以参考GIL的官方介绍文档来了解。我们这里主要分享一下当我们遇到这个问题的时候要如何解决。</p>
<h2 id="优化python程序性能"><a class="markdownIt-Anchor" href="#优化python程序性能"></a> 优化Python程序性能</h2>
<p>其实我们不能直接说python的多线程是无用的，这还得看我们的具体问题。如果我们是想同时执行一个cpu密集型和一个io密集型任务，那么python的多线程依然是有效的。比如执行下面的测试我们将看到多线程带来了速度的提升：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@log_time</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">heavy_calculation</span>():</span><br><span class="line">    <span class="keyword">import</span> math</span><br><span class="line">    a = <span class="number">0</span></span><br><span class="line">    <span class="built_in">pow</span> = math.<span class="built_in">pow</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10000000</span>):</span><br><span class="line">        a += <span class="built_in">pow</span>(<span class="number">2</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@log_time</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">heavy_io</span>():</span><br><span class="line">    <span class="built_in">open</span>(<span class="string">r&#x27;some-600MB-file&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>).read()</span><br><span class="line"></span><br><span class="line"><span class="meta">@log_time</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">exec_in_single_thread</span>():</span><br><span class="line">    heavy_calculation()</span><br><span class="line">    heavy_io()</span><br><span class="line"></span><br><span class="line"><span class="meta">@log_time</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">exec_in_multi_thread</span>():</span><br><span class="line">    <span class="keyword">from</span> threading <span class="keyword">import</span> Thread</span><br><span class="line"></span><br><span class="line">    threads = [Thread(target=heavy_calculation), Thread(target=heavy_io)]</span><br><span class="line">    <span class="keyword">for</span> thread <span class="keyword">in</span> threads:</span><br><span class="line">        thread.start()</span><br><span class="line">    <span class="keyword">for</span> thread <span class="keyword">in</span> threads:</span><br><span class="line">        thread.join()</span><br><span class="line"></span><br><span class="line">exec_in_single_thread()</span><br><span class="line">exec_in_multi_thread()</span><br></pre></td></tr></table></figure>
<p>（完整代码可以参考<a href="https://github.com/gmlove/experiments/tree/master/python_perf">这里</a>）</p>
<p>这里的IO操作差不多需要0.5s，执行后会发现<code>exec_in_single_thread</code>花费了2.5s左右，而<code>exec_in_multi_thread</code>只花费了2s。</p>
<p>当我们想要并行加速多个计算密集型任务时，主要思路有两个：</p>
<ol>
<li>用c语言实现，显示的释放GIL，之后就可以利用线程加速了</li>
<li>改用多进程来加速，避免了GIL问题</li>
</ol>
<p>下面将分别介绍这两种方案。</p>
<h3 id="显示的释放gil加速"><a class="markdownIt-Anchor" href="#显示的释放gil加速"></a> 显示的释放GIL加速</h3>
<p>参考Python的<a href="https://docs.python.org/3.7/c-api/init.html#thread-state-and-the-global-interpreter-lock">文档</a>我们知道，其实可以很简单的在c语言中用一个宏来实现GIL的显示控制。对于上面的计算，我们可以用c语言实现如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> PyObject *</span><br><span class="line"><span class="title function_">demo_pure_heavy_calculation</span><span class="params">(PyObject *self, PyObject *args)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">long</span> a = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000000</span>; i++) &#123;</span><br><span class="line">        a += <span class="built_in">pow</span>(<span class="number">2</span>, <span class="number">10</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> PyLong_FromLong(a);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（完整代码可以参考<a href="https://github.com/gmlove/experiments/tree/master/python_perf/c_extension">这里</a>）</p>
<p>我们编译运行此代码，将会看到执行时间为0.028s左右，c语言的实现带来了近百倍的提速。但是由于我们还没加入GIL的释放代码，所以多线程运行时，速度并不会加快。</p>
<p>修改代码如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> PyObject *</span><br><span class="line"><span class="title function_">demo_heavy_calculation_allow_thread</span><span class="params">(PyObject *self, PyObject *args)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">long</span> a = <span class="number">0</span>;</span><br><span class="line">    Py_BEGIN_ALLOW_THREADS</span><br><span class="line">    <span class="title function_">for</span> <span class="params">(<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000000</span>; i++)</span> &#123;</span><br><span class="line">        a += <span class="built_in">pow</span>(<span class="number">2</span>, <span class="number">10</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    Py_END_ALLOW_THREADS</span><br><span class="line">    <span class="keyword">return</span> <span class="title function_">PyLong_FromLong</span><span class="params">(a)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>改成这样，再次运行，我们将看到多线程带来的提速了。</p>
<h3 id="更简单的实现"><a class="markdownIt-Anchor" href="#更简单的实现"></a> 更简单的实现</h3>
<p>上面这样的实现能解决问题，但是看起来略繁琐，其实我们有一个简单的库<code>Cython</code>可以辅助我们更简单的编写代码。参考<a href="http://docs.cython.org/en/latest/src/tutorial/cython_tutorial.html">官方文档</a>，我们可以用类python的语法编写代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> libc.math cimport <span class="built_in">pow</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">heavy_calculation</span>():</span><br><span class="line">    cdef double a = <span class="number">0</span></span><br><span class="line">    cdef <span class="built_in">int</span> i  <span class="comment"># 这里的定义使得cython编译器会优化下面带range循环为c的for循环</span></span><br><span class="line">    <span class="keyword">with</span> nogil:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10000000</span>):</span><br><span class="line">            a += <span class="built_in">pow</span>(<span class="number">2</span>, <span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> a</span><br></pre></td></tr></table></figure>
<p>（完整代码可以参考<a href="https://github.com/gmlove/experiments/tree/master/python_perf/cython_extension">这里</a>）</p>
<p>Cython运行时会把上述函数编译为跟我们上面差不多的c语言代码，大大简化了我们的代码维护工作。同时简单的使用<code>with nogil</code>就实现了GIL锁的释放。并且测试还会发现，用Cython的实现，几乎会比用c实现的快2-3倍。这应该是编译优化导致的。</p>
<p>如果我们的代码是纯c实现，不需要操作python对象，那么我们还可以参考<a href="http://www.swig.org/tutorial.html">SWIG</a>，它给我们的代码管理也带来了方便。</p>
<h3 id="使用多进程加速"><a class="markdownIt-Anchor" href="#使用多进程加速"></a> 使用多进程加速</h3>
<p>为了避免重写代码，最简单的恐怕是直接改为多进程的机制。</p>
<p>如果当前是用线程池实现的，改为使用python的进程池，我们几乎只用修改一行代码就可以实现。两种实现方式示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">execute_concurrently</span>(<span class="params">num_workers, func, *parameters_list</span>):</span><br><span class="line">    <span class="keyword">with</span> concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) <span class="keyword">as</span> executor:</span><br><span class="line">        func_future = &#123;executor.submit(func, *parameters): parameters <span class="keyword">for</span> parameters <span class="keyword">in</span> <span class="built_in">zip</span>(*parameters_list)&#125;</span><br><span class="line">    <span class="keyword">for</span> future <span class="keyword">in</span> concurrent.futures.as_completed(func_future):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            data = future.result()</span><br><span class="line">            <span class="keyword">yield</span> data</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> exc:</span><br><span class="line">            logger.warn(<span class="string">&#x27;task(%s) generated an exception: %s&#x27;</span> % (func_future[future], exc))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">keep_silent_on_exception</span>(<span class="params">func: <span class="type">Callable</span>, *args, **kwargs</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> func(*args, **kwargs)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        logger.warn(<span class="string">&#x27;&#123;&#125; raises exception: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(func, e.args))</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;keep_silent_on_exception&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">execute_concurrently_by_process</span>(<span class="params">num_workers, func, *parameters_list</span>):</span><br><span class="line">    <span class="keyword">with</span> concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) <span class="keyword">as</span> executor:</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> executor.<span class="built_in">map</span>(keep_silent_on_exception, [func] * <span class="built_in">len</span>(parameters_list[<span class="number">0</span>]), *parameters_list):</span><br><span class="line">            <span class="keyword">if</span> data != <span class="string">&#x27;keep_silent_on_exception&#x27;</span>:</span><br><span class="line">                <span class="keyword">yield</span> data</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>上述代码进行非常简单的封装，并忽略了错误。</p>
<p>只是这样就够了吗？改为进程池，带来的问题就是所有的参数传递，都变为了进程间的数据传递，也就是进程间通信问题。</p>
<p>参考Python的进程池文档可以知道，Python内部实现是先使用<code>pickle</code>将数据序列化，然后再相互传输的。这就提醒我们：</p>
<ol>
<li>在设计并发函数参数的时候，需要特别注意参数，尽量避免将大量的数据作为参数进行传递，如一个大型的<code>numpy</code>数组。</li>
<li>我们无法将不能<code>pickle</code>序列化的对象(如某一个对象，其内部有一个类型为socket连接的属性)作为参数传递。</li>
<li>我们需要深入分析多进程情况下的对象生命周期，比如，多进程可能导致我们为每一个进程创建了一个socket连接，这会不会带来问题呢？</li>
</ol>
<p>在实践过程中，还有以下两点可能是值得考虑的：</p>
<ol>
<li>避免在将要循环执行的函数内部执行某一可共享的耗时操作，比如在上面代码中传入的<code>func</code>的实现里面就不宜加入耗时且可共享的操作，这个时候我们可以使用延迟初始化的方式来解决这个问题。比如我们可以设计一个单例的<code>SharedObjects</code>对象，然后在其中延迟进行这种操作。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SharedObjects</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self._some_big_object_from_heavy_io = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_some_big_object</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> self._some_big_object_from_heavy_io = <span class="literal">None</span>:</span><br><span class="line">            self._some_big_object_from_heavy_io = create_some_big_object_from_heavy_io()</span><br><span class="line">        <span class="keyword">return</span> self._some_big_object_from_heavy_io</span><br><span class="line"></span><br><span class="line">shared_objects = SharedObjects()</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>考虑使用进程间共享内存的方式，避免大对象的拷贝带来的内存开销（从python的api来看我们还是需要做序列化的工作）</li>
</ol>
<p>到这里我们应该对如何优化python程序性能有了一定的认识了。有其他问题欢迎留言讨论交流。</p>
]]></content>
      <categories>
        <category>技术</category>
        <category>python</category>
        <category>performance</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>GIL</tag>
      </tags>
  </entry>
  <entry>
    <title>代码中的领域</title>
    <url>/2019/08/08/domain-concept-in-your-code/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>随着微服务和DDD的兴起，领域这个词逐渐成为了一个大家每天讨论中的高频词。对于经验稍欠缺的同学们，刚接触领域这个词，总会感觉有点神秘。到底什么算是一个领域呢？我们经常在谈论领域模型、领域服务、领域事件、领域边界等等，如果对领域概念没有一个清晰的认识，在接受这些相关概念上想必也会遇到阻碍。本文将结合我个人的理解以及一些实践经验来谈谈对这个概念的理解，希望能帮助大家更好的认识领域，进而更好的理解和运用相关的概念，最终更好的指导软件开发实践。</p>
<span id="more"></span>
<h2 id="概念理解"><a class="markdownIt-Anchor" href="#概念理解"></a> 概念理解</h2>
<p>什么是领域？跟领域相关的词我们可以想到领土、领地、业务域、业务领域、自然科学领域、动物的领域等等。领域这个词我们平常的中文使用场景非常广泛，可能这也是导致这个词不容易理解的原因。领域这个词的中文解释是：（来源：<a href="http://cd.hwxnet.com/view/ahecdjginknflmnk.html%EF%BC%89">http://cd.hwxnet.com/view/ahecdjginknflmnk.html）</a></p>
<pre><code>①犹领土。国家主权管辖下的区域：国家领域神圣不可侵犯。
②意识形态或社会活动的范围：思想领域｜学术领域｜生活领域｜科学领域。
</code></pre>
<p>在我们软件开发中，领域一般对应英文单词Domain，牛津词典解释如下：</p>
<pre><code>an area of knowledge or activity; especially one that sb is responsible for （知识、活动的）领域，范围，范畴
例：The care of older people is being placed firmly within the domain of the family. 照顾老人仍然被确认为是家庭范围的事。
例：Physics used to be very much a male domain. 物理学曾在很大程度上是男人的领域。
</code></pre>
<p>似乎很简单嘛！看起来就是一个“范围”的意思。其实“域”这个词本身就是范围的意思，加上“领”字，我们可以认为是一种特殊的范围。既然就是“范围”，那么就容易理解了。我们说自然科学领域，其实就是在自然科学研究范围内；我们说业务领域，其实就是和某项业务相关的范围内；我们说正整数的范围是1到无穷大，也差不多可以理解为1到无穷大这样一个“领域”（这里一般认为只是一个“域”）。</p>
<p>如果更严格一点，从数学上来认识，我们可以对应到集合这个概念。只不过，我们平常所说的领域可能是一种定义不严格的集合，只存在一个大致的边界。但是这通常不影响我们沟通交流，因为边界在当时可能不太重要。既然是集合，那么我们可以从下面这张图来对应理解领域概念。</p>
<p><img data-src="/attaches/2019/2019-08-08-domain-concept-in-your-code/domain-concept-and-math-collection.png" alt="domain concept and math collection" /></p>
<h2 id="代码中的领域"><a class="markdownIt-Anchor" href="#代码中的领域"></a> 代码中的领域</h2>
<p>有了”领域“就是”范围“这样一个简单的理解，我们回头来看我们代码中的领域，很多问题就会变得清晰起来。</p>
<p>比如我们有下面这个简单的求和函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sum</span>(<span class="params"><span class="keyword">from</span>, to</span>):</span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="keyword">from</span>, to):</span><br><span class="line">        total += i</span><br><span class="line">    <span class="keyword">return</span> total</span><br></pre></td></tr></table></figure>
<p>这里有哪些领域或者范围呢？</p>
<p>最底层的要算<code>for</code>循环体内的一个范围，也就是一个代码块。这里的代码块不仅从逻辑上构成了一个范围，在很多编程语言里面还反映在变量的作用域上，比如在这里定义的变量，代码块外面可能是访问不到的。其次是函数体构成一个范围。再次，如果这里的函数是某一个类的方法，那么该类本身构成了一个范围。再继续，类所在的包构成了一个范围，包所在的库构成了一个范围等等。按照领域来理解，我们可以认为这里的领域按照不同的细节程度和抽象程度构成了一个类似森林的结构。</p>
<p>再深入细节一些，我们甚至可以认为，我们常常用空格分隔起来的几行代码片段构成了一个范围或者微型的领域。</p>
<p>了解了范围和领域的概念如何帮助我们理解其他的相关概念呢？（下面的文字很多，但是每一节之间几乎是独立的，大家可以分成多次阅读。）</p>
<h2 id="内聚和耦合"><a class="markdownIt-Anchor" href="#内聚和耦合"></a> 内聚和耦合</h2>
<p>先来看一下内聚和耦合。</p>
<p>从领域的角度来理解，我们可以认为，领域内部的东西是内聚的，一个领域引用别的领域就构成了耦合。我们都说好的代码是高内聚低耦合的，其实反映到代码上，就是说，我们代码里面的任何一个领域尽量别去引用其他领域的东西。如果某一领域引用了极少的其他领域的东西，或者甚至没有引用其他领域的东西，那么我们就可以认为该领域可以独立自治的实现功能，它就是高内聚低耦合的。对于这样的高内聚低耦合的领域，它可能是某个函数或者某个类或者某一模块，甚至是某一个库。不管是什么，他们的理解和使用应该是非常容易的，因为除了这个领域我们很少需要理解其他领域。正是因为高内聚低耦合的代码好理解，易于使用，我们才会认为这是好代码。</p>
<p>有人可能会说我们几乎不可能不去引用别的领域就实现某个功能，就算是上面的求和函数，我们也引用了系统库里面的<code>range</code>函数。这里我们可以用DDD里面的<code>通用领域</code>概念来辅助理解，标准库即是一个通用领域，我们可以假定使用我们代码的人对于标准库的理解都是不错的，也就是说我们引用标准库领域一般是不会带来理解和使用上的问题。</p>
<p>在这里，面向对象中的封装思想可以帮我们缓解耦合的问题。通常我们更多的是去使用某一个库（这里的库不仅表示第三方库，而是更宽泛的其他领域的概念），我们也就更关注这个库好不好用，而少于关心这个库的实现是什么。对应到领域概念中，也即我们通常更关心领域的边界，而少于关心领域的内容。为什么说更关心领域边界呢？从代码层面理解，领域边界就是我们对外暴露的API，它包含所有公开函数的函数名、参数及返回值，类的构造器，类的状态变迁等。既然我们更关心接口，那么即便我们的领域比较复杂，引用很多，耦合比较高，但如果其边界比较简单，这样的领域一般也是较好的领域（之所以说它是较好的领域是因为复杂的领域存在不易阅读不易理解的缺点）。而封装就刚好可以实现将领域内部大量的事物隐藏起来，只对外暴露简单接口的作用。这里对于实践的指导就是相比代码实现的复杂度而言，我们要更关心接口的复杂度，通过封装大量细节可以让接口变得更简单。</p>
<p><img data-src="/attaches/2019/2019-08-08-domain-concept-in-your-code/complicated-domain-and-simple-domain-boundary.png" alt="complicated domain and simple domain boundary" /></p>
<h2 id="抽象层次"><a class="markdownIt-Anchor" href="#抽象层次"></a> 抽象层次</h2>
<p>再来看一下抽象层次。</p>
<p>很多时候，我们说一段代码做的事情应该是同一个抽象层次的事情。什么是同一个抽象层次呢？假设我们要去复印一份文件，要如何描述这个过程呢？大家想一下就可以脱口而出，我们可以通过这样几步来实现：1. 带上资料走到复印机前；2. 复印资料；3. 带走复印好的资料。这样的步骤很清晰，大家看到会很容易理解。实际上我们就可以认为这里的几件事情是同一个抽象层次的事情。</p>
<p>一个比较极端的反例是什么呢？可以是这样：1. 带上资料；2. 观察当前位置到打印机位置的路线；3. 选择一条路线；4. 走路；5. 绕过障碍；6. 避免跟人交谈；7. 排队； 8. 复印资料；9. 带走复印好的资料。这里的步骤就不是那么容易理解了。第一步到第七步过于细节，我们可以说它们分别和第八步、第九步不是同一个抽象层次的内容。事实上，这里过于细节的步骤会导致我们迷失方向，失去重点，大家可以想想，看了上面这些步骤之后，我们还能清楚的知道我们的目的是要复印资料吗？这里的步骤拆解其实跟代码编写是同样的道理，当我们把本该在另一个独立的函数内实现的功能放到当前代码中实现的时候，这样的问题就凸显出来了。</p>
<p>领域在这里如何帮助我们理解这个问题呢？上面对于抽象层次的理解其实还是比较模糊的，不同的人对于细节程度会有不同的认识。但如果我们从领域的角度来看问题，情况就会变得清晰起来。我们首先会发现反例里面涉及的内容过多（代码内的概念过多），里面有路线、走路、障碍、人、交谈、排队、复印机、资料等事物，即这是一个复杂的领域（复杂的代码）。复杂的领域难以理解，就像一个集合，里面充满了数量多而没有规律的数。如何让其变得更简单呢？我们将第一步到第七步合并为单独的领域（一个内部函数），即带上资料走到复印机前，这样就可以得到下面这样一个简单的领域（简单的代码）。</p>
<p><img data-src="/attaches/2019/2019-08-08-domain-concept-in-your-code/domain-and-subdomain.png" alt="domain and subdomain" /></p>
<p>仔细观察一下上面这个更简单的领域（更简单的代码），事实上“复印资料”和“带走复印好的资料”这两个步骤的复杂度跟“带上资料走到复印机前”是差不多的，只不过我们并没有分析它们的细节而已。从领域的角度来讲，我们可以大致认为上图中的三个小圈的领域复杂度（代码复杂度）相近。这里的分析对于抽象层次的启示就是，通过领域内包含的事物的多少可以在一定程度上量化分析两个领域是否是同一抽象层次的领域。当两个领域复杂度（代码复杂度）相近时，它们就有可能就是同一抽象层次的领域。最理想的代码莫过于代码对应的领域构成了一颗平衡树，每一片枝叶都是简单而独立的存在，每一个节点的子节点都是复杂度相近的子树（复杂度相近的子域，也即同一抽象层次的事情）。这个时候，我们实际上把系统拆分为了几个复杂度差不多的模块，将每一个模块又拆分为了复杂度差不多的类和函数，而每一个类和函数又都比较小巧。</p>
<p>我们还会发现我们脱口而出的几个步骤通常自然的就形成了好的领域（好的代码）。这是为什么呢？其实这是和我们的思维方式是一致的，我们去理解一个复杂事物的时候，总是会将其拆分为几个小的事物去理解。而我们描述某一个事物的时候，总是自然的就得到了合适的几个部分。在同一个描述里面，通过自然的方式得到的几个事物，一般就是同一个抽象层次的事物。当然这里的自然一定是出自于某一个个体，其他人可能有不认同的地方。但是多数人至少应该容易理解这样的拆分，因为这和我们平时和其他人交谈的时候容易理解其他人的话是同样的道理。到这里，大家是不是认为写代码和说话一样简单了呢？当然可能不止说话，应该说写好的代码应该和写好的文章差不多。</p>
<h2 id="依赖倒置"><a class="markdownIt-Anchor" href="#依赖倒置"></a> 依赖倒置</h2>
<p>再来看一下依赖倒置。</p>
<p>我们说依赖倒置，就是说要依赖于抽象，而不要依赖于实现。这是什么意思？为什么依赖抽象是更好的？这里的抽象我们是指某一个抽象的概念，通常反映在代码中就是接口，或者至少是抽象类。依赖抽象的好处在于我们可以根据需要在运行时将这个依赖替换为任意一个实现。有了这样的特性，我们可以方便的在测试中使用测试替身（test double）来替换掉某个依赖，于是测试就更易于编写。有了这样的特性，我们还能方便的提供多个实现，而在运行时根据需要选择一个，比如当我们抽象了一个repository接口来存储数据时，我们可以基于RDBMS数据库提供一个实现，同时基于NOSQL数据库再提供一个实现，然后根据需要选择任意一个实现而无需改变代码。这里依赖倒置为我们编写代码提供了非常大的灵活性。</p>
<p>从领域的角度如何理解依赖倒置带来的好处呢？我们还是要回到领域简单与否上面来。一般而言在某一个类里面依赖另一个类时，我们不会依赖另一个类的所有的API，而只是依赖于和当前待实现的功能相关的API。这个时候，如果直接依赖于另一个类，我们需要完全理解另一个类之后才能理解当前这个类。这就是说我们的领域更难以理解了。更好的方式是什么呢？通常我们可以将当前真正需要依赖的API抽象为一个新的概念，新建一个接口，然后依赖于这个接口进行当前类的实现，同时将之前的依赖类添加实现这个接口的声明。这样一来，由于依赖的东西变少了，当前这个类的实现就变得更简单更易于理解了（简单的领域）。这里可能还是有点绕，不太好理解。举例说明一下。假设我们要实现一个类，它将依赖一个队列来实现其功能，我们可以编写代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">interface</span> <span class="title class_">Queue</span> &#123;</span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">push</span><span class="params">(<span class="type">int</span> item)</span>;</span><br><span class="line">    <span class="type">int</span> <span class="title function_">pop</span><span class="params">()</span>;  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SomeCls</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Queue queue;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">SomeCls</span><span class="params">(Queue queue)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.queue = queue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在<code>SomeCls</code>中使用抽象的<code>Queue</code>接口相比于使用某一个库里面的<code>Queue</code>类给我们带来了很明显的好处，它使得我们理解<code>SomeCls</code>更容易了。因为我们明确的知道在<code>SomeCls</code>的实现中只会使用一个仅带有<code>push</code>和<code>pop</code>两个API的<code>Queue</code>，而不会使用可能的<code>Queue</code>的<code>size</code>，<code>isFull</code>这样的方法。而同时我们可以轻易的利用已有的标准库或者第三方库中的<code>Queue</code>实现去实现这里定义的<code>Queue</code>接口，只需要编写极少的额外代码。另一个好处是，通过接口定义，我们的依赖变得更清晰了，它只依赖这样一个<code>Queue</code>，这个<code>Queue</code>无需多一个API，也不会少一个API。也就是说，对于<code>SomeCls</code>这个领域而言，其边界是简单而清晰的，这个领域就是更易于理解的。同时我们可以看到这个类也是低耦合的，因为它引用了更简单的东西。</p>
<p>这里还可以举一个关于防腐层的例子。在DDD里面我们经常提到防腐层的概念。一个微服务在使用其他的微服务时，其他微服务的数据模型容易侵入当前的微服务代码而造成影响，防腐层就可以很好的解决这个问题。比如在电商的场景下，积分微服务定期访问订单微服务来更新积分（这里的流程仅用于举例）。订单微服务提供了一个API用来查询订单，这个API会返回订单的详情信息，但是积分微服务在查询订单的时候只想得到订单价格。在积分微服务与订单微服务进行集成时，如果我们直接将订单微服务返回的数据模型作为我们积分微服务的领域模型，那就将导致积分微服务的领域腐化。因为积分微服务根本无需关心订单详情，当我们在领域模型中加入了其他无关信息时，我们的理解负担就无形中加重了。而且这可能会带来订单详情信息在积分微服务代码里面滥用的问题。防腐层可以提供一层抽象，做一次映射将从订单微服务拿到的订单信息转化为积分微服务内真正需要的领域模型。这里的防腐层我们可以理解为保护了我们的领域。其实防腐层还可以理解为使我们的领域边界更清晰了，因为在积分微服务的实现里，我们只需要使用防腐层的接口，而无需访问订单API获取数据，也就是我们依赖了一个防腐层的抽象，而不是依赖于某一个REST API的真实实现。这里解决问题的方式是不是和上面的依赖倒置有相似之处呢？大家可以仔细体会一下。</p>
<p><img data-src="/attaches/2019/2019-08-08-domain-concept-in-your-code/anticorruption-layer.png" alt="anticorruption layer" /></p>
<h2 id="使用领域语言编写代码"><a class="markdownIt-Anchor" href="#使用领域语言编写代码"></a> 使用领域语言编写代码</h2>
<p>有了领域这个概念之后，我们就可以延伸到领域语言，领域语言就是用来在领域内部进行沟通的语言。我们说好的代码需要用业务语言来编写，这里可以认为业务语言就是一种领域语言。如果要下一个严格一点的定义，领域语言是仅使用某一个领域内的概念和大家都理解的通用的助词，通过语法规则而构成的语言。如何更好的使用领域语言呢？什么情况下，我们是使用了领域语言写代码呢？</p>
<p>这里的问题我们可以分层次来理解。通过前面对领域的分析，我们可以将代码按照细节层次不同分为函数或方法领域，类领域，模块领域，服务领域，系统领域等。从函数或方法领域来看，我们要仅使用领域内的概念和通用助词来编写代码，也就是说我们的变量命名，使用到的函数或者类的名字需要是包含于这个领域内的概念。比如上面的求和函数，分析求和过程可以得到这样的几个概念或过程：起始值，结束值，获取迭代范围，迭代过程当前值，当前累加结果值。他们分别对应了代码中的<code>from</code> <code>to</code> <code>range</code> <code>i</code> <code>total</code>。如果我们分析代码发现除了这些领域内的名字，没有使用其他的名字，我们就可以说这是用领域语言在编写代码。如果不用领域语言，试想我们将<code>total</code>这个变量名改为了一个领域外的名字，如<code>multiply_result</code>，大家还能轻易的读懂这段代码吗？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sum</span>(<span class="params"><span class="keyword">from</span>, to</span>):</span><br><span class="line">    multiply_result = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="keyword">from</span>, to):</span><br><span class="line">        multiply_result += i</span><br><span class="line">    <span class="keyword">return</span> multiply_result</span><br></pre></td></tr></table></figure>
<p>我们可以使用同样的方法去分析类领域，模块领域，服务领域，系统领域等。</p>
<p>使用领域语言写代码还有这样一些需要注意的地方。</p>
<ol>
<li>
<p>使用领域语言写代码，要求我们尽量多使用业务名词，尽量少使用技术名词。一些典型的技术名词包括<code>socket</code> <code>tcp</code> <code>udp</code> <code>http</code> <code>json</code> <code>mysql</code> <code>rabbitmq</code>等。如何尽量少的使用这些名词呢？一个办法就是用一个短小的类将这些名词的封装成一个领域概念。由于多了一层封装，这些技术名词就不会泄露到其他代码中去了。更进一步我们可以采用上述依赖倒置的手法，将这些概念抽象为接口，让领域代码依赖这个接口去实现功能，而这些技术名词就自然的被放到某个具体的接口实现代码中去了。这通常是合理而有效抽象手法，为了做到这样的抽象，我们在进行设计时可以像下面这样自问一下。当我们需要mysql时，我们是不是只需要一个抽象的RDBMS？当我们需要RDBMS时，我们是不是只需要一个抽象的存储服务？当我们需要RabbitMQ时，我们是不是只需要一个抽象的队列？当我们需要转换为<code>json</code>时，我们是不是只需要一个抽象的序列化过程？</p>
</li>
<li>
<p>使用领域语言写代码，要求我们使用一致的命名。比如，我曾经在一些代码里面发现对于同一个“位置”概念，代码里面有的地方用的命名是<code>position</code>而有的地方又使用<code>location</code>，这就是不一致的表现。不一致的命名将给我们理解代码带来困难，因为我们在看到这两个词时，只能猜测它们是否是同一个意思，而不能肯定的给出答案。而且使用不同的词，看上去给领域增加了新的概念，导致领域变复杂了。这在多个人同时编写代码的时候尤其容易出现，这就需要我们每个人都注意：在新编写代码的时候，使用大家都在谈论的领域字典中的名字；在修改代码的时候，使用和之前代码一致的名字；在重构代码的时候，将不一致的名字修改为领域字典中的名字。</p>
</li>
<li>
<p>使用领域语言写代码，要求我们使用更有意义的名字。很多同学喜欢用类似<code>rule</code> <code>business</code> <code>object</code> <code>context</code>这样的单词，这样的单词由于适用范围过于广泛，其实对于我们阅读代码时理解领域的帮助很少很少。我们几乎可以直接去掉这样的单词来理解代码，这样一来这些单词不仅仅没有给我们理解代码带来方便（可读性不高），反而带来了干扰。</p>
</li>
</ol>
<p>这里可能有人会担心不同的领域（函数）内会有相同的概念（比如多个函数里面都有<code>total</code>这个变量），从而导致混淆，这其实是正常情况。它们确实可能是使用同一个名字的概念，但是它们的内涵往往不同。我们平时交谈中使用的词语其实也常常是多义词，但这几乎不影响我们交谈，因为我们交谈中有上下文。我们阅读代码时也一样，代码对应的领域往往提供了比较明确的上下文，这就让我们区分不同内涵没那么困难了。</p>
<h2 id="尝试理解更多"><a class="markdownIt-Anchor" href="#尝试理解更多"></a> 尝试理解更多</h2>
<p>上面的分析有些过于发散，总结起来，通过领域去理解编程原则，我们可以尝试：</p>
<ol>
<li>将“领域”对应到“范围”去理解，</li>
<li>在不同的层次（函数或方法领域，类领域，模块领域，服务领域，系统领域等）去理解某一个编程原则。</li>
</ol>
<p>总之，领域还可以用来帮助理解更多的概念和编程原则，大家在遇到一些不容易懂的概念时，可以尝试从领域的角度来尝试理解，看看是不是更容易。</p>
]]></content>
      <categories>
        <category>敏捷</category>
        <category>架构</category>
        <category>DDD</category>
      </categories>
      <tags>
        <tag>架构</tag>
        <tag>DDD</tag>
        <tag>领域</tag>
      </tags>
  </entry>
  <entry>
    <title>从改善设计的角度理解TDD (2)</title>
    <url>/2019/08/18/tdd-for-improving-design-2/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>在文章开始之前，我们先回顾一下TDD带来的好处。当我们理解TDD之后我们至少会发现下面这三点：</p>
<ol>
<li>TDD是一种更加自然的编程方式，因为我们总是要先弄清需求再编写代码，而这跟TDD先写测试（通过测试清晰的定义需求）再写实现的顺序是完全一致的。</li>
<li>先写测试还要求我们站在使用者的角度来编写测试，这样我们可以自然的驱动出来更好的设计。</li>
<li>由于TDD天然的特性，测试在编写代码之前就有了，自然我们也就无需担心测试覆盖率不够带来的质量问题了。</li>
</ol>
<p>TDD给我们编写代码带来的好处多多，我前面有一篇<a href="/2019/07/20/tdd-for-improving-design/">文章</a>主要分析了如何从改善设计的角度理解TDD，相信大家能感受到TDD给改善程序设计带来的好处。这里我想再次分享一个用TDD改善设计的例子，我们将从中看到不用TDD时我们的代码可能会变成什么样，而用了TDD又将变成什么样。</p>
<span id="more"></span>
<h2 id="背景"><a class="markdownIt-Anchor" href="#背景"></a> 背景</h2>
<p>有这样一个需求，我们需要定义一个有向无环图将一组小的<code>Task</code>组织成一个功能更强大的<code>Job</code>，然后执行<code>Job</code>按照任务（<code>Task</code>）先后关系运行这个图。其实我们能找到很多用这样的方式来编排任务的开源工具，比如下面这些。</p>
<p><img data-src="/attaches/2019/2019-08-18-tdd-for-improving-design-2/workflow-tools.png" alt="Workflow工具" /></p>
<p>我们还希望以后能编写一个UI界面来辅助用户快速的编排任务，用户可以以拖拉拽的方式可视化的编排，可以灵活的配置任务参数，同时系统将自动的校验用户指定的及任务间传递的参数。</p>
<p>基本的需求就是这样，在了解了这些之后，我们来分别看看直接进行设计和用TDD进行辅助设计会是什么样子的。</p>
<h2 id="直接设计"><a class="markdownIt-Anchor" href="#直接设计"></a> 直接设计</h2>
<p>分析上述需求，如果我们想在用户编排任务的时候进行参数校验，那么我们必须在每个任务运行之前就有办法获取到各种参数和返回值的类型信息，它们将包括任务的可配置参数、任务的入参、任务的返回值等。由于这些参数都是针对某个具体的任务来定义的，我们可以设计任务的几个接口来获取这些类型信息。我们暂定只需要上述三种类型信息，可以得到如下的接口设计：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">interface</span> <span class="title class_">Task</span> &#123;</span><br><span class="line">    TypeOfSomeConfigurationType <span class="title function_">getConfigurationMeta</span><span class="params">()</span>;</span><br><span class="line">    TypeOfSomeInputType <span class="title function_">getInputMeta</span><span class="params">()</span>;</span><br><span class="line">    TypeOfSomeResultType <span class="title function_">getResultMeta</span><span class="params">()</span>;</span><br><span class="line">    SomeResultType <span class="title function_">execute</span><span class="params">(SomeInputType input, SomeConfigurationType config)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的<code>SomeXXXType</code>应该是什么呢？为了支持灵活的配置，这里我们需要一个非常灵活的数据结构。稍加思索大家应该就能想到我们可以用<code>Map</code>。我们可以定义一个<code>Map&lt;String, Object&gt;</code>的类型来存储任意键值，这时候，对<code>SomeConfigurationType</code>而言，<code>key</code>是配置的名字，配置的值可以是任意的一个对象；对于<code>TypeOfSomeConfigurationType</code>而言，它应该是一个<code>Map&lt;String, Class&lt;?&gt;&gt;</code>类型，<code>key</code>与配置的名字一致，值用于描述配置的值的类型。其他的<code>SomeInputType</code>和<code>SomeResultType</code>均可以这样定义。到这里我们可能还会有点小小的自豪，问题很简单啊，引入一个<code>Map</code>数据结构就完美解决了。这个时候我们的<code>Task</code>接口会设计成下面这样：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">interface</span> <span class="title class_">Task</span> &#123;</span><br><span class="line">    Map&lt;String, Class&lt;?&gt;&gt; getConfigurationMeta();</span><br><span class="line">    Map&lt;String, Class&lt;?&gt;&gt; getInputMeta();</span><br><span class="line">    Map&lt;String, Class&lt;?&gt;&gt; getResultMeta();</span><br><span class="line">    Map&lt;String, Object&gt; <span class="title function_">execute</span><span class="params">(Map&lt;String, Object&gt; input, Map&lt;String, Object&gt; config)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>仔细观察上面的接口，好像没那么干净，但似乎也挑不出什么毛病。<code>Map</code>看起来对于<code>Task</code>的实现会有一些干扰，因为<code>Task</code>实现里面势必会引入一些必要的强制类型转换的工作。能否避免这样的比较脏的类型转换代码呢？我们思考了一下，可能可以提供一些Utilities工具类来进行一些支持，或者编写一个<code>AbstractTask</code>抽象类，将一些公共的逻辑放到抽象类中进行复用。总体上感觉问题应该出在需要支持 <strong>灵活的配置</strong> 这样的需求上。由于需求是要保证灵活性，我们就只能将接口定义成这样。</p>
<p>如何将任务组织成为一个有向无环图呢？这看起来也不是难事，先定义一个DAG，然后一个节点一个节点往里面塞数据就可以了。同时为了支持有向无环图的执行我们可以定义一个<code>execute</code>方法。这个时候我们的<code>Job</code>类大概会设计成下面这样：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">interface</span> <span class="title class_">Job</span> &#123;</span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">addTask</span><span class="params">(Task task, Task... subTasks)</span>;</span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">execute</span><span class="params">(Map&lt;String, Object&gt; input, Map&lt;String, Object&gt; config)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>到这里基本的设计就差不多完成了。我们会隐约感受到一些不够<code>clean</code>的设计，但是似乎难以控制。为了尽快实现功能，先这样定吧。</p>
<h2 id="tdd驱动设计"><a class="markdownIt-Anchor" href="#tdd驱动设计"></a> TDD驱动设计</h2>
<p>如果我们用TDD的思想来驱动开发，情况会是什么样呢？</p>
<p>按照TDD解决问题的思路，我们要先编写一个测试。那么第一个测试要怎么写呢？分析一下需求可以发现，我们的目标是要实现一个DAG任务运行框架。那么我们的测试目标应当就是这个框架。这个框架需要实现的功能是：</p>
<ol>
<li>允许用户自定义一些<code>Task</code>；</li>
<li>允许用户将这些<code>Task</code>组织成一个有向无环图；</li>
<li>提供接口运行这个图。在测试的代码中，我们需要模拟这个框架的使用方式，提供输入，然后验证输出。</li>
</ol>
<p>于是这个测试的实现就会包含这样几个步骤：</p>
<ol>
<li>定义<code>Task</code>；</li>
<li>将<code>Task</code>组织成一个有向无环图；</li>
<li>利用框架运行这个图；</li>
<li>检查运行结果是否是我们想要的。</li>
</ol>
<p>我们可以先编写测试模板代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">JobSchedulerTest</span> &#123;</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">should_run_the_defined_job_and_output_the_expected_result</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// define tasks</span></span><br><span class="line">        <span class="comment">// create dag</span></span><br><span class="line">        <span class="comment">// execute dag</span></span><br><span class="line">        <span class="comment">// verify execution result</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如何定义<code>Task</code>呢？<code>Task</code>需要保持足够的灵活性，以便可以支持任意可能的配置，同时<code>Task</code>要暴露接口让框架获取到输入、配置以及输出的元数据信息（类型信息）以便支持参数校验。由于我们使用<code>Java</code>这样的静态类型语言，事实上我们可以认为这些元数据信息是自动提供的。那么一个理想的<code>Task</code>就应该定义成下面这样：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SimpleCalculationTask</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> CalculationResult <span class="title function_">execute</span><span class="params">(CalculationInput input, CalculationConfig config)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样的<code>Task</code>定义我们应该会比较满意，因为它只有一个接口，并且这个接口非常简洁而又有明确的类型信息。要实现这样的接口也应该是非常容易的。比如在测试中我们可以设计一个非常简单的加法任务，它不仅要输出加法的结果，还会附带输出获取到的输入参数，同时我们可以配置加法在什么区间可以按正常工作，而在另一个区间直接输出<code>-1</code>。这样的加法任务可以实现如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AdderTask</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">AdderInput</span> &#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="type">int</span> left;</span><br><span class="line">        <span class="keyword">public</span> <span class="type">int</span> right;</span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">AdderInput</span><span class="params">(<span class="type">int</span> left, <span class="type">int</span> right)</span> &#123; <span class="built_in">this</span>.left = left; <span class="built_in">this</span>.right = right; &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">AdderConfig</span> &#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="type">int</span> maxSupportedValue;</span><br><span class="line">        <span class="keyword">public</span> <span class="type">int</span> minSupportedValue;</span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">AdderInput</span><span class="params">(<span class="type">int</span> maxSupportedValue, <span class="type">int</span> minSupportedValue)</span> &#123;</span><br><span class="line">            <span class="built_in">this</span>.maxSupportedValue = maxSupportedValue; <span class="built_in">this</span>.minSupportedValue = minSupportedValue;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">AdderResult</span> &#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="type">int</span> left;</span><br><span class="line">        <span class="keyword">public</span> <span class="type">int</span> right;</span><br><span class="line">        <span class="keyword">public</span> <span class="type">int</span> result;</span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">AdderInput</span><span class="params">(<span class="type">int</span> left, <span class="type">int</span> right)</span> &#123; <span class="built_in">this</span>.left = left; <span class="built_in">this</span>.right = right; <span class="built_in">this</span>.result = result; &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">AdderInput</span> &#123;</span><br><span class="line">        <span class="keyword">public</span> <span class="type">int</span> left;</span><br><span class="line">        <span class="keyword">public</span> <span class="type">int</span> right;</span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">AdderInput</span><span class="params">(<span class="type">int</span> left, <span class="type">int</span> right)</span> &#123; <span class="built_in">this</span>.left = left; <span class="built_in">this</span>.right = right; &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> AdderResult <span class="title function_">execute</span><span class="params">(AdderInput input, AdderConfig config)</span> &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> input.left + input.right;</span><br><span class="line">        <span class="keyword">return</span> result &gt; config.maxSupportedValue || result &lt; config.minSupportedValue</span><br><span class="line">                ? <span class="keyword">new</span> <span class="title class_">AdderResult</span>(input.left, input.right, -<span class="number">1</span>)</span><br><span class="line">                : <span class="keyword">new</span> <span class="title class_">AdderResult</span>(input.left, input.right, result);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>有了这样的定义之后，我们需要想办法将任务组织成一个有向无环图。怎样才能方便的构造这个图呢？最好有一个调度器，可以在某个任务后安排其他任务，也可以安排几个并行执行的任务，而我们需要提供一种方式来构造下游任务的参数。按照这样的想法可以得到下面这样的测试代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">JobSchedulerTest</span> &#123;</span><br><span class="line">    Job <span class="title function_">createJob</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">TaskScheduler</span> <span class="variable">scheduler</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskScheduler</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> scheduler.scheduleTask(<span class="keyword">new</span> <span class="title class_">AdderTask</span>())</span><br><span class="line">            .next(<span class="keyword">new</span> <span class="title class_">AdderTask</span>(), adderResult -&gt; </span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">AdderInput</span>(adderResult.left, adderResult.result));</span><br><span class="line">        job = scheduler.scheduleParallelTask(job, <span class="keyword">new</span> <span class="title class_">AdderTask</span>())</span><br><span class="line">            .next(<span class="keyword">new</span> <span class="title class_">AdderTask</span>(), (jobAdderResult, taskAdderResult) -&gt; </span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">AdderInput</span>(jobAdderResult.result, taskAdderResult.result));</span><br><span class="line">        <span class="keyword">return</span> job;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">should_run_the_defined_job_and_output_the_expected_result</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> createJob();</span><br><span class="line">        <span class="comment">// execute dag</span></span><br><span class="line">        <span class="comment">// verify execution result</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在写完这些代码的时候，我们发现设计更为丰满了。其实到这里主要的设计就可以算完成了，后续的代码在逻辑上比较直接，为避免赘述我们就不继续了。</p>
<h2 id="回顾"><a class="markdownIt-Anchor" href="#回顾"></a> 回顾</h2>
<p>回顾两种方式产生的设计，不言而喻，TDD驱动出来的设计比直接设计出来的设计要易于使用得多，而且干净得多。不知道大家有没有被TDD给我们带来的强大能力所惊艳到呢？至少我是被惊艳到了。除了设计在易用性和干净程度上，事实上上面直接设计出来的东西还忽略了一部分功能，试想在运行时，我们如何将任务的参数进行上下串联呢？这是因为如果我们直接开始设计，由于一开始很难考虑清楚所有的情况，我们总是容易漏掉一些东西。而TDD由于是先从使用上面来定义设计应该有的接口和互操作方式，这使得我们更不容易漏掉这样的关键步骤。</p>
<p>我们经常听到说TDD可以带来十倍效率提升，一开始有人一定会觉得这有点夸大，难以相信。但是在这个例子里TDD带来的收益可以说是非常巨大，说十倍效率提升我觉得也不过分。我们可以尝试比较一下。如果我们用直接设计的方式得到最终的设计，那么后续我们在开发和调试<code>Task</code>的时候，我们将面临这样的问题：</p>
<ol>
<li><code>Task</code>的实现代码中充斥着大量的类型检查和强制类型转换；</li>
<li>阅读代码时，如果没有文档，我们无法知道某个<code>Task</code>究竟需要怎样的参数，因为全都是<code>String</code>和<code>Object</code>，必须要将<code>Task</code>运行起来通过断点的方式才能知道到底是什么；</li>
<li>如果有某个<code>Task</code>的详尽的文档，我们还需要维护文档和实现的一致性。</li>
</ol>
<p>单论这三点，我们就将消耗大量的时间。而用TDD驱动出来的对使用者友好的设计，类型检查在创建DAG的时候就可以自动完成，我们也无需维护文档，代码也更清晰可读。而TDD带来的测试质量保护网给我们节省的时间就更不用说了。</p>
<p>我们再次来回顾一下TDD的实践过程。由于TDD要先写测试，这就使得我们不得不在写代码之前（设计之前）先从使用者的角度思考如何使用（如何设计），因而我们也就自然的得到了易于使用的（好的）设计。上面的思考过程可以印证TDD如何驱动出更好的设计的过程，我们先后从使用者的角度思考了如何定义<code>Task</code>，从使用者的角度思考了如何构造DAG。这是两个非常关键的设计，这两个设计将给后续实现新的<code>Task</code>，调试<code>Task</code>带来巨大的便利。</p>
<p>当我们熟练使用TDD之后，实践TDD其实是一件非常愉快的事情。你将清晰的定义出需求，自然的写出更好的代码，同时TDD天然的测试屏障给我们的每行代码的正确性都带来了信心。我们不再会直接写出100行没有测试的代码，然后心里非常虚，然后还需要通过端到端启动应用这样非常低效的方式来验证代码正确性，而在修改了代码之后我们还不得不重复这样枯燥无聊的步骤。TDD可以让我们变成一个快乐的程序员。</p>
<p>最后，我想重复一下第一篇<a href="/2019/07/20/tdd-for-improving-design/">文章</a>最后一段的内容：</p>
<p>通过上面的经验的分享，不知道大家是不是更认可和接受TDD了呢？但是要熟练运用起来，关键还是在于刻意的去练习。每天的日常工作都是机会，希望大家能保持开放的心态，严格要求自己，遇到问题多讨论交流。当团队中所有人都会TDD，代码能力都上去了的时候，我们才能说我们是一个高效的团队，我们能做高质量的产品。所以，加油吧！</p>
]]></content>
      <categories>
        <category>tdd</category>
        <category>敏捷</category>
      </categories>
      <tags>
        <tag>agile</tag>
        <tag>敏捷</tag>
        <tag>tdd</tag>
        <tag>测试</tag>
        <tag>质量</tag>
      </tags>
  </entry>
  <entry>
    <title>你所理解的函数式可能不是我们所推崇的函数式</title>
    <url>/2019/08/26/the-functional-programming-you-understand-may-not-be-what-we-recommended/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>我时常在项目中听到一些经验稍欠缺的开发人员在Code Review时这么讲：</p>
<pre><code>这里为了方便测试我抽取了一个纯函数，这个函数包含了主要的业务逻辑，测试覆盖率也比较高，我们可以认为这一部分质量不错。
使用这个函数的地方由于集成度高不好测试，我们就不做自动化测试了。
</code></pre>
<p>他的代码可能写成下面这样：</p>
<figure class="highlight typescript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// some_file.ts</span></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">someEasyToTestMethod</span>(<span class="params"></span>) &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">A</span> &#123;</span><br><span class="line">    <span class="title function_">someMethod</span>(<span class="params"></span>) &#123;</span><br><span class="line">        <span class="title function_">someEasyToTestMethod</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<p>咋一看似乎也在理，主要的逻辑有测试覆盖了，质量有保障了，集成点的测试由于代价比较高就不通过自动化测试覆盖而是通过手工测试覆盖。但是在我看来这里还存在不少问题：</p>
<ol>
<li>为了测试方便而抽取函数，这反映出我们的代码不是用TDD驱动出来的，里面可能存在不好的设计</li>
<li>函数抽取的目的是为了方便测试，而不是为了让设计更好或可读性更好或复用性更好，这样的函数可能破坏了封装暴露了实现细节</li>
<li>放松了集成点的测试覆盖，可能导致更多的代码被放到这些所谓的集成点里面去，最终导致越来越多的代码没有测试</li>
<li>函数抽取可能过于随意，从而导致命名不易读，带有大量的参数等坏味道出现</li>
</ol>
<p>函数式近两年不断兴起，渐渐成为了一种大家推崇的编程范式，不少人就觉得一旦我抽取函数了，那我就是在实践函数式了。将简单的函数抽取说成函数式编程似乎将自己的编程水平拔高了一大截，而且其他人可能还不好在Code Review时指出真正正确的优化方式或重构方式。但函数式真的是这么简单吗？它的优势在哪里？与过程式的区别是什么？这些问题如果回答不清楚，那我们自称函数式编程就只能是自己骗自己了。</p>
<p>回顾我自己的软件开发历程，有一个阶段其实我的想法跟上面的很相似。之前我们用Java语言开发，在需要复用代码的时候，我也是第一时间想到抽取一个静态函数放到某个<code>Util</code>类中。当然这种方式不是不可以，但是这样的复用方式实在不怎么高明。如果这也算一种抽象，那这种抽象级别也是比较低的，作为专业的开发者，我们需要多走一步，从设计层面去思考更多的东西。</p>
<h2 id="真正的函数式编程是什么样的"><a class="markdownIt-Anchor" href="#真正的函数式编程是什么样的"></a> 真正的函数式编程是什么样的？</h2>
<p>关于这个问题的答案我们可以在网上找到很多，也有很多关于函数式编程讨论的书籍（推荐我司大牛 Neal Ford 编写的《函数式编程思维》），总结起来我们可以认为函数式之所以能流行起来，关键在于其所倡导的状态管理方式和函数式接口抽象。</p>
<p>过程式编程一般通过全局的变量来管理状态，我们现在都知道全局的状态是不好的，因为一旦状态多了，我们甚至很难给其一个独立的名字，更不用说可能导致的大量代码随意读写全局状态而产生的强耦合和高复杂度了。面向对象编程范式通过封装将状态管理限制到一小块代码中来解决状态管理问题。而函数式编程范式推崇的是直接去掉状态，从而无需复杂的状态管理逻辑，这点从我们所熟悉的纯函数（无副作用且引用透明）、不可变对象、流式风格等等特性中就能感受到。由于无状态的特性，函数式在并行执行方面有着天然的优势，我们无需再用各种锁机制谨慎的去协调线程间状态访问了。</p>
<p>当然函数式范式的好处还不止于此，它还给我们提供了一整套新的抽象，让我们无需编写各种循环结构，而是将这些操作抽象为一些更小的基于流的过滤(filter)、转换(map)、聚合(reduce, fold)等等操作。这些操作比起我们去理解<code>for</code>循环<code>while</code>循环要容易很多。同时在函数式编程范式中，函数是一等公民，也就是说我们可以将函数作为一个普通的变量来使用，从而我们可以实现如高阶函数、柯里化等。函数式范式还包括了闭包、尾递归优化、惰性求值、确定性、缓存结果等等概念和应用，这里就不列举了，大家如果不熟悉可以去参考相关的资料。</p>
<p>在了解了函数式之后，再来审视一下我们的代码，它真正是符合函数式范式吗？我们真的是在实践函数式吗？</p>
<h2 id="面向对象还是主流"><a class="markdownIt-Anchor" href="#面向对象还是主流"></a> 面向对象还是主流</h2>
<p>在知道了函数式的好处之后，有人可能会心潮澎湃，只要一写代码就想要用函数式，不用就不舒服。其实面向对象仍然是当前编程范式的主流。我们欣赏函数式，但不代表我们可以不学习面向对象。事实上，面向对象对于现实世界的抽象和我们理解现实的方式是一致的，这会让我们很容易理解面向对象写出来的代码。同时面向对象的范式可以在很大程度上通过封装隐藏复杂度，让我们在阅读代码的时候始终处于同一个抽象层级进行思考，不容易被繁琐的细节所干扰。当前绝大部分流行的库，甚至绝大部分新出现的流行的库，也都是基于面向对象构建的。</p>
<p>事实上函数式其实也有其缺点，比如，函数式可能会遇到下面这些问题：</p>
<ol>
<li>可能无意间引入一些低性能的操作，如在本应该使用<code>List.find</code>的地方用<code>List.filter</code>去实现，则会导致性能降低</li>
<li>多个流组合处理或者存在过多的流式逻辑时，可能导致难以理解的逻辑、大量新的类型或者随处可见的<code>Tuple</code></li>
<li>在需要管理可变状态时几乎无能为力，比如UI程序就很难完全使用函数式实现</li>
</ol>
<p>而我们采用命令式的方式结合面向对象的思想，上面的问题解决起来是可以得心应手的。</p>
<p>总结起来，我们可以认为，在编写复杂软件时，还是需要以面向对象范式为主，但是在细节实现的地方考虑结合函数式的思想，充分利用函数式的优势。</p>
<h2 id="几个实践的例子"><a class="markdownIt-Anchor" href="#几个实践的例子"></a> 几个实践的例子</h2>
<p>以面向对象范式为主，以函数式思想为辅的编码方式在我经历过的项目中经常使用，我们在项目中确实也深刻的感受到了它带来的好处。这里分享几个例子供大家参考。</p>
<p>在一个最近的客户项目上，我们用到了一个名为多边形的核心领域对象，在这个对象上面我们需要提供很多变换操作。比如多边形缩放、多边形简化、求多边形的最小外接凸多边形等等。借鉴函数式的思想，我们将其设计为了一个不可变对象，每经历一次变换，我们就返回一个新的多边形，而不是修改原多边形的状态。基于这样的设计，我们可以非常安全的进行各种各样的变换，完全不用担心调用者会由于状态改变而产生出乎意料的bug。我们的多边形定义成下面这样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Polygon</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, points: <span class="type">Union</span>[<span class="type">List</span>[<span class="type">List</span>[<span class="built_in">float</span>]], <span class="type">List</span>[<span class="type">Tuple</span>[<span class="built_in">float</span>, <span class="built_in">float</span>]], np.ndarray]</span>):</span><br><span class="line">        self._points = np.array(points)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">expand_from_center</span>(<span class="params">self</span>) -&gt; <span class="string">&#x27;Polygon&#x27;</span>:</span><br><span class="line">        points = ...</span><br><span class="line">        <span class="keyword">return</span> Polygon(points)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">convex_hull</span>(<span class="params">self</span>) -&gt; <span class="string">&#x27;Polygon&#x27;</span>:</span><br><span class="line">        points = ...</span><br><span class="line">        <span class="keyword">return</span> Polygon(points)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">simplify</span>(<span class="params">self, tolerance: <span class="built_in">float</span></span>) -&gt; <span class="string">&#x27;Polygon&#x27;</span>:</span><br><span class="line">        points = ...</span><br><span class="line">        <span class="keyword">return</span> Polygon(points)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">minimum_rotated_rectangle</span>(<span class="params">self</span>) -&gt; <span class="string">&#x27;Polygon&#x27;</span>:</span><br><span class="line">        points = ...</span><br><span class="line">        <span class="keyword">return</span> Polygon(points)</span><br><span class="line"></span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<p>在另一个项目上，我们需要把对一批数据进行类似SQL的聚合操作，利用函数式的代码风格，可以完全避免<code>for</code>循环，让代码更容易理解。比如要实现查询<code>select field1, field2, field3, count(*) from some_table group by field1, field2, field3</code>，我们可以将代码写成这样（为了方便演示没有考虑变量访问控制等问题）：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AggregationTest</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">aggregate</span><span class="params">(List&lt;SomeTable&gt; dataList)</span> &#123;</span><br><span class="line">        List&lt;SomeAggregated&gt; someAggregatedList =</span><br><span class="line">                dataList.stream()</span><br><span class="line">                        .collect(Collectors.groupingBy(</span><br><span class="line">                            SomeTable::groupingKeyOfField1Field2Field3, HashMap::<span class="keyword">new</span>, Collectors.counting()))</span><br><span class="line">                        .entrySet()</span><br><span class="line">                        .stream()</span><br><span class="line">                        .map(entry -&gt; <span class="keyword">new</span> <span class="title class_">SomeAggregated</span>(entry.getKey(), entry.getValue()))</span><br><span class="line">                        .collect(Collectors.toList());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value</span></span><br><span class="line">    <span class="meta">@AllArgsConstructor</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">SomeTable</span> &#123;</span><br><span class="line">        String field1;</span><br><span class="line">        String field2;</span><br><span class="line">        String field3;</span><br><span class="line">        String field4;</span><br><span class="line"></span><br><span class="line">        SomeAggregatedKey <span class="title function_">groupingKeyOfField1Field2Field3</span><span class="params">()</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">SomeAggregatedKey</span>(field1, field2, field3);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value</span></span><br><span class="line">    <span class="meta">@AllArgsConstructor</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">SomeAggregatedKey</span> &#123;</span><br><span class="line">        String field1;</span><br><span class="line">        String field2;</span><br><span class="line">        String field3;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value</span></span><br><span class="line">    <span class="meta">@AllArgsConstructor</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">SomeAggregated</span> &#123;</span><br><span class="line">        String field1;</span><br><span class="line">        String field2;</span><br><span class="line">        String field3;</span><br><span class="line">        Long field4Count;</span><br><span class="line"></span><br><span class="line">        SomeAggregated(SomeAggregatedKey key, Long count) &#123;</span><br><span class="line">            field1 = key.field1;</span><br><span class="line">            field2 = key.field2;</span><br><span class="line">            field3 = key.field3;</span><br><span class="line">            field4Count = count;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>另一个经常使用的技巧在实现纯函数时非常有效。函数式的思想告诉我们，纯函数具有确定性，每次输入同一个数据，总是能得到相同的输出结果。这是个非常好的特性，对于简化代码、增加可读性并降低理解难度帮助巨大。纯函数要求函数的实现是引用透明的，即函数的运行不依赖任何外部变量。一个常常被大家所忽略的例子是代码<code>new Date()</code>不是引用透明的，因为它会读取当前系统时间。为了实现纯函数，我们可以将代码写成下面这样（为了方便演示没有考虑变量访问控制等问题）：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PureFunctionTest</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">A</span> &#123;</span><br><span class="line">        <span class="keyword">interface</span> <span class="title class_">CurrentDateGetter</span> &#123;</span><br><span class="line">            Date <span class="title function_">currentDate</span><span class="params">()</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">CurrentDateGetter</span> <span class="variable">currentDateGetter</span> <span class="operator">=</span> Date::<span class="keyword">new</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">A</span><span class="params">()</span> &#123;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">A</span><span class="params">(CurrentDateGetter currentDateGetter)</span> &#123;</span><br><span class="line">            <span class="built_in">this</span>.currentDateGetter = currentDateGetter;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">someMethod</span><span class="params">()</span> &#123;</span><br><span class="line">            <span class="type">Date</span> <span class="variable">date</span> <span class="operator">=</span> currentDateGetter.currentDate();</span><br><span class="line">            <span class="comment">// do things with date</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">ATest</span> &#123;</span><br><span class="line">        <span class="meta">@Test</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">should_do_something</span><span class="params">()</span> &#123;</span><br><span class="line">            <span class="type">A</span> <span class="variable">a</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">A</span>(() -&gt; date(<span class="string">&quot;2019-01-01 00:00:00&quot;</span>));</span><br><span class="line">            a.someMethod();</span><br><span class="line">            <span class="comment">// assert ...</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">private</span> Date <span class="title function_">date</span><span class="params">(String dateStr)</span> &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">SimpleDateFormat</span>(<span class="string">&quot;yyyy-MM-dd hh:mm:ss&quot;</span>).parse(dateStr);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (ParseException e) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码提供了一个可选的构造器参数，使得外部可以控制如何获取当前时间，只要新建<code>A</code>的实例的时候传入了这个参数，构造出来的<code>A</code>的实例就是满足纯函数条件的实例（假设<code>A</code>的实现中的其他部分满足纯函数条件），因为它的输出完全依赖于输入，具有引用透明的特性。有了纯函数的特性，我们在测试时就方便得多了，在<code>ATest</code>中，我们可以轻易的构造想要的时间测试数据。</p>
<h2 id="几点建议"><a class="markdownIt-Anchor" href="#几点建议"></a> 几点建议</h2>
<p>回到文章开头的例子，针对这个具体的场景，当我们想抽取函数的时候，我们要如何做呢？下面是几点小建议，希望能有所启发。</p>
<h3 id="抽取方法的几个小建议"><a class="markdownIt-Anchor" href="#抽取方法的几个小建议"></a> 抽取方法的几个小建议</h3>
<p>在抽取函数时，我们首先要问的一个问题是：真的有必要抽取函数吗？一个典型的差的理由就是为了方便测试。一些好的理由应当是：</p>
<ol>
<li>降低当前类或者函数的复杂度</li>
<li>将方法归类到某一个模块或类下面，增加内聚性，降低耦合性</li>
<li>提高代码的可复用性</li>
<li>更符合整体的架构和设计</li>
<li>提高代码的可读性</li>
</ol>
<p>当然还有很多合理的理由，大家可以根据实际情况权衡。</p>
<p>当我们发现真的要抽取函数的时候，我们要思考函数放到什么地方是合适的。</p>
<p>如果过于随意的把某一个函数直接放在某一个模块里面成为一个公开可访问的接口，这其实是在暴露模块的内部实现，破坏封装。而且多一个API，系统内就多了一个需要管理的东西，系统的复杂度上升了，易理解度降低了。</p>
<p>一个比较合理的做法是，我们需要去阅读现有的代码，权衡一下放到哪里是合适的。如果我们发现有这样一个地方，那就顺理成章放进去。如果我们发现没有这样的地方，我们可以思考一下这样几个问题：1. 将来有什么地方能复用这个逻辑吗？ 2. 按照现在的架构和设计，这个函数应该放到哪里呢？ 3. 是不是可以抽取一个类或模块来增加可读性？ 4. 如果抽取类或模块，是不是将来可能有其他的逻辑可以归类到它上面？ 当我们的系统已经很复杂的时候，如果我们要抽取类或模块，我们可能要更谨慎一些，奥卡姆剃刀原则告诉我们，“如无必要，勿增实体”，如果有不增加对象的方式来解决问题，就别增加对象。但也别过于谨慎，导致生硬的将方法归类到关系不大的现有模块中。</p>
<h3 id="编写测试的几个小建议"><a class="markdownIt-Anchor" href="#编写测试的几个小建议"></a> 编写测试的几个小建议</h3>
<p>我们不能为了测试而抽取函数，测试应该用于优化设计，而不是限制设计表达的灵活性（所以更好的方式应该是采用TDD测试驱动设计的方式进行开发）。上面例子反映出的一个问题就是不知道如何写好测试。这里有几点小建议。</p>
<ol>
<li>如果我们在某一个框架下开发，弄清框架的工作原理，按照框架的工作方式相应去调用函数。也就是说我们要模拟框架的工作方式来测试。</li>
</ol>
<p>比如在<code>Angular</code>框架下写测试，我们可以参考<a href="https://angular.io/guide/testing#component-class-testing">这里</a>的文档。第一步是弄清<code>Angular</code>的工作方式，比如如何实例化对象，如何传入和传出参数，如何依次调用生命周期方法等。第二步是模拟框架的工作方式实例化测试对象，并依次调用方法，或者传参，比如<code>@Input</code>是其他模块提供的输入，我们可以通过<code>comp.input = ...</code>的方式模拟传值，比如<code>@Output</code>是我们需要输出的东西，我们可以据此验证我们的输出是否正确。</p>
<ol start="2">
<li>适当降低对于UI的单元测试，将尽量少的逻辑放到UI层。</li>
</ol>
<p>对于前端开发而言，现在都流行使用类MVVM的架构，视图层的功能蜕化为仅仅根据ViewModel进行简单且很傻的渲染，业务逻辑都放在ViewModel或服务层。而现在多数框架，无论是移动应用还是Web框架，都提供了强大的模板引擎，我们现在编写视图实际上是在使用这些框架规定的DSL编写代码。这些DSL代码，我们可以认为功能简单无需单元测试，它的复杂的渲染过程是框架的代码帮我们保证正确性的。另一方面的原因是如果我们要写单元测试，我们势必会引入框架的渲染过程，而这通常会导致运行缓慢的测试。还有一个理由是UI一般都变更太快，不够稳定，建立单元测试可能会导致维护成本太高。当然我们还是有必要建立集成测试去一定程度上覆盖这些DSL代码的。由于没有单元测试覆盖这些DSL代码，为了我们对于代码更有信心，我们就需要将尽量少的逻辑放到这样的视图层。基于这样的考虑，我个人会更推荐摒弃使用类似<a href="https://jestjs.io/docs/en/snapshot-testing">jest的snapshot testing</a>机制进行的测试。</p>
<p>我们博客大赛里面有很多更系统的关于如何写前端测试的介绍，比如这篇《#博客大赛# React 单元测试策略及落地》，大家在邮件内搜索就能找到，推荐大家读一下。</p>
<ol start="3">
<li>Mock外部依赖，选择性的mock内部依赖</li>
</ol>
<p>测试不好写的其中一个重要原因就是我们可能随意的代码中引入对于外部系统的依赖，比如我们可能无意间发起了一个http请求，读取了一个外部文件等等。没有了这些依赖，我们的程序无法完成其功能。在单元测试中，如果这些依赖引用杂乱无章的出现在任意的代码中，那么我们的测试将很难编写。其实当我们发现测试不好写的时候，通常都是我们的设计出了问题，好的设计应该是易于测试的。这里的好的设计应该是什么样的呢？其实很简单，通常我们可以将一组外部依赖抽象为一个独立的接口，然后具体调用外部系统的地方就只是这个接口的某个实现而已。当有了这样的设计时，在测试中我们只需要针对性的创建一个测试替身就好了。</p>
<p>内部的其他模块依赖，我们要怎么测试呢？一种方式是类似上面的做法，抽象一个接口就搞定。但有时候我们会发现这样不好操作，比如我们可能想要调用某个实体类上面的一个计算方法，这个时候难道为了mock这个方法，我们要将这个实体抽象为一个接口？还有时候，我们的代码里面会直接实例化一个工具类来使用，这同样也给测试造成了麻烦，因为这个时候工具类依赖实际上是我们要测试的对象的具体实现的一部分，而我们应该针对接口测试而不是实现。这个时候我的建议就是不mock，直接将这些调用当做内部实现进行测试。需要注意的一点是我们可以适当放松对于这些依赖实现的逻辑进行测试，因为我们常常应该在这些依赖自己的测试中去关注这些细节。这样做的一个额外的好处是让我们对于代码更有信心了，因为顺便测试到了集成点。不好的地方就是，当依赖的地方逻辑有修改可能导致这里的测试失败。</p>
<ol start="4">
<li>设计一层防腐层</li>
</ol>
<p>我们可以结合依赖的工具或框架，自行设计一层抽象接口，在业务代码中使用自己的接口，而不是使用那些工具或框架中的接口。这等同于在我们的代码域和第三方库域之间做了一层防腐层，可以有效的防止我们的代码腐化。同时因为在防腐层里面我们会将外部依赖的数据结构转换为领域对象，从而一定程度上屏蔽了外部依赖的复杂度，正是由于外部依赖更简单，我们的测试替身也将更容易创建，即我们的代码也更容易测试了。</p>
<p>当我们熟练掌握了上面几点技巧，我相信测试将不再成为抽取函数的理由。</p>
]]></content>
      <categories>
        <category>技术</category>
        <category>函数式</category>
      </categories>
      <tags>
        <tag>编程范式</tag>
        <tag>函数式</tag>
        <tag>面向对象</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop安全认证机制 （二）</title>
    <url>/2019/10/30/hadoop-auth-2/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>在<a href="/2019/10/27/hadoop-auth/">上一篇</a>文章中，我们分析了<code>Kerberos</code>协议的设计和通信过程。可以了解到，<code>Kerberos</code>主要实现了不在网络传输密码的同时又能在本地进行高性能鉴权。由于<code>kerberos</code>的协议设计相对复杂，看到评论有人还有疑问，这里再举一个例子来分析一下<code>kerberos</code>的安全性。</p>
<h2 id="kerberos协议回顾"><a class="markdownIt-Anchor" href="#kerberos协议回顾"></a> <code>Kerberos</code>协议回顾</h2>
<p>假设有三个组件A B C，A想和C进行安全通信，而B作为一个认证中心保存了认证信息。那么以以下的方式进行通信就可以做到安全：</p>
<ol>
<li>A向B请求说要访问C，将此消息用A的秘钥加密之后，发给B</li>
<li>B验证A的权限之后，用A自己的秘钥加密一个会话密码，然后传给A</li>
<li>同时B还向A发送一个A自己不能解密，只能由C解密的消息</li>
<li>A在解密会话密码之后，将需要和C通信的消息（业务消息）用这个会话密码加密然后发给C，同时A需要将B发给A而A又不能解密的消息发给C</li>
<li>C在拿到消息之后，可以将第三步中的消息解密，得到会话秘钥，从而可以解密A发过来的业务消息了</li>
</ol>
<span id="more"></span>
<p>整个过程，A无需知道C的密码，C也无需知道A的密码就可以完成安全通信。</p>
<p>这里的安全性我们可以从以下几个方面来看：</p>
<ol>
<li>
<p>如果消息被截获<br />
当第一步中的消息被截获：这里的消息用A的秘钥加密了，截获也无法解密<br />
当第二步中的消息被截获：这里的消息用A的秘钥加密了，截获也无法解密<br />
当第三步中的消息被截获：这里的消息用C的秘钥加密了，截获也无法解密<br />
当第四步中的消息被截获：这里的消息分别用会话秘钥、C的秘钥加密了，截获也无法解密<br />
当第五步中的消息被截获：这里的消息用会话秘钥，截获也无法解密</p>
</li>
<li>
<p>如果A是一个攻击方（某一个有权限的用户想要提权）<br />
他只能拿到自己的秘钥，而无法获取B或C的秘钥，他不能随意生成一个加密消息发给C请求服务（冒充其他用户），因为他无法伪造有会话密码而又用C的秘钥加密的消息</p>
</li>
<li>
<p>如果C是一个攻击方（欺骗某个有权限的用户）<br />
他无法解密第三步中的消息，所以无法解密A的消息，从而也就无从提供服务</p>
</li>
<li>
<p>如果B是一个攻击方<br />
他无法解密A的消息，从而无法提供服务</p>
</li>
<li>
<p>如果传输的消息被破解（任何加密都是可以被破解的，只是时间的问题）<br />
由于整个通信过程由会话秘钥来加密，会话秘钥的有效期通常比较短，当消息被破解之后，攻击者也不能利用破解得到的秘钥去破解后续的消息</p>
</li>
</ol>
<p>从这几个方面来看，这个协议都是比较安全的。</p>
<p>以上的安全通信步骤是<code>kerberos</code>安全的核心机制，A对应文章中的<code>Client</code>，B对应文章中的<code>TGS</code>，C对应文章中的<code>SS</code>。</p>
<p>但<code>kerberos</code>还引入了一个AS的组件，这主要为了提高性能和扩展性。</p>
<p>有了<code>AS</code>之后，我们可以将整个通信看成两个上述ABC通信模式的重复。第一个通信模式A对应文章中的<code>Client</code>，B对应文章中的<code>AS</code>，C对应文章中的<code>TGS</code>，为了实现<code>Client</code>和<code>TGS</code>的安全通信。第二个通信模式A对应文章中的<code>Client</code>，B对应文章中的<code>TGS</code>，C对应文章中的<code>SS</code>，为了实现<code>Client</code>和<code>SS</code>的安全通信。</p>
<p>为什么有了两次通信模式之后，就能提高性能和扩展性呢？实际上一般我们可以将<code>Client/TGS</code>的会话秘钥有效期配置得更长一些，而将<code>Client/SS</code>的会话秘钥有效期配置得比较短。由于一旦我们有一个有效的<code>TGT</code>及<code>Client/TGS</code>会话秘钥，在这个秘钥的有效期内，我们无需再访问<code>AS</code>去生成新的会话秘钥。当<code>Client/TGS</code>会话秘钥有效期较长的时候，我们就可以较少的访问<code>AS</code>，从而将<code>AS</code>这一第一入口服务的负载降低。而<code>TGS</code>由于需要经常参与秘钥生成，它的负载会相对较高，这里我们就可以将<code>TGS</code>扩展到多台服务器来支撑大的负载。<code>AS</code>可以给<code>Client</code>提供一个有效的<code>TGS</code>地址，从而实现<code>TGS</code>的分布式扩展。</p>
<h2 id="kerberos协议发展"><a class="markdownIt-Anchor" href="#kerberos协议发展"></a> <code>Kerberos</code>协议发展</h2>
<h3 id="gss-api"><a class="markdownIt-Anchor" href="#gss-api"></a> <code>GSS API</code></h3>
<p><code>Kerberos</code>协议本身只是提供了一种安全认证和通信的手段，要应用这个协议，我们需要一套<code>API</code>接口。在具体实现的时候，每个人都会写出不一样的代码，从而产生不同的<code>API</code>。这可不是好事，对于应用方而言，不仅仅学习成本高，而且系统迁移能力差，比如换一个<code>Kerberos</code>服务器可能就会出现兼容性问题。就像<code>windows</code>上面的换行用<code>\r\n</code>，而<code>unix</code>类操作系统用<code>\n</code>，这给每一个开发者都带来了麻烦。</p>
<p>所以，在具体的工程应用时，一种通用的<code>API</code>就变得非常重要。这就是<code>GSS API</code>，其全称是The Generic Security Services Application Program Interface，即通用安全服务应用程序接口。这套<code>API</code>在设计的时候其实不仅仅考虑了对于<code>Kerberos</code>的支持，还考虑了支持其他的协议，所以称为通用接口。由于我们总是会发展出其他的安全协议的，抽象一套可以长期保持不变的通用的<code>API</code>接口，就可以避免应用层进行修改。这一套<code>API</code>接口就是在上一篇文章中我们用到的接口了。</p>
<p>从<code>GSS API</code>接口来看，我们的认证过程可以抽象为这样几个简单的步骤：</p>
<ul>
<li>客户端：创建一个<code>Context</code>上下文用来保存数据 -&gt; 通过<code>initSecContext</code>获取一个<code>token</code> -&gt; 将<code>token</code>发送给服务器 -&gt; 等待服务器回发的用于通信的<code>token</code></li>
<li>服务器：创建一个<code>Context</code>上下文用来保存数据 -&gt; 读取客户端发来的<code>token</code> -&gt; 验证<code>token</code>，并（可能）生成一个新的用于通信的<code>token</code> -&gt; 将<code>token</code>发给客户端</li>
</ul>
<p>这里的认证过程简单到甚至没有出现认证服务器，基于这样的一套通用<code>API</code>去实现其他应用就相对轻松多了。<code>Kerberos</code>内部的通信细节，多次传输的各种密文全部都隐藏在这样的<code>API</code>实现中。具体的<code>GSS API</code>使用代码示例，大家可以参考上一篇文章中代码。</p>
<h3 id="spnego"><a class="markdownIt-Anchor" href="#spnego"></a> SPNEGO</h3>
<p>由于<code>GSS API</code>设计可以支持多种安全协议，另一个想法会自然的冒出来。我们可以让服务器支持多种认证协议，然后具体用哪种，由客户端和服务器端协商决定。这就使得我们在开发应用时可以给最终的用户提供选择，便于使用他或她所偏好使用的认证方式，从而带来更好的用户体验。同时，服务器和客户端在各自实现时，也可以相互独立的增量式的添加或去掉对于某一具体协议的支持，而不用完全同步的进行修改。这对于同一个服务器要支持多个版本的客户端而言会很有用。</p>
<p>这就是<code>SPNEGO</code>了，其全称是Simple and Protected GSSAPI Negotiation Mechanism，即基于<code>GSS API</code>实现的一套简单的协议协商机制。这一协议由微软最早提出并应用在windows操作系统中，与我们最贴近的应用，当属于浏览器的系统集成认证了。大家回忆一下我们使用IE浏览器的体验，可以发现，很多网站可以直接使用系统的域账户登录。这就是用<code>SPNEGO</code>协议实现的浏览器系统集成认证。在企业中，如果我们为所有员工配置了<code>windows</code>域账户，而当我们有一些基于web的企业应用需要认证时，就可以利用这一机制实现无感知的认证。其实不只是IE浏览器，<code>Firefox</code> <code>Chrome</code>等主流浏览器基本上都实现了这样的系统集成登录机制。</p>
<p>这个协议的通信过程大致为：</p>
<ol>
<li><code>Client</code>向<code>Server</code>请求服务</li>
<li><code>Server</code>检查<code>Client</code>是否有提供有效的认证信息：如果没有，返回消息（包括服务器支持的认证方式）给<code>Client</code>，以便<code>Client</code>可以完成认证；如果有，就提供服务</li>
<li><code>Client</code>完成认证之后，向<code>Server</code>请求服务，并带上认证信息</li>
<li>回到第二步中进行认证检查，直到通过或认证次数达到阈值为止</li>
</ol>
<h2 id="hadoop-认证机制"><a class="markdownIt-Anchor" href="#hadoop-认证机制"></a> Hadoop 认证机制</h2>
<p>介绍了这么多，其实都是为了我们分析<code>Hadoop</code>的认证机制实现。到这里，相信大家应该也猜到了，在<code>Hadoop</code>的认证中，各个节点的通信实际上使用的就是<code>GSS API</code>去实现的基于<code>Kerberos</code>协议的单点认证。而<code>Hadoop</code>对外提供的很多基于web的应用，比如Web HDFS、统计信息页面、Yarn Application管理等等，其认证都是基于<code>SPNEGO</code>协议的。这两个协议的配置其实在我们后续配置<code>Hadoop</code>认证时也是最主要的配置了。</p>
<h2 id="相关源代码分析"><a class="markdownIt-Anchor" href="#相关源代码分析"></a> 相关源代码分析</h2>
<p>（下面的内容请大家结合源代码一起分析，仅仅读文字可能有很多内容会难以理解）</p>
<h3 id="gss-api中的kerberos实现"><a class="markdownIt-Anchor" href="#gss-api中的kerberos实现"></a> GSS API中的<code>Kerberos</code>实现</h3>
<p>我们打开<code>OpenJDK</code>的<a href="https://github.com/unofficial-openjdk/openjdk/blob/5b0f4d762e/src/java.security.jgss/share/classes/module-info.java">源代码库</a>，浏览到下面这里的代码：</p>
<p><img data-src="/attaches/2019/2019-10-30-hadoop-auth-2/openjdk.png" alt="OpenJDK" /></p>
<p>这里的代码量还是挺大的，细节很多，我们一起看一下主要的设计。<code>GSS API</code>在Java语言中通过<code>jgss</code>模块来实现。<code>jgss</code>首先定义了一些底层认证机制需要实现的接口，即<code>sun.security.jgss.spi</code>包中的基本接口<code>GSSContextSpi</code> <code>GSSNameSpi</code> <code>GSSCredentialSpi</code>和工厂接口<code>MechanismFactory</code>。底层的协议只需要实现这几个接口就行了，关于<code>Kerberos</code>的实现在包<code>sun.security.jgss.krb5</code>中，其实这个包里面的代码只是对接了真正的<code>Kerberos</code>通信协议实现和<code>GSS API</code>接口。这里的设计，按照DDD的思想，我们可以理解为一套防腐层，<code>GSS API</code>和<code>Kerberos</code>可以看成两个独立的领域，通过引入防腐层，它们就可以相互独立的各自演进。当接口有改变的时候，我们只需要修改防腐层的代码就行了。</p>
<p>真正的<code>Kerberos</code>协议实现在包<code>sun.security.krb5</code>下面，这里的实现通过<code>javax.security.auth.kerberos</code>包下面的类对应用层暴露接口（应用层在使用<code>GSS API</code>时，有时还是需要关心底层认证机制的相关信息的）。作为应用层，如果有必要获取底层认证机制相关的信息，我们将只使用<code>javax.security.auth.kerberos</code>中定义的接口，而无需关心<code>sun</code>包下面的实现。这里的实现的核心代码在<code>Credentials</code>类中，我们看到其定义了<code>acquireTGTFromCache</code> <code>acquireDefaultCreds</code> <code>acquireServiceCreds</code>等接口用于交换秘钥。更细节的实现代码，大家如有兴趣，可以结合上一篇文章中的通信流程自行研究。我们这里只简要分析一下主要的设计思想。</p>
<h3 id="hadoop中使用gss-api进行认证"><a class="markdownIt-Anchor" href="#hadoop中使用gss-api进行认证"></a> <code>Hadoop</code>中使用<code>GSS API</code>进行认证</h3>
<p><code>Hadoop</code>中和认证相关的模块主要有两个：一个是直接使用<code>GSS API</code>进行认证，用于<code>tcp</code>通信的<code>org.apache.hadoop.security.UserGroupInformation</code>类；另一个是基于<code>SPNEGO</code>协议进行认证，用于<code>HTTP</code>通信的<code>org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler</code>。</p>
<p><code>UserGroupInformation</code>主要用于<code>Hadoop</code>各个内部模块间的通信，也可以用于某一个客户端和<code>Hadoop</code>的某个模块进行通信，它同时为服务器和客户端的认证提供了支持。比如<code>NameNode</code>的启动之后，它将发起一个登陆请求，用于验证给自己配置的<code>Principal</code>和<code>keytab</code>是否有效（<a href="https://github.com/apache/hadoop/blob/release-2.7.7-RC0/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/BootstrapStandby.java">这里</a>108行）。同时当有内部服务（如某个datanode）的rpc请求到来的时候，它将使用登陆得到的认证主体<code>Subject</code>中的<code>doAs</code>方法来验证发送过来的认证信息，并进行权限验证。有客户端的rpc请求到来时，它将获取客户端的用户信息，并根据配置的ACL（访问控制列表）进行权限验证（实现见<a href="https://github.com/apache/hadoop/blob/release-2.7.7-RC0/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java">这里</a>的1287行，及<a href="https://github.com/apache/hadoop/blob/release-2.7.7-RC0/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/security/token/block/BlockPoolTokenSecretManager.java">这里</a>）。为了缓存认证信息，避免没必要的重新认证，程序需要维护当前登录的账号的信息，这也就是为什么<code>UserGroupInformation</code>在设计上定义了很多静态的属性。同时我们可以注意到很多<code>synchronized</code> 关键字附加到了某些静态方法上，这是为了支持多线程访问这些全局缓存的信息。</p>
<p><code>KerberosAuthenticationHandler</code>的实现是为了支持在HTTP服务中进行<code>Kerberos</code>认证，这个类最终会封装为一个Web服务器中的<code>Filter</code>实现对所有HTTP请求的权限验证（<a href="https://github.com/apache/hadoop/blob/release-2.7.7-RC0/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/AuthFilter.java">这里的AuthFilter</a>及其<a href="https://github.com/apache/hadoop/blob/release-2.7.7-RC0/hadoop-common-project/hadoop-auth/src/main/java/org/apache/hadoop/security/authentication/server/AuthenticationFilter.java">基类AuthenticationFilter</a>）。由于基于Servlet的Web服务器有很成熟的接口设计，这个模块的实现也相对独立和简单。可以看到它在<code>init</code>的时候使用<code>GSS API</code>完成了登录，在<code>authenticate</code>的时候，将判断是否有有效的认证信息，如果没有将返回协商认证的HTTP头部消息以便客户端去完成认证，如果有将进行认证并提供服务。</p>
<h2 id="web服务器认证实现示例"><a class="markdownIt-Anchor" href="#web服务器认证实现示例"></a> Web服务器认证实现示例</h2>
<p>对于一个运行于Hadoop集群的<code>Spark</code>应用，我们通常是通过<code>spark-submit</code>命令行工具来向集群提交任务的。这一机制对于<code>spark</code>应用的开发者看起来很灵活，但如果我们想进行更多的统一管理，比如限制资源使用、提升易用性等等，这样的机制就略显不足了。这个时候一般的做法是将运行<code>spark</code>应用的这一能力封装为一个服务，以便进行统一的管理。<code>Livy</code>就是为实现这样的功能而开发的一个开源工具。</p>
<p>使用<code>Livy</code>，我们可以使用REST的接口向集群提交<code>spark</code>任务。在这里<code>Livy</code>其实相当于是整个<code>Hadoop</code>大数据集群的一个扩展服务。<code>Livy</code>在实现的时候如何进行权限的支持呢？当我们去查看<code>Livy</code>的源代码的时候，我们会发现，要为每个请求添加<code>Kerberos</code>认证，几乎只需要一行代码，<a href="https://github.com/apache/incubator-livy/blob/v0.5.0-incubating/server/src/main/scala/org/apache/livy/server/LivyServer.scala">这里</a>的237行即为那行关键的代码。这里Livy就是有效的利用了上面的<code>KerberosAuthenticationHandler</code>进行实现的。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>在简要分析了<code>Kerberos</code>的协议和发展及相关的实现代码之后，大家是不是对于这个协议及其在大数据上面的应用有了更深入的理解呢？我想大家一定对于搭建一套支持<code>Kerberos</code>认证的安全的大数据集群很有兴趣，后续的文章将与大家一起来尝试搭建一套这样的集群。由于<code>Hadoop</code>的安全机制的复杂性，我们在初次搭建这样的集群时可能会碰到各种各样的问题，上面的这些基础知识将为解决这些问题将提供很大的帮助。</p>
]]></content>
      <categories>
        <category>数据</category>
        <category>大数据</category>
        <category>安全</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>安全</tag>
        <tag>hadoop</tag>
        <tag>kerberos</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop安全认证机制 (一)</title>
    <url>/2019/10/27/hadoop-auth/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>安全无小事，我们常常要为了预防安全问题而付出大量的代价。虽然小区楼道里面的灭火器、消防栓常年没人用，但是我们还是要准备着。我们之所以愿意为了这些小概率事件而付出巨大的成本，是因为安全问题一旦发生，很多时候我们将无法承担它带来的后果。</p>
<p>在软件行业，安全问题尤其突出，因为无法预料的事情实在太多了。软件的复杂性让我们几乎无法完全扫清安全问题，模块A独立运行可能没问题，但是一旦和模块B一起工作也许就产生了安全问题。</p>
<p>不可否认为了让软件更安全，我们引入了很多复杂的机制。不少人开发者也抱怨为了进行安全处理而做了太多额外的事情。在一个复杂的分布式软件Hadoop中，我们为此付出的成本将更大。比如，我们可能可以比较轻松的搭建一个无安全机制的集群，但是一旦需要支持安全机制的时候，我们可能会付出额外几倍的时间来进行各种复杂的配置和调试。</p>
<p>Hadoop在开始的几个版本中其实并没有安全机制的支持，后来Yahoo在大规模应用Hadoop之后，安全问题也就日益明显起来。大家都在一个平台上面进行操作是很容易引起安全问题的，比如一个人把另一个人的数据删除了，一个人把另一个人正在运行的任务给停掉了，等等。在当今的企业应用里面，一旦我们的数据开始上规模之后，安全机制的引入几乎是必然的选择。所以作为大数据领域的开发者，理解Hadoop的安全机制就显得非常重要。</p>
<p>Hadoop的安全机制现在已经比较成熟，网上关于它的介绍也很多，但相对较零散，下面我将尝试更系统的，并结合实例代码，给大家分享一下最近一段时间关于Hadoop安全机制的学习所得，抛个砖。</p>
<p>预计将包括这样几个方面：</p>
<ol>
<li>Kerberos协议介绍及实践</li>
<li>Kerberos协议发展及Hadoop相关源码分析</li>
<li>Hadoop安全集群搭建及测试</li>
<li>周边工具的安全支持</li>
</ol>
<span id="more"></span>
<h2 id="安全认证协议"><a class="markdownIt-Anchor" href="#安全认证协议"></a> 安全认证协议</h2>
<h3 id="kerberos"><a class="markdownIt-Anchor" href="#kerberos"></a> Kerberos</h3>
<p>做Web开发的同学们可能比较熟悉的认证机制是<code>JWT</code>，近两年<code>JWT</code>的流行几乎让其成为了实现单点登录的一个标准。<code>JWT</code>将认证服务器认证后得到的<code>token</code>及一定的用户信息经过<code>base64</code>编码之后放到HTTP头中发送给服务器端，得益于<code>token</code>的加密机制（一般是非对称加密），服务器端可以在不连接认证服务器就进行<code>token</code>验证（第一次验证时会向认证服务器请求公钥），从而实现高性能的鉴权。这里的<code>token</code>虽然看起来不可读，实际上我们经过简单的解码就能得到<code>token</code>的内容。所以<code>JWT</code>一般是要结合<code>HTTPS</code>一起应用才能带来不错的安全性。</p>
<p><img data-src="/attaches/2019/2019-10-27-hadoop-auth/jwt.png" alt="JWT认证机制" /></p>
<p><code>JWT</code>看起来还不错呀，安全模型比较简单，能不能直接用在<code>Hadoop</code>上面呢？可能可以。但是由于<code>Hadoop</code>的出现早于<code>JWT</code>太多，所以当时的设计者们是不可能考虑使用<code>JWT</code>的。实际上<code>JWT</code>主要是针对web的场景设计的，对于分布式场景中，很多问题它是没有给出答案的。一些典型的场景比如服务间的认证该如何实现，如何支持其他的协议，等等。<code>Hadoop</code>的安全认证使用的是<code>Kerberos</code>机制。相比<code>JWT</code>，<code>Kerberos</code>是一个更为完整的认证协议，然而也正是因为其设计可以支持众多的功能，也给其理解和使用带来了困难。</p>
<p>这里之所以提到<code>JWT</code>，是因为<code>JWT</code>实际上可以看成是<code>Kerberos</code>协议的一个极简版本。<code>JWT</code>实现了一部分<code>Kerberos</code>的功能。如果我们能对于<code>JWT</code>的认证机制比较熟悉，那么对于<code>Kerberos</code>机制的理解应当是有较大帮助的。</p>
<p><code>Kerberos</code>协议诞生于MIT大学，早在上世纪80年代就被设计出来了，然后经过了多次版本演进才到了现在我们用的V5版本。作为一个久经考验的安全协议，<code>Kerberos</code>的使用其实是非常广泛的，比如<code>Windows</code>操作系统的认证就是基于<code>Kerberos</code>的，而<code>Mac</code> <code>Red Hat Enterprise Linux</code>也都对于<code>Kerberos</code>有完善的支持。各种编程语言也都有内置的实现。对于这样一个重要的安全协议，就算我们不从事大数据相关的开发，也值得好好学习一下。</p>
<p><code>Kerberos</code>设计的有几个大的原则:</p>
<ol>
<li>利用公开的加密算法实现</li>
<li>密码尽量不在网络上传输</li>
<li>高安全性和性能</li>
<li>支持广泛的安全场景，如防止窃听、防止重放攻击、保护数据完整性等</li>
</ol>
<p>那么这个协议是如何工作的呢？与<code>JWT</code>类似，<code>Kerberos</code>同样定义了一个中心化的认证服务器，不过对于这个认证服务器，<code>Kerberos</code>按照功能进一步将其拆分为了三个组件：认证服务器（Authentication Server，AS）、密钥分发中心（Key Distribution Center，KDC）、票据授权服务器（Ticket Granting Server，TGS）。在整个工作流程中，还有两个参与者：客户端(Client)和服务提供端(Service Server，SS)。</p>
<p><code>Kerberos</code>大体上的认证过程与<code>JWT</code>一致：第一步是客户端从认证服务器拿到<code>token</code>（这里的术语是<code>Ticket</code>，下文将不区分这两个词，请根据上下文理解）；第二步是将这个<code>token</code>发往服务提供端去请求相应的服务。</p>
<p>下图是整个认证过程中各个组件按顺序相互传递的消息内容，在阅读整个流程之前，有几点提需要注意:</p>
<ol>
<li>各个组件都有自己独立的秘钥：Client的秘钥由用户提供，AS、TGS、SS需要提前生成自己独立的秘钥</li>
<li>AS、TGS由于属于认证服务器的一部分，它们可以查询KDC得到用户或其他服务器的秘钥，比如AS可以认为拥有用户的、TGS的以及SS的秘钥</li>
</ol>
<p><img data-src="/attaches/2019/2019-10-27-hadoop-auth/kerberos-auth-sequence.png" alt="Kerberos认证流程" /></p>
<p>看了这个复杂的流程，大家心里应该有很多疑惑。整个通信过程传递了很多的消息，消息被来来回回加密了很多次，真的是有必要的吗？背后的原因是什么呢？事实上，我们结合上面提到的几个设计原则来看，问题就会相对清晰一些。</p>
<p>虽然整个通信过程涉及到的消息很多，但是我们仔细思考就可以发现这几条规律：</p>
<ol>
<li>整个认证过程中，避免了任何地方有明文的密码传输</li>
<li>与<code>JWT</code>一样，通信过程生成有效时间比较短的会话秘钥用于通信</li>
<li>与<code>JWT</code>一样，认证服务器无需存储会话秘钥，各个参与方（Client/SS）可以独立进行消息验证，从而实现高性能。这也是虽然消息B和E不能被Client解密，但是还是会发往Client，然后再由Client回发的原因</li>
<li><code>Kerberos</code>并没有对<code>Client</code>和<code>SS</code>之间的通信协议进行限制，虽然和认证服务器进行通信需要基于<code>TCP/UDP</code>，但<code>Client</code>和<code>SS</code>通信可以用任意协议进行</li>
</ol>
<p>理解了上述通信流程之后，可以看到，相比<code>JWT</code>，<code>Kerberos</code>还进行了下面的额外验证：</p>
<ol>
<li>认证过程将验证服务提供端的ID，一般会基于hostname进行</li>
<li>认证过程将验证各个组件的时间，相互不能相差太多，这也是<code>Kerberos</code>要求各个组件进行时间同步的原因</li>
</ol>
<p>除了上面这些安全验证，其实<code>Kerberos</code>还支持免密码输入的登录，我们可以将用户的秘钥（并非真正的密码，由真正的密码hash生成）生成到一个<code>keytab</code>格式的文件中，这样在第一步中，就可以由用户提供ID(principal)及<code>keytab</code>文件来完成了。</p>
<p>虽然<code>Kerberos</code>可以支持多种场景的认证，但是由于其协议设计比较复杂，在使用上会给我们带来不少的困难。比如我们需要提前为各个组件生成独立的秘钥，一般要求每个服务器都不一样，与不同的主机绑定，这就给我们部署服务带来了挑战，特别是在当前微服务、云原生应用、容器、k8s比较流行的时候。</p>
<h3 id="通信过程演示"><a class="markdownIt-Anchor" href="#通信过程演示"></a> 通信过程演示</h3>
<p>为了更清晰的看到整个通信的过程，我们可以动手实践一下看看：</p>
<p>运行下面的命令进入一个<code>centos</code>的容器：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -it centos:7 -p1800:1800 -p1802:1802 bash</span><br></pre></td></tr></table></figure>
<p>然后安装配置kdc并生成相关的秘钥：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将kdc kdc.hadoop.com加入hosts，以便后续进行基于hosts文件的主机名解析</span></span><br><span class="line">yum install net-tools -y</span><br><span class="line">ip_addr=$(ifconfig eth0 | grep inet | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span>)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$ip_addr</span> kdc-server kdc-server.hadoop.com&quot;</span> &gt;&gt; /etc/hosts</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装相关软件并进行配置</span></span><br><span class="line">yum install krb5-server krb5-libs krb5-workstation -y</span><br><span class="line"><span class="comment"># 创建krb5配置文件，详细配置解释请参考：https://web.mit.edu/kerberos/krb5-1.12/doc/admin/conf_files/krb5_conf.html</span></span><br><span class="line"><span class="built_in">cat</span> &gt; /etc/krb5.conf &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">#Configuration snippets may be placed in this directory as well</span></span><br><span class="line"><span class="string">includedir /etc/krb5.conf.d/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[logging]</span></span><br><span class="line"><span class="string">  default = FILE:/var/log/krb5.log</span></span><br><span class="line"><span class="string">  kdc = FILE:/var/log/krb5kdc.log</span></span><br><span class="line"><span class="string">  admin_server = FILE:/var/log/kadmind.log</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[libdefaults]</span></span><br><span class="line"><span class="string">  forcetcp = true</span></span><br><span class="line"><span class="string">  default_realm = HADOOP.COM</span></span><br><span class="line"><span class="string">  dns_lookup_realm = false</span></span><br><span class="line"><span class="string">  dns_lookup_kdc = false</span></span><br><span class="line"><span class="string">  ticket_lifetime = 24h</span></span><br><span class="line"><span class="string">  renew_lifetime = 7d</span></span><br><span class="line"><span class="string">  forwardable = true</span></span><br><span class="line"><span class="string">  udp_preference_limit = 1</span></span><br><span class="line"><span class="string">  default_tkt_enctypes = des-cbc-md5 des-cbc-crc des3-cbc-sha1</span></span><br><span class="line"><span class="string">  default_tgs_enctypes = des-cbc-md5 des-cbc-crc des3-cbc-sha1</span></span><br><span class="line"><span class="string">  permitted_enctypes = des-cbc-md5 des-cbc-crc des3-cbc-sha1</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[realms]</span></span><br><span class="line"><span class="string">  HADOOP.COM = &#123;</span></span><br><span class="line"><span class="string">    kdc = kdc-server.hadoop.com:2802</span></span><br><span class="line"><span class="string">    admin_server = kdc-server.hadoop.com:2801</span></span><br><span class="line"><span class="string">    default_domain = hadoop.com</span></span><br><span class="line"><span class="string">  &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[domain_realm]</span></span><br><span class="line"><span class="string">  .hadoop.com = HADOOP.COM</span></span><br><span class="line"><span class="string">  hadoop.com = HADOOP.COM</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="comment"># 创建kdc配置文件，详细配置解释请参考：https://web.mit.edu/kerberos/krb5-1.12/doc/admin/conf_files/kdc_conf.html</span></span><br><span class="line"><span class="built_in">cat</span> &gt; /var/kerberos/krb5kdc/kdc.conf &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">default_realm = HADOOP.COM</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[kdcdefaults]</span></span><br><span class="line"><span class="string"> kdc_ports = 0</span></span><br><span class="line"><span class="string"> v4_mode = nopreauth</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[realms]</span></span><br><span class="line"><span class="string"> HADOOP.COM = &#123;</span></span><br><span class="line"><span class="string">    kdc_ports = 2800</span></span><br><span class="line"><span class="string">    kdc_tcp_ports = 2802</span></span><br><span class="line"><span class="string">    admin_keytab = /etc/kadm5.keytab</span></span><br><span class="line"><span class="string">    database_name = /var/kerberos/krb5kdc/principal</span></span><br><span class="line"><span class="string">    acl_file = /var/kerberos/krb5kdc/kadm5.acl</span></span><br><span class="line"><span class="string">    key_stash_file = /var/kerberos/krb5kdc/stash</span></span><br><span class="line"><span class="string">    max_life = 10h 0m 0s</span></span><br><span class="line"><span class="string">    max_renewable_life = 7d 0h 0m 0s</span></span><br><span class="line"><span class="string">    master_key_type = des3-hmac-sha1</span></span><br><span class="line"><span class="string">    supported_enctypes = arcfour-hmac:normal des3-hmac-sha1:normal des-cbc-crc:normal des:normal des:v4 des:norealm des:onlyrealm des:afs3</span></span><br><span class="line"><span class="string">    default_principal_flags = +preauth</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&#x27;123456\n123456&#x27;</span> | kdb5_util create -r HADOOP.COM -s  <span class="comment"># 创建一个名为HADOOP.COM的域</span></span><br><span class="line">/usr/sbin/krb5kdc &amp;&amp; /usr/sbin/kadmind                        <span class="comment"># 启动kdc及kadmind服务</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&#x27;123456\n123456&#x27;</span> | kadmin.local addprinc gml    <span class="comment"># 创建gml账号</span></span><br><span class="line">kadmin.local xst -k gml.keytab gml@HADOOP.COM           <span class="comment"># 生成gml账号的keytab文件</span></span><br><span class="line"></span><br><span class="line">kadmin.local addprinc -randkey root/localhost@HADOOP.COM       <span class="comment"># 创建名为root并和kdc主机进行绑定的服务账号</span></span><br><span class="line">kadmin.local xst -k server.keytab root/localhost@HADOOP.COM    <span class="comment"># 创建用于服务器的keytab文件</span></span><br></pre></td></tr></table></figure>
<p>将生成的keytab文件下载到本地，然后就可以进行测试了。编写测试的客户端和服务端代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.ietf.jgss.GSSContext;</span><br><span class="line"><span class="keyword">import</span> org.ietf.jgss.GSSCredential;</span><br><span class="line"><span class="keyword">import</span> org.ietf.jgss.GSSException;</span><br><span class="line"><span class="keyword">import</span> org.ietf.jgss.GSSManager;</span><br><span class="line"><span class="keyword">import</span> org.ietf.jgss.Oid;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.DataInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.DataOutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.ServerSocket;</span><br><span class="line"><span class="keyword">import</span> java.net.Socket;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Test</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">TestClient</span> &#123;</span><br><span class="line">        <span class="keyword">private</span> String srvPrincal;</span><br><span class="line">        <span class="keyword">private</span> String srvIP;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">int</span> srvPort;</span><br><span class="line">        <span class="keyword">private</span> Socket socket;</span><br><span class="line">        <span class="keyword">private</span> DataInputStream inStream;</span><br><span class="line">        <span class="keyword">private</span> DataOutputStream outStream;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">TestClient</span><span class="params">(String srvPrincal, String srvIp, <span class="type">int</span> srvPort)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">            <span class="built_in">this</span>.srvPrincal = srvPrincal;</span><br><span class="line">            <span class="built_in">this</span>.srvIP = srvIp;</span><br><span class="line">            <span class="built_in">this</span>.srvPort = srvPort;</span><br><span class="line">            <span class="built_in">this</span>.initSocket();</span><br><span class="line">            <span class="built_in">this</span>.initKerberos();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">initSocket</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">            <span class="built_in">this</span>.socket = <span class="keyword">new</span> <span class="title class_">Socket</span>(srvIP, srvPort);</span><br><span class="line">            <span class="built_in">this</span>.inStream = <span class="keyword">new</span> <span class="title class_">DataInputStream</span>(socket.getInputStream());</span><br><span class="line">            <span class="built_in">this</span>.outStream = <span class="keyword">new</span> <span class="title class_">DataOutputStream</span>(socket.getOutputStream());</span><br><span class="line">            System.out.println(<span class="string">&quot;Connected to server: &quot;</span> + <span class="built_in">this</span>.socket.getInetAddress());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">initKerberos</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">            System.setProperty(<span class="string">&quot;java.security.krb5.conf&quot;</span>, <span class="string">&quot;experiment/src/main/krb5.conf&quot;</span>);</span><br><span class="line">            System.setProperty(<span class="string">&quot;java.security.auth.login.config&quot;</span>, <span class="string">&quot;experiment/src/main/client.conf&quot;</span>);</span><br><span class="line">            System.setProperty(<span class="string">&quot;javax.security.auth.useSubjectCredsOnly&quot;</span>, <span class="string">&quot;false&quot;</span>);</span><br><span class="line">            System.setProperty(<span class="string">&quot;sun.security.krb5.debug&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line"></span><br><span class="line">            System.out.println(<span class="string">&quot;init kerberos: set up objects as configured&quot;</span>);</span><br><span class="line">            <span class="type">GSSManager</span> <span class="variable">manager</span> <span class="operator">=</span> GSSManager.getInstance();</span><br><span class="line">            <span class="type">Oid</span> <span class="variable">krb5Oid</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Oid</span>(<span class="string">&quot;1.2.840.113554.1.2.2&quot;</span>);</span><br><span class="line">            <span class="type">GSSContext</span> <span class="variable">context</span> <span class="operator">=</span> manager.createContext(</span><br><span class="line">                    manager.createName(srvPrincal, <span class="literal">null</span>),</span><br><span class="line">                    krb5Oid, <span class="literal">null</span>, GSSContext.DEFAULT_LIFETIME);</span><br><span class="line">            context.requestMutualAuth(<span class="literal">true</span>);</span><br><span class="line">            context.requestConf(<span class="literal">true</span>);</span><br><span class="line">            context.requestInteg(<span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">            System.out.println(<span class="string">&quot;init kerberos: Do the context establishment loop&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="type">byte</span>[] token = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span> (!context.isEstablished()) &#123;</span><br><span class="line">                <span class="comment">// token is ignored on the first call</span></span><br><span class="line">                token = context.initSecContext(token, <span class="number">0</span>, token.length);</span><br><span class="line"></span><br><span class="line">                <span class="comment">// Send a token to the server if one was generated by initSecContext</span></span><br><span class="line">                <span class="keyword">if</span> (token != <span class="literal">null</span>) &#123;</span><br><span class="line">                    System.out.println(<span class="string">&quot;Will send token of size &quot;</span> + token.length + <span class="string">&quot; from initSecContext.&quot;</span>);</span><br><span class="line">                    outStream.writeInt(token.length);</span><br><span class="line">                    outStream.write(token);</span><br><span class="line">                    outStream.flush();</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// If the client is done with context establishment then there will be no more tokens to read in this loop</span></span><br><span class="line">                <span class="keyword">if</span> (!context.isEstablished()) &#123;</span><br><span class="line">                    token = <span class="keyword">new</span> <span class="title class_">byte</span>[inStream.readInt()];</span><br><span class="line">                    System.out.println(</span><br><span class="line">                            <span class="string">&quot;Will read input token of size &quot;</span> + token.length + <span class="string">&quot; for processing by initSecContext&quot;</span>);</span><br><span class="line">                    inStream.readFully(token);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            System.out.println(<span class="string">&quot;Context Established! &quot;</span>);</span><br><span class="line">            System.out.println(<span class="string">&quot;Client is &quot;</span> + context.getSrcName());</span><br><span class="line">            System.out.println(<span class="string">&quot;Server is &quot;</span> + context.getTargName());</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sendMessage</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">            <span class="comment">// Obtain the command-line arguments and parse the port number</span></span><br><span class="line"></span><br><span class="line">            <span class="type">String</span> <span class="variable">msg</span> <span class="operator">=</span> <span class="string">&quot;Hello Server &quot;</span>;</span><br><span class="line">            <span class="type">byte</span>[] messageBytes = msg.getBytes();</span><br><span class="line">            outStream.writeInt(messageBytes.length);</span><br><span class="line">            outStream.write(messageBytes);</span><br><span class="line">            outStream.flush();</span><br><span class="line"></span><br><span class="line">            <span class="type">byte</span>[] token = <span class="keyword">new</span> <span class="title class_">byte</span>[inStream.readInt()];</span><br><span class="line">            System.out.println(<span class="string">&quot;Will read token of size &quot;</span> + token.length);</span><br><span class="line">            inStream.readFully(token);</span><br><span class="line"></span><br><span class="line">            <span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(token);</span><br><span class="line">            System.out.println(s);</span><br><span class="line"></span><br><span class="line">            System.out.println(<span class="string">&quot;Exiting... &quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">            <span class="type">TestClient</span> <span class="variable">client</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TestClient</span>(<span class="string">&quot;root/localhost@HADOOP.COM&quot;</span>, <span class="string">&quot;localhost&quot;</span>, <span class="number">9111</span>);</span><br><span class="line">            client.sendMessage();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">TestServer</span> &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">int</span> localPort;</span><br><span class="line">        <span class="keyword">private</span> ServerSocket ss;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">Socket</span> <span class="variable">socket</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">TestServer</span><span class="params">(<span class="type">int</span> port)</span> &#123;</span><br><span class="line">            <span class="built_in">this</span>.localPort = port;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">receive</span><span class="params">()</span> <span class="keyword">throws</span> IOException, GSSException &#123;</span><br><span class="line">            <span class="built_in">this</span>.ss = <span class="keyword">new</span> <span class="title class_">ServerSocket</span>(localPort);</span><br><span class="line">            socket = ss.accept();</span><br><span class="line">            <span class="type">DataInputStream</span> <span class="variable">in</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DataInputStream</span>(socket.getInputStream());</span><br><span class="line">            <span class="type">DataOutputStream</span> <span class="variable">out</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DataOutputStream</span>(socket.getOutputStream());</span><br><span class="line">            <span class="built_in">this</span>.initKerberos(in, out);</span><br><span class="line"></span><br><span class="line">            <span class="type">int</span> <span class="variable">length</span> <span class="operator">=</span> in.readInt();</span><br><span class="line">            <span class="type">byte</span>[] token = <span class="keyword">new</span> <span class="title class_">byte</span>[length];</span><br><span class="line">            System.out.println(<span class="string">&quot;Will read token of size &quot;</span> + token.length);</span><br><span class="line">            in.readFully(token);</span><br><span class="line">            <span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(token);</span><br><span class="line">            System.out.println(<span class="string">&quot;Receive Client token: &quot;</span> + s);</span><br><span class="line"></span><br><span class="line">            <span class="type">byte</span>[] token1 = <span class="string">&quot;Receive Client Message&quot;</span>.getBytes();</span><br><span class="line">            out.writeInt(token1.length);</span><br><span class="line">            out.write(token1);</span><br><span class="line">            out.flush();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">initKerberos</span><span class="params">(DataInputStream in, DataOutputStream out)</span> <span class="keyword">throws</span> GSSException, IOException &#123;</span><br><span class="line">            <span class="type">GSSManager</span> <span class="variable">manager</span> <span class="operator">=</span> GSSManager.getInstance();</span><br><span class="line">            <span class="type">GSSContext</span> <span class="variable">context</span> <span class="operator">=</span> manager.createContext((GSSCredential) <span class="literal">null</span>);</span><br><span class="line">            <span class="type">byte</span>[] token;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span> (!context.isEstablished()) &#123;</span><br><span class="line">                token = <span class="keyword">new</span> <span class="title class_">byte</span>[in.readInt()];</span><br><span class="line">                System.out.println(<span class="string">&quot;Will read input token of size &quot;</span> + token.length + <span class="string">&quot; for processing by acceptSecContext&quot;</span>);</span><br><span class="line">                in.readFully(token);</span><br><span class="line"></span><br><span class="line">                token = context.acceptSecContext(token, <span class="number">0</span>, token.length);</span><br><span class="line"></span><br><span class="line">                <span class="comment">// Send a token to the peer if one was generated by acceptSecContext</span></span><br><span class="line">                <span class="keyword">if</span> (token != <span class="literal">null</span>) &#123;</span><br><span class="line">                    System.out.println(<span class="string">&quot;Will send token of size &quot;</span> + token.length + <span class="string">&quot; from acceptSecContext.&quot;</span>);</span><br><span class="line">                    out.writeInt(token.length);</span><br><span class="line">                    out.write(token);</span><br><span class="line">                    out.flush();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            System.out.println(<span class="string">&quot;Context Established! &quot;</span>);</span><br><span class="line">            System.out.println(<span class="string">&quot;Client is &quot;</span> + context.getSrcName());</span><br><span class="line">            System.out.println(<span class="string">&quot;Server is &quot;</span> + context.getTargName());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, GSSException &#123;</span><br><span class="line">            System.setProperty(<span class="string">&quot;java.security.krb5.conf&quot;</span>, <span class="string">&quot;experiment/src/main/krb5.conf&quot;</span>);</span><br><span class="line">            System.setProperty(<span class="string">&quot;java.security.auth.login.config&quot;</span>, <span class="string">&quot;experiment/src/main/server.conf&quot;</span>);</span><br><span class="line">            System.setProperty(<span class="string">&quot;javax.security.auth.useSubjectCredsOnly&quot;</span>, <span class="string">&quot;false&quot;</span>);</span><br><span class="line">            System.setProperty(<span class="string">&quot;sun.security.krb5.debug&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="type">TestServer</span> <span class="variable">server</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TestServer</span>(<span class="number">9111</span>);</span><br><span class="line">            server.receive();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>先运行<code>Server</code>程序，再运行<code>Client</code>程序，我们将能从输出内容中看到整个通信的过程。</p>
<p>当前web应用成为主流的时候，<code>Kerberos</code>如何在<code>HTTP/HTTPS</code>协议场景下使用呢？我们又要如何配置，才能运行一套支持认证的Hadoop集群呢？请关注后续文章。</p>
<p>参考：</p>
<ul>
<li><a href="https://docs.oracle.com/en/java/javase/13/security/source-code-advanced-security-programming-java-se-authentication-secure-communication-and-single-sig.html">Java官方Demo</a></li>
<li><a href="https://zh.wikipedia.org/wiki/Kerberos">Wiki</a></li>
<li><a href="https://web.mit.edu/kerberos/krb5-1.12/doc/admin/conf_files/krb5_conf.html">krb5配置</a></li>
<li><a href="https://web.mit.edu/kerberos/krb5-1.12/doc/admin/conf_files/kdc_conf.html">kdc配置</a></li>
</ul>
]]></content>
      <categories>
        <category>数据</category>
        <category>大数据</category>
        <category>安全</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>安全</tag>
        <tag>hadoop</tag>
        <tag>kerberos</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop安全认证机制 （三）</title>
    <url>/2019/11/11/hadoop-auth-3/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>系列文章：</p>
<ul>
<li><a href="/2019/10/27/hadoop-auth/">Hadoop安全认证机制 (一)</a></li>
<li><a href="/2019/10/30/hadoop-auth-2/">Hadoop安全认证机制 (二)</a></li>
</ul>
<p>前面的文章中我们分析了Hadoop安全机制中用到的协议及相关源代码实现，这一篇文章我们主要来看看如何搭建一套安全的Hadoop集群。</p>
<p>简单起见，我们这里的集群所有的组件将运行在同一台机器上。对于keytab的配置，我们也从简，只配置一个kerberos的service账号供所有服务使用。</p>
<h2 id="建立测试用例"><a class="markdownIt-Anchor" href="#建立测试用例"></a> 建立测试用例</h2>
<p>TDD是敏捷最重要的实践之一，可以有效的帮助我们确定目标，验证目标，它可以带领我们走得又快又稳。跟随TDD的思想，我们先从测试的角度来看这个问题。有了前面的基础知识，假设我们已经有了一套安全的Hadoop集群，那么我们应当可以从集群读写文件，运行MapReduce任务。我们可以编写读写文件的测试用例如下：</p>
<span id="more"></span>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HdfsTest</span> &#123;</span><br><span class="line">    <span class="type">TestConfig</span> <span class="variable">testConfig</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TestConfig</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">should_read_write_files_from_hdfs</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        testConfig.configKerberos();</span><br><span class="line"></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        conf.addResource(<span class="keyword">new</span> <span class="title class_">Path</span>(testConfig.hdfsSiteFilePath()));</span><br><span class="line">        conf.addResource(<span class="keyword">new</span> <span class="title class_">Path</span>(testConfig.coreSiteFilePath()));</span><br><span class="line">        UserGroupInformation.setConfiguration(conf);</span><br><span class="line">        UserGroupInformation.loginUserFromKeytab(testConfig.keytabUser(), testConfig.keytabFilePath());</span><br><span class="line"></span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fileSystem</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line">        <span class="type">Path</span> <span class="variable">path</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/user/root/input/core-site.xml&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (fileSystem.exists(path)) &#123;</span><br><span class="line">            <span class="type">boolean</span> <span class="variable">deleteSuccess</span> <span class="operator">=</span> fileSystem.delete(path, <span class="literal">false</span>);</span><br><span class="line">            assertTrue(deleteSuccess);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">fileContent</span> <span class="operator">=</span> FileUtils.readFileToString(<span class="keyword">new</span> <span class="title class_">File</span>(testConfig.coreSiteFilePath()));</span><br><span class="line">        <span class="keyword">try</span> (<span class="type">FSDataOutputStream</span> <span class="variable">fileOut</span> <span class="operator">=</span> fileSystem.create(path)) &#123;</span><br><span class="line">            fileOut.write(fileContent.getBytes(<span class="string">&quot;utf-8&quot;</span>));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        assertTrue(fileSystem.exists(path));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> (<span class="type">FSDataInputStream</span> <span class="variable">in</span> <span class="operator">=</span> fileSystem.open(path)) &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">fileContentRead</span> <span class="operator">=</span> IOUtils.toString(in);</span><br><span class="line">            assertEquals(fileContent, fileContentRead);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        fileSystem.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（完整代码请参考<a href="https://github.com/gmlove/bigdata_conf/blob/master/test/src/test/java/test/HdfsTest.java">这里</a>）</p>
<p>到这里我们的任务目标就明确了，只要上面的测试能通过，我们的集群就应该搭建好了。</p>
<p>（如果有条件，下面的内容请大家结合代码及参考文档，一边读文章，一边动手实践，否则可能会遗漏很多细节。）</p>
<h2 id="建立基本集群"><a class="markdownIt-Anchor" href="#建立基本集群"></a> 建立基本集群</h2>
<p>我们先跟随<a href="https://hadoop.apache.org/docs/r2.7.7/hadoop-project-dist/hadoop-common/SingleCluster.html">官网的教程</a>搭建一个非安全的集群。</p>
<p>这里我选择的Hadoop版本为2.7.7（我这里是为了和实际项目中用到的版本保持一致，大家可以自行尝试其他版本，思路和大部分的脚本都应该是相同的）。我们选择伪分布式模式（Pseudo-Distributed）来进行尝试，这种模式下，每个组件会运行为一个独立的java进程，与真实的分布式环境类似。</p>
<p>我们还是使用容器来进行试验，启动一个容器，并依次运行下面的命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -it --name shd -h shd centos:7 bash</span><br></pre></td></tr></table></figure>
<p>在容器中运行下面的命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 建立并切换到我们的工作目录</span></span><br><span class="line"><span class="built_in">mkdir</span> /hd &amp;&amp; <span class="built_in">cd</span> /hd</span><br><span class="line"><span class="comment"># 下载软件、解压、进入根目录</span></span><br><span class="line">yum install wget vim less -y</span><br><span class="line">wget https://archive.apache.org/dist/hadoop/common/hadoop-2.7.7/hadoop-2.7.7.tar.gz</span><br><span class="line">tar xf hadoop-2.7.7.tar.gz</span><br><span class="line"><span class="built_in">ln</span> -sv hadoop-2.7.7/ hadoop</span><br><span class="line"><span class="built_in">cd</span> hadoop</span><br><span class="line"><span class="comment"># 配置hadoop</span></span><br><span class="line"><span class="built_in">echo</span> shd &gt; etc/hadoop/slaves</span><br><span class="line"><span class="built_in">cat</span> &gt; etc/hadoop/core-site.xml &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;hdfs://0.0.0.0:9000&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;/configuration&gt;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="built_in">cat</span> &gt; etc/hadoop/hdfs-site.xml &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.replication&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;1&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;/hd/data/hdfs/namenode&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;/hd/data/hdfs/datanode&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;/configuration&gt;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="comment"># 配置ssh，测试：是否能通过`ssh localhost`免密登录</span></span><br><span class="line">yum install openssh-clients openssh-server -y</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;root:screencast&#x27;</span> | chpasswd</span><br><span class="line">sed -i <span class="string">&#x27;s/PermitRootLogin prohibit-password/PermitRootLogin yes/&#x27;</span> /etc/ssh/sshd_config</span><br><span class="line">sed <span class="string">&#x27;s@session\s*required\s*pam_loginuid.so@session optional pam_loginuid.so@g&#x27;</span> -i /etc/pam.d/sshd</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;export VISIBLE=now&quot;</span> &gt;&gt; /etc/profile</span><br><span class="line">ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key -P <span class="string">&#x27;&#x27;</span> &amp;&amp; ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key -P <span class="string">&#x27;&#x27;</span></span><br><span class="line">/usr/sbin/sshd</span><br><span class="line">ssh-keygen -t rsa -P <span class="string">&#x27;&#x27;</span> -f ~/.ssh/id_rsa</span><br><span class="line"><span class="built_in">cat</span> ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line"><span class="built_in">chmod</span> 0600 ~/.ssh/authorized_keys</span><br><span class="line"><span class="comment"># 安装jdk,并配置环境变量</span></span><br><span class="line">yum install -y java-1.8.0-openjdk-devel</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;export JAVA_HOME=/usr/lib/jvm/java&#x27;</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/java</span><br><span class="line"><span class="comment"># 启动hdfs</span></span><br><span class="line">bin/hdfs namenode -format</span><br><span class="line">sbin/start-dfs.sh</span><br><span class="line"><span class="comment"># 测试</span></span><br><span class="line">bin/hdfs dfs -<span class="built_in">mkdir</span> /user</span><br><span class="line">bin/hdfs dfs -<span class="built_in">mkdir</span> /user/root</span><br><span class="line">bin/hdfs dfs -put etc/hadoop input</span><br><span class="line">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar grep input output <span class="string">&#x27;dfs[a-z.]+&#x27;</span></span><br><span class="line">bin/hdfs dfs -<span class="built_in">cat</span> output/*  <span class="comment"># 这里的结果将显示配置文件里面关于dfs的内容</span></span><br></pre></td></tr></table></figure>
<p>到这里我们的非安全的单机模式集群应该就能运行起来了。但是在这个集群里面我们还没法运行分布式任务，因为目前仅仅是一个HDFS分布式文件系统。如果用<code>jps</code>查看一下有哪些java进程，将发现我们启动了三个进程<code>NameNode</code> <code>SecondaryNameNode</code> <code>DataNode</code>。</p>
<p>下一步，我们还需要配置并启动用于管理分布式集群任务的关键组件<code>Yarn</code>。运行如下这些命令，即可启动<code>Yarn</code>：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 配置Yarn</span></span><br><span class="line"><span class="built_in">cat</span> &gt; etc/hadoop/mapred-site.xml &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;yarn&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;0.0.0.0:10020&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;0.0.0.0:19888&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;/configuration&gt;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="built_in">cat</span> &gt; etc/hadoop/yarn-site.xml &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;true&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;!-- fix node unhealthy issue --&gt;</span></span><br><span class="line"><span class="string">    &lt;!-- `yarn node -list -all` report node unhealthy with message indicate no disk space (disk space check failed) --&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">        &lt;name&gt;yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage&lt;/name&gt;</span></span><br><span class="line"><span class="string">        &lt;value&gt;99.9&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">    &lt;!-- to fix issue: &#x27;Failed while trying to construct...&#x27; (http://blog.51yip.com/hadoop/2066.html) --&gt;</span></span><br><span class="line"><span class="string">    &lt;property&gt;</span></span><br><span class="line"><span class="string">         &lt;name&gt;yarn.log.server.url&lt;/name&gt;</span></span><br><span class="line"><span class="string">         &lt;value&gt;http://shd:19888/jobhistory/logs&lt;/value&gt;</span></span><br><span class="line"><span class="string">    &lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;/configuration&gt;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="comment"># 启动Yarn：启动之后我们将能通过`./bin/yarn node -list -all`查看到一个RUNNIN的node</span></span><br><span class="line">sbin/start-yarn.sh</span><br><span class="line"><span class="comment"># 启动History server用于查看应用日志</span></span><br><span class="line">sbin/mr-jobhistory-daemon.sh start historyserver</span><br><span class="line"><span class="comment"># 测试：我们将能看到下面的命令从0%到100%按进度完成。</span></span><br><span class="line"><span class="comment"># 验证：运行`./bin/hadoop dfs -cat output/wc/part-r-00000`还将看到计算出来的结果。</span></span><br><span class="line"><span class="comment"># 验证：运行`./bin/yarn application -list -appStates FINISHED`可以看到已运行完成的任务，及其日志的地址。</span></span><br><span class="line">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar  wordcount input/* output/wc/</span><br></pre></td></tr></table></figure>
<p>执行上面的命令启动<code>Yarn</code>及<code>historyserver</code>之后，我们将发现有三个额外的进程<code>ResourceManager</code> <code>NodeManager</code> <code>JobHistoryServer</code>随之启动了。</p>
<p>如果我们的容器所在主机有一个浏览器可以用，那么我们可以通过访问<code>http://$&#123;SHD_DOCKER_IP&#125;:8088/cluster/apps</code>将能看到上面的<code>wordcount</code>程序运行的状态及日志。这里的<code>SHD_DOCKER_IP</code>可以通过下面的命令查找出来。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker inspect -f &#x27;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&#x27; shd</span><br></pre></td></tr></table></figure>
<p>如果容器是在一个远端的主机上面启动的，我们可以用<code>ssh tunnel</code>的方式建立一个代理，通过代理来访问我们的集群。运行命令<code>ssh -f -N -D 127.0.0.1:3128 $&#123;USER&#125;@$&#123;REMOTE_DOCKER_HOST_IP&#125;</code>即可建立这样的代理。然后我们运行<code>echo &quot;$&#123;SHD_DOCKER_IP&#125; shd&quot; &gt;&gt; /etc/hosts</code>将容器的主机名加入到我们本地的<code>hosts</code>。再使用<code>firefox</code>浏览器来配置代理（如下图），这样我们就可以通过本地的<code>firefox</code>来访问到远端的集群了。</p>
<p><img data-src="/attaches/2019/2019-11-11-hadoop-auth-3/firefox-ssh-tunnel-proxy.png" alt="Firefox Proxy" /></p>
<p>我们将能看到如下的web应用，通过这个web应用，我们实际上还可以查询到更多的集群相关的信息。</p>
<p><img data-src="/attaches/2019/2019-11-11-hadoop-auth-3/app-log.png" alt="App Log" /></p>
<p>可以看到，经过多年的优化，即便是一个非常复杂的分布式系统，我们现在也可以快速的上手了。几乎所有的配置都有相对合理的默认值，我们仅仅需要调整很少的配置。</p>
<p>Hadoop本身内置了很多实用的工具，当我们遇到问题的时候，这些工具可以有效的辅助诊断问题。如果大家经过上面的步骤还是没法通过测试（命令行中的测试）。大家可能可以从以下几个方面去查找问题：</p>
<ol>
<li>检查各个组件进程是否都启动起来了</li>
<li>检查各个组件的日志，比如，如果<code>datanode</code>启动失败，可能我们要查看<code>logs/hadoop-root-datanode-shd.log</code>日志做进一步分析</li>
<li>使用<code>bin/yarn node -list -all</code>检查<code>node</code>的状态</li>
<li>检查最终生成的配置<code>http://172.17.0.12:8042/conf</code>是否是我们所希望的，比如我们可能由于拼写错误导致配置不对</li>
</ol>
<h2 id="kerberos安全配置"><a class="markdownIt-Anchor" href="#kerberos安全配置"></a> Kerberos安全配置</h2>
<p>在本系列<a href="/2019/10/27/hadoop-auth/">第一篇文章</a>中，我们尝试了搭建一个kerberos认证服务器，这里我们可以用与之前一致的方式先搭建起一个kerberos认证服务器。需要的执行脚本如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将kdc kdc.hadoop.com加入hosts，以便后续进行基于hosts文件的主机名解析</span></span><br><span class="line">yum install net-tools -y</span><br><span class="line">ip_addr=$(ifconfig eth0 | grep inet | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span>)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$ip_addr</span> kdc-server kdc-server.hadoop.com&quot;</span> &gt;&gt; /etc/hosts</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装相关软件并进行配置</span></span><br><span class="line">yum install krb5-server krb5-libs krb5-workstation -y</span><br><span class="line"><span class="comment"># 创建krb5配置文件，详细配置解释请参考：https://web.mit.edu/kerberos/krb5-1.12/doc/admin/conf_files/krb5_conf.html</span></span><br><span class="line"><span class="built_in">cat</span> &gt; /etc/krb5.conf &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">#Configuration snippets may be placed in this directory as well</span></span><br><span class="line"><span class="string">includedir /etc/krb5.conf.d/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[logging]</span></span><br><span class="line"><span class="string">  default = FILE:/var/log/krb5.log</span></span><br><span class="line"><span class="string">  kdc = FILE:/var/log/krb5kdc.log</span></span><br><span class="line"><span class="string">  admin_server = FILE:/var/log/kadmind.log</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[libdefaults]</span></span><br><span class="line"><span class="string">  forcetcp = true</span></span><br><span class="line"><span class="string">  default_realm = HADOOP.COM</span></span><br><span class="line"><span class="string">  dns_lookup_realm = false</span></span><br><span class="line"><span class="string">  dns_lookup_kdc = false</span></span><br><span class="line"><span class="string">  ticket_lifetime = 24h</span></span><br><span class="line"><span class="string">  renew_lifetime = 7d</span></span><br><span class="line"><span class="string">  forwardable = true</span></span><br><span class="line"><span class="string">  udp_preference_limit = 1</span></span><br><span class="line"><span class="string">  default_tkt_enctypes = des-cbc-md5 des-cbc-crc des3-cbc-sha1</span></span><br><span class="line"><span class="string">  default_tgs_enctypes = des-cbc-md5 des-cbc-crc des3-cbc-sha1</span></span><br><span class="line"><span class="string">  permitted_enctypes = des-cbc-md5 des-cbc-crc des3-cbc-sha1</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[realms]</span></span><br><span class="line"><span class="string">  HADOOP.COM = &#123;</span></span><br><span class="line"><span class="string">    kdc = kdc-server.hadoop.com:2802</span></span><br><span class="line"><span class="string">    admin_server = kdc-server.hadoop.com:2801</span></span><br><span class="line"><span class="string">    default_domain = hadoop.com</span></span><br><span class="line"><span class="string">  &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[domain_realm]</span></span><br><span class="line"><span class="string">  .hadoop.com = HADOOP.COM</span></span><br><span class="line"><span class="string">  hadoop.com = HADOOP.COM</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="comment"># 创建kdc配置文件，详细配置解释请参考：https://web.mit.edu/kerberos/krb5-1.12/doc/admin/conf_files/kdc_conf.html</span></span><br><span class="line"><span class="built_in">cat</span> &gt; /var/kerberos/krb5kdc/kdc.conf &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">default_realm = HADOOP.COM</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[kdcdefaults]</span></span><br><span class="line"><span class="string"> kdc_ports = 0</span></span><br><span class="line"><span class="string"> v4_mode = nopreauth</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[realms]</span></span><br><span class="line"><span class="string"> HADOOP.COM = &#123;</span></span><br><span class="line"><span class="string">    kdc_ports = 2800</span></span><br><span class="line"><span class="string">    kdc_tcp_ports = 2802</span></span><br><span class="line"><span class="string">    admin_keytab = /etc/kadm5.keytab</span></span><br><span class="line"><span class="string">    database_name = /var/kerberos/krb5kdc/principal</span></span><br><span class="line"><span class="string">    acl_file = /var/kerberos/krb5kdc/kadm5.acl</span></span><br><span class="line"><span class="string">    key_stash_file = /var/kerberos/krb5kdc/stash</span></span><br><span class="line"><span class="string">    max_life = 10h 0m 0s</span></span><br><span class="line"><span class="string">    max_renewable_life = 7d 0h 0m 0s</span></span><br><span class="line"><span class="string">    master_key_type = des3-hmac-sha1</span></span><br><span class="line"><span class="string">    supported_enctypes = arcfour-hmac:normal des3-hmac-sha1:normal des-cbc-crc:normal des:normal des:v4 des:norealm des:onlyrealm des:afs3</span></span><br><span class="line"><span class="string">    default_principal_flags = +preauth</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&#x27;123456\n123456&#x27;</span> | kdb5_util create -r HADOOP.COM -s  <span class="comment"># 创建一个名为HADOOP.COM的域</span></span><br><span class="line">/usr/sbin/krb5kdc &amp;&amp; /usr/sbin/kadmind                        <span class="comment"># 启动kdc及kadmind服务</span></span><br></pre></td></tr></table></figure>
<h2 id="配置hadoop安全支持"><a class="markdownIt-Anchor" href="#配置hadoop安全支持"></a> 配置Hadoop安全支持</h2>
<p>前面我们分析了Kerberos的运行原理，及Hadoop的相关源代码，可以知道，为了启动安全支持，每一个集群节点的每一个hadoop组件都将需要单独的Kerberos账号及其keytab文件，每个组件最好还能用不同的账户启动。这里由于我们使用伪分布式模式来部署集群，所有的组件都运行在同一个节点，简单起见，我们这里将使用root账号来启动集群，并让所有的组件使用同一个kerberos账号。</p>
<p>首先我们生成账号如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /hd/conf/</span><br><span class="line"><span class="comment"># 生成hadoop集群需要的账号</span></span><br><span class="line">kadmin.local addprinc -randkey root/shd@HADOOP.COM</span><br><span class="line">kadmin.local addprinc -randkey HTTP/shd@HADOOP.COM</span><br><span class="line">kadmin.local xst -k /hd/conf/hadoop.keytab root/shd@HADOOP.COM HTTP/shd@HADOOP.COM</span><br><span class="line"><span class="comment"># 生成测试用的普通账号</span></span><br><span class="line">kadmin.local addprinc -randkey root@HADOOP.COM</span><br><span class="line">kadmin.local xst -k /hd/conf/root.keytab root@HADOOP.COM</span><br></pre></td></tr></table></figure>
<p>接下来我们来完成hadoop的配置，由于配置文件内容比较多，我统一整理到了github的一个repo中，下面的配置将主要通过copy这些文件来生成，而辅以说明主要修改的地方。如果大家有兴趣知道确切的修改之处，可以备份这些文件，然后用diff来查看修改，或者用git对配置文件进行版本管理，然后查看修改。</p>
<h3 id="配置集群"><a class="markdownIt-Anchor" href="#配置集群"></a> 配置集群</h3>
<h4 id="配置core-sitexml"><a class="markdownIt-Anchor" href="#配置core-sitexml"></a> 配置<code>core-site.xml</code></h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/gmlove/bigdata_conf/master/auth/hadoop/etc/hadoop/core-site.xml -O etc/hadoop/core-site.xml</span><br><span class="line">sed -i <span class="string">&#x27;s/hd01-7/shd/g&#x27;</span> etc/hadoop/core-site.xml</span><br></pre></td></tr></table></figure>
<p>这里主要加入的配置项及其解释如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hadoop.proxyuser.root.hosts=*           # 配置root用户（组件启动时认证的kerberos账户）可以以任意客户端认证过的用户（proxy user）来执行操作，详见：https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/Superusers.html</span><br><span class="line">hadoop.proxyuser.root.groups=*</span><br><span class="line">hadoop.proxyuser.HTTP.hosts=*</span><br><span class="line">hadoop.proxyuser.HTTP.groups=*</span><br><span class="line">hadoop.security.authorization=true</span><br><span class="line">hadoop.security.authentication=kerberos</span><br></pre></td></tr></table></figure>
<h4 id="配置hdfs-sitexml"><a class="markdownIt-Anchor" href="#配置hdfs-sitexml"></a> 配置<code>hdfs-site.xml</code></h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/gmlove/bigdata_conf/master/auth/hadoop/etc/hadoop/hdfs-site.xml -O etc/hadoop/hdfs-site.xml</span><br><span class="line">sed -i <span class="string">&#x27;s/hd01-7/shd/g&#x27;</span> etc/hadoop/hdfs-site.xml</span><br></pre></td></tr></table></figure>
<p>这里主要加入的配置项如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dfs.block.access.token.enable=true</span><br><span class="line">dfs.namenode.keytab.file=/hd/conf/hadoop.keytab</span><br><span class="line">dfs.namenode.kerberos.principal=root/_HOST@HADOOP.COM</span><br><span class="line">dfs.namenode.kerberos.internal.spnego.principal=HTTP/_HOST@HADOOP.COM</span><br><span class="line">dfs.web.authentication.kerberos.principal=HTTP/_HOST@HADOOP.COM</span><br><span class="line">dfs.web.authentication.kerberos.keytab=/hd/conf/hadoop.keytab</span><br><span class="line">dfs.datanode.keytab.file=/hd/conf/hadoop.keytab</span><br><span class="line">dfs.datanode.kerberos.principal=root/_HOST@HADOOP.COM</span><br><span class="line">dfs.datanode.address=0.0.0.0:1004</span><br><span class="line">dfs.datanode.http.address=0.0.0.0:1006</span><br><span class="line">dfs.journalnode.keytab.file=/hd/conf/hadoop.keytab</span><br><span class="line">dfs.journalnode.kerberos.principal=root/_HOST@HADOOP.COM</span><br><span class="line">dfs.journalnode.kerberos.internal.spnego.principal=HTTP/_HOST@HADOOP.COM</span><br></pre></td></tr></table></figure>
<h4 id="配置mapred-sitexml"><a class="markdownIt-Anchor" href="#配置mapred-sitexml"></a> 配置<code>mapred-site.xml</code></h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/gmlove/bigdata_conf/master/auth/hadoop/etc/hadoop/mapred-site.xml -O etc/hadoop/mapred-site.xml</span><br><span class="line">sed -i <span class="string">&#x27;s/hd01-7/shd/g&#x27;</span> etc/hadoop/mapred-site.xml</span><br></pre></td></tr></table></figure>
<p>这里主要加入的配置项如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mapreduce.jobhistory.address=shd:10020</span><br><span class="line">mapreduce.jobhistory.webapp.address=shd:19888</span><br><span class="line">mapreduce.jobhistory.principal=root/_HOST@HADOOP.COM</span><br><span class="line">mapreduce.jobhistory.keytab=/hd/conf/hadoop.keytab</span><br></pre></td></tr></table></figure>
<h4 id="配置yarn-sitexml"><a class="markdownIt-Anchor" href="#配置yarn-sitexml"></a> 配置<code>yarn-site.xml</code></h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/gmlove/bigdata_conf/master/auth/hadoop/etc/hadoop/yarn-site.xml -O etc/hadoop/yarn-site.xml</span><br><span class="line">sed -i <span class="string">&#x27;s/hd01-7/shd/g&#x27;</span> etc/hadoop/yarn-site.xml</span><br></pre></td></tr></table></figure>
<p>这里主要加入的配置项如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yarn.resourcemanager.principal=root/_HOST@HADOOP.COM</span><br><span class="line">yarn.resourcemanager.keytab=/hd/conf/hadoop.keytab</span><br><span class="line">yarn.resourcemanager.webapp.https.address=$&#123;yarn.resourcemanager.hostname&#125;:8090</span><br><span class="line">yarn.nodemanager.principal=root/_HOST@HADOOP.COM</span><br><span class="line">yarn.nodemanager.keytab=/hd/conf/hadoop.keytab</span><br><span class="line">yarn.web-proxy.principal=root/_HOST@HADOOP.COM</span><br><span class="line">yarn.web-proxy.keytab=/hd/conf/hadoop.keytab</span><br></pre></td></tr></table></figure>
<h4 id="配置hadoop-envsh"><a class="markdownIt-Anchor" href="#配置hadoop-envsh"></a> 配置<code>hadoop-env.sh</code></h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/gmlove/bigdata_conf/master/auth/hadoop/etc/hadoop/hadoop-env.sh -O etc/hadoop/hadoop-env.sh</span><br></pre></td></tr></table></figure>
<p>主要加入的配置项如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> JSVC_HOME=/usr/bin             <span class="comment"># 指定jsvc的路径，以便运行安全模式的datanode</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_JAAS_DEBUG=<span class="literal">true</span>         <span class="comment"># 开启Kerberos认证的debug日志</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_OPTS=<span class="string">&quot;-Djava.net.preferIPv4Stack=true -Dsun.security.krb5.debug=true -Dsun.security.spnego.debug&quot;</span>  <span class="comment"># 开启Kerberos认证的debug日志</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_SECURE_DN_USER=root     <span class="comment"># 运行安全模式的datanode组件的用户</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HDFS_USER=root          <span class="comment"># 运行hdfs组件的用户</span></span><br></pre></td></tr></table></figure>
<h4 id="修复启动脚本"><a class="markdownIt-Anchor" href="#修复启动脚本"></a> 修复启动脚本</h4>
<p>由于我们开启了<code>Kerberos</code>的调试日志，原来的脚本需要稍加修改才能使用。执行脚本如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/gmlove/bigdata_conf/master/auth/hadoop/sbin/stop-dfs.sh -O sbin/stop-dfs.sh</span><br><span class="line">wget https://raw.githubusercontent.com/gmlove/bigdata_conf/master/auth/hadoop/sbin/start-dfs.sh -O sbin/start-dfs.sh</span><br></pre></td></tr></table></figure>
<p>主要修改为将通过<code>hdfs getconf SOME_CONFIG</code>命令拿到的配置，修改为通过<code>hdfs getconf SOME_CONFIG &gt;/dev/null | tail -n 1</code>去获取配置。这里的<code>tail -n 1</code>可以去掉命令运行中的<code>Kerberos</code>调试日志。</p>
<h3 id="启动集群"><a class="markdownIt-Anchor" href="#启动集群"></a> 启动集群</h3>
<p>启动集群并运行测试如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y apache-commons-daemon-jsvc.x86_64     <span class="comment"># 安装jsvc以便可以用安全模式启动datanode，详见：https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SecureMode.html#Secure_DataNode</span></span><br><span class="line">sbin/start-dfs.sh &amp;&amp; ./sbin/start-secure-dns.sh &amp;&amp; sbin/start-yarn.sh &amp;&amp; sbin/mr-jobhistory-daemon.sh start historyserver     <span class="comment"># 依次启动集群的其他组件</span></span><br><span class="line"><span class="comment"># 测试：我们将能看到下面的命令从0%到100%按进度完成。</span></span><br><span class="line"><span class="comment"># 验证：运行`./bin/hadoop dfs -cat output/wc/part-r-00000`还将看到计算出来的结果。</span></span><br><span class="line"><span class="comment"># 验证：运行`./bin/yarn application -list -appStates FINISHED`可以看到已运行完成的任务，及其日志的地址。</span></span><br><span class="line">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar  wordcount input/* output/wc/</span><br></pre></td></tr></table></figure>
<p>如果我们无需再测试了，可以用以下命令停止集群：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sbin/stop-dfs.sh &amp;&amp; ./sbin/stop-secure-dns.sh &amp;&amp; sbin/stop-yarn.sh &amp;&amp; sbin/mr-jobhistory-daemon.sh stop historyserver</span><br></pre></td></tr></table></figure>
<h3 id="运行最初定义的测试"><a class="markdownIt-Anchor" href="#运行最初定义的测试"></a> 运行最初定义的测试</h3>
<p>执行命令如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 加入相关的hosts</span></span><br><span class="line">SHD_DOCKER_IP=$(docker inspect -f <span class="string">&#x27;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&#x27;</span> shd)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$&#123;SHD_DOCKER_IP&#125;</span> shd kdc-server kdc-server.hadoop.com&quot;</span> &gt;&gt; /etc/hosts</span><br><span class="line"><span class="comment"># 下载源代码</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/gmlove/bigdata_conf.git</span><br><span class="line"><span class="comment"># 更新配置文件</span></span><br><span class="line"><span class="built_in">cd</span> bigdata_conf</span><br><span class="line"><span class="built_in">cd</span> <span class="built_in">test</span>/src/test &amp;&amp; <span class="built_in">mv</span> resources resources.1</span><br><span class="line">docker <span class="built_in">cp</span> shd:/hd/hadoop/etc/hadoop/hdfs-site.xml ./resources/</span><br><span class="line">docker <span class="built_in">cp</span> shd:/hd/hadoop/etc/hadoop/core-site.xml ./resources/</span><br><span class="line">docker <span class="built_in">cp</span> shd:/hd/hadoop/etc/hadoop/yarn-site.xml ./resources/</span><br><span class="line">docker <span class="built_in">cp</span> shd:/etc/krb5.conf ./resources/</span><br><span class="line">docker <span class="built_in">cp</span> shd:/hd/conf/root.keytab ./resources/</span><br><span class="line"><span class="built_in">cp</span> ./resources.1/log4j.properties ./resources/</span><br><span class="line"><span class="comment"># 运行测试</span></span><br><span class="line">mvn -Dtest=test.HdfsTest <span class="built_in">test</span></span><br></pre></td></tr></table></figure>
<p>运行上面的命令，我们将能看到测试成功执行。</p>
<h3 id="如果容器在一个远端的主机上启动"><a class="markdownIt-Anchor" href="#如果容器在一个远端的主机上启动"></a> 如果容器在一个远端的主机上启动</h3>
<p>如果容器是在一个远端的主机上面启动的，我们还是可以通过<code>ssh tunnel</code>的方式将远端的端口映射到本地来执行此测试。不过，我们需要对前面步骤中的内容作出一些修改。主要的修改是将涉及到的<code>hostname</code>配置从<code>shd</code>改为<code>localhost</code>。这是由于在做端口映射之后，所有的服务均会通过<code>localhost</code>来访问，如果我们还是用<code>shd</code>，则集群在进行<code>Kerberos</code>认证时，主机名验证会出错。</p>
<p>这个任务还是挺有意思的，可以有效的检验我们对于网络、Hadoop集群、<code>Kerberos</code>认证机制等的理解。有兴趣的小伙伴可以尝试实验一下，本文就不赘述了。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>搭建一套安全的hadoop集群，确实不容易，即使我们只是一个伪分布式环境，还做了各种配置简化，也需要花费一番功夫，更别提真正在生产环境中搭建一套集群了。如果是生产可用，我们可能还需要关心机架、集群网络情况、稳定性、性能、跨地域高可用、不停机升级等等一系列的问题。在实际企业应用中，这些大数据基础设施运维实际上是一个比较复杂的工作，这些工作更可能是由一个单独的运维团队去完成的。这里我们所完成的例子的主要价值不在于生产可用，而在于它可以帮助我们理解hadoop集群的安全机制，以便指导我们日常的开发工作。另一个价值是，这里的例子实际上完全可以作为我们平时测试用的一套小集群，简单而又功能完整，我们完全可以将这里完成的工作制作为一个docker镜像（后续文章将尝试制作此镜像），随时启动这样一套集群，这对于我们测试一些集群集成问题时将带来很大的便利。</p>
<p>大家如果有自己实践，相信在这个过程中可能还会碰到其他的问题，欢迎留言交流，一起学习。</p>
<p>在这篇文章里，我们搭建了一个安全的hadoop集群，那么大数据相关的其他组件应该要如何安全的和hadoop集群进行整合呢？下一篇文章我们将选取几个典型的组件来分析并进行实践，欢迎持续关注。</p>
<h2 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h2>
<ul>
<li>Hadoop官方文档<code>Secure Mode</code>：<a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SecureMode.html">https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SecureMode.html</a></li>
<li>Hadoop官方文档<code>Proxy User</code>：<a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/Superusers.html">https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/Superusers.html</a></li>
</ul>
]]></content>
      <categories>
        <category>数据</category>
        <category>大数据</category>
        <category>安全</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>安全</tag>
        <tag>hadoop</tag>
        <tag>kerberos</tag>
      </tags>
  </entry>
  <entry>
    <title>技术人员的耐心和包容心</title>
    <url>/2019/09/05/programmers-tolerance/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>有一个技术人员都知道的很老的段子。如果我们想将一个技术论坛搞火起来，那么我们只需要发一篇帖子“php是世界上最好的语言”。虽然是很老的段子，但是就算现在我也常常能听到有人谈论它。很有意思的一个段子。</p>
<p>不仅仅是在论坛中，在我们日常的团队合作中，其实也常常有这样的事情。回忆一下我的 Code Review 活动，是不是常常有某一行代码引起了大家的广泛讨论，把整个会议给“搞火”了？大家可能就一个问题讨论很久，争执不下。</p>
<p>对于这样的讨论，如果大家能心平气和，互相理解，可能能较快的达成一致。但是事实上常常会出现这样的情况，双方争论很久争执不下，后来可能有人说，“这你都不知道啊”，或者“这我理解不了，你这里明显有问题”，或者“你说的都好，我用我的方式”，或者“你这里就明显是在<code>#define true=false</code>”等等。在这样的讨论中，我们比较容易情绪化（可能没有情绪化这么严重，但是这里姑且先用这个词），最后本来应该心平气和的讨论演变成了针对某个个人的互怼，或者直接拒绝交流。一旦情况变成这样，那么不仅讨论效率会大大下降，而且常常在相互心中产生芥蒂，影响后面的高效合作。</p>
<span id="more"></span>
<p>情绪化不是一个成熟的职场人员所应有的处事方式，但在我们技术人员中间却可能更容易的出现。因为大家逻辑思维都很好，思维也都很敏捷，追求高效率，相对更缺乏耐心。如果大家还能回忆得起来，《社交网络》中的扎克伯格的形象可能是一个典型的高效技术人员的形象，说话滔滔不绝，做事雷厉风行。我发现身边的技术人员多多少少都具有点这样的特质。我自己反思下来，也常常能发现自己有不够耐心的时候。比如某次在和他人交流的时候，对方话还没说完，我就着急开始讲话，然后对方不得已也跟着着急的说“你先听我说完嘛”。</p>
<p>正因为如此，我们技术人员可能更需要有一颗耐心和包容心。在没有写代码，而是跟其他人讨论交流时，我们有没有即时的切换状态，更耐心的对待他人的问题？我们在看别人的代码的时候，当发现有一些不是自己所推崇的模式的时候，有没有仔细想一下别人为什么要这么做？我们在遗留代码上面工作的时候，是不是一边工作一边吐槽代码写得太烂，而没有考虑到当时可能有各种各样的原因？我们是不是只一味的自己讲话，而没有仔细倾听对方的话？</p>
<h2 id="一个例子"><a class="markdownIt-Anchor" href="#一个例子"></a> 一个例子</h2>
<p>印象较深刻的有这样一个例子，我们的代码里面有这样的一段逻辑：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Something</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, Object&gt; attributes;</span><br><span class="line">    <span class="keyword">public</span> &lt;T&gt; T <span class="title function_">getAttribute</span><span class="params">(String name)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> (T)attributes.get(name);</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当我们在review代码的时候，有人一看到上面这行代码，还没等人解释为什么要这么做就直接说，“这个地方明显有问题啊，更好的方式是返回一个<code>Option</code>，让调用方去处理异常”。当作者开始要解释的时候，他又表现得听不进去，始终坚持自己是对的。最后由于这个小问题，可能要讨论十分钟。</p>
<p>这个问题的原因是什么呢？原来是由于<code>Something</code>里面的属性其实是调用方自己定义的，由于业务的要求，调用方可以定义各种类型的属性，而当调用方想要获取某一个属性的时候，就通过<code>getAttribute</code>获取。作者的设计意图是提供一个便捷的类型转换功能，封装这类类型强制转换的代码，避免这类不好的代码泄漏到每一个调用此方法的地方，而假设调用方确定的知道所查询的属性是什么类型（属性是调用方自己定义的）。如果这里的类型转换出错，那么会抛出一个运行时异常，这是写代码时就必须要处理的bug。</p>
<p>这里的分析合情合理，在我看来是完全可以接受的。试想，如果我们返回一个<code>Option</code>，每一个调用的地方都需要处理类型转换失败的情况，而调用方要如何处理呢？似乎也只能将其抛给更上层。其实这里作为调用方可能会很奇怪，为啥我明明知道不会抛出异常，还需要显示的处理异常呢？而且由于这样的调用方可能很多，每个地方都需要处理这样的异常，我们的代码其实是变得更糟糕了。</p>
<p>回过头来看这样的讨论，且不说它有没有价值，至少在我看来是低效的。如果我们有更多的耐心和包容心，我们先听作者把话说完，仔细倾听他人写代码时的考虑，是不是可以直接避免这样的讨论呢？我们的合作是不是更加顺畅呢？</p>
<p>耐心、包容心对于我们的TL其实有更高的要求，在面对一些经验稍差的团队成员写出来的代码，有时即便是有非常明显的问题，我们也需要虚心的耐心的倾听作者的解释，包容他的问题，然后合理的给出建议。只有这样，团队成员才能感受到自己是受重视的，自己哪里经验还比较欠缺，要往哪方面去努力。</p>
<h2 id="几个小建议"><a class="markdownIt-Anchor" href="#几个小建议"></a> 几个小建议</h2>
<p>我们每天和不同背景不同经历的团队成员进行合作，大家可能很容易的产生分歧，我们无意间发表的观点也可能会伤到他人的自尊。如何让自己有更好的耐心和包容心？这个问题可能是每一个作为成熟的职场人所必须要经常思考和练习的。只有每个人都做好了这些，我们在日常工作中才能更顺畅的交流，更高效的合作，更和谐的相处。</p>
<p>我们公司是一个反馈文化很浓厚的公司，反馈的技巧对于培养自己更好的耐心和包容心同样适用。要想有好的反馈效果，我们通常不是直接指出对方的问题，因为我们观察到的对方的问题一般都只是我们自己根据事实的推测，内里的原因我们未必知道。那么我们第一步是讲事实，倾听他人的解释，然后验证自己的假设。如果对方根本没有这个问题（先前的假设不存在），那么我们的反馈自然也就不存在。如果真的存在问题，那么我们应该适当引导他，让他自己发现做的不对，然后主动的去改正，我们当然也可以在这个时候分享一些自己的经验，给出一些自己的建议。这样的反馈其实很需要耐心和包容心。</p>
<p>我个人的另一些经验来自卡耐基《人性的弱点》这本书。相信很多同学们都看过这本书，书中对于如何指出别人的错误，如何提出建议给出了很多很有效的方法。这本书并不是像很多“成功学”的书一样，似乎我们看了就能成就多么伟大的一番事业。这本书更多的是教会大家如何去追求内心的平静，如何将自己的社会关系建立得更加和谐。看完这本书，我们可能会更少的抱怨，更多的付出，同时也更满足，更幸福。</p>
<p>这里有一些书中内容的引用，与大家共勉。</p>
<p><strong>如何指出别人的错误？</strong></p>
<ul>
<li>用称赞和真诚的欣赏作开始</li>
<li>教导他人时，要做到让别人不觉得在被教导</li>
<li>提出别人不知之事要像是提醒别人遗忘之事</li>
<li>尊重他人，间接的指出人们的过错，使用“如果xx那么xx”</li>
<li>在批评对方之前，不妨先谈谈你自己的错误</li>
<li>使错误看起来容易改正</li>
<li>用请求、建议、商量、赞美、提问的方式进行，别用命令的口吻，保全他人的面子</li>
</ul>
]]></content>
      <categories>
        <category>心态</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>心态</tag>
      </tags>
  </entry>
  <entry>
    <title>上山容易下山难</title>
    <url>/2019/12/22/its-harder-to-go-downhill/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>昨天和项目组的几个小伙伴去爬山。这次爬山坐标深圳梧桐山。从西北门进山，我们沿着蜿蜒的公路一路而上，历时三小时登顶。下山时不想原路返回，故意选了另一条路。从山上往下看，这条路陡峭得很。不过，对于几个血气方刚的男性，这条路正好。因为大家都觉得上山太简单不过瘾，想挑战一下高难度。于是我们一致同意换路而行。我们走的这条路就是凌云道。</p>
<p>说起凌云道这条路，真是名副其实。它不仅几乎呈垂直高度下降，而且台阶较窄仅有半脚宽。路两边树丛虽然茂盛，但是都不高大，山下的情形总是能进入眼帘。我一向有点恐高，在这垂直高度近1千米地方往下看，还真是心里有点慌。刚开始下山，小伙伴们见此山势，纷纷停下脚步拍照。得几张无P图片如下，大家可以感受一下：</p>
<span id="more"></span>
<p><img data-src="/attaches/2019/2019-12-22-its-harder-to-go-downhill/lingyundao-1.jpeg" alt="lingyundao" /><br />
<img data-src="/attaches/2019/2019-12-22-its-harder-to-go-downhill/lingyundao-2.jpeg" alt="lingyundao" /><br />
<img data-src="/attaches/2019/2019-12-22-its-harder-to-go-downhill/lingyundao-3.jpeg" alt="lingyundao" /></p>
<p>其实二维图片由于没有了层次感，跟实际感受相比还要差很多。如有爱爬山的小伙伴，建议去试试亲身感受一下（千万注意安全）。</p>
<p>大家开始下山，其他几个小伙伴都按照我们正常向前走的方式下山。我由于之前爬山偶然得到一个经验，那就是倒着下山，后续几天小腿不会那么痛。于是我就倒着走下山。一路下山的还有很多其他路人，大家几乎都是按照正常的向前走的方式下山。这个时候估计有不少人笑话我这种下山方式很奇怪。不过，我是基本上不在乎大家怎么看的。因为我相信不管我们自己的做法多怪异，只要不跟他人的切身利益相关，在别人眼中其实都是无关紧要的，最多一笑而过。</p>
<p>不过，一路下山，我还是很愿意和小伙伴们分享一下倒着下山的感受的，因为我真的感受到这样走下山是又省力又安全。特别是在下山了几百米之后，好几个小伙伴都在说小腿在颤抖的时候。跟大家分享之后，引来了几个小伙伴的尝试，大家确实也发现有一定的效果。</p>
<p>我仔细思考了一下为什么我会感觉倒着下山能既省力又安全，可能是这样几个原因：</p>
<ul>
<li>面向山体，而不是面向山下，可以避免恐高带来的心慌</li>
<li>即便脚下踩滑，手上可以快速使劲，不至于滑太远甚至摔下去</li>
<li>每下一步都是先由上面的一只脚使劲稳住，然后再由另一只脚伸直下探，最后下探的脚尖着地支撑。这样的动作组合不会给下山的脚带来太大的冲击力，进而避免运动过度而导致后续小腿痛（我查了一些资料，发现确实是有科学根据的，从膝盖受力来说，下台阶几乎是上台阶时的两倍）</li>
</ul>
<p>今天已是爬山回来的第二天。原以为昨天爬山一整天，即便下山倒走也不可避免的会小腿痛，但今早起来居然惊喜的发现仅仅是双腿有点累需要恢复一下而已，小腿完全没有疼痛难以走路的感觉。尝试一跳，还能跃起。</p>
<p>惊喜之余，我又自问了一下，为什么刚开始我可能也不会用这种方式。大概有这样几个原因：</p>
<ul>
<li>倒走姿势怪异，在别人眼中成为了另类</li>
<li>挪步缓慢，速度跟不上</li>
<li>形似年迈老人的姿势，无法展现年轻人的活力</li>
<li>挪步的时候，需要向后看身后的台阶，但刚好被身体挡住，很多时候需要靠估计来挪步，不够安全</li>
<li>可能由于强度减弱，达不到爬山健身的目的</li>
</ul>
<p>想到这里，我不禁发现倒走下山似乎跟我们的TDD实践有一定相似之处。刚接触TDD的小伙伴们，估计大部分也会这么觉得：</p>
<ul>
<li>TDD姿势怪异，是另类</li>
<li>TDD缓慢，速度跟不上</li>
<li>TDD过于强调细节，每写一行代码都要先写一行测试，过于谨慎，过于冗余</li>
<li>TDD可能导致测试过多，难以维护</li>
<li>TDD关注在测试上，可能导致设计关注不够，从而产生设计很差的代码</li>
</ul>
<p>初看TDD，确实会有违反常人先写代码后写测试的逻辑，我们会觉得不舒服，效率降低。有人甚至会觉得这完全是倒行逆施，有很大的抵触心理。这大概也是为什么TDD一直以来存在这么大的争议。</p>
<p>但是，TDD却是作为敏捷最核心的实践之一存在着。TDD既然这么不舒服，它究竟是为什么能得到这一部分人的认可，并得到他们不遗余力的推广呢？也许只有当我们了解他们的感受，理解这些人背后的逻辑之后，我们再来审视这件事，可能才能消除自己先前的偏见。就像倒走下山，一开始我们可能不会认可，自己随意尝试一下，我们可能还是不会认可。也许只有我们真的深入尝试过体会过（比如某一次坚持倒走下山，然后第二天体会一下），然后我们再来看待这件事才能有自己的答案。浅尝辄止就给出判断是不够的。</p>
<p>事实上，一个让人用起来不舒服的实践是很难一直得到人的认可的。即便当时强行接受，也几乎无法让人每天坚持去做。只有当一个人深刻认识到这个实践的好处，觉得它用起来很舒服，在潜意识里面认可它，我们才可能每天坚持去做。想想我们每天早上起来洗脸刷牙这件事，小时候吵着闹着不舒服不想洗，但长大后居然就变得自觉起来，而且一直坚持在做。我们之所以能坚持，是不是主要由于我们觉得洗完脸刷完牙之后感觉特别舒服，让我们有了新的面貌去迎接新的一天？</p>
<p>所以我们要想做到每天坚持TDD实践，只有当我们潜意识都认为TDD实践很舒服的时候，我们才能做到。因为这时它已经变成一种自然发生的事情，跟意志力无关。要让我们潜意识里认识到这一点，需要每个人自己去深入体会和改进这个过程中的每一步。就像我在体会倒走下山的每一步的时候一样，当我觉得倒走下山的每一步都很舒服的时候，我自然会每次都倒走下山了。开始时我也会觉得看不到身后的台阶而不舒服，但是我可以不断的调整姿势来改进这一点，直到我觉得舒服为止。对于TDD，我们可以尝试自问一下：TDD每一步都让我们很舒服吗？我在哪一步会不舒服？为什么会不舒服？是不是我的理解有问题？是不是我的方式不对？能不能改进这个方式，让我用起来舒服？</p>
<p>我相信一旦大家这样自问并且自我改进之后，一定能找到一种自己用起来很舒服的TDD的方式并坚持下去。</p>
<p>在这里我也趁此机会分享一些我个人的经验。</p>
<p>明确目标。TDD不是做软件的目标。就像倒走下山一样，怎么走不重要，关键在于我们能不能下山，能不能高质量的下山。同样，做出软件，做出高质量的软件是我们的目标。那么，我们要关注的事情变成：TDD是如何去支持这一目标的。从这一点来说，如果我们发现我们做的TDD中的某一步骤不能支持这一目标，那就是可以改变的。</p>
<p>以设计为核心。软件的内建质量几乎完全通过设计来呈现。软件的设计从大到小可以包括架构设计、模块设计、类设计、方法设计、变量设计。TDD如何帮助我们改进这些不同层面的设计呢？它在这些设计的过程中发挥着什么样的作用？如果能回答这两个问题，那么我们实践TDD就不是问题了。</p>
<p>关于以上两个方面我也有一些自己的思考，如果大家有兴趣，请参考我之前的博客：</p>
<ul>
<li><a href="/2019/07/20/tdd-for-improving-design/">从改善设计的角度理解TDD（一）</a></li>
<li><a href="/2019/08/18/tdd-for-improving-design-2/">从改善设计的角度理解TDD（二）</a></li>
</ul>
<p>上山不难下山难。上山几乎成为了大家日常可以完成得很好的事情，无需过多的技巧。但是对于下山，我们可能真正需要认真思考一下方法。</p>
]]></content>
      <categories>
        <category>TDD</category>
        <category>敏捷</category>
      </categories>
      <tags>
        <tag>敏捷</tag>
        <tag>TDD</tag>
      </tags>
  </entry>
  <entry>
    <title>再读重构</title>
    <url>/2019/10/07/after-reading-of-refactoring-v2/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>《重构–第二版》在我的书单里面待了好长一段时间了，趁着放假有时间读了一遍。这本书作为我司首席科学家老马的大作，同时又有大熊和林丛羽的翻译加持，值得每个人认真的反复的学习。</p>
<p>重构作为敏捷实践的精髓之一，在我们这个以敏捷为立身之本的公司里应当属于大家信手拈来的基本技能了。虽然说重构的基本思想长期不过时，但是第一版《重构》毕竟已经是20年前的事情了，20年以来软件开发行业兴起了无数新的编程思想、语言、工具、框架等，现在回过头去看第一版，会发现不仅纸质书籍难以买到，而且知识上也总觉得有点脱节。新版本以JavaScript语言作为示例，重新思考并改进了第一版本中的众多重构手法，结合了多年来一些新的观点和思考，带给了我们一套更为丰富完善的重构体系。</p>
<p>通读一遍本书，很多让我产生共鸣的地方，同时本书让我对于我们日常的一些实践有了新的看法，对于我们经常讨论的一些问题也有了新的结论。下面想摘录一些重要的观点，并分享几点我的理解，与大家一起学习。</p>
<span id="more"></span>
<h2 id="重构的几个要点"><a class="markdownIt-Anchor" href="#重构的几个要点"></a> 重构的几个要点</h2>
<p>书中讲到的几个重构要点值得每个人在实践重构的时候引起注意：</p>
<ul>
<li>重构不改变原有程序的可观测的行为</li>
<li>把添加新功能和重构当做两件不同的事情来对待，就像两顶帽子，在开发过程中我们经常两顶帽子换着戴</li>
<li>小步重构，更安全的前进，让代码绝大部分时间处于可工作的状态</li>
<li>捡垃圾式的重构：发现一个垃圾时，不想跑题太多，同时也不想将垃圾留在原地；如果此时很容易重构，就立即完成，否则就记录下来，等后续再来重构</li>
<li>绝大多数的重构是见机行事的，而非单独安排的一项工作</li>
<li>重构的唯一目的是让我们开发更快，用更少的工作量创造更高的价值；重构不是来自“整洁的代码”“良好的工程实践”等道德要求，而是纯粹从经济角度出发的考量</li>
<li>自测试代码是重构的基石，也是持续集成的关键环节。要想“敏捷”做到名副其实，必须要做好这三大实践–自测试代码、持续集成、重构（自测试代码和重构一起构成了TDD）</li>
</ul>
<h2 id="各种基础重构手法组合使用以实现高级的重构目的"><a class="markdownIt-Anchor" href="#各种基础重构手法组合使用以实现高级的重构目的"></a> 各种基础重构手法组合使用，以实现高级的重构目的</h2>
<p>我常常见到团队中有人在得到一个好的设计之后，就完全忽略之前的代码，重新进行一遍实现。然而重新实现一遍代码真的不难，难点在于如何让之前的遗留代码还能正常工作。我们常常要手工去处理这些遗留代码，不仅非常花费时间，还很容易出错，如果之前的代码自动化测试不足，那基本上等于自己给自己挖了一个大坑了。有时，我们还可能会让代码中存在两个版本的逻辑，给新的API一个版本号，这就更让人疑惑了。试想，如果我们在修改已有的代码，我们是否应该用新的API呢？新的API真的能和已有的老版本API兼容吗（常常是不行的，比如我们可能会将数据写入到两个不同的数据库表）？</p>
<p>老马的书中反复地乐此不疲地强调小步重构，以便可以随时回退到上一个可工作的版本再次来过。我能想象在没有重构工具支撑时，这是多么重要。但是，现在我们的自动化重构工具已经比较成熟（特别是静态类型语言），我们在做重构时，常常以较大的步子快速完成，我自己也经常这么做。这使得当我们要做一个巨大的重构的时候，我们常常忘了通过小步重构来实现。上面的不计后果的重写某个模块就是这样的一个例子。</p>
<p>实际上通过一系列的小步重构，我们几乎可以完成任意的巨大重构。比如书中的例子，以子类取代类型码的重构。这是一个很复杂的重构了，但是我们可以通过这样一系列步骤安全的进行：</p>
<ul>
<li>用封装变量将类型码封装到一个函数内部</li>
<li>创建一个工厂函数，根据类型构造不同的子类</li>
<li>创建其中一个子类</li>
<li>在工厂函数中替换构造出来的对象</li>
<li>对每个类型重复上述操作</li>
<li>去除类型码</li>
<li>使用函数下移重构和以多态处理条件表达式重构来处理原来的函数调用处的代码</li>
</ul>
<h2 id="营地法则"><a class="markdownIt-Anchor" href="#营地法则"></a> 营地法则</h2>
<p>对于如何让我们代码越来越健康，而不是逐渐腐化，我常常在团队里面给大家这样分享：我们每个人都应当在提交代码时停下来想一下，我们这次提交是让代码更健康了，还是更腐化了，还是没变化？只有我们每次提交代码都至少没有让代码更腐化，代码才能越来越健康。一些腐化的例子比如我们引入了一个坏味道，我们测试覆盖率降低了等等。而一个健康的例子就是我们在增加功能的时候，顺便重构了原来的代码，让其可读性更高，可复用性更好等等。</p>
<p>在老马谈论捡垃圾式重构法时提到了营地法则–我们应该至少在离开营地时，让营地比我们到来时更干净。如果每次经过一段代码，都让其变得更干净，积少成多，垃圾总是会被处理掉。</p>
<p>仔细一想，这样的观点竟然出奇的一致。与大家共勉。</p>
<h2 id="使用pr进行代码复审还是专门组织代码复审活动"><a class="markdownIt-Anchor" href="#使用pr进行代码复审还是专门组织代码复审活动"></a> 使用PR进行代码复审还是专门组织代码复审活动？</h2>
<p>在谈论到如何在代码复审进行重构时，老马提到我们可以在阅读他人代码之后，如果有一些点子，就可以直接进行重构，从而获得比想象出来的更直观的认识。这样的代码复审活动最好能有代码作者一起pair，不仅可以有机会充分理解原来的代码，还能一起分享重构的意图。</p>
<p>现在有些团队热衷于使用Pull Request的方式进行代码复审，并在代码后面留下大篇大篇的评论，以便让代码作者去修复问题。这样的风潮大概是兴起于github的流行，多分支管理策略如<code>git flow</code>和<code>github flow</code>中建议以Pull Request的方式进行代码复审和合并。看起来由于多了一道关卡，我们合入主干的代码质量能有所提高。但是这样的分支管理策略是不够敏捷的，它之所以适合在github上推行，是由于github上面的项目多是由分布式的团队完成。有一大群水平参差不齐的，对代码理解也差异巨大的开发者可能要一起修改代码，并且大家还要跨地域跨时区进行协作。要支持这样的团队开发，多分支策略有其优势。但是对于我们日常的敏捷团队而言，大家每天坐一起，专注在同一个项目上，这样的多分支策略就显得过于重量级了，发挥不出团队可以随时沟通交流的优势。</p>
<p>那么对于敏捷团队而言，更好的代码复审方式是怎么样的呢？我们可以尝试少数人pair的方式进行复审，我个人更推荐还是要回归到每天的团队代码复审活动中来。</p>
<h2 id="重构与单分支管理策略"><a class="markdownIt-Anchor" href="#重构与单分支管理策略"></a> 重构与单分支管理策略</h2>
<p>与上面代码复审类似，敏捷团队中更推荐的是单分支管理策略，因为这样的分支策略可以让我们更快的集成，从而更好的支持重构。试想，如果不是单分支，当我们在代码库里面进行重构之后，又必须得经过一个复杂而耗时的流程才能合入主干，这个时候合并代码会有多痛苦。我们很可能发现在一个两天前的提交中使用的一个接口，却已经被另一个人通过重构改名了。有人说我们可以通过频繁拉取主干的代码来缓解这个问题，但是合并是双向的过程，当修改太多的时候，每次的合并操作也会让人累的够呛，而且我可能长时间看不到别人的修改，潜在的合并代码风险无形中变大了。总之，特性分支游离的时间越长，合并越痛苦。基于单分支的策略，只要代码能通过测试，我们就可以随时将本地可用的代码推送到分支上，随时集成。这对于重构带来的压力将会小很多很多（将减少很多没必要的合并操作和破坏代码的机会）。</p>
<p>单分支管理策略不是说完全不使用分支，我们还是可以适当使用分支完成一些探索性的工作，或者完成产品发布工作。在这里，快速的合并代码和快速的集成是最重要的。</p>
<p>所以，对于一些热衷于<code>git flow</code>或者<code>github flow</code>的团队，我们可能尤其需要注意这个问题。</p>
<h2 id="重构与测试"><a class="markdownIt-Anchor" href="#重构与测试"></a> 重构与测试</h2>
<p>测试是重构的保护伞，我们需要有一组可靠的测试才能放手进行重构。测试的重要性不言而喻，相信我司大家都认可这一点。这里我想引用书中的观点，并提及的一点是我们应该何时停止写测试。</p>
<p>有一些测试规则建议会尝试保证我们测试一切的组合，虽然这些建议值得了解，但是实践中我们需要适可而止，因为测试达到一定程度之后，其边际效用会递减。如果编写太多测试，我们可能因为工作量太大而气馁。我们应该把注意力集中在最容易出错的地方，最没有信心的地方。</p>
<p>一些测试的指标，如覆盖率，能一定程度上衡量测试是否全面而有效，但是最佳的衡量方式可能来自于主观的感受，如果我们觉得对代码比较有信心，那就说明我们的测试做的不错了。</p>
<h2 id="不依赖于某个特定测试框架进行测试"><a class="markdownIt-Anchor" href="#不依赖于某个特定测试框架进行测试"></a> 不依赖于某个特定测试框架进行测试</h2>
<p>在老马的测试例子中，用到了<code>mocha</code>和<code>chai</code>两个JavaScript的测试工具，恰好这两个框架也是我写JS代码时最喜欢用的工具，除此之外，还有一个用来模拟对象的库<code>sinon</code>。这三个工具是大概两年前我从我们的QA处得知的，用起来十分趁手，一直沿用到现在。</p>
<p>这三个工具的一大特点就是不依赖任何的其他框架而独立存在，属于那种小而美的工具。这里我想提这三个工具的原因是我经常发现不少同学喜欢使用某个框架自带的测试基础设施进行测试，而非使用这些小而美的工具。比如很多人喜欢使用<code>Angular</code>提供的<code>TestBed</code>进行测试，或者喜欢使用<code>Spring</code>提供的<code>SpringBootTest</code>注解进行测试。然而这样的测试的问题在于其过度依赖于某个框架，测试运行过程中会执行到大量的框架代码，从而导致测试运行缓慢，出错了也不好定位问题。事实上我们的代码中主要关注的是应用自身的业务逻辑，这些业务逻辑才是测试的重点，而非框架的逻辑。当然有时候我们可能对框架的配置代码信心不够强（比如spring的配置还是比较复杂的），这个时候，我们可以有针对性的写少数几个测试来验证这些配置就足够了。对于应用自身的业务逻辑代码的测试，我们完全没必要基于某个具体框架来做，试想如果这些测试都是仅仅基于<code>junit</code>实现的，那这些测试将非常容易理解，非常容易迁移（比如当前的一个基于<code>Spring</code>的后端项目，可以根据需要很容易的迁移到Android移动平台）。</p>
<p>基于工具而非某个特定框架去组织测试的实践在我的平常工作中获益良多，而基于某个特定框架实现的测试往往维护困难。有了这样的认识，我们再来看本书中的所有测试，我们将发现它们都是简单而有效的。</p>
<p>（严格来说，<code>mocha</code>或者<code>junit</code>应该也算一种测试框架，但是他们的好处在于非常轻量级，没有任何其他框架的依赖和束缚。在这里我想表达的是我们要弱化某个具体的框架，转而使用一些通用框架和工具进行测试。）</p>
<h2 id="最后"><a class="markdownIt-Anchor" href="#最后"></a> 最后</h2>
<p>书中的精华还有很多很多，我尤其喜欢前四章以及后续重构名录中的动机部分，这些部分详细的回答了为什么做以及何时做这两个问题。总之，本书值得当做一本程序员的字典时常翻阅。</p>
<p>在当下，研发效能提升是一个被大家热议的话题。我们探讨的研发效能通常是指团队的研发效能而非某个个人的效能。在团队工作中，如果所有开发人员都能有效协作，将更有可能形成1+1大于2的高效团队。从这个角度看，重构就显得更为重要，因为我们编写的软件不再是只为实现功能，更多是为将来的自己或其他团队成员能理解和修改。花费一定的时间进行重构，改进软件的设计，可以让团队在以后的维护工作中更轻松，团队效能更高。</p>
<p>作为追求软件匠艺的工程师，我们应当重构，并应当更频繁地重构！让我们行动起来吧！</p>
]]></content>
      <categories>
        <category>敏捷</category>
        <category>重构</category>
      </categories>
      <tags>
        <tag>agile</tag>
        <tag>敏捷</tag>
        <tag>重构</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop安全认证机制 （四）</title>
    <url>/2019/12/02/hadoop-auth-4/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>系列文章：</p>
<ul>
<li><a href="/2019/10/27/hadoop-auth/">Hadoop安全认证机制 (一)</a></li>
<li><a href="/2019/10/30/hadoop-auth-2/">Hadoop安全认证机制 (二)</a></li>
<li><a href="/2019/11/11/hadoop-auth-3/">Hadoop安全认证机制 (三)</a></li>
</ul>
<p>前面的文章中，我们搭建了一套安全的<code>hadoop</code>集群，并建立了一个对应的测试。结合相关的基础知识，我们应该对安全的<code>hadoop</code>集群有了一定的认识。本文主要关注如何将大数据其他组件安全地与<code>hadoop</code>进行集成。我们将关注这几个组件：<code>hive</code> <code>hbase</code> <code>spark</code> <code>livy</code>。</p>
<h2 id="hive"><a class="markdownIt-Anchor" href="#hive"></a> <code>hive</code></h2>
<p>首先来看<code>hive</code>，<code>hive</code>是最初由<code>facebook</code>发起的基于<code>hadoop</code>大数据架构的数据仓库。<code>hive</code>直接将<code>hdfs</code>变为了一个支持<code>sql</code>的数据存储。时至今日，<code>hive</code>已成为企业大数据最基础的组件之一，各种上层的组件均和<code>hive</code>有良好的集成。</p>
<p>采用跟之前同样的思路，我们先来建立一个测试，如下：</p>
<span id="more"></span>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HiveTest</span> &#123;</span><br><span class="line">    <span class="type">TestConfig</span> <span class="variable">testConfig</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TestConfig</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">should_connect_to_hive_and_execute_query</span><span class="params">()</span> <span class="keyword">throws</span> IOException, SQLException &#123;</span><br><span class="line">        testConfig.configKerberos();</span><br><span class="line">        org.apache.hadoop.conf.<span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span></span><br><span class="line">                <span class="title class_">org</span>.apache.hadoop.conf.Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;hadoop.security.authentication&quot;</span>, <span class="string">&quot;Kerberos&quot;</span>);</span><br><span class="line">        UserGroupInformation.setConfiguration(conf);</span><br><span class="line">        UserGroupInformation.loginUserFromKeytab(testConfig.keytabUser(), testConfig.keytabFilePath());</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">url</span> <span class="operator">=</span> testConfig.hiveUrl();</span><br><span class="line">        <span class="type">Connection</span> <span class="variable">conn</span> <span class="operator">=</span> DriverManager.getConnection(url);</span><br><span class="line">        <span class="type">Statement</span> <span class="variable">statement</span> <span class="operator">=</span> conn.createStatement();</span><br><span class="line"></span><br><span class="line">        statement.execute(<span class="string">&quot;create database if not exists t&quot;</span>);</span><br><span class="line">        statement.execute(<span class="string">&quot;drop table if exists t.t&quot;</span>);</span><br><span class="line">        statement.execute(<span class="string">&quot;create table t.t (a int)&quot;</span>);</span><br><span class="line">        statement.execute(<span class="string">&quot;insert into table t.t values (1), (2)&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">ResultSet</span> <span class="variable">resultSet</span> <span class="operator">=</span> statement.executeQuery(<span class="string">&quot;desc t.t&quot;</span>);</span><br><span class="line">        resultSet.next();</span><br><span class="line">        assertEquals(<span class="string">&quot;a&quot;</span>, resultSet.getString(<span class="string">&quot;col_name&quot;</span>));</span><br><span class="line">        assertEquals(<span class="string">&quot;int&quot;</span>, resultSet.getString(<span class="string">&quot;data_type&quot;</span>));</span><br><span class="line">        assertEquals(<span class="string">&quot;&quot;</span>, resultSet.getString(<span class="string">&quot;comment&quot;</span>));</span><br><span class="line"></span><br><span class="line">        resultSet = statement.executeQuery(<span class="string">&quot;select * from t.t&quot;</span>);</span><br><span class="line">        resultSet.next();</span><br><span class="line">        assertEquals(<span class="number">1</span>, resultSet.getInt(<span class="string">&quot;a&quot;</span>));</span><br><span class="line">        resultSet.next();</span><br><span class="line">        assertEquals(<span class="number">2</span>, resultSet.getInt(<span class="string">&quot;a&quot;</span>));</span><br><span class="line"></span><br><span class="line">        conn.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（完整代码请参考<a href="https://github.com/gmlove/bigdata_conf/blob/master/test/src/test/java/test/HiveTest.java">这里</a>）</p>
<p><code>hive</code>的运行时包括两个核心组件，存储元数据的<code>metastore</code>及对外提供<code>sql</code>操作服务<code>hiveserver</code>。在这里我们用使用最广泛<code>mysql</code>作为<code>metastore</code>的存储。</p>
<p>执行脚本如下，即可搭建并运行<code>metastore</code>及<code>hiveserver</code>:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 进入我们之前创建好的容器</span></span><br><span class="line">docker <span class="built_in">exec</span> -it shd bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载、解压、配置</span></span><br><span class="line"><span class="built_in">cd</span> /hd</span><br><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/apache/hive/hive-1.2.2/apache-hive-1.2.2-bin.tar.gz</span><br><span class="line">tar xf apache-hive-1.2.2-bin.tar.gz</span><br><span class="line"><span class="built_in">ln</span> -sv apache-hive-1.2.2-bin hive</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装metastore</span></span><br><span class="line">yum install -y mariadb-server</span><br><span class="line">/usr/libexec/mariadb-prepare-db-dir mariadb.service</span><br><span class="line">/usr/bin/mysqld_safe --basedir=/usr 2&gt;&amp;1 1&gt;hive/hive.metastore.mysql.log &amp;</span><br><span class="line">mysql -uroot -e <span class="string">&quot;create user &#x27;hive&#x27;@&#x27;localhost&#x27; identified by &#x27;123456&#x27;; grant all on *.* to hive@&#x27;localhost&#x27;;&quot;</span></span><br><span class="line"><span class="comment"># 测试metastore连接</span></span><br><span class="line">mysql -uhive -p123456 -e <span class="string">&#x27;select now()&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置、启动hive</span></span><br><span class="line">wget https://repo1.maven.org/maven2/mysql/mysql-connector-java/5.1.48/mysql-connector-java-5.1.48.jar -O hive/lib/mysql-connector-java-5.1.48.jar</span><br><span class="line">wget https://raw.githubusercontent.com/gmlove/bigdata_conf/master/auth/hive/conf/hive-site.xml -O hive/conf/hive-site.xml</span><br><span class="line"><span class="built_in">cd</span> hive &amp;&amp; bin/hive --service metastore 2&gt;&amp;1 1&gt;hive.metastore.service.log &amp;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用hive的命令行工具测试 (下面的命令需要成功运行)</span></span><br><span class="line"><span class="built_in">cd</span> hive &amp;&amp; bin/beeline</span><br><span class="line">&gt; !connect jdbc:hive2://localhost:10000/default;principal=root/shd@HADOOP.COM</span><br><span class="line">Enter username <span class="keyword">for</span> jdbc:hive2://localhost:10000/default;principal=root/shd@HADOOP.COM: (这里直接Enter)</span><br><span class="line">Enter password <span class="keyword">for</span> jdbc:hive2://localhost:10000/default;principal=root/shd@HADOOP.COM: (这里直接Enter)</span><br><span class="line">&gt; create database <span class="keyword">if</span> not exists t;</span><br><span class="line">&gt; drop table <span class="keyword">if</span> exists t.t;</span><br><span class="line">&gt; create table t.t (a int);</span><br><span class="line">&gt; insert into table t.t values (1), (2);</span><br><span class="line">&gt; select * from t.t;</span><br></pre></td></tr></table></figure>
<p>我们这里修改的配置如下：</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">hive.server2.authentication</span>=<span class="string">KERBEROS</span></span><br><span class="line"><span class="attr">hive.server2.authentication.kerberos.principal</span>=<span class="string">root/_HOST@HADOOP.COM</span></span><br><span class="line"><span class="attr">hive.server2.authentication.kerberos.keytab</span>=<span class="string">/hd/conf/hadoop.keytab</span></span><br><span class="line"></span><br><span class="line"><span class="attr">hive.metastore.sasl.enabled</span>=<span class="string">true</span></span><br><span class="line"><span class="attr">hive.metastore.kerberos.keytab.file</span>=<span class="string">/hd/conf/hadoop.keytab</span></span><br><span class="line"><span class="attr">hive.metastore.kerberos.principal</span>=<span class="string">root/_HOST@HADOOP.COM</span></span><br><span class="line"></span><br><span class="line"><span class="attr">javax.jdo.option.ConnectionURL</span>=<span class="string">jdbc:mysql://localhost/hive_remote?createDatabaseIfNotExist=true</span></span><br><span class="line"><span class="attr">javax.jdo.option.ConnectionDriverName</span>=<span class="string">com.mysql.jdbc.Driver</span></span><br><span class="line"><span class="attr">javax.jdo.option.ConnectionUserName</span>=<span class="string">hive</span></span><br><span class="line"><span class="attr">javax.jdo.option.ConnectionPassword</span>=<span class="string">123456</span></span><br></pre></td></tr></table></figure>
<p>运行最初我们定义的测试如下：（接上篇中对应的测试运行部分）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> bigdata_conf/test</span><br><span class="line"><span class="built_in">cat</span> &gt; src/test/resources/hive-site.xml &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt;</span></span><br><span class="line"><span class="string">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="string">&lt;configuration&gt;</span></span><br><span class="line"><span class="string">  &lt;property&gt;</span></span><br><span class="line"><span class="string">    &lt;name&gt;hive.server2.authentication&lt;/name&gt;</span></span><br><span class="line"><span class="string">    &lt;value&gt;KERBEROS&lt;/value&gt;</span></span><br><span class="line"><span class="string">  &lt;/property&gt;</span></span><br><span class="line"><span class="string">  &lt;property&gt;</span></span><br><span class="line"><span class="string">    &lt;name&gt;hive.server2.authentication.kerberos.principal&lt;/name&gt;</span></span><br><span class="line"><span class="string">    &lt;value&gt;root/shd@HADOOP.COM&lt;/value&gt;</span></span><br><span class="line"><span class="string">  &lt;/property&gt;</span></span><br><span class="line"><span class="string">  &lt;property&gt;</span></span><br><span class="line"><span class="string">    &lt;name&gt;hive.metastore.sasl.enabled&lt;/name&gt;</span></span><br><span class="line"><span class="string">    &lt;value&gt;true&lt;/value&gt;</span></span><br><span class="line"><span class="string">  &lt;/property&gt;</span></span><br><span class="line"><span class="string">  &lt;property&gt;</span></span><br><span class="line"><span class="string">    &lt;name&gt;hive.metastore.kerberos.principal&lt;/name&gt;</span></span><br><span class="line"><span class="string">    &lt;value&gt;root/shd@HADOOP.COM&lt;/value&gt;</span></span><br><span class="line"><span class="string">  &lt;/property&gt;</span></span><br><span class="line"><span class="string">&lt;/configuration&gt;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line">mvn -DshdHost=shd -Dtest=test.HiveTest <span class="built_in">test</span></span><br></pre></td></tr></table></figure>
<p>到这里一个安全的<code>hive</code>搭建和测试就完成了。</p>
<h2 id="hbase"><a class="markdownIt-Anchor" href="#hbase"></a> <code>hbase</code></h2>
<p><code>hbase</code>是一个分布式大规模数据存储组件，支持随机的、实时的读写超过数十亿行的超大数据库。<code>hbase</code>基于google的论文《Bigtable: A Distributed Storage System for Structured Data》设计实现。我们来看看如何搭建一个安全的<code>hbase</code>数据库。</p>
<p>对于一个安全<code>hbase</code>的读写，我们可以建立测试如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HbaseTest</span> &#123;</span><br><span class="line">    <span class="type">TestConfig</span> <span class="variable">testConfig</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TestConfig</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">should_read_write_hbase</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        testConfig.configKerberos();</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">config</span> <span class="operator">=</span> HBaseConfiguration.create();</span><br><span class="line">        config.addResource(<span class="keyword">new</span> <span class="title class_">Path</span>(testConfig.hbaseSiteFilePath()));</span><br><span class="line">        UserGroupInformation.setConfiguration(config);</span><br><span class="line">        UserGroupInformation.loginUserFromKeytab(testConfig.keytabUser(), testConfig.keytabFilePath());</span><br><span class="line"></span><br><span class="line">        <span class="type">TableName</span> <span class="variable">tableName</span> <span class="operator">=</span> TableName.valueOf(<span class="string">&quot;test&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">Connection</span> <span class="variable">connection</span> <span class="operator">=</span> ConnectionFactory.createConnection(config);</span><br><span class="line">        <span class="type">Admin</span> <span class="variable">admin</span> <span class="operator">=</span> connection.getAdmin();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (admin.tableExists(tableName)) &#123;</span><br><span class="line">            admin.deleteTable(tableName);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">family1</span> <span class="operator">=</span> <span class="string">&quot;Family1&quot;</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">family2</span> <span class="operator">=</span> <span class="string">&quot;Family2&quot;</span>;</span><br><span class="line">        <span class="type">HTableDescriptor</span> <span class="variable">tableDescriptor</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HTableDescriptor</span>(tableName);</span><br><span class="line">        tableDescriptor.addFamily(<span class="keyword">new</span> <span class="title class_">HColumnDescriptor</span>(family1));</span><br><span class="line">        tableDescriptor.addFamily(<span class="keyword">new</span> <span class="title class_">HColumnDescriptor</span>(family2));</span><br><span class="line">        admin.createTable(tableDescriptor);</span><br><span class="line"></span><br><span class="line">        <span class="type">Put</span> <span class="variable">p</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Put</span>(Bytes.toBytes(<span class="string">&quot;row1&quot;</span>));</span><br><span class="line">        <span class="type">String</span> <span class="variable">qualifier1</span> <span class="operator">=</span> <span class="string">&quot;Qualifier1&quot;</span>;</span><br><span class="line">        p.addColumn(family1.getBytes(), qualifier1.getBytes(), <span class="string">&quot;value1&quot;</span>.getBytes());</span><br><span class="line">        p.addColumn(family2.getBytes(), qualifier1.getBytes(), <span class="string">&quot;value2&quot;</span>.getBytes());</span><br><span class="line"></span><br><span class="line">        <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> connection.getTable(tableName);</span><br><span class="line">        table.put(p);</span><br><span class="line"></span><br><span class="line">        <span class="type">Get</span> <span class="variable">g</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Get</span>(Bytes.toBytes(<span class="string">&quot;row1&quot;</span>));</span><br><span class="line"></span><br><span class="line">        assertEquals(<span class="string">&quot;value1&quot;</span>, <span class="keyword">new</span> <span class="title class_">String</span>(table.get(g).getValue(family1.getBytes(), qualifier1.getBytes())));</span><br><span class="line">        connection.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（完整代码请参考<a href="https://github.com/gmlove/bigdata_conf/blob/master/test/src/test/java/test/HbaseTest.java">这里</a>）</p>
<p><code>hbase</code>的运行时包括三个核心组件，存储元数据的<code>Master</code>、存储数据的<code>RegionServers</code>及一个分布式协调器<code>ZooKeeper</code>。在这里，我们将部署<code>ZooKeeper</code>作为一个独立的大数据组件运行，以便将来当我们要引入其他的基于<code>ZooKeeper</code>的组件时可以直接使用。</p>
<p>运行下面的命令，即可搭建并运行一个安全的<code>ZooKeeper</code>:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://archive.apache.org/dist/zookeeper/zookeeper-3.5.5/apache-zookeeper-3.5.5-bin.tar.gz</span><br><span class="line">tar xf /</span><br><span class="line"><span class="built_in">ln</span> -sv apache-zookeeper-3.5.5-bin zookeeper</span><br><span class="line"><span class="comment"># 创建对应的key</span></span><br><span class="line">kadmin.local addprinc -randkey zookeeper/shd@HADOOP.COM</span><br><span class="line">kadmin.local xst -k /hd/conf/zookeeper.keytab zookeeper/shd@HADOOP.COM</span><br><span class="line"><span class="comment"># 配置、启动</span></span><br><span class="line">wget https://raw.githubusercontent.com/gmlove/bigdata_conf/master/auth/zookeeper/bin/zkEnv.sh -O zookeeper/bin/zkEnv.sh</span><br><span class="line">wget https://raw.githubusercontent.com/gmlove/bigdata_conf/master/auth/zookeeper/conf/jaas.conf -O zookeeper/conf/jaas.conf</span><br><span class="line">wget https://raw.githubusercontent.com/gmlove/bigdata_conf/master/auth/zookeeper/conf/client-jaas.conf -O zookeeper/conf/client-jaas.conf</span><br><span class="line">wget https://raw.githubusercontent.com/gmlove/bigdata_conf/master/auth/zookeeper/conf/zoo.cfg -O zookeeper/conf/zoo.cfg</span><br><span class="line">sed -i <span class="string">&quot;s/__HOST__/shd/g&quot;</span> conf/jaas.conf</span><br><span class="line">sed -i <span class="string">&quot;s/__HOST__/shd/g&quot;</span> conf/client-jaas.conf</span><br><span class="line"><span class="built_in">cd</span> zookeeper &amp;&amp; bin/zkServer.sh start</span><br><span class="line"><span class="comment"># 测试如下：</span></span><br><span class="line"><span class="built_in">cd</span> zookeeper &amp;&amp; bin/zkCli.sh</span><br><span class="line">&gt; create /test <span class="built_in">test</span></span><br><span class="line">&gt; get /test</span><br></pre></td></tr></table></figure>
<p>接下来是<code>hbase</code>，运行命令如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 下载、配置hbase</span></span><br><span class="line">wget http://mirrors.tuna.tsinghua.edu.cn/apache/hbase/hbase-1.3.6/hbase-1.3.6-bin.tar.gz</span><br><span class="line">tar xf hbase-1.3.6-bin.tar.gz</span><br><span class="line"><span class="built_in">ln</span> -sv hbase-1.3.6 hbase</span><br><span class="line">wget https://raw.githubusercontent.com/gmlove/bigdata_conf/master/auth/hbase/conf/hbase-site.xml -O hbase/conf/hbase-site.xml</span><br><span class="line">wget https://raw.githubusercontent.com/gmlove/bigdata_conf/master/auth/hbase/conf/hbase-env.sh -O hbase/conf/hbase-env.sh</span><br><span class="line">wget https://raw.githubusercontent.com/gmlove/bigdata_conf/master/auth/hbase/conf/jaas.conf -O hbase/conf/jaas.conf</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;shd&#x27;</span> &gt; hbase/conf/regionservers</span><br><span class="line">sed -i <span class="string">&quot;s/__HOST__/shd/g&quot;</span> conf/hbase-site.xml</span><br><span class="line">sed -i <span class="string">&quot;s/__HOST__/shd/g&quot;</span> conf/jaas.conf</span><br><span class="line"><span class="comment"># 启动</span></span><br><span class="line"><span class="built_in">cd</span> hbase</span><br><span class="line">./bin/start-hbase.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试</span></span><br><span class="line">./bin/hbase shell</span><br><span class="line">&gt; create <span class="string">&#x27;member&#x27;</span>, <span class="string">&#x27;id&#x27;</span>,<span class="string">&#x27;address&#x27;</span>,<span class="string">&#x27;info&#x27;</span></span><br><span class="line">&gt; put <span class="string">&#x27;member&#x27;</span>, <span class="string">&#x27;debugo&#x27;</span>, <span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;1&#x27;</span></span><br><span class="line">&gt; get <span class="string">&#x27;member&#x27;</span>, <span class="string">&#x27;debugo&#x27;</span></span><br></pre></td></tr></table></figure>
<p>运行最初我们定义的测试如下：（接上篇中对应的测试运行部分）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> bigdata_conf/test</span><br><span class="line">docker <span class="built_in">cp</span> shd:/hd/hbase/conf/hbase-site.xml ./resources/</span><br><span class="line">mvn -DshdHost=shd -Dtest=test.HbaseTest <span class="built_in">test</span></span><br></pre></td></tr></table></figure>
<p>到这里一个安全的<code>hase</code>搭建和测试就完成了。</p>
<h2 id="spark"><a class="markdownIt-Anchor" href="#spark"></a> <code>Spark</code></h2>
<p><code>Spark</code>是一个独立的通用的高性能分布式计算引擎。相比基于<code>MapReduce</code>计算模型的<code>hive</code>，<code>Spark</code>设计了一套高效的<code>DAG</code>来优化计算流，有效的防止了多余的中间数据存储。由于<code>Spark</code>提供了更高的计算效率，它逐渐成了当前最流行的计算框架。</p>
<p><code>Spark</code>其实是作为一个工具库来与<code>Hadoop</code>大数据集群进行集成的。我们直接依赖<code>Spark</code>的库就可以使用，无需任何配置。</p>
<p>我们可以建立测试如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkTest</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">TestConfig</span> <span class="variable">testConfig</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TestConfig</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">should_be_able_to_read_hive_from_spark</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        testConfig.configKerberos();</span><br><span class="line">        org.apache.hadoop.conf.<span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span></span><br><span class="line">                <span class="title class_">org</span>.apache.hadoop.conf.Configuration();</span><br><span class="line">        conf.set(<span class="string">&quot;hadoop.security.authentication&quot;</span>, <span class="string">&quot;Kerberos&quot;</span>);</span><br><span class="line">        UserGroupInformation.setConfiguration(conf);</span><br><span class="line">        UserGroupInformation.loginUserFromKeytab(testConfig.keytabUser(), testConfig.keytabFilePath());</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .appName(<span class="string">&quot;Simple Spark Example&quot;</span>)</span><br><span class="line">                .master(<span class="string">&quot;yarn&quot;</span>)</span><br><span class="line">                .enableHiveSupport()</span><br><span class="line">                .config(<span class="string">&quot;spark.sql.warehouse.dir&quot;</span>, testConfig.sparkSqlWarehouseDir())</span><br><span class="line">                .config(<span class="string">&quot;hive.metastore.uris&quot;</span>, testConfig.hiveMetastoreUrl())</span><br><span class="line">                .getOrCreate();</span><br><span class="line"></span><br><span class="line">        spark.sql(<span class="string">&quot;create database if not exists t&quot;</span>);</span><br><span class="line">        spark.sql(<span class="string">&quot;drop table if exists t.t&quot;</span>);</span><br><span class="line">        spark.sql(<span class="string">&quot;create table t.t (a int)&quot;</span>);</span><br><span class="line">        spark.sql(<span class="string">&quot;insert into table t.t values (1), (2)&quot;</span>);</span><br><span class="line">        spark.sql(<span class="string">&quot;desc t.t&quot;</span>).show();</span><br><span class="line">        spark.sql(<span class="string">&quot;select * from t.t&quot;</span>).show();</span><br><span class="line"></span><br><span class="line">        spark.stop();</span><br><span class="line">        spark.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（完整代码请参考<a href="https://github.com/gmlove/bigdata_conf/blob/master/test/src/test/java/test/SparkTest.java">这里</a>）</p>
<p>运行以上测试：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> bigdata_conf/test</span><br><span class="line">mvn -DshdHost=shd -Dtest=test.SparkTest <span class="built_in">test</span></span><br></pre></td></tr></table></figure>
<p>如果我们想使用<code>spark-shell</code>来交互式的探索<code>spark</code>，则我们需要下载spark并做一定的配置。</p>
<p>执行脚本如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://archive.apache.org/dist/spark/spark-2.1.0/spark-2.1.0-bin-hadoop2.7.tgz</span><br><span class="line">tar xf spark-2.1.0-bin-hadoop2.7.tgz</span><br><span class="line"><span class="built_in">ln</span> -sv spark-2.1.0-bin-hadoop2.7 spark</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/hd/hadoop</span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/hd/hive</span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=/hd/hadoop/etc/hadoop</span><br><span class="line"><span class="built_in">cp</span> hive/conf/hive-site.xml spark/conf/</span><br><span class="line">wget https://repo1.maven.org/maven2/mysql/mysql-connector-java/5.1.48/mysql-connector-java-5.1.48.jar -O spark/jars/mysql-connector-java-5.1.48.jar</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试：（下面的spark程序将能计算出PI的近似值）</span></span><br><span class="line"><span class="built_in">cd</span> spark</span><br><span class="line">./bin/spark-submit \</span><br><span class="line">    --class org.apache.spark.examples.SparkPi \</span><br><span class="line">    --master yarn \</span><br><span class="line">    --deploy-mode cluster \</span><br><span class="line">    --executor-memory 512M \</span><br><span class="line">    --num-executors 1 \</span><br><span class="line">    examples/jars/spark-examples_2.11-2.1.0.jar 1000</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行spark-shell进入交互式环境</span></span><br><span class="line">./bin/spark-shell --master yarn</span><br><span class="line">&gt; new org.apache.spark.sql.SQLContext(sc).sql(<span class="string">&quot;show databases&quot;</span>).collectAsList()</span><br></pre></td></tr></table></figure>
<h2 id="livy"><a class="markdownIt-Anchor" href="#livy"></a> <code>Livy</code></h2>
<p><code>Livy</code>将运行<code>spark</code>应用的这一能力封装为了一个服务，这样我们就可以更方便的进行统一资源管理。</p>
<p>对于一个安全的<code>Livy</code>服务，我们可以编写对应的测试如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LivyTest</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">Logger</span> <span class="variable">log</span> <span class="operator">=</span> LoggerFactory.getLogger(LivyTest.class);</span><br><span class="line"></span><br><span class="line">    <span class="type">TestConfig</span> <span class="variable">testConfig</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TestConfig</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">should_submit_and_run_job_through_livy</span><span class="params">()</span> <span class="keyword">throws</span> IOException, URISyntaxException, InterruptedException, ExecutionException &#123;</span><br><span class="line">        testConfig.configKerberos();</span><br><span class="line">        <span class="type">LivyClient</span> <span class="variable">client</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">LivyClientBuilder</span>()</span><br><span class="line">                .setURI(<span class="keyword">new</span> <span class="title class_">URI</span>(testConfig.livyUrl()))</span><br><span class="line">                .setConf(<span class="string">&quot;livy.client.http.spnego.enable&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">                .setConf(<span class="string">&quot;livy.client.http.auth.login.config&quot;</span>, testConfig.jaasConfPath())</span><br><span class="line">                .setConf(<span class="string">&quot;livy.client.http.krb5.conf&quot;</span>, testConfig.krb5FilePath())</span><br><span class="line">                .setConf(<span class="string">&quot;livy.client.http.krb5.debug&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">                .build();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">piJar</span> <span class="operator">=</span> testConfig.sparkPiJarFilePath();</span><br><span class="line">            log.info(<span class="string">&quot;Uploading &#123;&#125; to the Spark context...&quot;</span>, piJar);</span><br><span class="line">            client.uploadJar(<span class="keyword">new</span> <span class="title class_">File</span>(piJar)).get();</span><br><span class="line"></span><br><span class="line">            <span class="type">int</span> <span class="variable">samples</span> <span class="operator">=</span> <span class="number">10000</span>;</span><br><span class="line">            log.info(<span class="string">&quot;Running PiJob with &#123;&#125; samples...\n&quot;</span>, samples);</span><br><span class="line">            <span class="type">double</span> <span class="variable">pi</span> <span class="operator">=</span> client.submit(<span class="keyword">new</span> <span class="title class_">PiJob</span>(samples)).get();</span><br><span class="line"></span><br><span class="line">            log.info(<span class="string">&quot;Pi is roughly: &quot;</span> + pi);</span><br><span class="line">            assertEquals(<span class="number">3</span>, Double.valueOf(pi).intValue());</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            client.stop(<span class="literal">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（完整代码请参考<a href="https://github.com/gmlove/bigdata_conf/blob/master/test/src/test/java/test/LivyTest.java">这里</a>及<a href="https://github.com/gmlove/bigdata_conf/blob/master/test/src/main/java/test/PiJob.java">这里</a>）</p>
<p>我们曾在<a href="/2019/10/30/hadoop-auth-2/">Hadoop安全认证机制 (二)</a>中介绍过<code>Livy</code>的安全机制。结合当时的原理介绍，我们只需要运行下面的脚本即可以配置好一个安全的<code>Livy</code>:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y unzip</span><br><span class="line"><span class="built_in">ln</span> -sv livy-0.5.0-incubating-bin livy</span><br><span class="line"><span class="built_in">cat</span> &gt;&gt; livy/conf/livy.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">livy.impersonation.enabled = true</span></span><br><span class="line"><span class="string">livy.server.auth.type = kerberos</span></span><br><span class="line"><span class="string">livy.server.auth.kerberos.keytab = /hd/conf/hadoop.keytab</span></span><br><span class="line"><span class="string">livy.server.auth.kerberos.principal = HTTP/shd@HADOOP.COM</span></span><br><span class="line"><span class="string">livy.server.launch.kerberos.keytab = /hd/conf/hadoop.keytab</span></span><br><span class="line"><span class="string">livy.server.launch.kerberos.principal = root/shd@HADOOP.COM</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动livy</span></span><br><span class="line"><span class="built_in">cd</span> livy &amp;&amp; ./bin/livy-server start</span><br></pre></td></tr></table></figure>
<p>运行上面的<code>java</code>测试用例：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> bigdata_conf/test</span><br><span class="line"><span class="built_in">cat</span> &gt;&gt;src/test/resources/jaas.conf &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">com.sun.security.jgss.krb5.initiate &#123;</span></span><br><span class="line"><span class="string">  com.sun.security.auth.module.Krb5LoginModule required debug=true</span></span><br><span class="line"><span class="string">  refreshKrb5Config=true</span></span><br><span class="line"><span class="string">  doNotPrompt=true</span></span><br><span class="line"><span class="string">  useKeyTab=true</span></span><br><span class="line"><span class="string">  keyTab=&quot;src/test/resources/root.keytab&quot;</span></span><br><span class="line"><span class="string">  principal=&quot;root&quot;;</span></span><br><span class="line"><span class="string">&#125;;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="built_in">cp</span> -v /root/dev/projects/tmp/bigdata_conf/test/src/test/resources&#123;.1,&#125;/spark-pi.jar</span><br><span class="line">mvn -DshdHost=shd -Dtest=test.LivyTest <span class="built_in">test</span></span><br></pre></td></tr></table></figure>
<h2 id="制作docker镜像"><a class="markdownIt-Anchor" href="#制作docker镜像"></a> 制作<code>docker</code>镜像</h2>
<p>到这里我们常用的几个基础组件的安全配置就介绍完了。为便于重现和复用这样一套环境，我们可以制作一个<code>docker</code>镜像。我这里已经将此镜像制作完成，并上传到了<code>docker hub</code><a href="https://hub.docker.com/repository/docker/brightlgm/bigdata-auth/general">这里</a>，大家可以直接下载使用，或者也参考这里的<code>Dockerfile</code>自行制作镜像。</p>
<p>有时候由于我们本地的资源不够运行集群的所有组件，我们可以在另一台机器上面通过容器运行此集群，然后通过<code>ssh tunnel</code>的方式将需要的端口映射到本地。这样本地测试时就可以直接连接<code>localhost</code>进行测试了。我也将此镜像制作完成，并上传到了<code>docker hub</code><a href="https://hub.docker.com/repository/docker/brightlgm/bigdata-auth-localhost/general">这里</a>。</p>
<p>对于<code>localhost</code>模式，我们需要映射的端口如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kdc</span></span><br><span class="line">ssh -L localhost:1802:localhost:1802 root@rshd</span><br><span class="line"></span><br><span class="line"><span class="comment">## test hbase:</span></span><br><span class="line"><span class="comment"># hbase zookeeper</span></span><br><span class="line">ssh -L localhost:2181:localhost:2181 root@rshd</span><br><span class="line"><span class="comment"># hbase master</span></span><br><span class="line">ssh -L localhost:16000:localhost:16000 root@rshd</span><br><span class="line"><span class="comment"># hbase region server</span></span><br><span class="line">ssh -L localhost:16201:localhost:16201 root@rshd</span><br><span class="line"></span><br><span class="line"><span class="comment">## test hive:</span></span><br><span class="line"><span class="comment"># hive</span></span><br><span class="line">ssh -L localhost:10000:localhost:10000 root@rshd</span><br><span class="line"></span><br><span class="line"><span class="comment">## test hdfs:</span></span><br><span class="line"><span class="comment"># hdfs namenode</span></span><br><span class="line">ssh -L localhost:9000:localhost:9000 root@rshd</span><br><span class="line"><span class="comment"># hdfs datanode</span></span><br><span class="line">sudo ssh -i /root/.ssh/id_rsa -L localhost:1004:localhost:1004 root@rshd -p 12822</span><br><span class="line"></span><br><span class="line"><span class="comment">## test livy</span></span><br><span class="line">ssh -L localhost:8998:localhost:8998 root@rshd</span><br><span class="line"></span><br><span class="line"><span class="comment">## test spark with hive</span></span><br><span class="line"><span class="comment"># hdfs namenode</span></span><br><span class="line">ssh -L localhost:9000:localhost:9000 root@rshd</span><br><span class="line"><span class="comment"># hdfs datanode</span></span><br><span class="line">sudo ssh -i /Users/gmliao/.ssh/id_rsa -L localhost:1004:localhost:1004 root@rshd -p 12822</span><br><span class="line"><span class="comment"># hive metastore</span></span><br><span class="line">ssh -L localhost:9083:localhost:9083 root@rshd</span><br></pre></td></tr></table></figure>
<p>对于前面几个组件的运维，我还将它们组织到了一个<code>Makefile</code>中，请参考<a href="https://github.com/gmlove/bigdata_conf/blob/master/auth/Makefile">这里</a>。有了这个脚本我们可以通过执行<code>make start-hbase</code>即可启动<code>hbase</code>了。其他的运维工具请参考<code>Makefile</code>源代码。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>本系列文章通过以下四个方面较全面的介绍了<code>hadoop</code>的安全机制：</p>
<ol>
<li>Kerberos协议介绍及实践</li>
<li>Kerberos协议发展及Hadoop相关源码分析</li>
<li>Hadoop安全集群搭建及测试</li>
<li>周边工具的安全支持</li>
</ol>
<p>通过这些介绍，相信大家对于<code>hadoop</code>的安全机制有了一定的了解了。本系列文章也将告一段落。当然我们在实际使用过程中可能还会遇到其他的问题，如有相关问题，欢迎大家留言交流。</p>
]]></content>
      <categories>
        <category>数据</category>
        <category>大数据</category>
        <category>安全</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>安全</tag>
        <tag>hadoop</tag>
        <tag>kerberos</tag>
      </tags>
  </entry>
  <entry>
    <title>用DDD思想来编写Pipeline</title>
    <url>/2020/01/05/DDD-in-pipeline-code/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>作为我们使用最广泛的CI/CD工具Jenkins，它对于<code>Pipeline as Code</code>的支持却并不能算友好。在多个项目中使用之后，我发现它存在的主要问题有：</p>
<ul>
<li>Groovy语言的学习成本</li>
<li>调试低效</li>
<li>灵活性差</li>
</ul>
<p>Groovy语言相对而言还是比较小众的。其设计为一种动态类型的语言，这给编译器、IDE的类型推断带来了困难，从而导致较弱的自动代码提示。除此之外，由于Groovy可以在没有歧义的情况下省略括号和行尾分号，并且如果最后一个参数是一个闭包则可以将其写在函数调用之后，这就导致了相对比较怪异的语法出现。比如，刚接触Groovy的人可能不太能一下子理解下面这段代码的工作原理：</p>
<figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">a(<span class="number">1</span>) &#123;</span><br><span class="line">    something(<span class="number">123</span>)</span><br><span class="line">    someother <span class="attr">id:</span> <span class="number">1</span>, <span class="attr">message:</span> <span class="string">&quot;test&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<p>看起来似乎是函数定义，但其实这里是一个函数调用，其背后的函数定义为：<code>def a(int i, Closure c);</code> <code>def someother(int id, String message);</code></p>
<p>注意，这里我并不是要说Groovy语言不是世界上最好的语言，而是想说明对于不常用这门语言的同学而言，由于其不够自然而存在一定的学习门槛。比如我就常常忘记Groovy的语法，而当我要重新开始一个项目时，我不得不又花一定的时间重新学习一下，可气的是这时还得不到多少IDE的辅助。大概也是由于Groovy对于新人入门不算友好，Gradle积极去支持了Kotlin语言。</p>
<p>至于调试低效，相信写过较复杂的Jenkins <code>pipeline</code>代码同学们已有同感。编写好代码之后，我们很难编写一个针对它的测试。想要测试我们的<code>pipeline</code>代码，我们不得不把<code>pipeline</code>运行起来看看效果，然后为了触发目标代码的执行，我们可能还要在网页上点来点去，花一定的时间操作好几个网页元素。</p>
<p>说到灵活性差，主要是指对于其他编译工具的集成而言。想要和Jenkins有好的集成，我们不得不编写一个Jenkins插件来实现。所以，我们就看到了大把大把的Jenkins插件。这些插件真的实现了所有原有编译工具提供的特性吗？这些插件质量怎么样，是否存在bug？某一个新的工具是否有插件支持？</p>
<p>说了这么多，可能有人觉得只是在吐槽而已。这里其实是想给大家分享一下另一种编写<code>pipeline</code>代码的方式，我个人长期使用下来发现更为高效。希望对于有相同困惑的小伙伴们有一定的参考价值。</p>
<h2 id="适合实现日常编译运维工作的工具与语言"><a class="markdownIt-Anchor" href="#适合实现日常编译运维工作的工具与语言"></a> 适合实现日常编译运维工作的工具与语言</h2>
<p><code>pipeline</code>完成的工作其实是一些日常的编译运维工作。说到如何支持这些编译运维工作，相信大家最熟悉不过的就是命令行工具了，各种各样的工具几乎都会提供完善的命令行接口。如何组合这些命令行工具来完成这些工作呢？这种场景下，<code>shell</code>应当是比较适合的胶水了。然而<code>shell</code>脚本的功能性却比较弱，比如高级语言里面司空见惯的各种集合功能，在<code>shell</code>里面却没有提供直接的支持。</p>
<p>这里我经常选用的是一种虽然比较古老，但却能方便的实现大部分编译运维功能的工具：<code>make</code>。其实<code>make</code>工具在<code>c/c++</code>的世界里一直是非常流行的，编译过<code>c/c++</code>项目的同学对于<code>make &amp;&amp; make install</code>命令一定不陌生。<code>make</code>工具支持的<code>Makefile</code>脚本功能是相当丰富的，但作为我们日常使用进行编译运维，通常只需要一个很小的子集就足够了。使用这样的一个功能很小的子集可以有效降低大家的学习成本，让新手亦能迅速上手。</p>
<p>对于后面要使用的<code>make</code>，我们只需要了解下面几点就够了：</p>
<ol>
<li><code>make</code>将一组命令组织成一个<code>task</code>，一个<code>Makefile</code>里面可以存在多个<code>task</code>以支持不同种类的运维工作，<code>task</code>间可以相互依赖。比如:</li>
</ol>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">// Makefile</span><br><span class="line"></span><br><span class="line"><span class="section">build-java:</span></span><br><span class="line">    mvn clean package <span class="comment"># 注意行首必须为一个或多个tab</span></span><br><span class="line"></span><br><span class="line"><span class="section">build-nodejs:</span></span><br><span class="line">    npm run build</span><br><span class="line"></span><br><span class="line"><span class="section">build: build-java build-nodejs</span></span><br></pre></td></tr></table></figure>
<ol start="2">
<li>每一条命令均独立的通过一个子<code>shell</code>去执行，所以命令可以是任意一段合法的<code>shell</code>脚本。</li>
</ol>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">// Makefile</span><br><span class="line"></span><br><span class="line">modules=a b c</span><br><span class="line"><span class="section">build-java:</span></span><br><span class="line">    for m in $modules; do \</span><br><span class="line">        cd $$m &amp;&amp; mvn clean package; \</span><br><span class="line">    done  <span class="comment"># 按顺序编译多个模块</span></span><br><span class="line"></span><br><span class="line"><span class="section">build-nodejs:</span></span><br><span class="line">    npm run build</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>
<p><code>make</code>中我们可以定义变量，这些变量可以初始化一个默认值，可以通过调用<code>task</code>时设置值进行覆盖。</p>
<p>比如上面的<code>Makefile</code>，我们如果调用时使用命令<code>make build-java modules=&quot;a b c d&quot;</code>，那么这个<code>build-java</code>将会去<code>a b c d</code>四个目录下分别执行<code>mvn clean package</code>。</p>
</li>
</ol>
<p>了解了上面这几个<code>make</code>的特性，相信你已经能想象出很多很多的可能了。比如，一个简单的应用部署可以视为编译、打包、上传到目标机器、重启服务的过程。通过覆盖不同的变量，我们就能复用部署脚本，将应用部署到另一个环境。</p>
<p>我曾经在多个多语言、多工具项目中采用make来进行自动化日常运维工作。几乎在每个项目中，它都给我带来了巨大的效率提升。</p>
<p>即便我们工作在<code>windows</code>下，也无需担心，因为只要使用git，我们就有了一个随时可用的<code>bash</code>（<code>git-bash</code>），然后配以一个<code>windows</code>下编译的<code>make</code>工具，依赖的环境就搭建好了。这里我会给大家推荐用<a href="https://github.com/bmatzelle/gow">gow</a>，它是一个相比Cygwin轻量得多的常用<code>gnu</code>工具包，只需要10MB左右的空间就够了。</p>
<p>当然如果我们有条件使用<code>windows</code>提供的<code>linux</code>子系统，那就更简单了。</p>
<h2 id="用ddd的思路来编写pipeline"><a class="markdownIt-Anchor" href="#用ddd的思路来编写pipeline"></a> 用DDD的思路来编写pipeline</h2>
<p>从DDD的角度来看，这里我们所要真正解决的问题是搭建一个CI/CD的<code>pipeline</code>，而Jenkins在这里扮演的是CI/CD的某种具体实现工具。如果条件允许，我们完全可以换用其他的具体实现工具来搭建这个<code>pipeline</code>。</p>
<p>对于Jenkins这个第三方工具，使用DDD的思想，我们要如何处理呢？这里我们可以将其视为一个独立的领域，仔细思考就会发现，这种场景与我们在项目中去使用某个第三方服务是没什么两样的。</p>
<p>为了确保我们的核心领域<code>pipeline</code>可以独立健康的发展，不为Jenkins这个第三方工具提供的功能所支配，我们首先需要从核心领域出发来定义业务流程。</p>
<p>对于一个典型的<code>pipeline</code>，我们可以定义这样几个顺序执行的步骤：构建（编译、单元测试、打包） -&gt; 部署到开发环境 -&gt; 运行集成测试 -&gt; 部署到测试环境 -&gt; 部署到高级测试环境 -&gt; 部署到生产环境。</p>
<p>这里的顺序其实是一个潜在的变更点，因为我们完全可以定义另一条<code>pipeline</code>以支持直接部署到生产环境：构建（编译、单元测试、打包） -&gt; 部署到生产环境。</p>
<p>于是这里我们可以抽象这样几个通用的领域能力：构建、运行集成测试、部署到某一环境。</p>
<p>有了这些分析，我们就可以着手编写实现了。用我们上文提到的<code>Makefile</code>脚本来实现这里的领域能力，可以得到类似下面这样的脚本。</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">build:</span></span><br><span class="line">    mvn clean verify package</span><br><span class="line"></span><br><span class="line">TARGET_HOST=1.1.1.1</span><br><span class="line"><span class="section">deploy:</span></span><br><span class="line">    scp target/xxx.jar $&#123;TARGET_HOST&#125;:/app/</span><br><span class="line">    ssh $&#123;TARGET_HOST&#125; <span class="string">&quot;cd /app/ &amp;&amp; sh restart.sh&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="section">deploy-dev:</span></span><br><span class="line">    make deploy TARGET_HOST=1.1.1.2</span><br><span class="line"></span><br><span class="line"><span class="section">deploy-qa:</span></span><br><span class="line">    make deploy TARGET_HOST=1.1.1.3</span><br><span class="line"></span><br><span class="line"><span class="section">integration-test:</span></span><br><span class="line">    cd src/test/integration &amp;&amp; npm run test</span><br></pre></td></tr></table></figure>
<p>上述只是一个简单的示例，实际情况可能比这里复杂很多。比如我们可能需要将构建出来的文件发布到一个制品库里面，我们可能需要管理上传制品库的密码。比如我们可能是一个多模块的项目，需要支持多个模块的构建。还比如，我们可能要构建出来的是一个容器镜像。</p>
<p>但是，无论怎样，通过从核心领域出发来考虑问题，我们定义了几个清晰且相对稳定的接口。</p>
<p>有了上面实现的领域能力，下一步就是利用Jenkins制作一个的图形化流水线了。到这里再来看需要编写的<code>pipeline</code>代码，我们会发现需要写的<code>pipeline</code>代码已经变得很少了。主要的代码如下：</p>
<figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    stages &#123;</span><br><span class="line">        stage(<span class="string">&quot;build&quot;</span>) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh <span class="string">&quot;make build&quot;</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        stage(<span class="string">&quot;deploy dev&quot;</span>) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh <span class="string">&quot;make deploy-dev&quot;</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        stage(<span class="string">&quot;integration test&quot;</span>) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">                sh <span class="string">&quot;make integration-test&quot;</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>pipeline</code>代码的变少说明我们对第三方工具的依赖变弱了，这正是想要的效果。我们将主要的投资放在了核心域，而不是与第三方的集成。</p>
<p>到这里我们的<code>pipeline</code>代码就基本编写完成了。回顾一下编写好的代码，我们可以发现这样一些好处：</p>
<ul>
<li>减少了大家不熟悉的Groovy代码的编写</li>
<li>使用大家更为熟悉的<code>shell</code>命令来组织运维脚本，可维护性变高</li>
<li>测试这些自动运维脚本的成本变低了，比如，我们只需要本地运行一下<code>make build</code>就可以测试<code>build</code>相关脚本是否正确的编写</li>
<li>核心领域内的功能可以独立的发展，而不会对实现<code>pipeline</code>的Groovy代码有影响（相对稳定的接口）</li>
<li>设计变得足够灵活，后续如果需要更换Jenkins为另一种工具，这将是很简单的一件事</li>
<li>使用变得足够灵活，某一天即使Jenkins服务出故障了，我们也可以很轻松的在一台开发机器上面手动去完成必要的运维工作</li>
</ul>
<p>以上这些都是DDD的设计思想带给我们的好处。</p>
<p>回顾整个应用DDD思想的过程，我们按顺序经历了这样几个步骤：识别核心域 -&gt; 从核心领域出发定义领域能力 -&gt; 和其他周边工具进行集成。这是我在应用DDD时的几个主要步骤，虽然本文只是用于解决<code>pipeline</code>这一特定场景下的问题，但是其实这几个步骤在几乎所有场景下都适用的。</p>
<p>可能很多人觉得DDD的思想是一种必须在很复杂的业务场景下才有用的思想，进而怀疑在这个简单的场景下谈DDD是否会显得大材小用。这样的质疑是可以理解的，我了解过的很多DDD的资料也都是针对复杂业务场景来讨论问题。</p>
<p>但是，在我看来，DDD思想中以领域为核心的一些观点，其实是无所谓问题的复杂程度的。因为任何一个简单的业务问题，越往后发展越复杂，最终都可能成为一个复杂的问题。比如上传文件的功能，一开始我们可能可以用几行代码就实现了，但是随着系统的发展，我们可能要进一步跟踪进度、支持多文件、做文件类型限制等等，这个功能很容易就变成需要上千行代码才能实现的功能。</p>
<p>如果DDD仅限于解决复杂问题，那么它就失去了在问题还比较简单时就去解决它的先机。事实恰恰相反，最好的实践DDD的方式就是从一开始就应用这样的设计思想。</p>
<p>所以，对于任意复杂程度的问题，只要我们应用DDD的思想来进行思考，我们几乎都能从中获益。</p>
<p>最后，希望这里的分享的一些经验对大家有所帮助。有任何问题，欢迎留言交流。</p>
<p>相关文章：<a href="/2019/08/08/domain-concept-in-your-code/">代码中的领域</a></p>
]]></content>
      <categories>
        <category>DDD</category>
        <category>敏捷</category>
      </categories>
      <tags>
        <tag>敏捷</tag>
        <tag>DDD</tag>
      </tags>
  </entry>
  <entry>
    <title>仪式感与专业服务</title>
    <url>/2019/12/02/sense-of-ceremony-and-professional-service/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>进门，双手帮你脱下外套，挂起。洗发师双手提起一件深色防水的丝质套衫，你伸手，换上。拿起腰带，穿过你的腰，两圈，拉扯一次，拉扯两次，系紧。抹平套衫肩部，拉住袖口，拉扯一次，拉扯两次，展平。拉住套衫底部，拉扯一次，拉扯两次，拉齐。</p>
<p>将你带到洗头处，你看到一个用于平躺的台面，台面上深色皮质的垫子分为两部分，前面部分可拆卸，上放一块叠起来的深蓝色毛巾，毛巾上面是一朵颜色鲜艳的大荷花。在台面前部放有一个与垫子同样深色皮质的单人凳。</p>
<p>洗发师伸开右手，将你迎向凳子坐下。介绍洗头服务：我是37号洗发师为您服务，本次洗发50分钟，请您稍坐，我去准备毛巾和其他用品。</p>
<span id="more"></span>
<p>洗发师离开片刻即推着一个装满深色毛巾及洗护用品的篮子过来。拉起你的衣服领口，从脊梁处开始，一只手拉住，另一只手用虎口夹住你的衣领往你的胸前划去，展平。另一边，展平。拉起你的领口，将一张防水薄巾塞入，伸手向两边抚平。将薄巾往两边肩部有节奏的轻拉，轻拉，数次。拉住薄巾在肩部的两角，有节奏的往下拉，一次，两次，三次。轻抚肩部薄巾，展平。轻抚后背衣服，展平。</p>
<p>洗发师双手抹上精油，拍手，抹匀。双手向你的肩部及颈部抹去，抹匀精油。以肩部肌肉为中心，使劲，用手掌从上往下刮去。略感疼痛。左右两边各数次。找准肩胛骨附近穴位，按压。另起几式复杂难以描述的手法，揉，刮，按压。循环，5分钟。</p>
<p>起身整理台面，端起垫子前部带荷花的台面，放到后部长垫下面镂空处。台面端起后出现一个水槽，内有一个可折叠的头垫，翻起。在长垫末端放置一个长条枕头状的软垫。伸手将你迎向垫子躺下，前后调整好位置，头靠在水槽里面的头垫上，脚脖子架在末端软垫上。拿来鞋套，帮你套上。拉起两边的深紫色帘子。随即取来一条热毛巾，抬起腰部，放在腰部下面垫起。你感到腰部背后一阵暖流。</p>
<p>洗发师坐回水槽前面的凳子，手指沾上精油，在你眼前或以拍打浪花的手势将精油往下甩，或以折扇展开的手势将精油扩散至整个面部。一边散精油，一边引导道：此精油有安神，放松的功效，深呼吸，放松，深呼吸，放松，深呼吸，放松。待你照做之后，一种特殊的香味出现，你感到整个头部弥漫在这样的香气之中。</p>
<p>洗发师开始按摩头部，自额头正中开始往上，用双手大拇指按压，一边按压一边挪动，直到头顶。一轮，两轮。左右两边找准穴位，一揉一按。循环数次。以拇指为轴心，用折扇展开的手势依次打开每一个手指，指尖有节奏的敲击你的头部。循环此手法，从头顶开始往两侧移动，一次，两次，三次。手指向下移动，找准后颈窝两边肌肉，用拇指及虎口来回刮揉。略感疼痛。另起几式复杂难以描述的手法，揉，刮，按压。循环，10分钟。</p>
<p>抹上洗发水，采用之前头部按摩类似的手法，一边按摩一边清洗。10分钟，清洗两次。</p>
<p>清洗干净之后，冲水。随即抹上另一种洗发水，这次却大不相同，你感觉头皮有一种暖流流动，整个头皮都发热起来。洗发师介绍道：这是本店特色头皮温泉浴，是以生姜为原料特制的一种洗发水，可以温暖头皮，放松肌肉，夏季我们将更换为一种以薄荷为原料的洗发水，可以凉爽头皮。配以轻柔的按摩之后，热水冲净。</p>
<p>至此洗发完毕。洗发师双手捋住头发，捋干大部余水。轻声道：请稍候，我去取颈敷毛巾和眼敷毛巾。片刻而归，将颈敷毛巾架在你的后颈，将眼敷毛巾放在你的双眼之上。你闭上双眼感受来自后颈和眼部的热流。洗发师走到长垫右边中间坐下，从肩部向下到手掌依次按压整个手臂。拉起你的手腕，放松手掌，你的手指自然下垂，洗发师依次拉伸你的每一个手指，砰，砰，砰，几声清脆的声音。拉起你的整条手臂，往下，往上，往后，提拉，三次。换左手手臂，重复上面的手法。</p>
<p>按摩手臂完毕，休息一分钟，洗发师将你扶起，用毛巾擦干头发余水，将你迎向外面的理发师。整个洗发服务完毕。</p>
<p>每次到这家理发店理发后，都有一种浑身舒畅的感觉。不禁叹服于他们服务的专业，也因身边能有这样高质量的服务而暗喜。古时将相能享受到的服务也不过如此吧。</p>
<p>回想整个服务过程，为什么让人觉得专业呢？我想主要来自于细节和节奏感。他们讲究细节和节奏感，因此要在洗发之前不遗余力帮你整理好衣衫；因此要将垫子分为两部分，并配以荷花点缀；因此要以软垫垫上你的脚脖子，以热毛巾垫上你的后腰，又以热毛巾热敷你的后颈和双眼；因此要创造一套头皮温泉浴让你眼前一亮，特别惊喜。这样的服务，用无微不至形容亦不为过。</p>
<p>细节和节奏感的把握有效的营造了一种仪式感。就像婚礼现场，大家都细心打扮，西装革履，整齐的端立于红毯两旁，牧师的宣言在教堂内回荡。就像升旗仪式，举旗，正步，肃穆，注视。</p>
<p>这样的仪式感让人觉得专业。联想我们的敏捷软件开发。打开我们公司首页，你将看到，ThoughtWorks对外提供的是professional service，专业服务。阅读几本经典敏捷书籍之后，你将能看到，我们将敏捷里面的活动称为ceremony，仪式。敏捷软件交付服务应该就是这样一种有仪式感的专业服务。</p>
<p>敏捷的仪式感于我是随时引用的敏捷宣言，是retro的时候跟大家一起有节奏感的自信的诵读“我们坚信。。。”，是坚持测试坚持tdd，是对完美设计的不懈追求和对技术卓越的不懈追求，是对产品质量的高要求，是对缺陷的零容忍，是谦虚的态度，是以客户价值和用户价值为导向的建议，还有很多。。。极限编程指导我们迈向敏捷，其实也是在指导我们提供极致的专业服务，难道不是吗？</p>
]]></content>
      <categories>
        <category>敏捷</category>
      </categories>
      <tags>
        <tag>敏捷</tag>
        <tag>仪式感</tag>
        <tag>专业服务</tag>
      </tags>
  </entry>
  <entry>
    <title>强化学习入门</title>
    <url>/2020/02/06/DRL-the-problem/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>自机器学习重新火起来开始，深度强化学习就一直是科研的一大热点，也是最有可能实现通用人工智能的一个分支。然而对于没有强化学习基础的同学们，如果直接去学习深度强化学习，想必会碰到很多问题。本文尝试普及一下最基础的强化学习算法，并以一个小例子来辅助大家理解。</p>
<h2 id="问题定义"><a class="markdownIt-Anchor" href="#问题定义"></a> 问题定义</h2>
<p>强化学习究竟研究的是一个什么样的问题，让其具有实现通用人工智能的潜力？</p>
<p>这个问题与我们认识世界的方式相关。我们都知道这个世界时刻在变化着，而每件事物的变化，势必是由其他一系列事物导致的。这就是我们所普遍认识的世界，一个由因果律定义的世界。由于有因果律的存在，我们就有可能根据某个当前世界的状态，计算后一时刻世界的状态。</p>
<p>而我们人类，作为一个智能体，通过观察这个世界，并进行各种各样的自主行动，来在这个世界中生存，并影响这个世界。通用人工智能的实现，就是期望能通过计算机模拟人类这样的智能体进行各种各样的行动决策。</p>
<span id="more"></span>
<p>为了简化问题，我们可以像下面这样建模这个世界和智能体。我们可以认为在某一个时刻整个世界处于状态<code>S1</code>，当智能体进行了某一个行动之后，这个世界的状态变化为了<code>S2</code>。智能体之所以能够做出这一行动，是因为其心中有一个目标，并且从这个世界中得到了一定的反馈。</p>
<p>举个例子。比如我们想要喝水（目标），身边有一个杯子和一个饮水机（状态S1），我们会观察杯子和饮水机的位置，再伸手去拿取杯子（行动），然后将杯子靠近（反馈）饮水机，到达饮水机出水位置之后（状态S2），饮水机开始出水，之后我们再将杯子举到嘴边就能喝到水了。</p>
<p>这个简单的模型可以图示如下：</p>
<p><img data-src="/attaches/2020/2020-02-06-DRL-the-problem/mdp.png" alt="Markov Decision Process" /></p>
<p>智能体（<code>Agent</code>）通过观察这个世界（<code>Environment</code>）的状态（<code>State: s</code>），经过智能决策，开展了一些行动（<code>Actions: a</code>），这些行动进而引起了这个世界的状态变化。智能体从这些变化的状态中获得关于之前行动的反馈（<code>Reward: r</code>），从而指导后续的行动决策。就这样，整个世界周而复始的一直循环下去。</p>
<p>考虑这个模型，由于有因果律的存在，是不是知道了<code>S1</code>这个初始状态及智能体做出的行动<code>A</code>之后，我们就可以直接计算下一状态<code>S2</code>了呢？理论是可行的，但实际情况要更复杂一些，因为状态实在太多太多了，我们通常无法直接建模所有的状态。这时，我们可以用统计学的方式来解决这个问题。我们可以认为在我们做出某一行动之后，这个世界的状态只是有一定概率会转换为<code>S2</code>，同时也有一定的概率会转换为<code>S2_1</code>等等。这样就算我们建模的状态不全，也是可以相对较好的描述这个系统。</p>
<p>引入统计学的思维，也就引入了不确定性，虽然如此，但是却带来了更合理的描述系统的方式和系统层面的确定性。</p>
<p>以上描述的这一模型，在强化学习的世界里，我们称作Markov决策过程，简称MDP（Markov Decision Process）。这里面的不确定性也就是Markov特性。</p>
<p>有了这个模型之后，我们就可以从数学上来研究这个问题了。强化学习研究的正是如何在这样的一个数学模型的基础上去实现一个有效的算法来进行智能决策。</p>
<h2 id="一个小例子"><a class="markdownIt-Anchor" href="#一个小例子"></a> 一个小例子</h2>
<p>我们可以设计一个简单的小游戏来辅助解决这个问题。</p>
<p><img data-src="/attaches/2020/2020-02-06-DRL-the-problem/grid-world.png" alt="Grid World" /></p>
<p>如上图，机器人（智能体）可以在这样的网格中移动：</p>
<ul>
<li>绿色格子代表机器人可以移动到的位置</li>
<li>灰色格子表示有障碍物，机器人不能移动到那个位置</li>
<li>红色格子表示一个陷进，如果机器人移动到此，游戏失败</li>
<li>黄色格子代表一个出口，如果机器人移动到此，游戏成功</li>
</ul>
<p>这个游戏中的MDP，可以描述为如下：</p>
<ol>
<li>系统状态：格子位置，机器人位置</li>
<li>机器人可执行的动作：向上下左右四个方向移动</li>
<li>状态转换概率：如果机器人向某个方向移动，它移动到对应方向的格子的概率假设为<code>0.7</code>（如果无法移动到对应方向的位置，则留在原格子的概率为<code>0.7</code>），移动到其他位置的概率为<code>0.3/n</code>，<code>n</code>为其他可转换到的状态的数量。</li>
</ol>
<p>状态转换概率举例如下（假设我们对格子进行编码，编码方式与excel表格的编码方式一致，从<code>A1</code>到<code>E3</code>。）：</p>
<ol>
<li>假设机器人在位置<code>A2</code>，如果其向上移动，有<code>70%</code>的概率会移动到<code>A1</code>，分别有<code>15%</code>的概率会移动到<code>A2</code>（留在原位）和<code>A3</code></li>
<li>假设机器人在位置<code>A2</code>，如果其向左或向右移动，有<code>70%</code>的的概率会留在原位<code>A2</code>，分别有<code>15%</code>的概率会移动到<code>A1</code>和<code>A3</code></li>
</ol>
<p>我们的算法要解决的问题是，在任意绿色格子里面放置一个机器人，算法可以指导机器人一步一步到达位置<code>E1</code>（成功完成游戏）。</p>
<h2 id="方案与算法"><a class="markdownIt-Anchor" href="#方案与算法"></a> 方案与算法</h2>
<p>为了实现一个智能算法解决上述机器人走格子问题，我们可以考虑给每个格子定义一个价值。这个价值表示到达这个格子后有多大可能性能成功完成游戏。</p>
<p>观察这个游戏可以发现，<code>D1</code>的价值应该高于<code>C1</code>，<code>C1</code>的价值应该高于<code>B1</code>。</p>
<p>如果可以计算出每个格子的价值，我们是不是就解决了这个问题了呢？因为，无论机器人处于哪个位置，它只需要往价值比当前格子更高的格子方向走即可。</p>
<p>现在问题转化为如何定义和计算这个价值。</p>
<p>我们先将我们的目标数值化。由于到达出口格子即成功，如果机器人能到达此处，我们就给智能体反馈奖励<code>1</code>。同理，如果到达陷进格子，反馈奖励<code>-1</code>，到达绿色格子则奖励<code>0</code>。</p>
<p>这个时候我们来看格子<code>D1</code>。如果机器人在此处，它可以往四个方向移动。如果右移，有<code>70%</code>的概率可以到达出口，获得奖励<code>1</code>。如果往其他三个方向走，则分别有<code>10%</code>的概率会到达出口，获得奖励<code>1</code>。</p>
<p>经过以上的分析可以发现，我们其实可以将概率与奖励相乘来代表某个移动方向的价值。得到如下的价值数值：</p>
<ul>
<li>向右移动：<code>0.7 * 1 = 0.7</code></li>
<li>向上/下/左移动：<code>0.1 * 1 = 0.1</code></li>
</ul>
<p>这里的数值我们可以定义为动作价值。有了这个动作价值，要计算某个格子的价值，我们其实可以直接用最大的动作价值来表示，即：<code>max([0.7, 0.1, 0.1, 0.1]) = 0.7</code>。</p>
<p>如果要计算格子<code>C1</code>的价值呢？这时，虽然达到格子<code>D1</code>的奖励为0，但是我们可以利用刚计算好的<code>D1</code>的价值。还是按照前面的方式进行计算：</p>
<ul>
<li>向右移动：<code>0.7 * (0 + 0.7) = 0.49</code></li>
<li>向上/下/左移动：<code>0.1 * (0 + 0.7) = 0.07</code></li>
<li>格子价值：<code>max([0.49, 0.07, 0.07, 0.07]) = 0.49</code></li>
</ul>
<p>到这里，一个简单的算法呼之欲出。我们只需要找到所有有奖励的位置，然后从那里开始去计算其他所有位置的奖励，好像这个问题就解决了。</p>
<p>实际情况会稍微复杂一些。因为我们可能有很多个位置都存在奖励，而且这些奖励的多少可能由于任务定义而不一样。这里更实际一些的算法是利用多次迭代来实现。</p>
<p>为了不失一般性，我们可以定义公式：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>Q</mi><mo>∗</mo></msup><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></munder><mi>T</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo separator="true">,</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo><mo stretchy="false">[</mo><mi>R</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo separator="true">,</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo><mo>+</mo><msup><mi>V</mi><mo>∗</mo></msup><mo stretchy="false">(</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">Q^*(s, a) = \sum_{s&#x27;} T(s, a, s&#x27;)[R(s, a, s&#x27;) + V^*(s&#x27;)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.3439900000000002em;vertical-align:-1.2939850000000002em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8560149999999997em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828285714285715em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2939850000000002em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.051892em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></span>
<p>（表示每个动作的价值，其中：<code>s</code>表示当前状态；<code>a</code>表示动作；<code>s'</code>表示下一个状态；<code>T(s, a, s')</code>表示在状态<code>s</code>，执行动作<code>a</code>转换到状态<code>s'</code>的概率；<code>R(s, a, s')</code>表示表示在状态<code>s</code>，执行动作<code>a</code>转换到状态<code>s'</code>得到的奖励）</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>V</mi><mo>∗</mo></msup><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>a</mi></munder><msup><mi>Q</mi><mo>∗</mo></msup><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">V^*(s) = \max\limits_a Q^*(s, a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.45em;vertical-align:-0.7em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43056em;"><span style="top:-2.4em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">a</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mclose">)</span></span></span></span></span>
<p>（表示每个格子的价值，其中：<code>s</code>表示当前状态，<code>a</code>表示动作）</p>
<p>一般而言，我们会引入一个额外的γ参数，对下一个状态的价值打一定的折扣，这是因为当前获得的奖励一般会优于下一个状态的价值的，毕竟下一个状态的价值只是一个估计值。这时，上述第一个公式变为：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>Q</mi><mo>∗</mo></msup><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></munder><mi>T</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo separator="true">,</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo><mo stretchy="false">[</mo><mi>R</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo separator="true">,</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo><mo>+</mo><mi>γ</mi><mo>∗</mo><msup><mi>V</mi><mo>∗</mo></msup><mo stretchy="false">(</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">Q^*(s, a) = \sum_{s&#x27;} T(s, a, s&#x27;)[R(s, a, s&#x27;) + \gamma*V^*(s&#x27;)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.3439900000000002em;vertical-align:-1.2939850000000002em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8560149999999997em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828285714285715em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2939850000000002em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.6597200000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.051892em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></span>
<p>于是，我们的算法就可以描述为：</p>
<ul>
<li>对每一个状态，初始化 <code>V := 0</code></li>
<li>循环，直到<code>V</code>收敛：
<ul>
<li>对每一个状态，</li>
</ul>
</li>
</ul>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>V</mi><mo>∗</mo></msup><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo><mi>max</mi><mo>⁡</mo></mo><mi>a</mi></munder><munder><mo>∑</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></munder><mi>T</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo separator="true">,</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo><mo stretchy="false">[</mo><mi>R</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo separator="true">,</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo><mo>+</mo><mi>γ</mi><mo>∗</mo><msup><mi>V</mi><mo>∗</mo></msup><mo stretchy="false">(</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">V^*(s) = \max\limits_a \sum_{s&#x27;} T(s, a, s&#x27;)[R(s, a, s&#x27;) + \gamma*V^*(s&#x27;)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.3439900000000002em;vertical-align:-1.2939850000000002em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43056em;"><span style="top:-2.4em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">a</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8560149999999997em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828285714285715em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2939850000000002em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.6597200000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.051892em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></span>
<p>这里为判断<code>V</code>是否收敛，我们可以检查当前这次迭代是否会更新<code>V</code>的值。</p>
<p>用<code>javascript</code>代码实现，主要代码如下：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="title class_">MDPVISolver</span>.<span class="property">solve</span> = <span class="keyword">function</span> (<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">var</span> values = m.<span class="title function_">zeroArray</span>([<span class="variable language_">this</span>.<span class="property">states</span>.<span class="property">length</span>]);</span><br><span class="line">    <span class="keyword">var</span> valuesNew = values;</span><br><span class="line">    <span class="keyword">var</span> iterations = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        <span class="keyword">var</span> qValuesAll = [];</span><br><span class="line">        values = valuesNew;</span><br><span class="line">        valuesNew = [];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; <span class="variable language_">this</span>.<span class="property">states</span>.<span class="property">length</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">var</span> state = <span class="variable language_">this</span>.<span class="property">states</span>[i];</span><br><span class="line">            <span class="keyword">var</span> qValues = <span class="variable language_">this</span>.<span class="title function_">qValues</span>(values, state);</span><br><span class="line">            qValuesAll.<span class="title function_">push</span>(qValues);</span><br><span class="line">            <span class="keyword">var</span> value = <span class="variable language_">this</span>.<span class="title function_">value</span>(qValues);</span><br><span class="line">            valuesNew.<span class="title function_">push</span>(value);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;finished iteration &#x27;</span> + (++iterations));</span><br><span class="line">        <span class="comment">// console.log(&#x27;values: &#x27;, values);</span></span><br><span class="line">    &#125; <span class="keyword">while</span>(!<span class="variable language_">this</span>.<span class="title function_">converged</span>(values, valuesNew));    </span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里我已经实现了上述的游戏的一个Demo，见<a href="/examples/mdp/grid-world.html">这里</a>。完整代码见<a href="https://github.com/gmlove/gmlove.github.io/blob/source/source/examples/mdp/grid-world.js">这里</a>865行到890行。</p>
<p>上述算法就是强化学习里面的经典算法 <strong>价值迭代</strong> 算法了。而我们上面定义<code>V</code>的迭代形式的公式就是著名的 Bellman 公式了，其最初由 Richard Bellman 提出。</p>
<h2 id="另一个思路"><a class="markdownIt-Anchor" href="#另一个思路"></a> 另一个思路</h2>
<p>上述算法存在一个问题，我们最后得到的是一系列状态价值（每个格子的价值），为了得到我们想要的行动，我们还需要根据根据状态价值，计算行动价值，即上述<code>Q(s, a)</code>。使用上有所不便。</p>
<p>那么有没有办法改进呢？再来思考一下这个问题的目标，实际上我们想要找到一种指导机器人行动的策略。这里的策略可以表示为：在任意一个位置，算法可以给出一个恰当的行动。</p>
<p>我们能不能直接去衡量某一个策略的价值呢？因为一旦有了这个策略的价值，我们就可以考虑直接去优化这个策略，而不是去对所有的状态计算价值。</p>
<p>对于某一策略，由于其可以基于当前状态指导我们作出行动，我们可以定义它为一个 <strong>输入为状态</strong> <strong>输出为行动</strong> 的函数，即<code>π: a = π(s)</code></p>
<p>既然这样，参考价值迭代算法中的状态价值（格子价值）定义，我们可以定义策略价值函数为：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>V</mi><mi>π</mi></msup><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></munder><mi>T</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>π</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo><mo stretchy="false">[</mo><mi>R</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>π</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo><mo>+</mo><mi>γ</mi><mo>∗</mo><msup><mi>V</mi><mi>π</mi></msup><mo stretchy="false">(</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">V^\pi(s) = \sum_{s&#x27;} T(s, \pi(s), s&#x27;)[R(s, \pi(s), s&#x27;) + \gamma*V^\pi(s&#x27;)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7143919999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.3439900000000002em;vertical-align:-1.2939850000000002em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8560149999999997em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828285714285715em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2939850000000002em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.6597200000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.051892em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7143919999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></span>
<p>（策略<code>π</code>的价值，其中：<code>s</code>表示当前状态；<code>a = π(s)</code>表示动作；<code>s'</code>表示下一个状态；<code>T(s, π(s), s')</code>表示在状态<code>s</code>，执行动作<code>a=π(s)</code>转换到状态<code>s'</code>的概率；<code>R(s, π(s), s')</code>表示在状态<code>s</code>，执行动作<code>a=π(s)</code>转换到状态<code>s'</code>得到的奖励）</p>
<p>上面的公式是一个迭代形式的定义，既然如此，我们可以参考之前的<strong>状态价值迭代算法</strong>，迭代计算这个策略的价值，最后这个价值可能会收敛到某个具体的值。</p>
<p>然而就算我们可以计算策略的价值，我们如何得到一个有效的策略呢？如果没有策略，我们其实也无从计算其价值。</p>
<p>能不能随机初始化一个策略？有了这个策略，我们就可以计算其价值。然后我们可以想办法看看能不能得到一个更好的策略。</p>
<p>对于以上解决问题的思路，我第一次看到的时候，也不禁暗暗赞叹。事实上，这就是我这里想要给大家介绍的另一个强化学习经典算法：<strong>策略迭代</strong> 算法。</p>
<p>如何根据一个策略寻找更优策略？可以这样做：</p>
<ul>
<li>计算在当前策略下，哪一个行动能得到最大价值</li>
<li>选择价值最大的行动作为新策略的行动</li>
</ul>
<p>用公式表述如下：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo><mi mathvariant="normal">arg max</mi><mo>⁡</mo></mo><mi>a</mi></munder><munder><mo>∑</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></munder><mi>T</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo separator="true">,</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo><mo stretchy="false">[</mo><mi>R</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo separator="true">,</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo><mo>+</mo><mi>γ</mi><mo>∗</mo><msup><mi>V</mi><mi>π</mi></msup><mo stretchy="false">(</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\pi_{i+1}(s) = \argmax\limits_a \sum_{s&#x27;} T(s, a, s&#x27;)[R(s, a, s&#x27;) + \gamma*V^\pi(s&#x27;)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.3439900000000002em;vertical-align:-1.2939850000000002em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.20556em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">a</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop"><span class="mord mathrm">a</span><span class="mord mathrm">r</span><span class="mord mathrm" style="margin-right:0.01389em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathrm">m</span><span class="mord mathrm">a</span><span class="mord mathrm">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.89444em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8560149999999997em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828285714285715em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2939850000000002em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.6597200000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.051892em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7143919999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">π</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.801892em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">]</span></span></span></span></span>
<p>（下一个（第<code>i+1</code>个）更优策略<code>π(i+1)</code>，其中：<code>s</code>表示当前状态；<code>a = π(s)</code>表示动作；<code>s'</code>表示下一个状态；<code>T(s, a, s')</code>表示在状态<code>s</code>，执行动作<code>a</code>转换到状态<code>s'</code>的概率；<code>R(s, a, s')</code>表示在状态<code>s</code>，执行动作<code>a</code>转换到状态<code>s'</code>得到的奖励）</p>
<p>到这里，这个 <strong>策略迭代</strong> 算法就差不多完成了。用<code>javascript</code>代码实现，主要代码如下：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="title class_">MDPPISolver</span>.<span class="property">solve</span> = <span class="keyword">function</span> (<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">var</span> policy = <span class="variable language_">this</span>.<span class="title function_">randomPolicy</span>();</span><br><span class="line">    <span class="keyword">var</span> policyNew = policy;</span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        policy = policyNew;</span><br><span class="line">        values = <span class="variable language_">this</span>.<span class="title function_">solveForPolicy</span>(policy);</span><br><span class="line">        policyNew = <span class="variable language_">this</span>.<span class="title function_">improvePolicy</span>(values, policy);</span><br><span class="line">    &#125; <span class="keyword">while</span> (!<span class="variable language_">this</span>.<span class="title function_">converged</span>(policy, policyNew));</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>完整代码见<a href="https://github.com/gmlove/gmlove.github.io/blob/source/source/examples/mdp/grid-world.js">这里</a>932行到1024行。</p>
<h2 id="扩展"><a class="markdownIt-Anchor" href="#扩展"></a> 扩展</h2>
<h3 id="状态空间降维"><a class="markdownIt-Anchor" href="#状态空间降维"></a> 状态空间降维</h3>
<p>虽然我们可以用上述两个经典算法解决这个问题，但是它们的效率是很低的，算法复杂度用大O计算法可以表示为<code>O(a*s*s)</code>。对于这个非常简单的问题，计算速度尚能接受，但是如果我们考虑一些更复杂的问题，就会发现这里的状态<code>s</code>的取值空间可能会非常大。</p>
<p>比如对于下面这个吃豆子的游戏，这里的状态数量为：</p>
<pre><code>    状态数量 = 格子数量 * N (N为每个格子的可能状态：比如是否有吃豆人、是否有豆子、是否有敌人及敌人的类型等等)
</code></pre>
<p><img data-src="/attaches/2020/2020-02-06-DRL-the-problem/pac-man.png" alt="Pacman" /></p>
<p>过大的状态空间就导致上述经典算法实际无法执行，也就无法满足实际需求。</p>
<p>一个可能的优化手段是人为的设计一些特征来表示某个状态<code>s</code>，这样就实现了对<code>s</code>进行降维的操作。比如对于上面吃豆子的游戏，我们可以建模这样几个特征：</p>
<ul>
<li>离最近的豆子的方向和距离</li>
<li>离每个敌人的方向和距离</li>
<li>敌人的移动速度和方向</li>
</ul>
<p>有了这样的很小的状态空间，上述算法就可以执行了。</p>
<h3 id="深度强化学习dqn"><a class="markdownIt-Anchor" href="#深度强化学习dqn"></a> 深度强化学习<code>DQN</code></h3>
<p>有了上述状态空间降维的办法，我们可以考虑是不是可以用一个深度神经网络来替代人工特征的过程呢？当然是可以的，这就是前几年 <code>Deep Mind</code> 轰动学界和产业界的关于 <strong>深度强化学习</strong> 的论文中的内容了。</p>
<p><code>DQN</code>的全称是<code>Deep Q-Network</code>，它的核心是一个<code>Q</code>值迭代的算法。<code>Q</code>值迭代公式就是我们 <strong>价值迭代</strong> 公式中的关于行动价值的公式的一个迭代形式。算法也是不断迭代直到收敛。</p>
<p>我在另一篇文章中有关于<code>DQN</code>的更多内容。详情见<a href="/2016/12/05/let-machine-play-games/">这里</a>。</p>
<h3 id="更多的问题"><a class="markdownIt-Anchor" href="#更多的问题"></a> 更多的问题</h3>
<p>考虑一个更实际的问题，上述经典算法假设我们知道了状态转移函数<code>T</code>。但实际上当前世界可能对于我们是全新的，<code>T</code>对于我们而言当然也是未知的。这个时候有什么办法呢？一个简单的思路是我们可以通过不断在这个世界中进行探索，去了解这个世界的运作方式，也就是不断的弄清了这个<code>T</code>函数。在强化学习的研究中，抽象一下这个过程，即通过不断采样来近似估计<code>T</code>函数。</p>
<p>另一个实际的问题是，有时候我们可能无法执行这么多次探索，或者每次探索的成本太高以至于负担不起。这时，一个有效的思路是，我们可以从别人的经验中学习，或者通过看电影读书进行学习。当前的强化学习方法也在这个方向上进行了很多探索。</p>
<p>对于如何高效的进行学习，还有一个思路，那就是，我们能否模仿某个已有的不错的行动策略呢？比如，假设我们希望训练机器人做家务，那么是不是可以通过演示一遍给机器人看，然后机器人通过模仿进行学习呢？这就是模仿学习思路去解决这个问题。</p>
<p>关于这个领域，我们还可以想出更多的问题，比如，如何让机器人自己去探索解决问题的方法？如何处理连续的动作（文章开始时提到的喝水的例子，这里移动双手的过程其实就是连续动作决策的过程）？如何自动设置奖励甚至不设置奖励？很多越来越难问题被一个一个提出，同时又正在被不断提出的新思路一个一个攻克。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>总结起来，强化学习其实就是关于如何学习的研究。这个领域发展至今能解决的问题其实还比较有限，我们离最终的通用人工智能的路还很长。同时，很多新的有挑战性的问题不断被提出来，被大家研究，很多创新的解决问题的思路也不断被发掘出来。正是我们对这个领域充满热情，才导致了这个领域如此蓬勃的发展。相信终有一天这个问题能被我们人类攻克。</p>
]]></content>
      <categories>
        <category>machine-learning</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>Reinforcement Learning</tag>
        <tag>DQN</tag>
        <tag>MDP</tag>
        <tag>Markov Decision Process</tag>
        <tag>机器学习</tag>
        <tag>算法</tag>
        <tag>强化学习</tag>
        <tag>深度强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Rust内建最佳实践</title>
    <url>/2020/03/23/rust-the-good-part/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>在前面的文章中提到我们在一个高性能场景中尝试了<code>rust</code>，那么它的效果如何呢？</p>
<p>在这次<code>rust</code>的尝试中，我们实现了一个通用的特征数据处理框架，并实现了几个常用的算子。这个数据处理框架目标是实现 <code>Spark ML pipeline</code> 的在线计算，为机器学习模型的在线推理场景提供特征处理。</p>
<p>我们选用了两个<code>rust</code>的<code>grpc</code>框架对外提供服务。它们分别是<a href="https://github.com/stepancheg/grpc-rust"><code>grpc</code></a>和<a href="https://github.com/hyperium/tonic"><code>tonic</code></a>，前者是基于线程池的实现，后者是基于rust异步模式<code>async/await</code>的实现。实验过程发现两者性能相差不大，<code>tonic</code>稍好，快<code>2ms</code>左右（不到5%），这可能是由于其数据结构设计更为精简带来的。</p>
<p>为了更有参考性，我们直接进行端到端的测试（用<code>grpc</code>客户端发起请求，在客户端采集数据），并与<code>scala</code>版本的实现进行性能对比。下面的结果中，服务端应用均部署在同一台<code>64核心</code>+<code>32GB内存</code>的服务器上，客户端也在此服务器上发起请求。由于数据处理的逻辑一致，客户端使用同一个<code>java</code>版本的实现。</p>
<span id="more"></span>
<p>对于<code>rust</code>版本的实现，为处理1000条数据，我们发起了20个并发请求，每个请求50条数据。客户端测试得到的响应时间在<code>25ms</code>到<code>38ms</code>间波动。观察服务端应用的内存占用，发现其稳定在<code>2%</code>，整个过程，几乎没有变化。<code>cpu</code>一直处于<code>1300%</code>到<code>2000%</code>之间。</p>
<p>考虑到实现的通用性，我们实现的<code>rust</code>版本的数据处理逻辑与<code>mleap</code>版本的数据处理逻辑是类似的。对于<code>mleap</code>，我们使用了官方推荐的<a href="https://mleap-docs.combust.ml/mleap-runtime/row-transformer.html">基于行计算</a>的最高性能模式。<code>mleap</code>版本在处理同样的一组数据时，在没有发生<code>gc</code>的情况下，性能相对稳定，在<code>90ms</code>到<code>130ms</code>区间波动。如果某一时刻发生<code>gc</code>，则性能可能下降到<code>150ms</code>到<code>200ms</code>，甚至也有数百毫秒的时候。</p>
<p>再比较一下我们自实现的一个专用的java版本（将数个算子的计算过程进行联合优化，不仅针对性的优化了算法，还尽可能的减少了内存分配）。这个版本由于计算量降低了很多，其性能是很不错的，正常时，响应时间可以稳定在<code>20ms</code>到<code>40ms</code>间，但是我们也常常能观察到<code>70ms</code>及以上的波动发生。如果我们开启10个线程，每个线程处理100条数据，则数据相对更为稳定，但响应时间会增加<code>10ms</code>左右。</p>
<p>通过数据对比，<code>rust</code>不仅显示出了很高的性能，还表现出了特别强的稳定性。这都跟<code>rust</code>的极小的运行时设计及内存管理机制是分不开的。</p>
<p><code>rust</code>除了这两点具有特别的吸引力之外，还有哪些地方值得推崇呢？事实上，<code>rust</code>在语言设计层面做了很多努力，以期帮助开发者直接采用当前社区所推荐的最佳实践，并在语言层面直接避免许多潜在的问题。我们的实践过程也从这些特性中受益颇多。下面将分享一些<code>rust</code>语言内建的一些最佳实践。</p>
<h2 id="rust语言内建最佳实践"><a class="markdownIt-Anchor" href="#rust语言内建最佳实践"></a> <code>rust</code>语言内建最佳实践</h2>
<h3 id="摒弃类继承仅支持trait多态"><a class="markdownIt-Anchor" href="#摒弃类继承仅支持trait多态"></a> 摒弃类继承，仅支持<code>trait</code>多态</h3>
<p>在<code>rust</code>中，我们没有<code>object</code>或<code>class</code>关键字，与之相对应的是<code>struct</code>，结构体。我们通过<code>struct</code>来组织数据，并在这些数据上面定义方法。一个<code>struct</code>即为一个类。但在<code>rust</code>中我们却无法定义一个结构体去继承另一个结构体的成员和方法。</p>
<p>作为面向对象编程思想的一个重要特性，继承，近年来越来越受到大家的质疑。继承是一个很好的解决代码复用问题的手段，但却常常被滥用，而我们总是很轻易的就滥用了继承。这些滥用表现在：1. 在设计时抽象出了没必要的复杂继承树；2. 为了代码复用，随意的（不合理的）把某些子类方法放到父类中；3. 重构时，简单的插入中间抽象类，导致越来越深的继承树；4. 单纯为了复用代码而抽象出并不合理的继承关系。</p>
<p>对于继承所带来的代码复用优势，当前我们所更为推荐的做法是：1. 通过接口实现来表达对象具有某一特性，并借此实现多态（这也是函数式编程所采用的做法）；2. 利用 <strong>组合优于继承</strong> 的思想设计职责更单一的组件和并实现代码复用。</p>
<p>在<code>rust</code>中，我们无法定义结构体的继承关系，我们却可以轻松的去定义一个<code>trait</code>，这里的<code>trait</code>可以类比<code>scala</code>语言中的<code>trait</code>，或者<code>java</code>中的<code>interface</code>，是一种更单纯的无状态的接口定义。同时，像在其他语言中一样，我们也可以在<code>trait</code>中提供默认的方法实现。</p>
<h3 id="模块-属性默认private"><a class="markdownIt-Anchor" href="#模块-属性默认private"></a> 模块、属性默认<code>private</code></h3>
<p>在<code>rust</code>中，我们可以在一个文件中使用<code>mod</code>关键字定义一个或多个模块。模块内部可以存在各种语言支持的元素，如<code>struct</code> <code>enum</code> <code>constant</code> <code>trait</code> <code>function</code>等。这样的便利性，让我们可以更自由的以领域为中心去组织代码，从而提升代码的内聚性，降低耦合度。并且我们不用担心像<code>java</code>一样默认一个类对应一个文件，从而导致过多的文件。</p>
<p>同时<code>rust</code>在设计上默认限制访问方式为<code>private</code>，即仅供模块或结构体内部访问。这里的<code>private</code>限制包括：1. <code>struct</code>的内部属性默认无法从外部访问；2. <code>struct</code>的方法，默认无法从外部调用；3. 模块内部所有的元素默认均无法从外部访问；4. 模块默认可以访问其父模块的元素。</p>
<p>由于默认的<code>private</code>访问限制，<code>rust</code>程序将极大减少对外暴露非必须的接口，从语言设计层面促进了高内聚低耦合的特性。</p>
<h3 id="数据默认不可变"><a class="markdownIt-Anchor" href="#数据默认不可变"></a> 数据默认不可变</h3>
<p>默认情况下，<code>rust</code>中的数据都是不可变的，如果要使得数据可变，我们需要额外添加关键字<code>mut</code>，来显示的指定其可变性。</p>
<p>我们知道函数式编程特性中最重要的一点就要算不可变性了。正是由于数据不可变，我们可以轻松的在多线程中共享这些数据，可以轻松的实现惰性优化，或通过适当的重复计算来实现自动故障处理等。数据不可变还常常带来纯函数的特性，从而使得代码更易于理解。</p>
<p><code>rust</code>在语言级别对数据的可变性提供了支持，除非我们显示的标记某一变量为<code>mut</code>可变，否则我们将无法修改其内部数据。<code>rust</code>提供的不可变标记比其他语言提供的不可变性要更严格，它真正表达了一组无法改变的状态。在<code>scala</code>或<code>typescript</code>中，我们可以通过<code>val</code>或者<code>const</code>来定义不可变的变量。但是它们仅仅标记为对应的变量不可重复赋值。我们依然可以改变变量对应的对象的内部状态。而在<code>rust</code>中，如果我们尝试这么做，我们的代码将连编译都无法通过。</p>
<h3 id="实现错误处理的精致语法糖"><a class="markdownIt-Anchor" href="#实现错误处理的精致语法糖"></a> 实现错误处理的精致语法糖</h3>
<p>在<code>rust</code>中，我们没有类似<code>java</code>一样的异常处理手段。比如，我们没法新建一个异常对象，然后<code>throw</code>到更上层。我们当然也没法<code>catch</code>住异常，而进行不同的处理。</p>
<p><code>rust</code>提供了一种类似<code>c</code>语言的异常处理机制，即，通过函数调用结果来返回异常数据。这里可能有人会担心我们代码写得像<code>c</code>语言一样，遇到异常就要加一个<code>if</code>判断语句进行处理。这里的担心是多余的，<code>rust</code>语言在设计上专门为异常处理进行了特别的设计。</p>
<p>由于<code>rust</code>内建了强大的类型系统，所以，如果有异常发生，我们将会得到一个枚举类型的<code>Result&lt;T, E&gt;</code>值，它可能有<code>Ok(T)</code>或<code>Err(E)</code>两种情况。这时我们可以对返回的结果通过<code>match</code>语法进行类似<code>scala</code>提供的模式匹配进行处理。</p>
<p>但是，如果每个地方都需要<code>match</code>，那也将带来满屏幕的异常处理代码。<code>rust</code>是如何处理的呢？</p>
<p>其实我们平常处理的异常可以分为两类：1. 不可恢复异常；2. 可恢复异常。</p>
<p>对于不可恢复异常，通常是我们的代码写得不对，或者输入违反了某一个明确的假设，比如，越界访问一个数组就属于这种情况(<code>let a = [1, 2]; let b = a[2];</code>)。对于这个例子中的不可恢复异常，我们应当加入适当的越界判断逻辑，也就是说我们应该完善代码。这时通常的错误处理做法是，输出明确的被违反的假设，然后直接退出程序。<code>rust</code>为我们设计了<code>panic</code>宏方法以达到此目的。</p>
<p>对于可恢复异常，我们即可使用上述枚举类型<code>Result&lt;T, E&gt;</code>来进行处理。在我们的程序中，大部分异常都应当通过不可恢复异常进行处理。真正需要通过结果类型处理的异常会被限制到，比如文件读取错误，没有权限，自定义的必须要处理的异常等。</p>
<p>同时，对于我们常常需要调用的<code>match result &#123; ... &#125;</code>语句，<code>rust</code>提供了多种语法糖进行处理。如果我们需要<code>panic</code>，只需要调用<code>result.unwrap()</code>即可达到此目的，如果想要在<code>panic</code>时输出一些信息，则可以使用<code>result.expect(&quot;some message&quot;)</code>来实现。如果我们需要冒泡式的将异常抛出到上层进行处理，我们只需要在访问变量之前增加一个问号，即<code>let result = result?</code>，然后我们就可以在后续代码直接使用<code>result</code>变量了，就像没有异常一样。</p>
<p>总之，<code>rust</code>设计了非常精致而简洁的语法糖来支持异常处理，可以帮助我们编写健壮而简洁的代码。大家如想了解更多，请参考<a href="https://kaisery.github.io/trpl-zh-cn/ch09-00-error-handling.html">这里</a>。</p>
<h3 id="强大的类型推断和贴心的编译提示"><a class="markdownIt-Anchor" href="#强大的类型推断和贴心的编译提示"></a> 强大的类型推断和贴心的编译提示</h3>
<p>用过<code>rust</code>的人，相信都会喜欢上<code>rust</code>强大的编译器，它的强大类型推断能力，可以让我们少写很多代码。</p>
<p><code>rust</code>的编译器可以让我们尽量少做类型标注。</p>
<p>比如我们写下代码<code>let mut map = HashMap::new(); map.insert(&quot;abc&quot;, 123);</code>时，<code>rust</code>将自动的推断出<code>map</code>的类型为<code>HashMap&lt;&amp;str, i32&gt;</code>。我们无需在定义<code>map</code>变量时指定类型。</p>
<p>再比如，当我们写下代码<code>let a: Vec&lt;i32&gt; = (0..100).collect();</code>时，<code>rust</code>自动为我们调用了生成<code>Vector</code>的函数。而当我们写下代码<code>let a: HashMap&lt;i32, i32&gt; = (0..100).zip((100..200)).collect();</code>时，<code>rust</code>又自动为我们调用了生成<code>HashMap</code>的函数。</p>
<p>喜欢<code>rust</code>编译器的另一个理由是其强大的发现错误的能力和贴心的编译提示。一个强大的编译器可以让很多错误提前暴露到编译期，以便我们可以更早的发现问题。谁也不想程序运行一段时间之后才报告有<code>bug</code>。尽管有时候<code>rust</code>编译器提示太多难免让人觉得沮丧，但我们最终总是会感谢它帮我们发现了很多低级的问题，节约了我们大量的时间。同时，我们也会感谢它推动了代码的风格一致性，编码的严谨性。</p>
<p>举个例子，由于<code>rust</code>具有不少内存访问规则限制，如果要人为分析变量的所有权（ownership），可能要让很多人望而生畏了。<code>rust</code>的编译器可以贴心的指出我们代码中的问题，比如，如果我们编写了如下代码，它涉及到引用的问题：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">test</span>() &#123;</span><br><span class="line">    <span class="meta">#[derive(Debug)]</span></span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">B</span> &#123; b: <span class="type">i32</span> &#125;;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">b</span> = B &#123; b: <span class="number">10</span> &#125;;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">b1</span> = &amp;<span class="keyword">mut</span> b;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">b2</span> = &amp;b;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;b1: &#123;:?&#125;&quot;</span>, b1); <span class="comment">// 防止 b1 的生命周期提前结束</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当我们尝试编译此代码时，我们将得到如下错误：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">error[E0502]: cannot borrow `b` as immutable because it is also borrowed as mutable</span><br><span class="line">  --&gt; rust_test/src/lib.rs:70:26</span><br><span class="line">   |</span><br><span class="line">69 |                 let b1 = &amp;mut b;</span><br><span class="line">   |                          ------ mutable borrow occurs here</span><br><span class="line">70 |                 let b2 = &amp;b;</span><br><span class="line">   |                          ^^ immutable borrow occurs here</span><br><span class="line">72 |                 println!(&quot;b1: &#123;:?&#125;&quot;, b1);</span><br><span class="line">   |                                      -- mutable borrow later used here</span><br></pre></td></tr></table></figure>
<p>类似这样的地方还有很多，大家一上手便可以感受到。其实，<code>rust</code>的编译器不仅能清晰的指出问题，它还常常能给出我们要如何修改代码的建议。</p>
<p>比如，<code>rust</code>默认会在编译时检查变量是否使用过，对没有使用的变量会打印警告，并提示你<code>note: #[warn(unused_must_use)] on by default</code>，这时我们可能可以选择性的将这个编译选项关闭。</p>
<p>还比如，如果我们尝试格式化的打印一个没有实现<code>Debug</code> <code>trait</code>的<code>struct</code>（比如当上述代码中的<code>struct B</code>没有<code>#[derive(Debug)]</code>标记时），<code>rust</code>将拒绝编译代码，并提示<code>note: add #[derive(Debug)] or manually implement std::fmt::Debug</code>。</p>
<p>在遇到这类错误，并得到<code>rust</code>编译器贴心的<code>help</code>或<code>note</code>时，我们写代码也会感受到一丝丝温暖。</p>
<h3 id="变量隐藏及强大的解构赋值"><a class="markdownIt-Anchor" href="#变量隐藏及强大的解构赋值"></a> 变量隐藏及强大的解构赋值</h3>
<p><code>rust</code>另一个让我觉得特别方便的地方是在同一个作用域内，我们可以定义重名的变量，这些重名的变量会隐藏掉之前的变量。比如，我们可以编写代码：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">x</span> = String::<span class="title function_ invoke__">new</span>(<span class="string">&quot;&#123;\&quot;x\&quot;: 1&#125;&quot;</span>);</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">x</span> = <span class="title function_ invoke__">parse_json</span>(x);</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">x</span> = x.x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>一般的静态类型语言都不支持在同一个作用域内定义重名变量，而是只支持父子作用域的同名变量隐藏。偏爱<code>python</code>的小伙伴会喜欢<code>rust</code>的这一特性，因为<code>python</code>的动态类型使得我们可以完成与上面类似的代码。</p>
<p>有人会担心同一个作用域内定义重名变量会带来不易读的代码，但是如果我们秉承小函数的思路，其实由于变量重名而带来的可读性问题基本不会发生。反而，我们常常要为属于不同的类型的同一个概念想出不同的名字，这让人很难受。</p>
<p>比如，上述代码在<code>scala</code>中，我们常常要给变量添加没必要的类型后缀，写成：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">App</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> xJsonStr = <span class="string">&quot;&#123;\&quot;x\&quot;: 1&#125;&quot;</span>;</span><br><span class="line">    <span class="keyword">val</span> xJson = parseJson(xJsonStr);</span><br><span class="line">    <span class="keyword">val</span> x = xJson.x;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同时，提到赋值，不得不称赞的是<code>rust</code>强大的解构赋值功能。我们可以编写下面这样的代码：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">p</span> = Point &#123; x: <span class="number">0</span>, y: <span class="number">7</span> &#125;;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">Point</span> &#123; x: a, y: b &#125; = p;</span><br><span class="line">    <span class="keyword">let</span> (x, y, z) = (<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>);</span><br><span class="line">    <span class="keyword">let</span> ((a, b), Point &#123;x, y&#125;) = ((<span class="number">3</span>, <span class="number">10</span>), Point &#123; x: <span class="number">3</span>, y: -<span class="number">10</span> &#125;);</span><br><span class="line">    <span class="comment">// 在for循环语句中进行解构</span></span><br><span class="line">    <span class="title function_ invoke__">for</span> (index, value) <span class="keyword">in</span> v.<span class="title function_ invoke__">iter</span>().<span class="title function_ invoke__">enumerate</span>() &#123;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 在if-let语句中进行解构</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Some</span>(color) = favorite_color &#123;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 在函数入参中进行解构</span></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">print_coordinates</span>(&amp;(x, y): &amp;(<span class="type">i32</span>, <span class="type">i32</span>)) &#123;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 在match语句进行解构</span></span><br><span class="line">    <span class="keyword">match</span> x &#123;</span><br><span class="line">        <span class="number">1</span> | <span class="number">2</span> =&gt; <span class="built_in">println!</span>(<span class="string">&quot;one or two&quot;</span>),</span><br><span class="line">        <span class="number">3</span> =&gt; <span class="built_in">println!</span>(<span class="string">&quot;three&quot;</span>),</span><br><span class="line">        <span class="number">4</span>..=<span class="number">10</span> =&gt; <span class="built_in">println!</span>(<span class="string">&quot;four through ten&quot;</span>),</span><br><span class="line">        _ =&gt; <span class="built_in">println!</span>(<span class="string">&quot;something else&quot;</span>),</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="其他"><a class="markdownIt-Anchor" href="#其他"></a> 其他</h3>
<h4 id="使用引用传递避免非预期的内存拷贝"><a class="markdownIt-Anchor" href="#使用引用传递避免非预期的内存拷贝"></a> 使用引用传递，避免非预期的内存拷贝</h4>
<p>除了一些拷贝成本极低的基本类型数据，<code>rust</code>内部总是使用引用传递数据，所以，我们无需担心非预期的拷贝。<code>rust</code>不会通过编译生成这样的拷贝内存的代码。如果我们要拷贝一个对象，我们需要显示的调用<code>clone</code>方法。</p>
<h4 id="推荐通过线程间通信来共享数据"><a class="markdownIt-Anchor" href="#推荐通过线程间通信来共享数据"></a> 推荐通过线程间通信来共享数据</h4>
<p>解决线程间通信问题时，<code>rust</code>提供了用于线程间通信的<code>channel</code>模式，这与<code>go</code>的线程共享数据的哲学类似：<code>Do not communicate by sharing memory; instead, share memory by communicating.</code></p>
<p>当然<code>rust</code>还支持通过传递变量所有权的方式，将变量安全的在线程间进行传递。</p>
<p>除此之外，<code>rust</code>还支持通过<code>Mutex</code>来实现共享对象的锁定访问。</p>
<h4 id="内建的测试支持"><a class="markdownIt-Anchor" href="#内建的测试支持"></a> 内建的测试支持</h4>
<p><code>rust</code>内建了对于测试的支持，不仅如此，<code>rust</code>甚至在设计层面有意识的区分了<code>单域测试</code>与<code>集成测试</code>两种不同的测试类型。这两种测试种类其实有着非常不同的属性。单元测试通常应该使用<code>mock</code>来构建，它应该非常快，测试到的路径足够多。而集成测试，通常为了验证模块之间是否能整合在一起工作，对于执行速度没有过于苛刻的要求。</p>
<p>对于单元测试，我们只需要在同一文件里面编写即可。而对于集成测试，我们需要放到一个单独的文件夹下面。</p>
<p><code>rust</code>内建了常用的<code>assert</code>语句，同时还支持了在文档中编写的测试，即<code>doctest</code>（喜欢这一风格的<code>python</code>爱好者也将很乐意见到这样的支持）。</p>
<h4 id="统一的工程管理工具"><a class="markdownIt-Anchor" href="#统一的工程管理工具"></a> 统一的工程管理工具</h4>
<p><code>rust</code>提供了一套类似<code>npm</code>的统一的工程管理工具<code>cargo</code>。<code>npm</code>的使用，极大的促进了<code>javascript</code>生态的发展。同样，<code>cargo</code>让我们使用<code>rust</code>与使用<code>nodejs</code>一样简单，源代码组织形式一致，依赖管理便利。</p>
<p>其实，相比<code>npm</code>，<code>cargo</code>可以说走得更进了一步。<code>cargo</code>不仅提供了工程管理规范，甚至有关于文档的规范。只要我们按照<code>cargo</code>的规范去组织文档，那么我们运行<code>cargo doc</code>即可生成项目文档了。这一点跟<code>javadoc</code>类似。</p>
<h4 id="编译与方便的交叉编译"><a class="markdownIt-Anchor" href="#编译与方便的交叉编译"></a> 编译与方便的交叉编译</h4>
<p>作为性能可以媲美<code>c</code>语言的高性能语言，<code>rust</code>将代码直接编译为机器码，并尽可能的将引用到的库进行静态链接。这一点跟<code>go</code>语言很类似。它极大的方便了我们对于程序的维护管理。在我们的实践中，一个编译好的二进制代码，可以在各种linux发行版中运行，无需安装其他依赖(<code>glibc</code>除外，除非我们编译<code>musl</code>版本)。类比<code>java</code>可知，我们至少需要安装<code>jre</code>，这带来了些许不便。如果我们愿意，我们甚至可以在一台裸的容器(通过<code>FROM scratch</code>创建)里面运行<code>rust</code>程序，除了系统内核，无需任何其他依赖支持。</p>
<p><code>rust</code>不仅以二进制机器码为编译目标，而且支持广泛的运行平台。<a href="https://forge.rust-lang.org/release/platform-support.html">这里</a>有一个列表。可以看到，我们甚至可以将<code>rust</code>程序运行在<code>android</code>或者<code>iOS</code>系统中。</p>
<p>同时，<code>rust</code>的交叉编译也是很方便的，我在<code>windows</code>上面，通过为数不多的几步操作，就可以用<code>llvm</code>编译一个<code>musl</code>版本的二进制可执行程序出来。</p>
<h4 id="高级特性支持"><a class="markdownIt-Anchor" href="#高级特性支持"></a> 高级特性支持</h4>
<p><code>rust</code>已经支持了很多我们所喜欢的高级特性，包括<code>async/await</code>的异步编程模式，元编程等。也包括很多较底层的特性，包括和<code>c</code>语言库的互操作性、内联汇编等。</p>
<h2 id="编码时一些烦人的限制"><a class="markdownIt-Anchor" href="#编码时一些烦人的限制"></a> 编码时一些（烦人的）限制</h2>
<p><code>rust</code>为了达到的安全和高性能的设计目标，当然还是损失了一定的易用性的。相比<code>java</code> <code>scala</code> <code>javascript</code>或<code>python</code>这类高级语言，我们可能会在下面这几点中折腾挺长时间：</p>
<ol>
<li>编译期分配的内存大小必须编译期可知，使用基于<code>trait</code>的多态时，我们不得不利用<code>Box&lt;dyn trait&gt;</code>进行封装</li>
<li>相比java，引入的概念更多，上手难度更高</li>
<li>IDE集成不够，调试体验较差，对<code>macro</code>编译期生成的代码支持较差</li>
<li>即便有IDE支持也很难一次性通过编译</li>
</ol>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>总结起来，通过在线上机器学习推理的场景中尝试使用<code>rust</code>，我们发现<code>rust</code>在设计上拥抱了非常多先进的编程理念。在我看来，作为一个开发者，无论我们是否会在将来的项目中使用<code>rust</code>语言，这门语言都非常值得大家学习。它不仅仅是一门新的编程语言，更是一系列优秀的编程实践的集合，相信所有学习过<code>rust</code>的小伙伴都将有巨大的收获，也将潜移默化的指导我们以后编写的每一行代码。</p>
<p><code>rust</code>无疑为高性能服务器编程提供了另一个选择，当前<code>rust</code>的发展可谓非常快速。但，<code>rust</code>可能还需要一个明星项目来为其背书，才能使其得到进一步的推广，让我们期待这样的明星项目的诞生。</p>
]]></content>
      <categories>
        <category>技术</category>
        <category>rust</category>
      </categories>
      <tags>
        <tag>性能</tag>
        <tag>高性能</tag>
      </tags>
  </entry>
  <entry>
    <title>程序员需要知道的C/C++编译知识</title>
    <url>/2020/03/29/native-code-compilation-process-programmers-should-know/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>作为一个非专业<code>c/c++</code>开发人员，相信很多人跟我一样，常常会在跟<code>c/c++</code>打交道时碰到困难。然而，我们所使用的很多底层的库或软件，却有大量是用<code>c/c++</code>编写而成。所以，了解一些基本的<code>c/c++</code>知识对于非专业<code>c/c++</code>开发人员将非常有帮助。</p>
<p>在下面这些典型的场景中，我们可能会需要用到这些知识：</p>
<ul>
<li>当由于平台需要，我们需要自己编译某些<code>c/c++</code>项目</li>
<li>当需要在非<code>c/c++</code>程序里面进行少量的<code>c/c++</code>开发，并与<code>c/c++</code>代码交互</li>
<li>遇到一些常见的库找不到、版本不兼容等问题</li>
</ul>
<p>本文尝试总结一下基本的<code>c/c++</code>知识，包括常见的平台、静态库/动态库的原理、基础编译指令等。并将结合一些实例来加深理解。</p>
<span id="more"></span>
<h2 id="平台"><a class="markdownIt-Anchor" href="#平台"></a> 平台</h2>
<p>与一般的跨平台语言（如java、python、nodejs等）不同，如果我们要用<code>c/c++</code>来开发一个项目，首先要考虑的问题就是平台支持问题。</p>
<p>什么是平台？一般而言，我们可以将平台理解为一套基础设施，它由一组特定的硬件和软件构成，并使得应用软件可以运行于其上。从硬件层面上讲，平台会主要根据cpu架构不同而不同。由于cpu指令集不同，虽然是同样的代码，往往也会编译为不同的机器码来执行，这就造成了不同平台间显著的差异。从软件层面上讲，平台会主要根据操作系统不同而不同。由于操作系统不同，应用程序接口及系统调用也相应不同，这也造成了不同平台间显著的差异。</p>
<p>一些常见的平台比如：</p>
<ul>
<li>Intel 32/64位 CPU + Linux / Windows / macOS</li>
<li>Arm CPU + Linux / Windows / macOS</li>
</ul>
<p>如果我们日常每写一行代码都要去考虑平台支持，那将大大降低效率。事实上，现在我们的<code>c/c++</code>程序都会基于一些基础的跨平台库来开发。最经典的莫过于标准<code>c</code>库和标准<code>c++</code>库了，我们开发的几乎所有应用层程序都是基于这些标准库的。</p>
<p>然而这些库的跨平台性怎么样呢？这里不得不提到POSIX标准。</p>
<p><code>POSIX</code> 的全称是 Portable Operating System Interface。它是为维护操作系统间的兼容性而定义的一系列标准。<code>POSIX</code>定义了操作系统应用程序接口，<code>shell</code>及一些实用工具。最初是为 <code>Unix</code> 系列操作系统定义，所以在<code>Unix</code>系列操作系统中能拥有良好的兼容性。一些<code>POSIX</code>兼容的操作系统包括 <code>macOS</code> <code>Solaris</code> <code>AIX</code>等，还有由华为公司维护的<code>EulerOS</code>。拥有绝大部分兼容性的包括 <code>Android</code> <code>GNU/Linux</code> <code>OpenBSD</code> <code>FreeBSD</code>等。而 <code>Windows</code> 对于<code>POSIX</code>标准的兼容性几乎都是由社区提供，如<code>Cygwin</code> <code>MinGW</code>等，微软自己提供的<code>C Runtime Library</code>只实现了常用的接口，兼容性具有不确定性。</p>
<p>既然是这样，我们就多多少少需要关注一下代码的跨平台性了。如果我们只调用常用的标准库<code>API</code>，那么程序的兼容性一般是有保障的。而如果我们调用一些平台相关的<code>API</code>，那么在向其他平台移植时，将不得不考虑如何处理这些<code>API</code>。</p>
<p>一般而言，我们在开发<code>c/c++</code>程序时，需要考虑支持大家广泛使用的平台，如 <code>Intel 64bit CPU</code> + <code>Linux</code> / <code>Windows</code> / <code>macOS</code> 。这主要是由于我们很可能有人在 <code>macOS</code> 或 <code>Windows</code> 上面进行日常的开发工作，而程序最终被发布到 <code>Linux</code> 上面去运行。</p>
<h2 id="编译过程与依赖库"><a class="markdownIt-Anchor" href="#编译过程与依赖库"></a> 编译过程与依赖库</h2>
<p>如果我们只需要编写一个比较简单的没有依赖库的应用，我们可能根本不需要关心程序库。现代的编译器或者IDE会自动帮我们处理好内部的库引用问题。但是，一旦我们的程序比较复杂，或者需要引用其他非标准库，我们就需要关心程序库的运行机制了。</p>
<p>一个最简单的 <code>HelloWorld</code> 程序可以用<code>c</code>语言编写如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// hello_world.c</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span>* argv[])</span> &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello World!\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在<code>Linux</code>下，如果我们要将其编译为一个可执行的程序，使用<code>gcc</code>编译器，只需要运行命令<code>gcc hello_world.c</code>即可。运行此命令之后，<code>gcc</code>会在当前目录下生成一个名为<code>a.out</code>的可执行程序。运行此程序就可以在控制台打印<code>Hello World!</code>了。</p>
<p>看起来整个过程似乎跟程序库没有关系，但是如果我们思考一下<code>printf</code>函数是如何来的，就会发现情况不对。其实，就算是这个简单的程序，背后也会有一个程序库来支持，它就是前面提到的<code>c</code>标准库。<code>printf</code>函数是<code>c</code>标准库提供的一个<code>API</code>，在<code>Linux</code>下面，它的二进制代码一般位于文件<code>/usr/lib/x86_64-linux-gnu/libc.so</code>中。</p>
<p>事实上，整个编译过程将分为以下4个步骤完成：</p>
<ol>
<li>预处理，处理源代码中的文件包含、宏展开等，通过<code>gcc -E hello_world.c</code>命令可以看到预处理结果</li>
<li>编译，将预处理后的文件编译为汇编代码，通过<code>gcc -S hello_world.c</code>命令可以生成汇编文件<code>hello_world.s</code></li>
<li>汇编，将编译之后的汇编代码生成可重定向的二进制文件，通过<code>gcc -c hello_world.c</code>命令可生成文件<code>hello_world.o</code></li>
<li>链接，将可重定向文件与库文件一起链接生成可执行的二进制文件，通过<code>gcc hello_world.o</code>可生成文件<code>a.out</code></li>
</ol>
<p>在<code>macOS</code>和<code>Windows</code>上，我们可以使用<a href="https://clang.llvm.org/docs/UsersManual.html#introduction"><code>llvm clang</code></a>和<a href="https://docs.microsoft.com/en-us/cpp/build/reference/compiler-options-listed-by-category?view=vs-2019"><code>cl</code></a>命令进行编译，编译过程与上述过程类似。</p>
<p>如何查看生成的二进制可执行文件中链接的库呢？</p>
<p>在<code>Linux</code>中，我们可以通过<code>ldd</code>命令来查看二进制文件中链接的库。如果我们执行<code>ldd a.out</code>，即可以看到类似下面的输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># ldd a.out</span><br><span class="line">    linux-vdso.so.1 (0x00007ffd7d934000)</span><br><span class="line">    libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f6006bac000)</span><br><span class="line">    /lib64/ld-linux-x86-64.so.2 (0x00007f600719f000)</span><br></pre></td></tr></table></figure>
<p>而在<code>macOS</code>和<code>Windows</code>上，我们可以使用<code>otool -L a.out</code>和<code>dumpbin /dependents hello_world.exe</code>达到相似的目的。</p>
<h2 id="静态库与动态库"><a class="markdownIt-Anchor" href="#静态库与动态库"></a> 静态库与动态库</h2>
<p>上面我们看到了一个简单的单文件源代码程序的编译，那么对于一个多文件源代码程序，情况是怎么样的呢？事实上编译器会将文件一个接一个进行编译，然后再通过第四步将编译好的二进制文件链接成为一个可执行程序。</p>
<p>比如，我们要实现一个乘法运算，有两个源代码文件及一个用于引用的头文件，代码如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// mul.c</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">mul</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> a * b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// mul.h</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">mul</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// main_mul.c</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;mul.h&quot;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span>* argv[])</span> &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;mul of %d and %d is %d&quot;</span>, <span class="number">2</span>, <span class="number">4</span>, mul(<span class="number">2</span>, <span class="number">4</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行<code>gcc --save-temps mul.c main_mul.c</code>即可生成可执行程序<code>a.out</code>，并保留所有的临时文件。</p>
<p>这里生成的可执行文件在运行时不再需要<code>mul.o</code>文件的存在了，它内部其实已经包括了<code>mul.o</code>文件的内容。这时，在程序进行链接时，<code>mul.o</code>与<code>main_mul.o</code>两个文件静态的链接到了一起。</p>
<p>如果我们想独立的发布<code>mul.c</code>文件中的内容，作为一个依赖库供其他人使用，该如何操作呢？这里我们就要用到静态库了。我们可以将多个中间二进制文件(<code>.o</code>文件)打包为一个文件，然后向他人提供这个文件。</p>
<p>通过命令<code>ar -rv libmul.a mul.o</code>即可生成一个名为<code>libmul.a</code>的静态库文件。而想要链接这个静态库文件，我们只需要运行命令<code>gcc -L. -lmul main_mul.c</code>即可生成与前面相同的<code>a.out</code>可执行程序。</p>
<p>用于<code>macOS</code>下编译器的<code>llvm clang</code>提供了与<code>gcc</code>兼容的命令行参数，我们只需要将上述<code>gcc</code>更换为<code>clang</code>即可达到相同的效果。<code>Windows</code>下，我们需要运行<code>cl mul.c mul.lib</code>以生成一个静态库文件，然后运行<code>cl /Femain.exe main_mul.c mul.lib</code>生成可执行程序。</p>
<p>使用静态库一个不方便的地方在于，库与可执行程序打包到了一起，这会导致生成的可执行程序较大，并且不方便库进行独立升级。这时，聪明的开发者们又想到了其他的办法，那就是动态库。动态库以一个独立的文件形式提供，程序在生成时并不打包动态库的内容，而是在运行时与库进行动态的链接。这就可以解决上面的两个问题了。</p>
<p>如何创建动态库呢？使用<code>gcc</code>，我们只需要运行命令<code>gcc -shared -fPIC mul.c -o libmul.so</code>即可生成一个名为<code>libmul.so</code>的动态库文件。而在创建可执行程序时，需要运行命令<code>gcc main_mul.c -L. -lmul</code>。在<code>macOS</code>下将<code>gcc</code>替换为<code>clang</code>即可。在<code>Windows</code>下，则运行<code>cl /LD mul.cc</code>及<code>cl main_mul.c /link mul.lib</code>即可。</p>
<p>大家可能注意到了在<code>Linux</code>和<code>macOS</code>下都需要在生成的库文件名添加一个<code>lib</code>前缀，这是由于历史原因造成的，链接器<code>ld</code>在查找库文件时会自动添加此前缀。</p>
<p>还需要注意的一点是，在<code>Windows</code>上面直接运行上述命令会失败，因为为了定义一个动态库函数，我们一般需要在函数定义时添加一个<code>__declspec(dllexport)</code>编译符号。而在使用动态库函数时，需要在声明函数时，显示的添加前缀<code>__declspec(dllimport)</code>。具体的解释，请参考<a href="https://docs.microsoft.com/en-us/cpp/build/exporting-from-a-dll?view=vs-2019">这里</a>。</p>
<h2 id="动态库的工作原理"><a class="markdownIt-Anchor" href="#动态库的工作原理"></a> 动态库的工作原理</h2>
<p>虽然很多平台都实现了动态库的功能，但是这些实现之间却有所不同。了解了动态库的实现原理，在遇到的动态库相关问题时，我们就可以更从容的去解决。下面对动态库实现原理进行简要介绍。</p>
<p>首先我们了解一下编译出来的二进制文件内容（这里的二进制文件包括动态库文件、中间二进制文件、可执行文件）。各个平台虽然都有自己的二进制格式标准，但大都基于一种通用的<a href="https://zh.wikipedia.org/wiki/COFF"><code>coff</code></a>(Common Object File Format)格式演进而来。在<code>linux</code>下，二进制文件采用<code>elf</code>格式，<code>windows</code>使用<code>pe</code>格式，<code>macOS</code>使用<code>mach-o</code>格式。虽然有所不同，这些格式都包括这几种元素：</p>
<ul>
<li>用于确定文件类型的魔数（Magic Number，比如<code>elf</code>格式为<code>7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00</code>）</li>
<li>包含文件信息的表（Program header），比如文件运行的平台，编译信息，长度等</li>
<li>节头（section headers），二进制文件按节进行组织</li>
<li>节体（section data），具体的节的内容</li>
</ul>
<p>对于同样的源代码文件在不同的平台编译，如果<code>cpu</code>相同，那么编译出来的二进制机器码也几乎是相同的。它们之间的差异通常在这几方面：</p>
<ul>
<li>链接的<code>c</code>库，不同的平台有不同的<code>c</code>库实现</li>
<li>启动和退出逻辑</li>
<li>节组织，<code>elf</code>格式的代码段一般是<code>.text</code>，而<code>pe</code>格式为<code>.code</code></li>
</ul>
<p>除机器码之外，二进制文件的其他节的内容是为密切配合操作系统的二进制文件加载方式而设计实现的。</p>
<p>源代码经过编译得到中间二进制文件，但是由于每个源代码文件单独编译，它们并不知道自己引用的外部函数或变量的地址。编译时通常将这些外部符号地址设置为一些特殊值，并记录到特定的节中，以便链接时可以正确的对他们进行修正。比如</p>
<p>如果我们用<code>objdump -S main_mul.o</code>命令查看前面编译出来的文件的汇编代码，可以看到以下汇编代码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">main_mul.o:     file format elf64-x86-64</span><br><span class="line"></span><br><span class="line">Disassembly of section .text:</span><br><span class="line"></span><br><span class="line">0000000000000000 &lt;main&gt;:</span><br><span class="line">   0:   55                      push   %rbp</span><br><span class="line">   1:   48 89 e5                mov    %rsp,%rbp</span><br><span class="line">   4:   48 83 ec 10             sub    $0x10,%rsp</span><br><span class="line">   8:   89 7d fc                mov    %edi,-0x4(%rbp)</span><br><span class="line">   b:   48 89 75 f0             mov    %rsi,-0x10(%rbp)</span><br><span class="line">   f:   be 04 00 00 00          mov    $0x4,%esi</span><br><span class="line">  14:   bf 02 00 00 00          mov    $0x2,%edi</span><br><span class="line">  19:   e8 00 00 00 00          callq  1e &lt;main+0x1e&gt;</span><br><span class="line">  1e:   89 c1                   mov    %eax,%ecx</span><br><span class="line">  20:   ba 04 00 00 00          mov    $0x4,%edx</span><br><span class="line">  25:   be 02 00 00 00          mov    $0x2,%esi</span><br><span class="line">  2a:   48 8d 3d 00 00 00 00    lea    0x0(%rip),%rdi        # 31 &lt;main+0x31&gt;</span><br><span class="line">  31:   b8 00 00 00 00          mov    $0x0,%eax</span><br><span class="line">  36:   e8 00 00 00 00          callq  3b &lt;main+0x3b&gt;</span><br><span class="line">  3b:   b8 00 00 00 00          mov    $0x0,%eax</span><br><span class="line">  40:   c9                      leaveq</span><br><span class="line">  41:   c3                      retq</span><br></pre></td></tr></table></figure>
<p>其中第<code>0x19</code>位置的指令使用<code>callq</code>调用了<code>mul</code>函数，这里的<code>mul</code>函数的地址是<code>0x1e</code>，对应重定位代码节<code>.rela.text</code>中的<code>mul</code>。使用命令<code>readelf -r main_mul.o</code>可以看到重定位代码节的内容：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Relocation section &#x27;.rela.text&#x27; at offset 0x270 contains 3 entries:</span><br><span class="line">  Offset          Info           Type           Sym. Value    Sym. Name + Addend</span><br><span class="line">00000000001a  000b00000004 R_X86_64_PLT32    0000000000000000 mul - 4</span><br><span class="line">00000000002d  000500000002 R_X86_64_PC32     0000000000000000 .rodata - 4</span><br><span class="line">000000000037  000c00000004 R_X86_64_PLT32    0000000000000000 printf - 4</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>而当我们用<code>objdump -S a.out</code>命令查看链接得到的可执行文件时，可以看到链接器对于位置修正的结果：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">000000000000064a &lt;main&gt;:</span><br><span class="line"> 64a:   55                      push   %rbp</span><br><span class="line"> 64b:   48 89 e5                mov    %rsp,%rbp</span><br><span class="line"> 64e:   48 83 ec 10             sub    $0x10,%rsp</span><br><span class="line"> 652:   89 7d fc                mov    %edi,-0x4(%rbp)</span><br><span class="line"> 655:   48 89 75 f0             mov    %rsi,-0x10(%rbp)</span><br><span class="line"> 659:   be 04 00 00 00          mov    $0x4,%esi</span><br><span class="line"> 65e:   bf 02 00 00 00          mov    $0x2,%edi</span><br><span class="line"> 663:   e8 92 00 00 00          callq  6fa &lt;mul&gt;</span><br><span class="line"> 668:   89 c1                   mov    %eax,%ecx</span><br><span class="line"> 66a:   ba 04 00 00 00          mov    $0x4,%edx</span><br><span class="line"> 66f:   be 02 00 00 00          mov    $0x2,%esi</span><br><span class="line"> 674:   48 8d 3d 19 01 00 00    lea    0x119(%rip),%rdi        # 794 &lt;_IO_stdin_used+0x4&gt;</span><br><span class="line"> 67b:   b8 00 00 00 00          mov    $0x0,%eax</span><br><span class="line"> 680:   e8 9b fe ff ff          callq  520 &lt;printf@plt&gt;</span><br><span class="line"> 685:   b8 00 00 00 00          mov    $0x0,%eax</span><br><span class="line"> 68a:   c9                      leaveq</span><br><span class="line"> 68b:   c3                      retq</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">00000000000006fa &lt;mul&gt;:</span><br><span class="line"> 6fa:   55                      push   %rbp</span><br><span class="line"> 6fb:   48 89 e5                mov    %rsp,%rbp</span><br><span class="line"> 6fe:   89 7d fc                mov    %edi,-0x4(%rbp)</span><br><span class="line"> 701:   89 75 f8                mov    %esi,-0x8(%rbp)</span><br><span class="line"> 704:   8b 45 fc                mov    -0x4(%rbp),%eax</span><br><span class="line"> 707:   0f af 45 f8             imul   -0x8(%rbp),%eax</span><br><span class="line"> 70b:   5d                      pop    %rbp</span><br><span class="line"> 70c:   c3                      retq</span><br><span class="line"> 70d:   0f 1f 00                nopl   (%rax)</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>上面<code>0x663</code>位置的指令对应前面<code>main_mul.o</code>中的<code>0x19</code>位置的指令，而这里的<code>mul</code>函数的地址已经被修正为<code>0x6fa</code>，即函数<code>mul</code>第一条指令的地址。</p>
<p>如果是静态链接，最后得到的是一个大的二进制文件，里面的符号地址可以在链接时全部被正确修正。但是如果是动态链接，情况就比较复杂了。由于操作系统将动态库加载到什么地址会动态变化，是不确定的，所以也就不能简单的预先进行地址修正。</p>
<p>事实上，之所以称作动态链接，正是由于这些库的链接过程（地址修正过程）是在运行时完成的。关于动态链接的原理，可以简单说明如下。对于一个动态库，一般情况下，我们首先将其编译为一个地址无关代码存储起来（地址无关代码可以简单理解为用相对地址进行变量或函数寻址，这也是<code>gcc</code>编译时参数<code>-fPIC</code>的作用，<code>PIC</code>的全称就是position independent code），当操作系统在加载这些地址无关代码时，动态链接程序会记录加载之后得到的变量或函数的真正地址到一个映射表(<code>GOT</code>)中，供使用库的进程查询。其次，在链接可执行文件时，编译器会将所需要链接的动态库及其版本写入到二进制文件的某些节中，这样，在程序运行时就可以根据这些信息去查询到相应的库函数了。</p>
<p>事实上，经过编译链接的可执行文件并不是一开始就执行我们定义的<code>main</code>函数，而是会执行<code>c</code>库中的一些启动函数。对于<code>linux</code> <code>glibc</code>而言，这个函数是<code>glibc</code>中的<code>_start</code>函数，代码可以参考<a href="https://github.com/lattera/glibc/blob/master/sysdeps/x86_64/start.S">这里</a>。这是一个用汇编语言编写的函数，它会进一步调用<a href="https://github.com/lattera/glibc/blob/master/csu/libc-start.c"><code>libc-start.c</code></a>中的<code>__libc_start_main</code>函数完成启动工作。对于动态链接的程序，在<code>c</code>库中的启动函数会调用链接器函数进行一定的初始化工作，包括动态库的查找，加载，初始化等。</p>
<p>到这里，我们应该大致了解了可执行程序及库的加载和运行机制。</p>
<h2 id="常见问题"><a class="markdownIt-Anchor" href="#常见问题"></a> 常见问题</h2>
<h3 id="在linux下遇到glibc版本不同"><a class="markdownIt-Anchor" href="#在linux下遇到glibc版本不同"></a> 在<code>Linux</code>下遇到<code>glibc</code>版本不同</h3>
<p>可以使用工具<a href="https://www.mankier.com/1/patchelf"><code>patchelf</code></a>修改二进制文件，对链接的库进行修正，但是这样就需要我们自己去保证库的版本兼容性了。一个典型的修正链接库路径的命令如下：</p>
<p><code>./patchelf --set-interpreter /path/to/newglibc/ld-linux.so.2 --set-rpath /path/to/newglibc/ myapp</code></p>
<h3 id="在windows下遇到dll文件找不到"><a class="markdownIt-Anchor" href="#在windows下遇到dll文件找不到"></a> 在<code>windows</code>下遇到<code>dll</code>文件找不到</h3>
<p>我们可以使用工具<a href="https://www.dependencywalker.com/"><code>dependency walker</code></a>找出程序的所有依赖库，并识别系统中没有的库文件。这些找不到的库文件一般都是<code>windows</code>的开发工具<code>Visual Studio</code>提供的库文件。有些程序没有在安装程序中提供这些动态库文件的拷贝，而是默认用户的系统中已经存在这些库了，这就造成<code>dll</code>文件找不到的问题。</p>
<p>参考：</p>
<ul>
<li><a href="https://eli.thegreenplace.net/2011/08/25/load-time-relocation-of-shared-libraries/">https://eli.thegreenplace.net/2011/08/25/load-time-relocation-of-shared-libraries/</a></li>
<li><a href="https://eli.thegreenplace.net/2011/11/03/position-independent-code-pic-in-shared-libraries/">https://eli.thegreenplace.net/2011/11/03/position-independent-code-pic-in-shared-libraries/</a></li>
<li><a href="https://www.cnblogs.com/catch/p/3857964.html">https://www.cnblogs.com/catch/p/3857964.html</a></li>
<li><a href="https://stackoverflow.com/questions/847179/multiple-glibc-libraries-on-a-single-host">https://stackoverflow.com/questions/847179/multiple-glibc-libraries-on-a-single-host</a></li>
</ul>
]]></content>
      <categories>
        <category>技术</category>
        <category>编译</category>
        <category>c_c++</category>
      </categories>
      <tags>
        <tag>编译</tag>
        <tag>编译器</tag>
        <tag>GCC</tag>
        <tag>CL</tag>
        <tag>CLang</tag>
        <tag>C</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>内存管理的新思路</title>
    <url>/2020/03/08/new-ways-to-manage-memory/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>在最近的一个客户项目上，为了做性能优化，我们花了大量的时间，然而最终结果还是不够理想。我们的场景是实现特征处理过程和机器学习模型线上推理服务。由于用户量巨大，我们需要做到2万的TPS，每个请求需要在30ms内返回，且每个请求中包括对1000个项目的处理过程。</p>
<p>我们所使用的技术栈是<code>spring</code>和<code>grpc</code>。在经过极致的代码优化及内存调优之后，运行在一台<code>32GB</code>内存<code>64核</code>CPU的服务器上，我们发现<code>90%</code>的请求可以在<code>25ms</code>完成。但是如果观察<code>99%</code>的分位线时，响应时间就下降到了<code>70ms</code>，有时候还可能超过<code>100ms</code>。</p>
<p>为什么会出现上面这么明显的波动呢？问题出在<code>java</code>的<code>gc</code>上。其实对于<code>gc</code>，我们已经非常仔细的做过调优了，整个过程没有<code>full gc</code>的发生。然而，在持续的压力测试下，<code>java</code>的<code>young gc</code>却在频繁的工作。由于处理的数据量过大，新生代的<code>gc</code>几乎每秒都会触发一次，每次释放<code>5GB</code>内存，耗时<code>30ms</code>左后。</p>
<span id="more"></span>
<p>由于要服务于线上上亿的用户群，这样的性能还是不够理想，难以直接交付给客户使用。</p>
<p><code>java</code>语言发展了这么长时间，其性能还是能为人们所认可的。在一些性能测试上面，<code>java</code>几乎可以媲美<code>c++</code>的计算性能，比如<a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/java.html">这里</a>就有一个这样的测试。然而内存管理却一直是<code>java</code>语言一个挑战，即便<code>java</code>已经有相对非常成熟的<code>gc</code>算法了。在编写极致性能需求的服务端程序时，<code>java</code>由于其本身的性能波动，似乎还是难以胜任。</p>
<p>究竟要如何做高性能的内存管理呢？难道非得像<code>c/c++</code>一样的手动去管理内存吗？</p>
<h2 id="当前流行内存管理机制"><a class="markdownIt-Anchor" href="#当前流行内存管理机制"></a> 当前流行内存管理机制</h2>
<p>我们先看看当前流行的编程语言所采用的内存管理机制。以我所接触过的，使用相对广泛的编程语言为例，可以整理如下：</p>
<ul>
<li><code>c</code>: 手动进行内存的申请和释放</li>
<li><code>c++</code>: 通过<code>delete</code>指针，在析构函数中手动释放内存</li>
<li><code>java</code>及各种基于<code>java</code>的语言: 适时分代<code>gc</code>，多种垃圾回收算法</li>
<li><code>python</code>: 引用计数，自动触发适时分代回收</li>
<li><code>obj c / swift</code>: 引用计数或自动引用计数回收，编译期插入引用计数代码</li>
<li><code>go</code>: 适时分代gc，并行标记清除模式</li>
<li><code>javascript(v8)</code>: 适时分代gc，并行标记清除模式</li>
<li><code>php</code>: 以引用计数为基础，适时触发<code>gc</code></li>
<li><code>lua</code>: 标记清除模式</li>
</ul>
<p>可以看到，当前的自动内存管理机制以 <strong>引用计数</strong> 和 <strong>分层并行标记清除</strong> 为主。</p>
<p>如果内存释放及时，引用计数机制对于程序运行时性能影响会比较小。但每一个对象都需要分配额外的内存去跟踪引用数量，这带来了额外的内存占用。如果没有自动引用计数的机制，在编写代码时，手动管理计数会带来不小的额外负担，内存的及时释放取决于引用计数代码的正确性。</p>
<p>而对于标记清除式的内存管理，由于其不可避免的会带来程序暂停，且并行标记还需要占用cpu时间，会对程序性能产生较大影响。</p>
<p>我们的眼光投向了<code>rust</code>。<code>rust</code>是一门没有<code>gc</code>也不使用引用计数（不以此为主）进行内存管理的语言。那它究竟是怎样管理内存呢？它还能让我们像写<code>java</code>代码一样流畅吗？</p>
<h2 id="内存管理的新思路"><a class="markdownIt-Anchor" href="#内存管理的新思路"></a> 内存管理的新思路</h2>
<p>回顾一下日常编写代码的过程，在实现某一个函数时，有这样几个要素：入参 函数体 返回值。比如，假设我们有下面这个计算字符串长度的函数：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">func</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">s1</span> = String::<span class="title function_ invoke__">from</span>(<span class="string">&quot;hello&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">let</span> (s2, len) = <span class="title function_ invoke__">calculate_length</span>(s1);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;The length of &#x27;&#123;&#125;&#x27; is &#123;&#125;.&quot;</span>, s2, len);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">calculate_length</span>(s: <span class="type">String</span>) <span class="punctuation">-&gt;</span> (<span class="type">String</span>, <span class="type">usize</span>) &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">length</span> = s.<span class="title function_ invoke__">len</span>();</span><br><span class="line">    (s, length)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>考虑内存释放这件事，我们会希望：</p>
<ol>
<li>对于函数<code>func</code>中的变量<code>s1</code>，由于我们将其作为参数转交给了函数<code>calculate_length</code>，在后续的执行过程，我们就不再希望关心它对应的字符串内存了。</li>
<li>对于<code>calculate_length</code>函数中的入参<code>s</code>，由于其作为函数值返回，我们不希望在离开函数时释放其对应的内存。</li>
<li>对于<code>calculate_length</code>函数计算得到的<code>length</code>变量，我们同样不希望在离开函数时释放内存，因为它也是一个返回值。</li>
<li>对于<code>func</code>从<code>calculate_length</code>函数得到的变量<code>s2</code>和<code>len</code>，我们希望在<code>func</code>函数离开的时候立即释放。</li>
</ol>
<p>上述虽然只是一些很简单的想法，但这里面似乎隐藏着一些规律，我们能不能更进一步呢？甚至，我们是不是可以以此规律去设计一种新的内存管理方式呢？事实上，稍加抽象可以得到：</p>
<ul>
<li>变量可以属于某个函数，即其所有权为某个函数</li>
<li>在函数结束的时候，回收函数所持有的所有变量的内存</li>
<li>在发生子函数调用时，如果我们传入某一变量，该变量的所有权将移交到子函数中去</li>
<li>在子函数调用返回时，如果有返回一些变量，则这些变量的所有权将回交给当前函数</li>
</ul>
<p>这就是<code>rust</code>的内存管理基础。初次接触这种全新的内存管理方式时，不禁让人觉得眼前一亮。这种方式看上去自然而高效，且根本无需独立的垃圾回收器。</p>
<p>在<code>rust</code>中，我们实际上讨论的是更细致的值（内存）的所有权问题，但基本的观点与上述几点相似。更为严格的，<code>rust</code>中定义了如下几条关于值（内存）的所有权的规则：</p>
<ul>
<li>每一个值均存在一个对应的变量，该变量是这个值的所有者</li>
<li>同一时间每个值只能有一个所有者变量存在</li>
<li>当所有者变量离开当前可访问的代码范围（可以是一个函数，或一个由括号<code>&#123;&#125;</code>定义的一个范围等）时，该值对应的内存将会被释放</li>
<li>变量作为函数参数值传递时，值的所有权将移交到函数参数对应的变量中</li>
<li>函数返回一个变量时，该变量对应的值的所有权将回到上层函数对应的变量中</li>
</ul>
<h2 id="延伸"><a class="markdownIt-Anchor" href="#延伸"></a> 延伸</h2>
<p>实际上，我们在编写代码时，会碰到比上述场景复杂得多的场景。那么这几条原则是否还奏效呢？</p>
<p>其中一个我们很快会碰到的问题就是，由于存在所有权移交，我们可能需要每次函数调用都返回一些额外的值。如果每个函数都这么写，那可能是一场灾难。因为这将带来不够清晰的函数定义，而这种不清晰将侵入到整个代码库里面去。</p>
<p><code>rust</code>是如何解决这个问题的呢？这就是<code>rust</code>中的引用和借用的机制。比如我们可以编写如下的代码：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">func</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">s1</span> = String::<span class="title function_ invoke__">from</span>(<span class="string">&quot;hello&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">len</span> = <span class="title function_ invoke__">calculate_length</span>(&amp;s1);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;The length of &#x27;&#123;&#125;&#x27; is &#123;&#125;.&quot;</span>, s1, len);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">calculate_length</span>(s: &amp;<span class="type">String</span>) <span class="punctuation">-&gt;</span> <span class="type">usize</span> &#123;</span><br><span class="line">    s.<span class="title function_ invoke__">len</span>()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过在变量前面增加一个<code>&amp;</code>符号，我们得到了一个称为 <strong>变量引用</strong> 的东西。对于变量引用而言，其对应的值的所有权并不会并发生移交。在函数调用时，我们可以仅仅将某一值的引用传递过去，这个时候发生的事情，称为借用。这里可以类比我们日常生活中借用别人的东西的场景，借用完之后，再归还给他。</p>
<p>另一个不难想到的问题是：如何去按照面向对象的方式组织数据？事实上，关于值的所有权定义也可以用来解决这个问题。在前面的讨论中，我们以函数作用范围举例，但这里的范围其实可以不只是函数，也可以是某个对象（或结构体，<code>rust</code>中成为<code>struct</code>）。也就是说，我们可以将某一个值作为另一个对象的一部分绑定到该对象上去，这样该值的所有者就变成了这个对象。这个对象本身可以作为一个值绑定到某一个变量中去，从而构成了一个完整的闭环。</p>
<p>还有一个问题，可能会成为<code>rust</code>的难题，即需要共享某一个值的场景。这时，我们需要让一个值同时属于多个所有者。这跟我们前面提到的<code>rust</code>的单一所有者原则相悖。在这样的场景下，<code>rust</code>定义了一个称为<code>Rc</code>的结构体，它存储的是这个对象的引用及一个引用计数。<code>Rc</code>实际上就是<code>reference count</code>的缩写。这里的内存管理其实就退化为引用计数式的内存管理。</p>
<p>我们还可以提出更多的问题，比如：多线程的情况下，值（内存）的所有权要怎么变化？如何实现线程同步的锁机制？如何处理循环引用问题？事实上，诸如此类的问题已经被<code>rust</code>的社区及其编写者们思考并实践了多年。<code>rust</code>所特有的所有权特性为解决这些问题提供了全新的思路，大部分问题也都被优雅的解决了。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>诞生于<code>Mozilla</code>社区的<code>rust</code>程序设计语言为我们带来了全新的内存管理思路。近几年来，<code>rust</code>语言发展迅速，由于其在性能和稳定性可以超越<code>c/c++</code>，在易用性上不输<code>java</code>等高级语言，在高性能服务器端开发领域<code>rust</code>已开始崭露头角。</p>
<p><code>rust</code>是否可以解决我们的线上特征处理和模型推理的极致性能需求呢？我们正在尝试过程中，同时满怀期待。</p>
<p>参考：</p>
<ul>
<li><a href="https://blog.codingnow.com/2018/10/lua_gc.html">https://blog.codingnow.com/2018/10/lua_gc.html</a></li>
<li><a href="https://blog.devtang.com/2016/07/30/ios-memory-management/">https://blog.devtang.com/2016/07/30/ios-memory-management/</a></li>
<li><a href="https://www.cnblogs.com/geaozhang/p/7111961.html">https://www.cnblogs.com/geaozhang/p/7111961.html</a></li>
<li><a href="https://segmentfault.com/a/1190000018161588">https://segmentfault.com/a/1190000018161588</a></li>
<li><a href="https://juejin.im/post/5b398981e51d455e2c33136b">https://juejin.im/post/5b398981e51d455e2c33136b</a></li>
<li><a href="https://doc.rust-lang.org/stable/book/">https://doc.rust-lang.org/stable/book/</a></li>
</ul>
]]></content>
      <categories>
        <category>技术</category>
        <category>rust</category>
      </categories>
      <tags>
        <tag>性能</tag>
        <tag>高性能</tag>
        <tag>内存管理</tag>
        <tag>gc</tag>
        <tag>垃圾回收</tag>
      </tags>
  </entry>
  <entry>
    <title>亿级数据Spark应用调优之旅</title>
    <url>/2020/01/21/spark-performance-tuning-on-billions-of-data/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>技术飞速发展，机器学习正在成为各个企业的核心竞争优势之一。除了在处于风口浪尖的计算机视觉方向的应用，可能更能产生直接的价值的一个方向是在智能推荐领域。比如广告推荐，如果我们有一个更有效的算法，更精准的向用户推荐了某个广告，用户的广告点击将为企业直接带来收益。</p>
<p>然而在推荐领域，我们面临的是与当前的深度学习颇有不同的问题。这些不同主要体现在：</p>
<ul>
<li>超大的数据量</li>
<li>领域专家人工设计的特征</li>
<li>极致的在线服务性能需求</li>
</ul>
<p>为了解决这个技术上非常有挑战的问题，一般情况下，我们要考虑的方案都是借助于大数据的工具。自Google的两篇经典论文发表以来，大数据相关生态发展至今已经十多年过去了，虽然一直都有新的思想的产生，但是很多经典的工具已趋于成熟。大数据的相关工具应对大数据的挑战应当是理所应当的选择。</p>
<span id="more"></span>
<p>近期，在一个客户的项目上，我们有机会参加到了一个类似场景下的机器学习应用中，帮助客户解决这一问题。我们选择的技术方案是基于Hadoop的Hive大规模分布式结构化数据存储系统，及高性能Spark分布式计算引擎。以它们为核心来处理数据和训练模型。对于模型的线上服务，我们选择了mleap，mleap是专门针对Spark机器学习库MLLib的高性能服务化而设计的。</p>
<p>在前期的工作中，我们用spark在一个小的数据集上面实现并验证过了所有的功能。但是由于我们的测试环境资源非常有限，无法针对超大规模数据进行测试。在将系统上线到一个类生产环境之后，我们终于面临了亿级数据处理的问题。虽然我们选择的技术方案理论上是可以直接支持这样级别的数据的，但是在实际运行之后，还是遇到了颇多问题，在这里总结并与大家分享一下。</p>
<h2 id="构建快速反馈环"><a class="markdownIt-Anchor" href="#构建快速反馈环"></a> 构建快速反馈环</h2>
<p>TDD教会我们快速反馈的重要性。一旦我们有了一个快速反馈的机制，我们就能快速修正问题，快速前进。但是在超大数据的场景下，问题的复杂性往往使得我们难以获取快速反馈。比如，一个spark的应用，可能需要运行数十分钟到数小时，而我们遇到的问题可能在数十分钟或数小时之后才会出现。</p>
<p>在这样的场景下，我们如何尽可能的构建快速反馈环就显得更为重要了。试想，如果我们修改一行代码，需要花两个小时才能部署到环境中，然后应用运行再需要两个小时才能重现问题，那么我们一次修改就需要花费4个小时的时间。一来一回，可能一周或者一个月过去了，我们也没有能解决所有问题。</p>
<p>这样的场景对于我们的技术经验及技术功底的要求无疑都非常高。然而在我看来，最关键的还是在于构建快速反馈环。</p>
<p>为了构建这个反馈环我们做了哪些事情呢？</p>
<p>打造环境和工具。在做大规模数据的测试之前，我们能预料到潜在的（几乎是必然的）会产生不少的代码修改。那么搭建一套专用的测试环境就显得非常重要。有了这套环境，在必要时，我们可以采用非常规手段尽快部署我们的修改。同时我们需要自动化一切可以自动化的事情，将各种部署的步骤都编写成可以一键执行的脚本，这就为高效工作奠定了基础。为了实现尽可能的自动化，我们编写了多个自动化的工具脚本。工欲善其事，必先利其器。这些准备工作为后续的性能优化奠定了基础。</p>
<p>打通Spark监控页面及日志。同时由于我们所使用的是一套类生产环境，出于数据保密的要求，我们无法通过网络直接访问到这些数据，而和这些数据部署在一起的大数据集群自然也不例外了。为了访问这些数据，我们需要首先通过某一专用vpn连接到一个内网，然后通过windows的远程桌面连接到某一台内网跳板机，最后我们从跳板机来发起访问。在这样的网络模式中，不仅由于网速慢而导致操作卡顿严重，而且复制粘贴操作也被严格的限制了。客户的安全限制无疑成为了一个阻碍我们快速诊断问题的障碍。在这样的情况下，我们果断的快速实现了一个代理机制，将yarn上的Spark监控页面及相关日志通过代理暴露到我们可访问的网络中来。这样一来，我们就可以快速查询到我们的spark应用的状态了。我们后续遇到的所有问题几乎都是靠Spark监控页面及日志辅助解决的。</p>
<p>启动Spark历史应用日志服务。Spark不仅可以在运行时提供一个内容丰富的监控页面，其实它也可以将运行时的监控数据保存下来供后续分析和查看（详情见<a href="https://spark.apache.org/docs/latest/monitoring.html">这里</a>）。我们只需要在运行应用时配置<code>spark.eventLog.enabled</code>为<code>true</code>，<code>spark.eventLog.dir</code>配置为某一个<code>hdfs</code>路径即可。有了这些日志之后，我们运行<code>./sbin/start-history-server.sh</code>启动日志服务工具，就可以在浏览器web页面上面看到相应的历史日志了。当我们的应用失败的时候，Yarn的Spark监控页面（driver节点上面启动的一个web服务）也会相应退出。这给我们分析这些失败的应用带来了困难。有了Spark历史应用日志服务，我们也就不会再有这样的问题。</p>
<h2 id="了解基本的spark优化方案"><a class="markdownIt-Anchor" href="#了解基本的spark优化方案"></a> 了解基本的Spark优化方案</h2>
<p>在开始我们的具体问题之前，有必要先了解一下基本的Spark优化手段有哪些。</p>
<p>首先，Spark应用也是一个普通的Java应用，所以所有的java程序优化手段都是适用的，例如如何合理利用缓存，如何优化数据结构和内存等。</p>
<p>其次，我们需要了解基本的分布式程序运行原理，简单来说就是<code>Map-Reduce</code>（后续简称MR）算法的基本原理，Spark应用最终都会以一系列MR任务的方式执行。</p>
<p>然后，我们需要了解一般情况下分布式程序工作的瓶颈所在。一般而言，运行某个分布式应用时，我们会拥有非常多的cpu并行执行代码，但是这些cpu分布在不同的物理机上，所以在这些cpu间共享数据和调度任务会成为一个问题。<br />
这里的问题会大致表现为：</p>
<ol>
<li>磁盘IO – 多机并行数据读写时是否充分利用了多个磁盘进行数据访问，是否读取了尽可能近的数据存储，是否避免了没有必要的写盘操作等；</li>
<li>网络IO – 在reduce操作时任务间交换的数据有多少，如何在不同的物理机上的进程共享一些大的对象等；</li>
<li>调度规模 – 是否因为任务调度慢而导致应用慢，比如任务数量过多。</li>
</ol>
<p>以上述几点为基础可以扩展出非常广泛的内容，各种资料也非常多，在这里就不重复赘述了。在这次的Spark应用优化中，我参考过的比较成体系的优化资料有：</p>
<ol>
<li>官方的<a href="https://spark.apache.org/docs/latest/tuning.html">Spark调优指南</a></li>
<li>来自美团的Spark优化指南 – <a href="https://tech.meituan.com/2016/04/29/spark-tuning-basic.html">初级篇</a>及<a href="https://tech.meituan.com/2016/05/12/spark-tuning-pro.html">高级篇</a></li>
<li><a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/index.html">Java应用GC调优指南</a></li>
</ol>
<p>从这些资料中，我们可以将Spark应用的优化方式整理为如下几点：</p>
<ul>
<li>算法性能优化
<ul>
<li>使用map-side的计算（在map过程进行预计算），如使用<code>reduceByKey</code>/<code>aggregateByKey</code>替代<code>groupByKey</code></li>
<li>使用带Partitions的API进行计算（一次函数调用处理一个Partition），如<code>mapPartitions</code>替代<code>map</code></li>
<li>使用<a href="https://tech.meituan.com/2016/05/12/spark-tuning-pro.html">手动添加前缀</a>的方式优化由于数据倾斜带来的性能问题</li>
</ul>
</li>
<li>并行度优化
<ul>
<li>调用<code>repartition</code> API设置分区数量</li>
<li>设置默认的<code>shuffle</code>操作之后的分区数量</li>
<li>数据量变化之后，调用<code>coalesce</code>重设分区数量</li>
</ul>
</li>
<li>缓存优化
<ul>
<li>调用<code>cache</code> <code>persist</code>及<code>unpersist</code>以便控制哪一个<code>RDD</code>需要缓存</li>
<li>缓存<code>RDD</code>时考虑使用序列化缓存，进一步考虑压缩</li>
</ul>
</li>
<li>内存优化
<ul>
<li>使用更节约内存的数据结构：如避免使用java的包装类型（boxed），避免使用内置的<code>Map</code> <code>List</code>等数据结构（会创建额外的<code>Entry</code>对象）等</li>
<li>使用广播变量：对于某个只读的大对象，在一个<code>Executor</code>内部共享，而不是每个<code>task</code>都复制一份</li>
<li>调整spark管理的内存大小：配置<code>spark.memory</code>相关参数</li>
<li>调整JVM的新生代和老生代内存比例</li>
<li>gc优化：使用<code>G1</code>垃圾收集器</li>
</ul>
</li>
<li>其他有用的优化方式
<ul>
<li>资源：配置<code>executor</code>的数量，每个<code>executor</code>的核数及内存，<code>driver</code>的核数和内存</li>
<li>调度：配置是否重启一个较慢的任务，设置<code>spark.speculation</code>相关参数</li>
<li>IO：使用节约空间的序列化方式，如配置<code>kryo</code>序列化，调整本地化程度等待时间<code>spark.locality.wait</code>参数</li>
</ul>
</li>
</ul>
<p>后文中针对每个问题的定位和优化均会从以上几点来进行考虑。</p>
<h2 id="解决大数据场景下的问题"><a class="markdownIt-Anchor" href="#解决大数据场景下的问题"></a> 解决大数据场景下的问题</h2>
<p>为了大家能理解后续的问题，对于我们的目标Spark应用，我整理了一个简单的数据处理流程图如下。</p>
<p><img data-src="/attaches/2020/2020-01-21-spark-performance-tuning-on-billions-of-data/system-process-flow.png" alt="System Process Flow Chart" /></p>
<p>整个系统基于<a href="https://spark.apache.org/docs/latest/ml-guide.html">Spark MLLib</a>构建。得益于<code>Spark MLLib</code>中的<code>Pipeline</code>抽象，我们可以将通用的数据处理过程建模为一个一个算子。比如原始数据中有一些字符串类型的分类特征(如按照出生时间可以分为80后、90后、00后等)，我们一般会先将其数值化。这通过一个字符串索引算子(<a href="https://spark.apache.org/docs/latest/ml-features.html#stringindexer">StringIndexer</a>)就可以实现。再比如，我们如果要将某一个特征进行正则化，我们可以通过正则算子(<a href="https://spark.apache.org/docs/latest/ml-features.html#normalizer">Normalizer</a>)来实现。将这些算子从前到后依次串联就可以实现一系列的可复用的处理过程。</p>
<p>某些算子需要预先做一些统计工作，比如为了实现正则化，我们需要知道当前特征的最大值最小值。计算这样的统计类信息的过程称为算子的<code>fit</code>过程，而真正执行计算的过程称为<code>transform</code>。</p>
<p>以上简述了<code>Spark MLLib</code>中最基本的抽象，想了解更多的同学们可以移步<a href="https://spark.apache.org/docs/latest/ml-features.html">这里</a>。</p>
<p>为了将数据处理为机器学习模型需要的数据格式，我们构建了一个类似下面的<code>Pipeline</code>。将一系列的数据（特征）转换为一个稀疏向量（上千万维）。</p>
<pre><code>StringIndexer(特征列a b c -&gt; a_idx b_idx c_idx)
 -&gt; OneHot(特征列a_idx b_idx c_idx -&gt; a_idx_oh b_idx_oh c_idx_oh)
 -&gt; MultiHot(特征列ma -&gt; ma_mh) 
 -&gt; MultiHot(特征列mb -&gt; mb_mh) 
 -&gt; MultiHot... 
 -&gt; VectorAssembler(特征列a_idx_oh b_idx_oh c_idx_oh ma_mh mb_mh ... -&gt; final_result)
</code></pre>
<p>（上述括号内的内容表示将某几个特征进行计算，输出对应箭头后的特征列，如<code>StringIndexer</code>算子处理特征列a后，输出特征列a_idx。）</p>
<p>这里用到的几个算子的功能简述如下：</p>
<ul>
<li><code>StringIndexer</code>算子：提取字符串数据表示的所有分类，然后对某一个数据进行数值化编码，如，当我们一共有分类<code>a</code> <code>b</code> <code>c</code>，则某一个分类<code>b</code>将编码为数值<code>1</code>（从0开始编码）</li>
<li><code>OneHot</code>算子：将一个数值数据进行OneHot编码，转换为一个稀疏向量，如，当我们一共有4个元素时，数值3将编码为<code>[0, 0, 0, 1, 0]</code></li>
<li><code>MultiHot</code>算子：将一个多值字符串数据编码为一个稀疏向量，如，对于某一特征<code>喜好</code>，所有的<code>喜好</code>类型有<code>a</code> <code>b</code> <code>c</code> <code>d</code>，则数据<code>b c</code>将编码为<code>[0, 1, 1, 0]</code></li>
<li><code>VectorAssembler</code>算子：将多个向量合并为一个大的向量，如数据<code>[0, 0, 1]</code> <code>[1, 0]</code>将合并为向量<code>[0, 0, 1, 1, 0]</code></li>
</ul>
<p>在应对亿级数据时，这样的Spark应用遇到了哪些问题，而我们又是如何一步一步解决的呢？</p>
<h3 id="计算特别慢最后出现oom问题"><a class="markdownIt-Anchor" href="#计算特别慢最后出现oom问题"></a> 计算特别慢，最后出现OOM问题</h3>
<p>由于我们已经在一个小的数据集上面实现并验证过了所有的功能，一开始我们直接将这个<code>Pipeline</code>应用于亿级数据。启动应用之后，我们发现计算特别慢，最后在某一个<code>MultiHot</code>算子出现OOM的问题，导致整个应用失败。</p>
<p><strong>资源优化</strong></p>
<p>我们的Spark应用，处理的数据规模在一亿左右，特征列的数量在120左右，大部分特征以字符串的形式存储，分区数8000，整个数据量占用空间约200G。这并不是一个特别大的数据集，按道理以Spark的设计可以轻松应对才是，但是如果不经优化，在这样的数据集情况下，很多性能问题都会显现出来。</p>
<p>首先我们想到的是优化资源，这是最简单的方式，修改应用启动配置即可。于是我们分配了100个executor，每个executor分配64GB内存加8个计算核心，总分配内存6TB左右。但是结果却不尽如人意，程序执行依然很慢。全部依赖资源是不现实的，我们开始着手优化应用实现。</p>
<p><strong>缓存优化</strong></p>
<p>经过上述优化之后，我们发现虽然我们分配了足够多的资源，但是应用还是会在后面几个<code>MultiHot</code>算子报错OOM退出。这是为什么呢？检查Spark监控页面下的<code>Storage</code>页面，我们发现有多个缓存的RDD，其中好几个RDD占用了1TB的内存。这不OOM才怪呢。</p>
<p><img data-src="/attaches/2020/2020-01-21-spark-performance-tuning-on-billions-of-data/too-many-cache.png" alt="TOO Many Cache" /></p>
<p>（此处的截图仅为了演示创建，非实际的图，实际的图会显示缓存大小1TB左右，分区数8000）</p>
<p>检查代码发现，在流程图步骤<code>5</code>保存样例数据时，我们添加了一个非预期的<code>dataset.cache()</code>，这导致每一个算子执行完毕之后都会缓存起来。去掉这个cache之后，测试，OOM问题消失。虽然这个问题没有了，但是应用运行到<code>VectorAssembler.fit</code>的时候会卡住，等待数小时依然无响应。</p>
<p>虽然没有了<code>MultiHot</code>算子的OOM问题，但是我们发现算子执行速度特别慢。这也是一个亟待优化的问题。否则为了重现上面的应用无响应问题，我们需要等待超过1小时的时间。这对于我们而言，太慢了。于是我们开始分析为什么算子执行速度特别慢。</p>
<p><strong><code>StringIndexer</code>优化</strong></p>
<p>查看Spark监控页面，我们发现在<code>StringIndexer</code>算子出现了特别多的名为<code>countByValue</code>的<code>Job</code>，每个<code>Job</code>执行都比较慢。</p>
<p><img data-src="/attaches/2020/2020-01-21-spark-performance-tuning-on-billions-of-data/many-count-by-value.png" alt="Many CountByValue" /></p>
<p>（此处的截图仅为了演示创建，非实际的图，实际的action执行时间在数分钟）</p>
<p>我们知道每个<code>Job</code>会对应一个<code>action</code>操作。这就表示我们的<code>StringIndexer</code>算子针对每一特征列触发了一个<code>action</code>操作。由于我们在这个算子上面将会处理上百个特征列，所以就出现了特别多的这样的操作。这些操作具体是做什么呢？回顾上述的<code>StringIndexer</code>的处理过程可知，我们需要先统计每一个特征列的所有分类（<code>fit</code>过程），然后构造一个字典来实现数据转换（<code>transform</code>过程）。这里的<code>CountByValue</code>操作看来是用于统计每一个特征列的所有分类了。一查代码果然如此。</p>
<p>但是为何会这么慢呢？难道每次操作都会重新去hive表读取数据？检查代码发现，果然是没有对输入的数据集进行缓存，在Spark监控页面下的<code>Storage</code>页面中也未发现任何缓存的数据。在流程图步骤<code>1</code>读取输入数据集后，添加缓存代码<code>dataset.cache()</code>，再进行测试。这次<code>CountByValue</code>速度立即提升了数十倍，达到数秒到数十秒的级别。这时再观察Spark监控页面下的<code>Storage</code>页面，将发现其缓存了一个<code>HiveTableScan</code>的<code>RDD</code>。</p>
<p>经过上述优化，整个<code>StringIndexer</code>算子的<code>fit</code>过程还是会花费5分钟左右。是否还可以从算法层面优化这个算子呢？实际上我们可以通过添加前缀的方式设计如下算法来解决这个问题：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">dataset.select(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>).rdd</span><br><span class="line">    .flatMap(row =&gt; row.toSeq.zipWithIndex.map &#123; <span class="keyword">case</span> (v, i) =&gt; <span class="string">s&quot;<span class="subst">$&#123;i&#125;</span>:<span class="subst">$&#123;v&#125;</span>&quot;</span> &#125;) <span class="comment">// 拼接列索引前缀</span></span><br><span class="line">    .countByValue</span><br><span class="line">    .keys</span><br><span class="line">    .groupBy(key =&gt; key.substring(<span class="number">0</span>, key.indexOf(<span class="string">&quot;:&quot;</span>))) <span class="comment">// 按照列索引分组</span></span><br><span class="line">    .toSeq</span><br><span class="line">    .map &#123; </span><br><span class="line">        <span class="keyword">case</span> (colIdx, categories) =&gt; </span><br><span class="line">            (<span class="type">Map</span>(<span class="number">0</span>-&gt; <span class="string">&quot;a&quot;</span>, <span class="number">1</span>-&gt; <span class="string">&quot;b&quot;</span>, <span class="number">2</span>-&gt; <span class="string">&quot;c&quot;</span>).get(colIdx.toInt).get, </span><br><span class="line">                categories.map(cate =&gt; cate.substring(cate.indexOf(<span class="string">&quot;:&quot;</span>) + <span class="number">1</span>)).toSeq)</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">// for testing</span></span><br><span class="line"><span class="comment">// 1. prepare data from beeline</span></span><br><span class="line"><span class="comment">// create table tt (a int, b varchar, c varchar, d double);</span></span><br><span class="line"><span class="comment">// insert into tt values(1, &#x27;1&#x27;, &#x27;2&#x27;, 3), (2, &#x27;2&#x27;, &#x27;3&#x27;, 4), (3, &#x27;3&#x27;, &#x27;4&#x27;, 5), (4, &#x27;4&#x27;, &#x27;5&#x27;, 6), (5, &#x27;5&#x27;, 6&#x27;, 7&#x27;);</span></span><br><span class="line"><span class="comment">// 2. run the code above, got:</span></span><br><span class="line"><span class="comment">// ArrayBuffer((c,ArrayBuffer(4, 5, 6, 2, 3)), (b,ArrayBuffer(4, 5, 1, 2, 3)), (a,ArrayBuffer(4, 5, 1, 2, 3)))</span></span><br></pre></td></tr></table></figure>
<p>通过添加前缀的方式，我们将多列合并为了一列，那么也就将针对每一特征列的计算，转换为了针对一个列的计算。完成计算之后，在driver端我们再根据之前的拼接规则按列进行拆分即可。</p>
<p>经过这样的算法优化之后，<code>StringIndexer</code>算子的<code>fit</code>过程优化到了1分半左右。这里如果我们发现得到的分类数太多，在最后一步map操作中，我们还可以考虑并行的对<code>values</code>进行处理以提升性能。</p>
<p><strong><code>MultiHot</code>优化</strong></p>
<p>在之前的<code>Pipeline</code>中，我们可以看到我们组合了多个<code>MultiHot</code>算子，这在实际使用中，不仅带来了易用性的问题（常常有数十个列需要进行处理），而且性能也不高。如何优化这个算子呢？我们可以参考<code>StringIndexer</code>类似的算法来进行处理。</p>
<p>主要算法代码如下：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> dict = dataframe.select(<span class="string">&quot;ma&quot;</span>, <span class="string">&quot;mb&quot;</span>).rdd</span><br><span class="line">    .flatMap(row =&gt; row.toSeq.zipWithIndex.flatMap &#123; <span class="keyword">case</span> (v, i) =&gt; v.toString.split(<span class="string">&quot; &quot;</span>).map(vj =&gt; <span class="string">s&quot;<span class="subst">$&#123;i&#125;</span>:<span class="subst">$&#123;vj&#125;</span>&quot;</span>) &#125;) <span class="comment">// 每一个值都拼接一个列索引前缀</span></span><br><span class="line">    .countByValue</span><br><span class="line">    .keys</span><br><span class="line">    .zipWithIndex</span><br><span class="line">    .toMap</span><br><span class="line"><span class="comment">// for testing</span></span><br><span class="line"><span class="comment">// 1. prepare data from beeline</span></span><br><span class="line"><span class="comment">// create table tt1 (ma string, mb string);</span></span><br><span class="line"><span class="comment">// insert into tt1 values(&quot;a b c&quot;, &quot;1 2 3&quot;), (&quot;b c d&quot;, &quot;2 3 4&quot;), (&quot;c d e&quot;, &quot;3 4 5&quot;);</span></span><br><span class="line"><span class="comment">// 2. run the code above, got: </span></span><br><span class="line"><span class="comment">// scala.collection.immutable.Map[String,Int] = Map(0:b -&gt; 0, 0:e -&gt; 1, 1:4 -&gt; 2, 1:3 -&gt; 3, 0:a -&gt; 4, 1:2 -&gt; 5, 1:1 -&gt; 6, 0:c -&gt; 7, 0:d -&gt; 8, 1:5 -&gt; 9)</span></span><br></pre></td></tr></table></figure>
<p>经过这里的处理之后，我们就得到一个所有列的所有可能值的一个大的字典。在进行数据转换时，我们首先需要同样的拼接一个列索引前缀，然后再按照字典查询并填充向量值。主要代码如下：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> dictSize = dict.size</span><br><span class="line">dataframe.select(<span class="string">&quot;ma&quot;</span>)</span><br><span class="line">    .rdd</span><br><span class="line">    .map(x =&gt; <span class="type">Vectors</span>.sparse(dictSize, x.getString(<span class="number">0</span>).split(<span class="string">&quot; &quot;</span>).map(xi =&gt; (dict(<span class="string">s&quot;0:<span class="subst">$&#123;xi&#125;</span>&quot;</span>), <span class="number">1.0</span>)).toSeq)) <span class="comment">// 拼接一个列索引前缀后再查询上述字典</span></span><br><span class="line"><span class="comment">// for testing</span></span><br><span class="line"><span class="comment">// run the code above, got:</span></span><br><span class="line"><span class="comment">// Array[org.apache.spark.ml.linalg.Vector] = Array((10,[0,4,7],[1.0,1.0,1.0]), (10,[0,7,8],[1.0,1.0,1.0]), (10,[1,7,8],[1.0,1.0,1.0]))</span></span><br></pre></td></tr></table></figure>
<p>实现了这个优化之后，不仅使得整个<code>fit</code>计算过程变快了数倍，而且由于我们的算子可以支持同时处理多个特征列，这带来了很大的易用性提升。</p>
<p>对于这里的实现，有经验的同学们可能已经发现另一个优化点，那就是这个<code>dict</code>变量。这个变量可能非常大，在我们的场景中，它内部可能有上千万个元素。由于map函数中使用到了这个变量，如果不做任何处理，我们将会序列化一个非常大的task到其他executor中执行，这将是非常低效的操作。这里我们可以将这个dict转化为一个广播变量，然后在map函数中引用这个广播变量。</p>
<p>主要代码如下：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> dictBC = dataframe.sparkSession.sparkContext.broadcase(dict)</span><br><span class="line">dataframe.select(<span class="string">&quot;ma&quot;</span>)</span><br><span class="line">    .rdd</span><br><span class="line">    .map(x =&gt; <span class="type">Vectors</span>.sparse(dictBC.value.size, x.getString(<span class="number">0</span>).split(<span class="string">&quot; &quot;</span>).map(xi =&gt; (dictBC.value(<span class="string">s&quot;0:<span class="subst">$&#123;xi&#125;</span>&quot;</span>), <span class="number">1.0</span>)).toSeq)) <span class="comment">// 拼接一个列索引前缀后再查询上述字典</span></span><br><span class="line"><span class="comment">// for testing</span></span><br><span class="line"><span class="comment">// run the code above, got:</span></span><br><span class="line"><span class="comment">// Array[org.apache.spark.ml.linalg.Vector] = Array((10,[0,4,7],[1.0,1.0,1.0]), (10,[0,7,8],[1.0,1.0,1.0]), (10,[1,7,8],[1.0,1.0,1.0]))</span></span><br></pre></td></tr></table></figure>
<h3 id="写hive表非常慢输出的数据表在hive下面查询非常慢"><a class="markdownIt-Anchor" href="#写hive表非常慢输出的数据表在hive下面查询非常慢"></a> 写hive表非常慢，输出的数据表在hive下面查询非常慢</h3>
<p>经过上述的优化，前面几个步骤都已经比较快了。由于业务需要，我们打算先在小数据集上面做验证。于是我们抽样了50w左右的一个数据集进行计算。程序很快的进入了流程图第<code>8</code>步写入数据到新表，这一步运行速度没有想象中的快。但更关键的是，<code>8.1</code>步创建数据集竟然会失败。一看日志，发现hive表查询超时。</p>
<p>这种情况显示，我们可以成功的创建hive表，但是hive表的查询非常慢。我们快速在<code>beeline</code>中进行了查询验证，发现也很慢。这是为什么呢？经过我们的<code>Pipeline</code>处理之后的数据究竟有啥不一样呢？</p>
<p>经过一段时间的分析，我们注意到当对生成的数据表进行<code>describe formatted &#123;TABLE_NAME&#125;</code>时，查询竟然要超过1分钟才能返回。不仅如此，查询结果时，hive控制台输出了一个特别长的元数据信息。类似下图：</p>
<p><img data-src="/attaches/2020/2020-01-21-spark-performance-tuning-on-billions-of-data/hive-table-metadata.png" alt="Hive Table Metadata" /></p>
<p>上图是一张示意图，真实情况，会有大量的<code>spark.sql.sources.schema.part.0</code>数据出现，末尾的数字会到递增9999，出现<code>spark.sql.sources.schema.part.9999</code>数据。</p>
<p>事实上，对某一张hive表进行<code>describe</code>操作时，我们仅仅是查询hive的元数据而已。查询元数据慢，预示着生成的hive表可能元数据太多。</p>
<p>这些元数据从哪里来的呢？我们又回到程序的源代码，经过仔细的代码走查，我们发现Spark的<code>Pipeline</code>算子会有很多元数据创建操作。这在我们之前优化<code>OneHot</code>算子时，也有发现过（以往的经验）。示例代码在<a href="https://github.com/apache/spark/blob/v2.1.0/mllib/src/main/scala/org/apache/spark/ml/feature/OneHotEncoder.scala">这个文件</a>94行。</p>
<p>既然可能是这些元数据惹的祸，并且这些元数据对于我们的应用用处不大，那么我们是不是可以在创建数据集的时候，预先将这些元数据都去掉？尝试修改原来写表的代码如下：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> dataframeWithoutMetadata = dataframe.sparkSession.createDataFrame(</span><br><span class="line">    dataframe.rdd, </span><br><span class="line">    <span class="type">StructType</span>(dataframe.schema.fields.map(f =&gt; <span class="type">StructField</span>(f.name, f.dataType, f.nullable, <span class="type">Metadata</span>.empty)))</span><br><span class="line">)</span><br><span class="line">dataframeWithoutMetadata.write.saveAsTable(<span class="string">&quot;sometable&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>在应用这样的修改之后，重新测试，我们发现查询元数据变得飞快了。运行<code>describe formatted &#123;TALBLE_NAME&#125;</code>时，也看不到如此大量的<code>spark.sql.sources.schema.part.9999</code>数据了。查询显示示意图如下：</p>
<p><img data-src="/attaches/2020/2020-01-21-spark-performance-tuning-on-billions-of-data/hive-table-metadata-removed.png" alt="Hive Table Metadata Removed" /></p>
<p>我们可以注意到这里的metadata值为<code>&#123;&#125;</code>，而之前的metadata是存在数据的。</p>
<h3 id="系统卡住长时间无响应"><a class="markdownIt-Anchor" href="#系统卡住长时间无响应"></a> 系统卡住，长时间无响应</h3>
<p>经过前面的优化，现在到达执行<code>VectorAssembler.fit</code>卡住的问题就比较快了。启动应用后差不多20分钟就可以重现这个问题。</p>
<p>经过一番日志分析之后，我们发现日志中有一个ERROR的消息，显示<code>java.lang.OutOfMemoryError: Requested array size exceeds VM limit</code>。出现了OOM，但是Spark程序仍然在运行。这是为什么呢？实际上，这个错误是由JVM的native代码抛出来的。JVM在分配数组之前会执行一个检查，防止我们分配的数组太大。当JVM发现我们要分配一个超过<code>2^31 - 2 = 2147483645</code>（64位系统）的数组时，就会抛出这个错误。但是这个错误却不会让JVM进程退出，只会让当前线程退出。</p>
<p>我们可以编写一个测试来验证：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OOMTest</span> &#123;</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">test_oom</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Thread</span>(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">final</span> <span class="type">byte</span>[] bytes = <span class="keyword">new</span> <span class="title class_">byte</span>[Integer.MAX_VALUE];</span><br><span class="line">        &#125;).start();</span><br><span class="line">        Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;executed here!&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行上述测试，我们会发现，控制台出现了一个<code>java.lang.OutOfMemoryError: Requested array size exceeds VM limit</code>报错，但是随即打印了<code>executed here!</code>字符串。</p>
<p>到这里我们大概猜到了问题的原因。应用在运行到<code>VectorAssembler.fit</code>时，分配了一个超大的数组。这导致了某个关键线程退出，从而导致应用无响应。这个关键的线程就是<code>dag-scheduler-event-loop</code>线程。看这个线程的名字我们就知道了，这个线程是负责进行任务调度的。没有了任务调度，所有的executor都处于等待中，Spark应用当然无响应了。</p>
<p>为验证这个问题，我们检查了Spark监控页面的Executor页面，发现当系统无响应时，下面这个线程不在了。</p>
<p><img data-src="/attaches/2020/2020-01-21-spark-performance-tuning-on-billions-of-data/dag-scheduler-thread.png" alt="DAG Scheduler Thread" /></p>
<p>那么这个数组从何而来呢？回顾一下代码，<code>VectorAssembler</code>究竟是做了什么呢？阅读其源代码会发现一个有问题的地方。在<a href="https://github.com/apache/spark/blob/v2.1.0/mllib/src/main/scala/org/apache/spark/ml/feature/VectorAssembler.scala">这个文件</a>的88行和89行，程序分配了一个超大的数组：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> numAttrs = group.numAttributes.getOrElse(first.getAs[<span class="type">Vector</span>](index).size)</span><br><span class="line"><span class="type">Array</span>.tabulate(numAttrs)(i =&gt; <span class="type">NumericAttribute</span>.defaultAttr.withName(c + <span class="string">&quot;_&quot;</span> + i))</span><br></pre></td></tr></table></figure>
<p>我们知道，由于这里的向量维度是在千万级别，上面这行代码将分配千万级别的数组，并创建上千万个字符串。</p>
<p>这是什么操作？这些字符串创建之后有什么用呢？我们还是只能在Spark源代码里面找答案。阅读相关的源代码之后可以发现，Spark在<code>DataFrame</code>类中设计了一个用于存储元数据的<code>metadata</code>。而<code>Spark MLLib</code>中的多个算子都会借用这个<code>metadata</code>来存储相关算子的状态，在算子开始计算的时候，会判断是否已经存在相关的<code>metadata</code>，如果已经存在，那么就可以避免某些计算。更多关于metadata的分析可以参考<a href="https://github.com/awesome-spark/spark-gotchas/blob/master/06_data_preparation.md">这里</a>。</p>
<p>这里的<code>metadata</code>看起来对于我们的应用没什么用处。既然如此，我们可以先忽略这里的元数据。于是修改代码，再进行测试，发现<code>VectorAssembler.fit</code>可以正常运行了。</p>
<p>事实上由于我们的维度仅仅在千万级别，上面分配数组的操作是可以正常完成的，真正的OOM报错出现在另一个地方。经过仔细的分析，我们最终找到了报错的地方。代码在<a href="https://github.com/apache/spark/blob/v2.1.0/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala">这里</a>的989-991行。最终报错的地方处于<a href="https://github.com/apache/spark/blob/v2.1.0/core/src/main/scala/org/apache/spark/serializer/JavaSerializer.scala">这里</a>的98-102行。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// DAGScheduler.scala</span></span><br><span class="line">      <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</span><br><span class="line">          <span class="type">JavaUtils</span>.bufferToArray(</span><br><span class="line">            closureSerializer.serialize((stage.rdd, stage.shuffleDep): <span class="type">AnyRef</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">// JavaSerializer.scala</span></span><br><span class="line">    <span class="keyword">val</span> bos = <span class="keyword">new</span> <span class="type">ByteBufferOutputStream</span>()</span><br><span class="line">    <span class="keyword">val</span> out = serializeStream(bos)</span><br><span class="line">    out.writeObject(t)</span><br><span class="line">    out.close()</span><br><span class="line">    bos.toByteBuffer</span><br></pre></td></tr></table></figure>
<p>分析这里的代码，我们大致可以得知，Spark在序列化一个任务的时候，会将RDD及其对应的程序闭包序列化，而RDD关联的元数据也会一并序列化。由于我们这里的metadata可能包含上千万的字符串对象，在将这样大的metadata序列化为字节数组的时候，自然有可能出现OOM了。实际上这里只需要对象序列化大小超过2GB，就可能会出现这个问题。</p>
<h3 id="保存mleap模型时oom"><a class="markdownIt-Anchor" href="#保存mleap模型时oom"></a> 保存Mleap模型时OOM</h3>
<p>在解决了<code>VectorAssembler.fit</code>算子的问题之后，程序可以正常运行到第<code>8</code>步了，但是这里又出现了OOM。程序在运行一段时间之后，退出。查看异常日志发现，保存Mleap模型的时候，我们需要将Mleap模型序列化，而序列化会报错<code>java.lang.OutOfMemoryError: Requested array size exceeds VM limit</code>。</p>
<p>有了前面的经验，处理这个问题还算比较快。我们快速的找到了Mleap相关代码，发现<a href="https://github.com/combust/mleap/blob/v0.14.0/bundle-ml/src/main/scala/ml/combust/bundle/serializer/NodeSerializer.scala">这里</a>的第48行会报错。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">JsonFormatNodeSerializer</span> <span class="keyword">extends</span> <span class="title">FormatNodeSerializer</span> </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">write</span></span>(path: <span class="type">Path</span>, node: <span class="type">Node</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="type">Files</span>.write(path, node.asBundle.toJson.prettyPrint.getBytes(<span class="string">&quot;UTF-8&quot;</span>))</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure>
<p>原来是Mleap在保存模型为Json格式时会将其先转换为一个字节数组，然后写入文件。我们这里由于存在几个上千万的大字典对象，这里的Json将会超过2GB大小。</p>
<p>如何解决呢？阅读Mleap的文档可知，我们可以用<code>ProtoBuf</code>格式去序列化这个模型，<code>ProtoBuf</code>比<code>Json</code>不仅存储压缩率更高，而且可以直接以流的形式写入文件。但是如果我们直接用Mleap的代码还是可能会出现类似的问题，因为Mleap的<code>ProtoBuf</code>序列化实现也会先在内存里面分配一个字节数组。代码见<a href="https://github.com/combust/mleap/blob/v0.14.0/bundle-ml/src/main/scala/ml/combust/bundle/serializer/NodeSerializer.scala">这里</a>的60行。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ProtoFormatNodeSerializer</span> <span class="keyword">extends</span> <span class="title">FormatNodeSerializer</span> </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">write</span></span>(path: <span class="type">Path</span>, node: <span class="type">Node</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="type">Files</span>.write(path, node.asBundle.toByteArray)</span><br><span class="line">  &#125;</span><br><span class="line">  ......</span><br></pre></td></tr></table></figure>
<p>没办法了，只能优化一下mleap的源代码了。实际上，这里我们可以获得<code>ProtoBuf</code>的输出流，那么处理的办法显而易见，直接将数据流写入文件就行了。我们可以用如下代码实现：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">byte</span>[] buffer = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">4096</span>];</span><br><span class="line"><span class="type">int</span> n;</span><br><span class="line"><span class="keyword">while</span> (EOF != (n = input.read(buffer))) &#123;</span><br><span class="line">    output.write(buffer, <span class="number">0</span>, n);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（这里省略了文件流的创建及流的关闭等代码）</p>
<p>修改Mleap的代码，编译，再运行我们的应用。发现这个问题已经被修复了。</p>
<p>这个问题修复之后，整个Spark应用终于可以正常运行了。我们最终测试发现整个数据处理过程在1小时左右结束（还有优化的空间）。</p>
<p>由于保存一个超过2GB的大模型还是很耗时的，我们后来将这个步骤放到了另一个线程里面去并行运行。这样整个应用的运行速度又有了一定的提升。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>回顾整个优化过程，我们可以发现这里出现的大多数问题是由于我们写代码的时候没有考虑代码在大数据场景下会出现什么问题引起的。</p>
<p>作为一个专业的软件开发者，写出高性能的代码是我们的基本要求。我们的代码真的高效吗？它的复杂度有多少？它会执行多长时间？它的可能的性能瓶颈在哪里？它是否存在内存问题？这些问题可能是我们写下每行代码的时候都需要反问自己的。</p>
<p>特别是在大数据的场景下，未经过性能考究的代码，一旦应用于真实的业务场景，性能问题可能会暴露得更加明显。</p>
<p>我们所使用的库同样可能存在性能问题，比如这里用到的<code>Spark</code> <code>Mleap</code>，它们都是很流行的大数据工具了，但是在比较极端的企业真实应用场景考验下，依然可能有问题。</p>
<p>最后，感谢阅读了这么长的文字的读者，希望这里的分享的优化经验有所帮助。有任何问题，欢迎留言交流。</p>
]]></content>
      <categories>
        <category>数据</category>
        <category>大数据</category>
        <category>machine-learning</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>机器学习</tag>
        <tag>性能</tag>
        <tag>Spark</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习平台架构实践--配置管理</title>
    <url>/2020/05/23/architecture-designing-practise-for-ml-platform-configuration/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>随着系统功能越来越多，系统的配置也越来越多，配置管理成为了一个重要的问题。做过线上运维的同学们一定对配置的复杂性有深刻体会，多少次加班都是因为一个配置不对而导致系统无法正常工作！配置问题由于难以建立有效的自动化测试而难以检测，常常使得我们不得不花费数小时甚至数天来调试才能找到配置上的问题。</p>
<p>对于分布式计算，这个问题变得更加突出了，熟悉分布式大数据处理的同学们对于分布式任务的复杂配置一定深有感触。分布式系统本身的复杂性常常使得单个组件的配置就有上百个。而在微服务架构流行的当下，我们的系统越来越多以分布式的形式出现，系统的配置管理问题也越来越突出。</p>
<p>本文尝试分享一下我们在构建机器学习平台时对于配置管理方面的设计实践。</p>
<span id="more"></span>
<h2 id="模块自有配置导致的混乱"><a class="markdownIt-Anchor" href="#模块自有配置导致的混乱"></a> 模块自有配置导致的混乱</h2>
<p>结合上文中关于平台架构的分析，我们看到系统拆分了一个名为<code>connector</code>的通用模块，负责实现和外部系统进行对接。这一模块会同时支持<code>Rest API</code>及<code>ml</code>两个应用层模块。</p>
<p>由于<code>Rest API</code>及<code>ml</code>两个模块会连接同一个大数据集群进行数据操作，所以它们的不少配置是一样的。比如某一租户运行任务的缓存路径，读写的<code>hbase</code>的数据库名字等。一个简单的想法就是将这些与<code>connector</code>相关的共享配置放到<code>connector</code>模块中去，然后将无法共享的配置放到<code>Rest API</code>及<code>ml</code>各自的模块中去。</p>
<p>在刚开始时，我们确实是这样做的。但是随着系统功能慢慢的变得复杂，配置项越来越多，这样简单粗暴的配置设计越来越难以支撑系统的快速演进。主要问题表现在：1. 开发人员在新增配置的时候，对于配置放哪里（至少有3个地方）一直存在争议；2. 为了支持多个环境并避免配置重复，不得不自己实现类似<code>Spring profile</code>的配置加载机制；3. 某一个功能用到的配置可能分散到多个地方，出现问题的时候，需要从多个地方去识别配置问题；4. 由于配置会打包到<code>jar</code>包中，我们不得不为每个环境生成不同的包。</p>
<h2 id="统一的配置管理设计"><a class="markdownIt-Anchor" href="#统一的配置管理设计"></a> 统一的配置管理设计</h2>
<p>那么，在一个多模块的复杂系统中我们要怎么做才能有效的管理配置呢？</p>
<p>分析上述提到的痛点可以发现，对于一个好的配置管理设计，一个重要的点是配置要能集中进行管理。</p>
<p>在我们的系统中配置应该集中到哪里呢？稍加分析就能知道，配置当然要集中在某个最外层的应用层模块进行，因为各个服务实例的组装就是在这里完成的。在上面的这个场景中，我们有两个应用层的模块，即<code>Rest API</code>及<code>ml</code>。实际上<code>ml</code>模块并不是可以独立运行的模块，它的内部是实现了特征处理<code>Pipeline</code>和各种机器学习算法，以<code>spark</code>应用的形式提供出来。这些分布式应用的调度却来自<code>Rest API</code>，也就是<code>Rest API</code>是一个驱动器，是更偏应用层的一个模块。对于<code>ml</code>模块中需要的配置，我们就可以在调度其运行时通过参数的方式传入。于是，我们的配置就应该集中到<code>Rest API</code>模块中。</p>
<p>改造之后的配置如下图所示：</p>
<p><img data-src="/attaches/2020/2020-05-22-architecture-designing-practise-for-ml-platform-configuration/centralized-configuration.png" alt="集中配置" /></p>
<p>恰好<code>Rest API</code>模块是基于<code>Spring Boot</code>构建的，这样一来，就可以完全借助于<code>Spring</code>为我们提供的配置管理工具来实现配置管理了。</p>
<p>实现了这一步骤之后，整个配置设计就变得简单易懂，上面提到的配置管理问题也被有效的解决了。除了<code>Rest API</code>模块会根据不同的环境构建不同的包，其他的包全部都是可以按版本独立发布且可在各个环境复用的。至于<code>Rest API</code>模块，其实我们也可以很容易实现一个包支持多个环境，只需要我们将配置独立出来作为一个外部文件来管理即可。</p>
<p>为了实现这一架构调整，我们在原有系统上面进行了较大的重构。在重构过程中，有几点设计上面的经验是比较有价值的：</p>
<ol>
<li>从依赖倒置的设计思想来看，作为一个通用的模块，其配置设计应该以一个接口的形式进行定义，然后在模块内部所有需要使用此配置的地方引用该接口</li>
<li>对模块内某一个具体类的配置设计，应该考虑最小信息原则，仅支持类自身需要知道的几个配置，而尽量不要直接引用一个大而全的配置对象</li>
<li>在模块内部，可以考虑提供一个配置接口的实现，以便提供一些合理的默认配置</li>
<li>在配置设计上需要尽量保持配置项的独立，避免设计一些本可以通过原子配置计算得到的配置，这样可以减少配置数量</li>
</ol>
<h2 id="微服务中的配置"><a class="markdownIt-Anchor" href="#微服务中的配置"></a> 微服务中的配置</h2>
<p>除了要考虑模块中的配置设计，另一个要考虑的配置问题就是各个微服务中的配置设计。</p>
<p>由于微服务需要独立的为外部系统提供服务，我们无法将其当做一个模块来对待，所以配置是不得不存在的。</p>
<p><code>Spring Cloud Config</code>为我们提供了一个中心化管理微服务配置的思路，它考虑了支持配置文件的集中加载、版本管理（可以通过git实现）、容错等需求的实现。但是多部署一个组件来管理配置引入了额外的复杂度，多数团队不太希望引入一个需要额外维护的模块。</p>
<p><code>k8s</code>的<code>ConfigMap</code>及<code>Persistent Volume</code>设计为我们管理配置提供了另一种方式。我们可以将配置放到某一个共享的<code>ConfigMap</code>或<code>Persistent Volume</code>中。</p>
<p>在实践中，我们采用了<code>k8s</code>提供的配置管理机制。</p>
<p>在我看来，采用何种配置管理机制的一个主要考量是有多少重复的配置。如果各个微服务间的重复配置特别多，我们甚至可以参考<code>helm</code>管理<code>k8s</code>配置的机制，即通过模板系统来提供一个更高层的配置抽象，从而得到更少的配置项，然后通过程序自动生成不同的微服务的配置。</p>
<p>这里另一个需要思考的问题是为什么会有这么多的重复配置，是不是微服务拆分本来就不合理呢？因为一旦有重复的配置，就说明不同的微服务间有一个相同的依赖。这即是微服务耦合的体现。在微服务设计时，一个指导原则就是要采用DDD的思路进行拆分，避免出现高耦合的分布式大泥球。高内聚低耦合是我们进行系统设计的不懈追求，如果我们发现是由于服务拆分不合理导致的配置重复，那我们就得更早的进行调整，防止带来更大的损失。</p>
<p>在机器学习平台系统中，我们拆分出来的<code>Spark-Meta</code> <code>Monitoring</code> <code>MLServing</code> <code>Rest API</code>等几个微服务间几乎没有配置重复，这也使得我们在管理微服务的配置上面变得非常轻松。</p>
<h2 id="配置的存储和更新"><a class="markdownIt-Anchor" href="#配置的存储和更新"></a> 配置的存储和更新</h2>
<p>在进行配置设计时另一个我们经常关注的问题是配置怎么存放及更新的问题。比如，对于某一个配置项，我们是将其放置到配置文件中呢，还是放到数据库中？还比如，对于某一个配置项，如果我们有需求要进行动态的更新要如何实现？</p>
<p>对于配置的存储位置，一般而言，我们会优先考虑存储到配置文件中。如果存储到数据库中，实际上我们是将配置当做数据进行管理了。既然是数据，那么其访问权限就要被严格限制，否则将带来安全隐患，比如配置文件中通常要存储一些系统间通信的账号密码，我们如何保证这些数据的安全性呢？一些将配置存放到数据库中的想法可能来源于配置的更新可以通过维护数据库中的数据来简单的实现。然而，配置的动态更新需要程序逻辑的支持才行。比如，对于缓存的配置要何时更新？已经创建的对象要如何重建？这些可能是非常复杂的问题，远非修改一个数据库数据可以实现。因此，如非必要，我们还是要优先考虑将配置存储到配置文件中。</p>
<p><code>Spring</code>为我们提供的配置管理实现了在线更新配置的<a href="https://docs.spring.io/spring-boot/docs/current/reference/html/production-ready-features.html#production-ready-endpoints">接口</a>，我们可以直接修改某一个配置，而无需重启服务。但是这样一来，这些更新了的配置就只是在当前进程中生效了，一旦重启这些配置将不复存在。在当前容器化的时代，我们一般不会想通过这种方式来管理配置。而希望用一种更易于管理的方式实现，比如我们可以把配置的更新当做应用程序的一次更新，然后通过滚动升级的方式应用这个更新。在广泛使用<code>k8s</code>进行应用运维的当下，要实现不停服升级是轻而易举的。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>本文分享了在机器学习平台系统建设过程中，我们对于配置管理设计方面的思考和实践，还分享了关于配置的存储和更新的一些思考。如对于内容有任何疑问，或者有其他有用的实践分享，欢迎留言讨论。</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>架构</category>
      </categories>
      <tags>
        <tag>架构</tag>
        <tag>机器学习</tag>
        <tag>机器学习平台</tag>
        <tag>架构设计</tag>
        <tag>配置管理</tag>
      </tags>
  </entry>
  <entry>
    <title>CTR技术解读 -- 概览</title>
    <url>/2020/04/12/an-apprehensible-way-to-describe-ctr--introduction/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>作为机器学习的一个细分领域，CTR预估一直以来都是研究的一大热点。之所以成为研究的热点，是因为推荐领域巨大的商业价值。无论是我们每天通信用的微信QQ，还是我们每天搜索用的Google百度，或者是娱乐用的抖音斗鱼，广告在这些产品的收入中都占据着非常重要的组成部分，广告收入的背后是广告推荐引擎在发挥作用。除了广告，我们网上购物时的物品推荐，看新闻时的新闻推荐，听音乐时的音乐推荐等等，这些都是推荐引擎发挥作用的地方。在这些地方，推荐引擎都产生了巨大的价值。</p>
<p>对于如此重要的一个领域，我们做机器学习的小伙伴多多少少都需要了解一下。下面我将结合一个项目上的实际案例，来分享一下整个CTR的研究和应用情况。我将尝试尽可能用通俗易懂的语言，使得只要有一些基本的机器学习知识就能理解文章内容。文章将从应用角度出发，重点关注基本原理及工程实现而弱化更偏理论的公式推导等。</p>
<p>本系列文章将分为以下几个部分：</p>
<ul>
<li>概览：背景，研究的问题，技术架构及演进，一个小的例子</li>
<li>传统模型：协同过滤、LR模型及其应用</li>
<li>Embedding、深度学习模型及其应用</li>
<li>FM与DeepFM</li>
<li>DCN及其他深度模型</li>
<li>基于LSTM的模型：DIN、DIEN及DSIN</li>
<li>多任务模型</li>
</ul>
<span id="more"></span>
<h2 id="ctr"><a class="markdownIt-Anchor" href="#ctr"></a> CTR</h2>
<p>CTR的全称是Click-Through Rate，即点击率。这里的点击当然就是指点击推荐的内容，如视频、音乐、新闻、广告等。</p>
<p>如何进行推荐呢？从结果来看，我们希望算法能输出一个推荐内容的列表，这个列表按照一定的规则（比如用户感兴趣的程度、最大化盈利）进行排序。为了计算这个列表，用户点击某个内容的概率将是一个重要的输入。所以，CTR预估成为了推荐领域的最重要的部分之一。事实上，CTR预估的准确程度很大程度上影响着推荐结果的好坏。</p>
<h2 id="主流推荐系统架构"><a class="markdownIt-Anchor" href="#主流推荐系统架构"></a> 主流推荐系统架构</h2>
<p>在推荐场景中，我们需要思考和解决下面这些问题：</p>
<ol>
<li>如何处理数据形成特征</li>
<li>如何高效的、稳定的进行模型训练</li>
<li>如何将训练好的模型快速用于线上推理</li>
<li>如何支持模型在线优化</li>
<li>如何快速的实验新的特征及模型</li>
</ol>
<p>从整体上来看，推荐系统架构将是一个离线、近在线、在线处理相结合的一个复杂系统。完全在线处理推荐系统中的所有问题是一种理想情况，其成本将非常高昂，即便大型互联网公司也未必能做到。一个相对完善的推荐系统解决方案都会组合利用这三种模式各自的优势来解决问题。</p>
<p>一般的机器学习任务都会包含数据和模型两部分，推荐系统也不例外。从数据层面看，推荐系统的数据可以来自三个方面：1. 用户数据，比如年龄、性别等；2. 物品（或广告）数据，比如广告文案、图像、视频等；3. 场景数据，比如广告位、当前时间、是否节假日等。于是，我们可以得到这样的推荐系统逻辑架构：</p>
<p><img data-src="/attaches/2020/2020-04-12-an-apprehensible-way-to-describe-ctr--introduction/logic-architecture.png" alt="推荐系统逻辑架构" /></p>
<p>对于这些数据，如果按照实时性维度来看，可以分为离线数据、近实时数据、实时数据。正好就可以用不同实时性的数据处理工具进行处理。</p>
<p>从模型层面看，简单的处理方式就是离线模型训练配合在线模型定期更新。如果模型训练时间比较长，可能只能实现按天进行更新。如果模型可以有一定的迁移能力，那么就有可能按小时进行模型离线迁移学习，实现按小时进行模型更新。如果工程能力比较强，能同时实现模型在线训练和服务，那么模型的更新周期就能缩短到分钟级别。模型更新的时效性通常对推荐的效果有很大的影响。</p>
<p>一般而言，当前主流的推荐系统会在设计上将整个推荐过程分成这样几个主要的步骤：召回 -&gt; 排序 -&gt; 再排序。召回层主要目标是快速缩小推荐范围，一般会利用业务规则、高效的算法或简单的模型实现。而排序层则对筛选出来的小规模数据进行CTR预估和排序。再排序层则会充分考虑推荐结果的多样性、流行度、新鲜度等指标，对排序好的结果进行最终的调整。</p>
<p>有了以上这些分析，我们可以得到一张常见的推荐系统的架构图：</p>
<p><img data-src="/attaches/2020/2020-04-12-an-apprehensible-way-to-describe-ctr--introduction/recommendation-system-architecture.png" alt="推荐系统架构" /></p>
<h2 id="推荐系统技术演进"><a class="markdownIt-Anchor" href="#推荐系统技术演进"></a> 推荐系统技术演进</h2>
<p>在推荐系统中，模型发挥作用最明显的一步就是排序层，同时排序层也是整个推荐系统中最重要的一步。所以，大多数的研究都是针对排序层的研究，这里提到的技术演进也主要是指排序层模型的技术演进。</p>
<p>2010年之前，业界主流的推荐系统一般都是基于协同过滤或简单的逻辑回归（<code>LR</code>）模型实现，也有的系统会基于某些业务特征进行推荐，比如标签、地域、热度等。这些模型利用数据的能力有限，需要大量的领域专家设计特征，准确率也不高。</p>
<p>从2010到2015年间，随着移动互联网的高速发展，基于传统模型进行了大量的改进。出现了因子分解机（<code>FM</code>）、梯度提升树（<code>GBDT</code>，<code>Facebook</code>的主要模型）等基于协同过滤的改进模型。也出现了<code>FTRL</code>（<code>Google</code>的主要模型）、混合逻辑回归（<code>MLR</code>，阿里的主要模型）等基于LR模型的改进。</p>
<p>2015年之后，随着深度学习在计算机视觉领域和自然语言处理领域的成功应用，推荐领域的研究方向也快速转向了以深度学习为主。由于深度模型更少的依赖人工特征工程，并能更有效的利用数据和发现数据中的模式，这些模型得到了非常快速的迭代演进和工程应用。当前常见用于各大互联网公司的模型，比如<code>Google</code>提出的<code>Wide&amp;Deep</code>模型，微软提出的<code>Deep Crossing</code>模型，阿里提出的引入注意力的<code>DIN</code>模型及可以进行时序建模的<code>DIEN</code>模型，基于深度学习的协同过滤模型<code>NeuralCF</code>等等。可以看到，深度推荐模型的设计思路开阔，方向多样，呈现出百花齐放的状态。</p>
<p>简单总结一下可以得到下图：</p>
<p><img data-src="/attaches/2020/2020-04-12-an-apprehensible-way-to-describe-ctr--introduction/model-evolving.png" alt="推荐模型发展" /></p>
<p>后续文章中，我将会陆续挑选一些主流的模型进行分析和实践。</p>
<h2 id="一些重要的问题"><a class="markdownIt-Anchor" href="#一些重要的问题"></a> 一些重要的问题</h2>
<p>除了模型之外，推荐系统中还有一些比较重要的问题。这里简要分析一下。</p>
<h3 id="特征处理"><a class="markdownIt-Anchor" href="#特征处理"></a> 特征处理</h3>
<p>机器学习领域有一个基本的认知，那就是“数据和特征决定了机器学习的上限，模型和算法只是在逼近这个上限”。所以，好的特征是非常关键的一步。在优化模型的时候，如果陷入了一个瓶颈，回过头来从数据层面进行分析可能会有意想不到的效果。常常需要对数据和模型进行综合优化才能实现较大的性能提升。</p>
<p>为了将特征接入模型，需要对数据进行一定的处理，转化为模型需要的格式。对于一般的类别特征，常见的特征处理办法是进行<code>OneHot</code>编码。对于多类别的特征，比如近期观看的电影列表这类，进行<code>MultiHot</code>编码可以实现类似<code>OneHot</code>的效果。（这两类数据处理方式可以参考我的<a href="/2020/01/21/spark-performance-tuning-on-billions-of-data/">另一篇文章</a>。）对于一些统计特征，比如平均每月在产品中的花费等，则可以直接将数值特征输入模型。</p>
<p>除了这些基本的数值型或类别型数据，由于深度学习的快速进步，对于文本、图片、视频等数据现在也有了更多的处理办法。比如对于文本特征，可以用数据挖掘常用的<code>TF-IDF</code>进行特征处理，也可以用深度学习模型，如<code>Word2Vec</code>、<code>Transformer</code>等模型将数据编码为稠密的特征向量。对于图片和视频，同样也可以采用深度学习模型提取特征向量。这些数值化之后的特征就可以作为模型输入了。除了应用基本的深度学习模型，在推荐领域，还发展出了<code>Item2Vec</code> <code>Graph Embedding</code>等抽取特征的模型。虽然这些特征的处理过程代价较高，但是它给我们带来了大量新的应用数据的可能。</p>
<h3 id="效果评估"><a class="markdownIt-Anchor" href="#效果评估"></a> 效果评估</h3>
<p>推荐问题，其本质是一个二分类机器学习问题，因为只需要预测用户会不会点击某个物品即可。为了支持排序，模型需要输出一个物品被点击的概率。对于这样的问题，一般的评估指标是模型的准确率（Accuracy）。但是在推荐领域，我们不能使用简单的准确率来评估模型效果。</p>
<p>推荐领域的数据集一般是非常不均衡的。对于应用给我们推荐的物品，大概计算一下点击过的次数就能意识到这个问题。有可能推荐的物品中有99%是没有被点击过的。这就带来了训练数据集庞大而非常不均衡的情况。在这样的情况下，如果采用准确率来评估，只要模型对所有数据预测为负就可能得到99%的准确率。但是此时的模型几乎没有任何用处。</p>
<p>在推荐领域，常用的模型评估指标是<code>AUC</code>，即 Area Under Curve 。是什么曲线下面的面积呢？在推荐领域这里的曲线一般是指<code>ROC</code>曲线，<code>ROC</code>曲线是以<code>FPR</code>（False Positive Rate，假阳率，错误的判定为正例的概率）为横轴，以<code>TPR</code>（True Positive Rate，真阳率，正确的判定为正例的概率）为纵轴的一条曲线。由于在<code>AUC</code>评估指标中使用了百分比为基础数据，它的结果与样本是否均衡无关。</p>
<p>除了模型指标之外，还可以考虑的一个问题是如何尽可能利用实时的数据进行效果评估。一个常用的方式是进行<code>A/B</code>测试，通过将用户进行随机分组并对不同的分组应用不同的模型，然后评估不同模型的效果。除此之外，微软在2013年提出了<code>InterLeaving</code>的方式进行在线的效果评估。<code>InterLeaving</code>通过在同一推荐位上交替展示不同模型的推荐来对比不同模型的效果。有了这些实时的模型评估手段，我们可以更有信心的进行模型选择，甚至可以让模型选择自动化的进行。</p>
<h3 id="冷启动"><a class="markdownIt-Anchor" href="#冷启动"></a> 冷启动</h3>
<p>推荐领域的一个重要的问题是冷启动问题。当一个新用户进入的时候，没有历史数据，如何进行推荐呢？当新物品加入的时候，如何进行推荐呢？当系统刚开始搭建起来，应用刚进入市场，如何进行推荐呢？</p>
<p>通常可以有两类方法解决冷启动问题。一是充分利用业务进行推荐，比如新用户加入的时候可以推荐热门榜单、最新榜单等条目。二是尽可能的挖掘信息，充分利用已有数据进行推荐。比如当新用户进入的时候，我们往往可以获取到用户注册时的基本信息，如人口学特征等，然后我们可以根据这些信息查找相似的用户，利用这些相似用户的信息进行推荐。当新物品加入的时候，也可以采用类似的方式。引导用户输入更多信息是一种有效的挖掘信息的方式，比如在产品设计上可以在新用户加入时引导其选择兴趣爱好，在音乐、新闻等内容应用上经常能见到此类功能设计。从第三方平台获取数据也不失为一种手段，当前有不少的统计分析平台，可以获取用户的一些统计特征，这些数据也可以作为推荐系统冷启动的数据来源。</p>
<h3 id="探索与利用"><a class="markdownIt-Anchor" href="#探索与利用"></a> 探索与利用</h3>
<p>一些做的不够完善的推荐系统常常在一段时间之后陷入推荐内容过于同质化的问题。比如系统发现用户喜欢汽车，就频繁推送汽车相关的物品。同质化严重将导致用户对推荐的内容逐渐失去兴趣。</p>
<p>这里的问题其实就是多度利用了历史数据带来的问题。推荐系统除了做好数据利用，还需要考虑如何探索用户的新需求新兴趣，同时也需要考虑长尾物品或长尾物品的推荐。在推荐系统的再排序过程可以根据业务具体情况加入一些合理的条目。比如经典的<code>ξ-greedy</code>探索策略，以一定的递减的概率随机加入一些推荐条目。也可以在模型层面来考虑解决这个问题，比如可以有针对性的添加模型参数随机扰动机制，引入了强化学习思想的<code>DRN</code>模型可以作为此类方案的一个典型代表。</p>
<h2 id="一个简单的示例"><a class="markdownIt-Anchor" href="#一个简单的示例"></a> 一个简单的示例</h2>
<p>实现一个完善的推荐系统是一个复杂而巨大的工程，但是，在理论和工具都非常丰富的现在，要搭建一个可用的推荐系统<code>MVP</code>其实并不难。下文将以一个简单的示例作为结尾。</p>
<p>协同过滤是常见的推荐系统算法，其基本思路是根据相似性进行推荐。例如，基于用户的协同过滤算法会推荐跟目标用户有相似爱好的其他用户所喜欢的物品。下面我们将在<a href="https://grouplens.org/datasets/movielens/"><code>MovieLens</code></a>数据集上面进行实验，尝试实现基于用户的协同过滤推荐系统。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">normalize</span>(<span class="params">vec_a: np.ndarray, vec_b: np.ndarray</span>):</span><br><span class="line">    vec_a_avg = vec_a.<span class="built_in">sum</span>() / (vec_a &gt; <span class="number">0</span>).<span class="built_in">sum</span>()</span><br><span class="line">    vec_b_avg = vec_b.<span class="built_in">sum</span>() / (vec_b &gt; <span class="number">0</span>).<span class="built_in">sum</span>()</span><br><span class="line">    vec_a_intersect = vec_a * (vec_b &gt; <span class="number">0</span>)</span><br><span class="line">    vec_a_intersect[vec_a_intersect &gt; <span class="number">0</span>] = vec_a_intersect[vec_a_intersect &gt; <span class="number">0</span>] - vec_a_avg</span><br><span class="line">    vec_b_intersect = vec_b * (vec_a &gt; <span class="number">0</span>)</span><br><span class="line">    vec_b_intersect[vec_b_intersect &gt; <span class="number">0</span>] = vec_b_intersect[vec_b_intersect &gt; <span class="number">0</span>] - vec_b_avg</span><br><span class="line">    <span class="keyword">return</span> vec_a_intersect, vec_b_intersect</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cos_sim</span>(<span class="params">vec_a, vec_b</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(vec_a, vec_b) / (np.linalg.norm(vec_a) * np.linalg.norm(vec_b))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    ratings = pd.read_csv(<span class="string">&#x27;data/movielens/ml-latest-small/ratings.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    movies = <span class="built_in">dict</span>([(movie_id, idx) <span class="keyword">for</span> (idx, movie_id) <span class="keyword">in</span> <span class="built_in">enumerate</span>(ratings[<span class="string">&#x27;movieId&#x27;</span>].unique())])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;movies(&#123;&#125;): &#123;&#125;...&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(movies), <span class="built_in">list</span>(movies.items())[:<span class="number">10</span>]))</span><br><span class="line"></span><br><span class="line">    user_rating_vectors = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> user_id <span class="keyword">in</span> ratings[<span class="string">&#x27;userId&#x27;</span>].unique():</span><br><span class="line">        user_rating_vector = np.zeros(<span class="built_in">len</span>(movies))</span><br><span class="line">        user_ratings = ratings[ratings[<span class="string">&#x27;userId&#x27;</span>] == user_id]</span><br><span class="line">        <span class="keyword">for</span> (_, rating) <span class="keyword">in</span> user_ratings.iterrows():</span><br><span class="line">            user_rating_vector[movies[rating[<span class="string">&#x27;movieId&#x27;</span>]]] = rating[<span class="string">&#x27;rating&#x27;</span>]</span><br><span class="line">        user_rating_vectors[user_id] = user_rating_vector</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;user_rating_vectors(&#123;&#125;): &#123;&#125;...&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(user_rating_vectors), <span class="built_in">list</span>(user_rating_vectors.items())[:<span class="number">2</span>]))</span><br><span class="line"></span><br><span class="line">    target_user_id = <span class="number">610</span></span><br><span class="line"></span><br><span class="line">    target_user_rating_vector = user_rating_vectors[target_user_id]</span><br><span class="line">    user_sim = [(user_id, cos_sim(*normalize(target_user_rating_vector, rating_vector)))</span><br><span class="line">                <span class="keyword">for</span> (user_id, rating_vector) <span class="keyword">in</span> user_rating_vectors.items()</span><br><span class="line">                <span class="keyword">if</span> user_id != target_user_id]</span><br><span class="line">    user_sim = <span class="built_in">sorted</span>(user_sim, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    similar_user = user_sim[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;similar_user: &#123;&#125;, user_sim: &#123;&#125;...&#x27;</span>.<span class="built_in">format</span>(similar_user, user_sim[:<span class="number">10</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;target_user_rating_vector: &#123;&#125;\nsimilar_user_rating_vector: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">list</span>(target_user_rating_vector), <span class="built_in">list</span>(user_rating_vectors[similar_user])))</span><br><span class="line"></span><br><span class="line">    similar_user_ratings = ratings[ratings[<span class="string">&#x27;userId&#x27;</span>] == similar_user]</span><br><span class="line">    similar_user_ratings = similar_user_ratings.sort_values(by=<span class="string">&#x27;rating&#x27;</span>, ascending=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;recommended movies:&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(similar_user_ratings.head(<span class="number">10</span>))</span><br></pre></td></tr></table></figure>
<p>到这里大家应该了解了一些基本的推荐系统知识，后续文章将挑选几个模型进行介绍并实践。敬请期待！</p>
]]></content>
      <categories>
        <category>machine-learning</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>ctr</tag>
        <tag>深度学习</tag>
        <tag>广告点击预测</tag>
      </tags>
  </entry>
  <entry>
    <title>银行贷款业务是怎么一回事？</title>
    <url>/2020/07/07/basic-loan-business/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>说起银行贷款，我们绝大多数人应该都用过这个业务。比如，我们上大学，不少人办理过国家助学贷款。看这个贷款名字，好像跟银行没什么关系。但其实办理过这个贷款的同学都知道，这个贷款是我们跟银行产生的一个借贷关系。我们需要跟银行签订贷款合同，毕业后还款也是向银行还款。只不过因为是助学性质，国家会有一定的优惠贴息。再比如，我们买房，现在房价很高，对于一个主要靠自己的收入作为买房资金来源的同学，不贷款几乎不可能。不管是商业贷款还是公积金贷款，这里面都是银行在提供贷款业务。对于个人经营需要，企业发展需要，银行贷款就更是少不了了。</p>
<span id="more"></span>
<p>我们多数人办理贷款，是怎么做的呢？比如我之前买房，首先是向售楼部的销售打听贷款的首付款数额，然后就是东拼西凑首付款，再之后就是让销售帮忙办理首付款支付。一刷卡，好不容易凑齐的几十万，人生中银行卡余额最多一次，一下子清零。接着就是等着办银行贷款了，我们先按销售说的去准备好收入证明、各种身份证件等，销售一通知，我们就去银行了。接着就是签名按手印，签名按手印，签名按手印。贷款材料一大摞，我们也不知道是啥，反正银行说在哪里签名，我们就在哪里签名，说在哪里按手印，我们就按。接下来，就等贷款下来了，又有某一天，销售一通知，说是要开始还款了。然后我们就每个月定期向银行卡里面存多少多少钱，银行也每个月从里面划走多少多少钱。</p>
<p>不少人稀里糊涂的在办着贷款，某一天突然一拍大腿，想起来，我的100万贷款怎么从来没有打到过我的银行卡里呢？曾经还以为这么大的数额可以炫耀一把，结果钱的影子都没看到！</p>
<p>那么银行的贷款业务究竟是怎么运作的呢？我们稀里糊涂签字按手印的都是什么内容？为什么贷款之后，钱都从来没有进入过我们的账号呢？今天我们就一起来了解一下银行贷款业务。</p>
<p>银行是帮我们管钱的机构，有了银行，我们就可以把钱存进去，从而不用操心如何在自己家保管的事情了。即便哪天家里失盗了，发生火灾了，我们的资金仍然是安全的。除此之外，钱存银行还能有一点点利息。</p>
<p>既然我们把钱都存进了银行，那么银行就变成了一个大型的金库。这样一个金库它是如何盈利的呢？没错，就是靠贷款了。贷款作为银行最主要的一个盈利渠道，是银行赖以生存的基础。一般而言，我们把钱存银行的利息是很少的，活期存款的年利率只有少的可怜的0.3%，即便定期一年的存款通常也只有百分之一点几。而贷款的利率就高了，一般年利率在百分之五左右，根据不同贷款的数额、时间、还贷风险有所不同。这里的差值就是银行的利润空间了。</p>
<p>贷款业务是如何进行的呢？一般而言，我们可以简单的将贷款分为三个阶段，即贷前贷中贷后。我们去提交贷款申请，银行进行贷款审批就是贷前发生的活动。银行贷款审批完成之后，就进入到贷中，我们要和银行签订贷款合同，银行根据约定的时间进行放款。银行放贷之后，就是我们按照合同约定进行还款了，这即是贷后。</p>
<p>这么一说好像也挺简单。如果我们每个人都遵纪守法，诚信借贷，银行就是躺着赚钱啊。</p>
<p>但是问题关键也就在这里，每个人都遵纪守法诚信借贷这是一个很强的前提。以前跟亲戚朋友借钱，还得考虑个人的信誉、形象及情感维护，该还的钱必须得还，要不然自己就被大家孤立了，以后再有困难就难以解决了。但是现在跟银行借钱，就不一样了，银行对于我们而言是一个没有感情的赚钱机器，拿着我们存进去的钱去放贷赚利差。那么，是不是我借了银行的钱不还也是合理的呢？反正银行通过我存进去的钱已经赚了很多了。另一个方面，就算这次我没还银行钱，下次说不定我还可以换家银行贷款呢！所以，银行贷款业务中，要让大家自主的去讲诚信，只是一个美好的愿望。如果没有合理的手段去进行限制，贷款业务就面临巨大风险。</p>
<p>这里的贷款风险，我们称作是信用风险。银行的贷款业务有很大一部分内容都是在讲如何降低信用风险带来的影响。</p>
<p>从贷前申请开始，我们要准备很多材料，到贷中我们要在一叠很厚的材料上面按几十个手印，这其实都是在通过各种各样的机制来降低信用风险。</p>
<p>在申请贷款时，我们通常要准备好身份证、户口本、工资收入证明、投资收入证明、财产证明、财产共有人信息等材料，如果有抵押物的，需要提供抵押物的所有权证明，如果有质押物的，需要提供质押物的处置权证明，如果有担保人保证，需要提供担保人的基本情况、经济收入、财产证明等。这些材料均需要权威机构才能出具，个人伪造的成本是很高的。银行在得到这些证明材料之后，就可以一定程度上判断借款人的还贷能力了。</p>
<p>申请贷款另一个重要的问题是借款人需要有明确的合理的贷款用途。比如，房贷，用途很明显就是买房，车贷就是买车，个人由于商业经营需要购买生产资料，比如贷款购买口罩机生产口罩，也是合理的贷款用途。</p>
<p>银行得知了贷款用途、贷款金额就能基本确定贷款信息的真实性。得知了借款人提供的材料，就能基本判断借款人的还款能力。有了这些信息就可以初步判断是否可以放贷了。对于这些材料的检查核验，及对贷款资格的初步确认称为贷款初审。</p>
<p>毕竟前面的材料都是借款人提供的，如果有假怎么办呢？所以银行进行贷款贷前调查也是很重要的一步。贷前调查一般会根据实际情况采用与借款人面谈或实地调查的方式进行。面谈的时候，可以根据借款人的语气、陈述的内容是否与提交的材料一致对贷款的真实性进行判断。比如，如果以住房作为抵押，面谈时，借款人连房子的面积、朝向都不能明确的说出，那么就很大程度上存在伪造材料的可能，如果面谈没有发现问题，实地调查则可以进一步确认房子是不是存在，是不是完好等。</p>
<p>经过贷款的初审及调查之后，银行对这笔贷款申请就更有信心了。接下来进入贷款审查和审批阶段。通常，在贷款审查阶段，银行审查人员需要审查借款人是否有资格和条件，贷款金额、期限是否符合规定，借款人提供的材料是否完整、合法、有效，初审及调查得出的分析结论是否合理等等。这里其实就是安排另一个人来对于前面步骤提交的资料进一步核实。多一个人多一双眼睛，就可能发现潜藏得更深的问题。审查没有发现问题，就可以提交审批人员进行贷款审批了。在贷款审批时，审批人员不仅要考虑审查结论，还需要结合国家政策、可行性、经济性方面综合考虑是否发放贷款。比如，现在银行存款不够，资金不足，或者国家正在严控此类贷款，那么即便前面的材料都是真实有效的，也可以拒绝贷款。由于贷款审批是银行决定是否发放贷款的最后一个关键步骤，所以根据不同的贷款金额，审批通常需要具有较高级别的人员才有权限操作。为了做好最后一环，审批阶段还可以通过多人审批来综合更多人的意见，从而降低风险。</p>
<p>在前面一系列的调查、审查、审批阶段之后，如果确认可以贷款，那贷前步骤就完成了。进入贷中，贷中主要的流程就是签订合同及放款。</p>
<p>为了防止违约，贷款合同的内容要事无巨细，清晰的写明双方的诚信承诺、贷款资金用途、贷款金额、贷款利率、支付方式、还款方式等。还需要明确的指出各方的权利和义务，违约责任等。这里的内容非常多，这也就是为什么我们要签字按手印重复数十遍了。对于合同的内容，作为一个诚信借款人，我们自信能按约定还款，一般也不会过多关注。这里材料太多，而且我们也没有专业的法律知识，就算我们能慢慢花时间看材料，通常也难以发现问题。有人会担心银行会不会偷偷在合同里面增加一些对他们有利的条款。其实国家法律对于合同的合理性有很严格的说明，贷款领域的法律更是非常完善，银行想在这方面欺诈借款人是比较难的。而且银行业没有必要因为某一笔贷款砸了自己的口碑。作为借款人，在这里我们主要会关心贷款的利率，它决定了我们要还多少钱，其他的只需要对于大致的违约责任有所认识就够了。比如，放贷不还，银行可以收回房子拍卖，有抵押物，银行也可以将抵押物拍卖偿债。</p>
<p>放款阶段是最激动人心的了，因为马上银行卡里面就会多一大笔钱。然而，很多时候我们可能根本见不到贷款来的钱。银行为了保证我们按照申请的用途使用贷款，原则上会直接将贷款发放到我们的交易对象账户。比如，房贷的发放，贷款直接进入了开发商的账户，车贷也直接进入了汽车经销商的账户。这一原则在多数情况下直接避免了我们把贷款用于其他用途。想想看，一旦我们自己账户里面多了一笔钱，其实银行是很难控制贷款用途的，因为我们可能可以随时将钱取出来或转账到其他地方。这一贷款发放方式叫做贷款人受托支付。如果受托支付由于某种原因无法进行，那么才有可能贷款进入自己的账户，这种情况虽然允许，但是有很多的限制，比如个人消费类贷款交易金额不超过30万，经营性贷款金额不超过50万等。</p>
<p>贷款业务的最后一个阶段就是贷后，贷后阶段主要涉及借款人按期进行还款。对于一个正常还款的贷款，银行在这一阶段几乎不需要做任何事情。但是作为银行的主营业务，银行的贷款数量是巨大的，一旦贷款多了，违约的情况也就司空见惯了。所以，在贷后阶段，银行还有很多事情要做。首先就是定期检查，银行需要跟踪了解借款人基本还贷能力的变化情况。比如，做生意亏了，工作没了，贷款就可能还不上了。再比如，房价暴跌也可能导致借款人违约，因为借款人可能会发现需要还银行的贷款都可以拿来再买一套房子了，那为啥要还款呢，让银行收回房子算了。所以借款人的还贷能力和还贷意愿定期跟踪是银行贷款业务的重要一环。除此之外，在贷后阶段，一旦有贷款违约发生，银行还需要根据合同的约定进行违约追偿，包括抵押物拍卖，向保证人追偿等。对于尚有还款意愿，只是暂时还款困难的，可能需要定期催收，包括以短信形式、上门的形式、司法诉讼的形式等。</p>
<p>贷后阶段还有一类常见的活动，就是贷款变更。比如，我们在贷款之后，生意大赚，一夜暴富，或者工作升迁，彩票中奖等等，有钱了，那也就不需要再按期还贷了，我们一次性还了它。这里的贷款变更，通常会包括贷款主体变更，即借款人变更，借款期限调整，比如提前还款或者贷款展期，还款方式变更，比如以前是等额本息，现在想调成等额本金等等。只要我们和银行达成了一致，贷款变更通常可以通过重新签订合同等方式比较容易的完成。</p>
<p>贷后阶段，银行还需要为借款人保管其提交的资料。这涉及档案管理工作，包括档案的归档登记、借阅管理、移交和接管等。</p>
<p>在合同期结束，借款人按期还款完毕，整个贷款就结束了，借款人从银行取档案材料回家。</p>
<p>以上就是银行贷款业务的大致内容了，用一张图可以概括如下：</p>
<p><img data-src="/attaches/2020/2020-07-07-basic-loan-business/loan-process.png" alt="loan process" /></p>
<p>到这里，大家应该对银行的贷款业务有了一定的了解了。随着时代经济的发展，银行贷款跟我们的关系可谓越来越密切，同时，贷款其实也对整个社会的发展意义重大，它不仅可以让我们提前住上新房，解决我们暂时的经营困境，还有力的促进了整个社会资源更合理的配置，提升了社会效率。可以说整个社会的发展繁荣离不开银行贷款。对于我们自身而言，合理的利用贷款，也能为我们建设更美好的幸福生活添砖加瓦。</p>
]]></content>
      <categories>
        <category>业务</category>
      </categories>
      <tags>
        <tag>金融</tag>
        <tag>业务</tag>
        <tag>贷款</tag>
      </tags>
  </entry>
  <entry>
    <title>极速软件发布的实现</title>
    <url>/2020/06/01/node-bpm/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>在当下很多的应用场景中，我们常常会想要应用具有一定的灵活性，以便我们可以在线调整计算逻辑，而不需要重新发布应用。这可能也可以称为以极限的速度发布软件的方式。</p>
<p><code>AB测试</code>可以说解决了一部分这样的需求，使得我们可以在线的针对部分用户改变应用的行为。但<code>AB测试</code>需要我们预先定义并实现两套逻辑，然后通过线上配置来应用不同的逻辑。显然，在可自定义的程度上，<code>AB测试</code>是非常弱的。如果我们想要更大规模的调整应用的逻辑，<code>AB测试</code>就不够了。</p>
<span id="more"></span>
<p>除了<code>AB测试</code>，有另一种大家能很容易想到的实现方式，那就是支持线上脚本。我们可以设计一个管理员功能，以便管理员可以上传代码，或者在线编辑代码，然后应用可以将这样的代码动态的应用到程序里面。为了方便的编写代码，通常这样的线上脚本语言会以更容易编写也更简洁的<code>Groovy</code> <code>Scala</code>或者<code>Python</code> <code>JavaScript</code>。</p>
<p>自定义脚本的方式虽然比<code>AB测试</code>更自由灵活，理论上可以实现任何功能。但是如果我们大量采用这样的方式来自定义程序功能，带来的弊端也是显而易见的，比如：</p>
<ul>
<li>程序可能没有经过完善测试就被应用到了线上，从而带来更多的潜在bug和不稳定性</li>
<li>脚本的版本管理可能更难以实施</li>
<li>可能导致功能被滥用，而导致代码越来越难以管理</li>
</ul>
<p>在实践中，我们常常要较好的平衡这样的动态脚本的功能范围，才能发挥好它应有的作用。</p>
<p>事实上，可能还有另一种处于AB测试和自定义脚本的中间实现方式。</p>
<h2 id="工作流应用"><a class="markdownIt-Anchor" href="#工作流应用"></a> 工作流应用</h2>
<p>在最近的一个项目上我有机会调研了一下比较传统的工作流应用。工作流应用的典型场景是在企业管理流程数字化领域。比如，对于一个请假流程，可能的流程是：1. 提交请假原因时间等信息；2. 部门领导审批；3. 人事部门审批；4. 请假结束销假。我们当然可以很容易的针对这样的流程实现一个请假应用。但是在另一个企业中，请假流程可能变为：1. 提交请假原因时间等信息；2. 给相关人员发邮件；3. 请假结束销假。我们难道要为每一个企业单独定制一种请假应用？工作流应用就是应用在这样的场景中，期望以一种低代码的方式快速定制出各个公司所需要的不同的工作流程。</p>
<p>早在20年前这个问题就开始被大家研究了。BPMI(The Business Process Management Initiative)曾经开发了一套标准叫业务流程建模符号(BPMN - Business Process Modeling Notation)。经过超两年的努力，于2004年5月对外发布了BPMN 1.0 规范。后BPMI并入到OMG组织，并于2011年推出BPMN2.0。很多商业公司实现了这个标准，并提供了相应的可视化流程设计器，我们只需要用这个设计器设计流程并编写少量的代码就能实现各种不同的企业应用了。这无疑大大推进了企业的数字化进程。</p>
<p>当前最流行的开源工作流引擎要算<code>activiti</code>了，它是由Alfresco公司开发，以<code>Apache license</code>授权在<code>GitHub</code>开源。使用<code>activiti</code>，要完成上述请假流程，我们首先用基于网页或者<code>eclipse</code>插件的流程设计器设计流程（包括可以分派给某人的流程任务和程序自动化完成的任务），导出<code>bpmn2</code>的流程配置文件，然后对于请假申请表单，审批表单等，可以用表单设计器设计相应的表单，最后根据需求进行一定的定制就可以完成了。以下几张截图可以让大家体会这个过程。</p>
<p><img data-src="/attaches/2020/2020-06-01-node-bpm/activiti-designer.png" alt="activiti designer" /><br />
<img data-src="/attaches/2020/2020-06-01-node-bpm/activiti-explorer.png" alt="activiti explorer" /></p>
<p>为了支持更完善的功能，<code>activiti</code>在<code>bpmn2</code>标准的基础上添加了很多的功能，比如基于事件处理器的机制，定时器机制，异常处理机制，数据库事务支持，发邮件，<code>WebService</code>集成支持等等。通过并行网关或者排他网关（相当于条件控制器），流程设计器还可以支持非常复杂的流程控制。</p>
<p>对于这类工作流应用，大家褒贬不一，反对意见主要在于：</p>
<ol>
<li>一旦我们过于依赖工作流应用，我们的代码逻辑可能会以众多脚本的形式分散到配置文件中，难以建立单元测试来保证程序功能；</li>
<li>难以从领域角度进行有效的建模，当流程过于复杂之后，这种基于流程和数据的架构难以支持应用的演进；</li>
<li>流程之间的数据传输基于无模型抽象的字典，一旦状态多了，程序会更难以理解和不好调试。</li>
</ol>
<p>总之要想发挥工作流应用的最大效果，我们需要平衡好抽象的粒度，需要梳理好哪些流程要交给代码完成（代码天生用于实现复杂流程控制），哪些交给工作流应用。</p>
<h2 id="极速发布的实现"><a class="markdownIt-Anchor" href="#极速发布的实现"></a> 极速发布的实现</h2>
<p>既然工作流应用对于流程定义有相对完善的支持，那么理论上可以用它来实现任意的程序功能。除了用于建模企业工作流程，是不是可以拿来解决文章开始提到的在线调整程序逻辑的功能呢？</p>
<p>为了实现这一功能，我们可以将应用服务<code>API</code>作为可供工作流服务任务（Service Task，程序自动化任务）调用的<code>API</code>提供出来，然后通过工作流设计器组装各种服务任务来完成一定的程序功能（也可以称作服务编排）。这样一来，我们不仅可以通过工作流设计来灵活的在线调整程序功能，也不至于使得工作流被设计得过于复杂。</p>
<p>在一些业务不确定性比较强的应用场景中这种工作方式可能是合适的。比如在银行风控领域，我们期望有一个<code>API</code>能评估某一用户的贷款申请的风险，这个<code>API</code>的实现会非常复杂而充满不确定性，而且我们期望它能比较灵活的支持在线逻辑调整。因为在实现这个<code>API</code>时我们需要综合考虑很多情况，比如失信名单，贷款金额，历史信用得分，不同的机器学习模型分析结果，不同模型的效果对比，模型陪跑测试等等。如果能有一个支持上述工作流级别的灵活的在线逻辑调整的功能就好了。</p>
<p>我们是不是可以用<code>activiti</code>来实现这样的功能呢？当然是可以的，但是传统的工作流应用可能并不合适，因为它并不是为支持这种场景而设计的，比如传统的工作流应用会持久化每一个流程的状态，以便可以支持一些用时很长的需要用户完成的任务。传统的工作流应用在这种场景下的一个重要的缺点就是性能太低，因为它支持了太多其他用不到的功能。在我的测试中，对于一个非常简单的自动化流程，<code>activiti</code>也需要80ms左右才能运行完成。</p>
<p>于是，我们需要一个高性能的自动化工作流引擎。为了缓解这一问题，我用<code>node</code>实现了一个这样的工作流引擎，该工作流引擎可以以微服务的形式发布出来，如无必要我们无需改动内部实现。使用与上面类似的一个工作流进行性能测试，95%的<code>API</code>响应时间在10ms以内，99%的<code>API</code>响应时间在20ms以内，单<code>node</code>进程可以支持1000左右的rps。</p>
<p><img data-src="/attaches/2020/2020-06-01-node-bpm/nodebpm-perf.png" alt="nodebpm performance" /></p>
<p>为了使得我们可以独立的用<code>activiti-modeler</code>进行流程设计，我对开源的<code>activiti-modeler</code>进行了一定的修改，移除了权限管理的模块，并预置了一些模板流程数据供大家参考。</p>
<p>尝试体验这个微服务很简单，我已经将应用部署到了<code>heroku</code>，大家只需要：</p>
<ol>
<li>打开网页<a href="https://node-bpm-modeler.herokuapp.com/"><code>https://node-bpm-modeler.herokuapp.com/</code></a>进行流程设计（由于没有后端<code>API</code>支持，所有的持久化相关的功能均不可用）</li>
<li>打开网页<a href="https://node-bpm.herokuapp.com/bp.html"><code>https://node-bpm.herokuapp.com/</code></a>将设计好的流程文件（BPMN 2.0 XML）格式填入，并定义好流程处理器代码，然后运行测试</li>
</ol>
<p>参考下图：</p>
<p><img data-src="/attaches/2020/2020-06-01-node-bpm/nodebpm-usage.png" alt="nodebpm usage" /></p>
<p>这个简单的工作流引擎开源在<code>GitHub</code>上面<a href="https://github.com/gmlove/nodebpm">这里</a>，大家如有兴趣，欢迎一起参与实现更多功能。如果有场景可以用到这个微服务，也欢迎大家进行尝试。</p>
]]></content>
      <categories>
        <category>工作流</category>
        <category>敏捷</category>
        <category>架构</category>
      </categories>
      <tags>
        <tag>敏捷</tag>
        <tag>架构</tag>
        <tag>工作流</tag>
        <tag>发布</tag>
        <tag>效率</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习平台架构实践--微服务</title>
    <url>/2020/05/22/architecture-designing-practise-for-ml-platform/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>一个项目越复杂，架构的作用就越显得重要。这就跟收拾家里面的东西一样，如果我们只有为数不多的几件物品，即便我们随意摆放，也不会妨碍我们找到想要的东西。但是随着购置的物品越来越多，如果不设置一套摆放规则，那么想找到东西就可能会花费大量的时间，效率低下。在我看来，架构就像这样一套摆放东西的规则。规则设置得好，屋子里面的东西将摆放得井井有条，我们的生活不仅将更高效也将更舒适顺心。</p>
<p>在最近的一个项目上，我们和客户一起建设了一个机器学习平台。对于某一个机器学习项目，最重要的四个部分是特征处理，模型探索，模型训练与模型推理。构建一个平台的目的是将这四个部分中通用的能力沉淀下来。一个成功的平台可以为新的机器学习项目提供基础设施，让项目快速起步，还可以使得项目组更专注在模型优化上而提升模型迭代效率。</p>
<span id="more"></span>
<p>在机器学习平台演进了将近一年之后，系统已经变得非常复杂。我们不仅需要支持大量通用的特征处理过程，还需要支持大量的通用机器学习算法及其指标。此外，对于超大数据集的支持也是系统中非常重要的一环，这就要求系统对于分布式计算有良好的支持。在这个平台中，分布式的特征处理过程和机器学习任务将需要被调度到<code>yarn</code>或者<code>kubernetes</code>上面执行。</p>
<p>对于这样一个复杂的系统，需要设计一个怎样的架构才能有效支撑系统的快速演进呢？本系列文章将从不同的方向切入，总结几个在我看来非常有效的架构设计决策，有了它们，系统更容易理解了，添加新功能更容易了，潜在的<code>bug</code>也更少了。这里的架构不仅不错的适应了当前规划的需求，而且具备足够的扩展性，能不错的支撑将来潜在的需求。</p>
<p>我将分为三个部分来进行分享，分别是：</p>
<ul>
<li>微服务实践</li>
<li>配置管理实践</li>
<li>面向对象设计实践</li>
</ul>
<p>本文将分享我们在微服务方面的实践。</p>
<h2 id="整体架构"><a class="markdownIt-Anchor" href="#整体架构"></a> 整体架构</h2>
<p>先来看一下系统的整体架构，简单来说，系统可以分为以下几个部分：</p>
<p><img data-src="/attaches/2020/2020-05-22-architecture-designing-practise-for-ml-platform/architecture.png" alt="系统架构" /></p>
<p>面向用户的接口包括一个基于<code>Angular</code>的<code>web</code>应用，还包括一个命令行工具。后端<code>Rest API</code>基于数据库实现，为面向用户的接口提供支持。调度器负责将任务调度到分布式计算平台上面执行，并负责任务状态的管理。整个系统的底层有一套大数据集群作支持，为系统提供数据存储和计算。</p>
<h2 id="微服务实践"><a class="markdownIt-Anchor" href="#微服务实践"></a> 微服务实践</h2>
<h3 id="认识微服务拆分带来的问题"><a class="markdownIt-Anchor" href="#认识微服务拆分带来的问题"></a> 认识微服务拆分带来的问题</h3>
<p>从上面的整体架构图中可以看出，后端<code>Rest API</code>部分集中了大量的业务逻辑。按照我们一般系统建设的思路，那就是考虑进行微服务拆分，将复杂度分散到多个服务中去。微服务拆分的一般思路是按照业务领域进行拆分，比如在我们的系统中，多数人会考虑拆分为数据集服务、<code>Pipeline</code>服务（特征处理）、模型服务等。</p>
<p>但是微服务拆分带来的弊端其实也是显而易见的，通常比较突出的有：</p>
<ul>
<li>一个<code>API</code>的实现逻辑被分配到好几个服务中去，一旦遇到问题，我们不得不跨多个服务去分析代码，联合调试</li>
<li>微服务拆分之后，各种维护工具（如<code>pipeline</code>、编译脚本等）、依赖组件（如数据库）都可能会存在多个，这不仅给系统运维带来了负担，还给问题诊断带来了成倍的工作量</li>
<li>本地集成测试将变得更慢。为了在本地运行起来整个系统，常常需要启动多个<code>web</code>服务，这带来了额外的启动时间，同时受制于开发机本身的配置，开发体验也将更差</li>
<li>可能带来潜在的难以解决的分布式一致性问题</li>
</ul>
<p>可能有人会说微服务发展这么长时间了，上面的问题其实都已经有很好的应对方案了。比如<code>spring cloud</code>给我们提供了中心化的配置解决方案，提供了断路器，日志追踪支持等等。<code>Istio</code>的边车方案，还将这些复杂性抽象到一个无侵入的伴生进程中。这些无疑有效的缓解了上面的问题，但是每个团队要自己维护这些额外的组件也并不是一件容易的事情。在系统尚未产生可见的大的价值之前，在我看来，进行过细的业务上的微服务拆分实际上可能会浪费费大量的宝贵时间，而产生的价值却不明显。</p>
<p>我们是怎么做的呢？有以下几点设计决策在我看来对我们帮助很大。</p>
<h3 id="设计上支持服务拆分但推迟执行"><a class="markdownIt-Anchor" href="#设计上支持服务拆分但推迟执行"></a> 设计上支持服务拆分，但推迟执行</h3>
<p>我们在业务领域维度只进行逻辑上的微服务拆分，而不进行物理上的微服务拆分。</p>
<p>在源代码管理上，对应到微服务设计，我们会相应进行模块划分。模块划分时按照隔离程度从低到高可以有：1. <code>java</code>包模块隔离；2. <code>maven module</code>模块隔离；3. 代码仓库模块隔离。单从隔离程度上看，我们期望越高越好，这样模块间的耦合程度就会越低。但隔离程度越高，相应的管理维护成本就会越高，因为在实际操作中我们会把模块配置进行不同程度的复制，而由复制带来的同步更新成本、依赖兼容性维护成本就会显现出来。在实际情况下，我们一般会根据具体情况，将这些模块划分方式结合起来使用。</p>
<p>具体而言，我们只使用了一个<code>API</code>模块来支持所有的业务<code>Rest API</code>，业务逻辑代码放在同一个<code>maven</code>模块内部（<code>Rest API</code>服务基于<code>Spring Boot</code>框架）。但是在模块内部，我们用<code>java</code>的包管理机制将不同的领域代码分配到不同的包中去。比如用于特征处理的<code>pipeline</code>模块代码会单独存放在一个<code>java</code>包中，用于实验管理的<code>experiment</code>模块代码存在于另一个<code>java</code>包中，等等。</p>
<p>由于不同业务领域的代码放在了同一个<code>maven</code>模块中，在演进过程中我们会难以避免的在不同模块间产生依赖，甚至会导致模块间循环依赖，这也是<code>java</code>包的隔离程度低带来的问题。但是这种做法的好处是，在允许一定程度的耦合下，我们可以更容易为程序添加功能。比如某一个<code>API</code>的实现可能会操作多个领域实体，这个时候只需要用一个<code>@Transactional</code>标记就可以完成事务控制。为避免模块间耦合过重，使用<code>archunit</code>（一个支持自动化架构测试的工具），我们添加了模块间依赖测试。如果不可避免的要引入不寻常的模块间依赖，我们需要显示的在测试中申明，并需要在<code>code review</code>时向大家解释这样做的合理性。</p>
<p>用这样的方式，我们避免了过早的进行业务级别的微服务拆分，保证了添加新功能的效率。但同时，我们在设计上为后续系统演进时可能要进行的微服务拆分留下空间，到时候拆分时也会相对容易。</p>
<p>同时我们还进行了分层设计，将系统拆分出了核心领域层（如<code>common</code>模块，主要是领域实体及领域逻辑）和通用层（如<code>connector</code>模块，用于连接各个外部系统，如<code>hive</code> <code>hbase</code>等）。分层模块间，采用隔离程度更高的<code>maven module</code>实现。同时在分层模块内部同样采用<code>java</code>包加<code>archunit</code>测试的方式来降低内部模块间的耦合。</p>
<p>将来，如果我们要进行业务级别的微服务拆分，我们主要需要完成三个部分改造：1. 建立同样的模块结构，将代码分出去；2. 用服务间<code>rpc</code>调用的方式处理耦合；3. 处理分布式情况下的数据一致性。</p>
<p>除了<code>Rest API</code>模块，应用层还有一个重要的<code>ml</code>模块，这个模块内部主要实现了运行于大数据集群之上的分布式应用。这些应用基于<code>Spark</code>分布式计算引擎实现，内部由于需要使用到一些领域对象，并需要连接<code>hbase</code>等外部组件，所以<code>ml</code>模块依赖了<code>common</code>和<code>connector</code>模块。</p>
<p>进行了上面的分析之后，我们可以得到下面这样的模块划分图：</p>
<p><img data-src="/attaches/2020/2020-05-22-architecture-designing-practise-for-ml-platform/modules.png" alt="模块划分" /></p>
<h3 id="拆分稳定且独立的模块"><a class="markdownIt-Anchor" href="#拆分稳定且独立的模块"></a> 拆分稳定且独立的模块</h3>
<p>除了<code>Rest API</code>和<code>ml</code>模块，对于相对稳定且功能较独立的通用领域服务，我们将它们拆分为独立的微服务，独立部署。</p>
<p>对于特征处理模块而言，其真实的运行环境是<code>yarn</code>集群，但是集群环境非常复杂，需要进行大规模的资源调度，其速度是很慢的。这个模块的另一个特点是配置特别多，比如某一个特征处理算子（可以理解为一个<code>Spark MLLib</code>的<code>Transformer</code>或者<code>Estimator</code>），为了支持其实现功能，可能会配置输入特征、输出特征、异常处理方式、外部资源信息等。配置一旦复杂，就比较容易引入配置错误，进而带来运行时错误，比如某一个不支持字符串类型的算子如果配置了字符串类型的输入特征，就会在运行时报错。</p>
<p>为了改进用户配置特征处理<code>Pipeline</code>的体验，我们希望实现<code>Pipeline</code>的调试功能。这个功能的目的是快速给用户提供反馈，其运行环境是一个本地的<code>Spark Session</code>。</p>
<p>另外，对于某些特征处理的算子，还存在<code>schema</code>计算无法通过简单配置来实现的问题，比如<code>SQL Transformer</code>算子，这个算子中，用户可以配置任意合法的<code>sql</code>，可以在<code>sql</code>中包含复杂的计算与函数调用，这就导致<code>schema</code>的计算也需要依赖一个<code>Spark</code>运行时环境。</p>
<p>经过对业务需求的理解和分析，我们发现可能需要抽象一个独立模块来快速的提供<code>Spark</code>运行时元信息支持，这个模块我们将其命名为<code>SparkMeta</code>。其功能相对独立和通用，可以在将来用于支持更多的<code>Spark</code>元信息服务。并且，在当前看来，由于我们特征处理模块强依赖<code>Spark</code>来实现功能，将来潜在的元信息相关需求还会比较多。这样的通用领域的抽象应该是合适的。</p>
<p>于是我们拆分了一个独立的<code>SparkMeta</code>模块，将其放置于同一个代码仓库里面，使用<code>maven module</code>进行隔离管理。</p>
<p>这一设计带来了很多好处：</p>
<ol>
<li>无需在<code>Rest API</code>的<code>web</code>服务中引入<code>Spark</code>相关的依赖。这些依赖特别多，一旦引入将导致最后的程序包体积变得很大，非常不利于运维和快速的持续集成部署</li>
<li><code>SparkMeta</code>模块的功能相对独立而稳定，我们无需频繁的进行部署，实际上在整个系统演进过程中，我们也只是进行过两到三次部署而已</li>
<li>对于测试环境，<code>SparkMeta</code>模块可以只部署一套环境，无需跟着<code>Rest API</code>模块一样去配置过多的环境（比如，我们一般会设置用于开发的<code>dev</code>环境，用于QA集成测试的<code>sys</code>环境，用于验收测试的<code>uat</code>环境），这进一步简化了整个系统的部署。</li>
</ol>
<p>与此类似，我们还设计了一个专用于监控告警的模块，同样使用<code>maven module</code>进行隔离，并独立部署为一个<code>web</code>服务。这个模块依赖于一个第三方的监控告警服务，需要进行特殊的配置（在虚拟机上面安装一个搜集数据的<code>agent</code>，对于容器化并不友好）。通过这样的独立微服务拆分，我们可以为其他系统模块提供一套更友好的<code>Restful</code>的<code>API</code>，使得其他模块更容易的集成监控告警服务。同时，如果某一天我们希望更换第三方监控告警服务，我们只需要修改这个模块即可，这带来了很大的灵活性。</p>
<p>通过这样的微服务拆分设计，我们可以得到下面这样的模块划分图：</p>
<p><img data-src="/attaches/2020/2020-05-22-architecture-designing-practise-for-ml-platform/microservice-modules.png" alt="微服务模块划分" /></p>
<h3 id="拆分具有架构不确定性的模块"><a class="markdownIt-Anchor" href="#拆分具有架构不确定性的模块"></a> 拆分具有架构不确定性的模块</h3>
<p>随着系统的演进，我们发现推理服务模块（未在整体架构中画出，其功能是将特征处理过程或机器学习模型发布为可供外部调用的服务）具有非常大的不确定性。这些不确定性主要体现在技术选型上。由于推理服务需要为线上业务提供支持，所以不管是在调用延迟还是在<code>TPS</code>指标上面要求都非常严格。我们先后尝试了多种技术方案，比如用<code>mleap</code>来支持特征处理的线上服务，用<code>angel serving</code>来支持<code>angel</code>模型的线上服务，采用高度优化的算法自实现线上服务，使用<code>rust</code>语言重写整个线上服务模块等。</p>
<p>对于不确定性如此高的一个模块，如果我们将其与<code>Rest API</code>置于同一个代码仓库，将带来非常大的不便。不仅要在同一个代码仓库支持多种编译工具，还需要共同遵守某些的（有时并不合理）规范。比如我们的<code>Rest API</code>采用<code>Merge Request</code>的机制进行代码合并，这种方式对于快速集成有一定的副作用，对于一个需要快速演进的服务并不适合。还比如持续集成和持续部署的<code>pipeline</code>，由于技术方案上需要快速变化，我们也在一定程度上进行了弱化。</p>
<p>为了这个线上服务模块可以快速演进，我们将其分离出来置于一个独立的代码仓库进行维护。这一决策对于我们去快速实验一些新的特性提供了很好的支持，使得我们的精力始终集中在最有价值的事情上。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>总结起来，对于一个实用的系统架构设计，有以下对于我们而言十分受用的几点经验：</p>
<ol>
<li>一个实用的微服务拆分方式并不是一开始就进行业务级别的微服务拆分，而是在设计上支持，但推迟执行</li>
<li>抽象更通用且更稳定更独立的支撑性领域服务，进行独立部署，可选的进行代码仓库拆分</li>
<li>拆分具有架构不确定性的模块，采用代码仓库级别的拆分，并设置不同程度的代码质量要求</li>
</ol>
<p>架构设计的主要目的是将繁杂的东西整齐有序的管理起来，降低系统的复杂度，快速的支撑业务。要做到这一点，从实现思路上讲，我们要有效的进行模块拆分，合理的运用各种技术手段。当模块间的耦合度有效降低且模块内的内聚性有效增强的时候，就证明我们的架构是合适的架构了。上面三点经验正是应用了这些思路，结合系统本身的业务需求一步步演进而来的。系统架构并不是一蹴而就，这要求我们在开发过程中时刻关注架构，一旦识别出不合理的地方，及时进行调整。</p>
<p>最后，希望这里的分享，对于我们构建其他复杂系统时有所帮助。有任何疑问或希望讨论的地方，欢迎留言交流。</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>架构</category>
      </categories>
      <tags>
        <tag>架构</tag>
        <tag>机器学习</tag>
        <tag>机器学习平台</tag>
        <tag>架构设计</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析思维</title>
    <url>/2020/08/22/data-analyst-mindset/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>以下是一组某电商应用消费数据，你能从中看出什么？</p>
<table>
<thead>
<tr>
<th>日期</th>
<th>2019/06/01</th>
<th>2019/06/02</th>
<th>2019/06/03</th>
<th>2019/06/04</th>
<th>2019/06/05</th>
<th>2019/06/06</th>
<th>2019/06/07</th>
</tr>
</thead>
<tbody>
<tr>
<td>金额（万）</td>
<td>213</td>
<td>181</td>
<td>163</td>
<td>147</td>
<td>152</td>
<td>155</td>
<td>171</td>
</tr>
</tbody>
</table>
<p>我们应该能很容易的注意到：</p>
<span id="more"></span>
<ol>
<li>6月1日消费比较多</li>
<li>6月2日消费也很多，但相对降低</li>
<li>6月3号到6号消费量持平</li>
<li>6月7号又开始上涨</li>
</ol>
<p>但是这些意味着什么呢？如果是一个数据分析师，他应该能结合数据的周期性规律进行解读：</p>
<ul>
<li>6月1日儿童节，大家的购物需求可能会上涨，此时可能会有礼品购买、活动举办等情况发生。同时6月1日恰逢周六，节日与周末叠加，消费需求应该更旺盛。</li>
<li>6月2日周日，消费大幅降低，但依然保持着较高水平。</li>
<li>工作日周一和周五，分别对应工作日开始和结束，人们有着较高的消费需求。结合我们平日的工作，周一有可能企业会有集中的办公品采购，周五则可能提前进入周末假期。</li>
</ul>
<p>总结起来，电商消费数据可能存在下述周期性规律：</p>
<ol>
<li>周末消费量高</li>
<li>节日消费量高</li>
<li>工作日周二、周三、周四消费量低</li>
<li>工作日周一、周五消费量高</li>
</ol>
<p>为更好的显示这样的周期性规律，可以绘制消费金额随时间的变化曲线：</p>
<p><img data-src="/attaches/2020/2020-08-22-data-analyst-mindset/transaction_total_of_time.png" alt="transaction_total_of_time.png" /></p>
<p>为突出变化趋势，将每一天的消费金额减去平均值，再次绘制曲线如下：</p>
<p><img data-src="/attaches/2020/2020-08-22-data-analyst-mindset/averaged_transaction_total_of_time.png" alt="averaged_transaction_total_of_time.png" /></p>
<p>这些观察对企业而言意味着什么呢？分为现状和未来两个方面来看。对于当前现状，可以分析当前业务是否健康。对于未来，可以预测后续消费数据，为仓库备货提供参考。</p>
<p>为分析业务健康状况，还需要历史数据做支撑。此时可以考虑搜集历史的消费数据进行分析。搜集前两周的数据，并以周为周期计算预测值如下：</p>
<p><img data-src="/attaches/2020/2020-08-22-data-analyst-mindset/predicted_transaction_total_of_time.png" alt="predicted_transaction_total_of_time.png" /></p>
<p>其中：</p>
<ul>
<li>6月1日预测数据由5月18日和5月25日数据的平均值得到，6月2日预测数据由5月19日和5月26日数据的平均值得到。以此类推。</li>
<li>节日效应为：6月1日的数据与预测数据之差，即 <code>213 - 187.5 = 25.5</code></li>
<li>6月8日的数据由5月18日、5月25日、6月1日的数据减去节日效应，并取平均得到，即<code>(185 + 190 + 213 - 25.5) / 3 = 187.5</code></li>
</ul>
<p>有了这些分析，可以发现：</p>
<ol>
<li>除了节日效应之外，6月1日到7日这一周的数据与预测值相差不大，可以认为业务活动趋于稳定</li>
<li>下周需备足金额为1153万的货</li>
</ol>
<p>如果还想进一步确定哪种货物备多少，那就继续分析每一种货物的出售情况。</p>
<p>上述分析结论可以有力的支持企业进行决策，这就是数据分析的力量。</p>
<p>数据分析的过程看上去好像很厉害的样子。但是仔细一想，这些分析的过程中也没用到什么高端的技术啊？作为程序员，这些我也会。事实上，这里主要是数据分析思维在发挥作用。</p>
<p>那么什么是数据分析思维，在我看来，就是有经验的数据分析师们惯用的思维模式。下面来看看都有哪些思维模式。</p>
<h2 id="数据分析思维"><a class="markdownIt-Anchor" href="#数据分析思维"></a> 数据分析思维</h2>
<h3 id="数据分析思维一建立标准的数据分析流程"><a class="markdownIt-Anchor" href="#数据分析思维一建立标准的数据分析流程"></a> 数据分析思维一：建立标准的数据分析流程</h3>
<p>回顾上述的数据分析过程，可以发现数据分析一般可以分为这样六个步骤：</p>
<ol>
<li>定义分析目标：评估当前的业务状况，为库存管理提供支持</li>
<li>确定分析思路，提出假设：按时间维度进行分析，周末节假日消费高，工作日一五消费高，工作日二三四消费低</li>
<li>搜集数据：搜集前几周的数据</li>
<li>数据预处理：对数据进行初步的分析处理，处理空值、异常值等</li>
<li>分析数据，验证假设：分析数据变化规律，验证之前假设是否正确</li>
<li>给出结论及建议：当前业务表现正常，下周备货1153万</li>
</ol>
<p>在开始真正分析数据之前，先定义分析目标、确定分析思路并提出合理假设，这两个前置步骤对于数据分析非常关键。它们决定了要如何进行后续分析。没有思路，无法进行分析。思路不对，则后续分析都是无用功。</p>
<p>除此之外，做出分析结论通常也是一件极具挑战的任务。如果分析结论不能论据充分并结合客观业务现状，那么来自业务方的挑战将使你失去信任。比如，在上面的例子中，如果我们发现6月1日销售额上涨，没有进行深入分析，就直接归因于市场部的营销活动做得好。这个时候，市场部的人跳出来说，我们没有做什么活动呀。那是不是很尴尬？</p>
<h3 id="数据分析思维二业务指导分析过程"><a class="markdownIt-Anchor" href="#数据分析思维二业务指导分析过程"></a> 数据分析思维二：业务指导分析过程</h3>
<p>先来思考一下，对于这样几个问题，你可以给出答案吗？</p>
<ul>
<li>张妈妈的孩子半岁大，喝婴儿奶粉，请问多少天后张妈妈需要买下一罐？</li>
<li>李妈妈家想换房，一家又老又破旧的小房子却比一个优质的高层小区房单价贵一倍，为什么？</li>
<li>王女士信用卡额度20000，一个月刷了10000。她老公额度15000刷了7500。王女士和她老公谁对于银行更有营销潜力？</li>
</ul>
<p>这里的答案分别是：</p>
<ul>
<li>6</li>
<li>学区房与郊区房</li>
<li>差不多</li>
</ul>
<p>如果我们没能答对这些问题，这说明我们不懂这部分业务。但是，这些业务知识对于一个数据分析师而言却非常重要。</p>
<p>比如，对于一个卖奶粉的电商业务，我们想统计流失的客户，以便进行客户挽回。应该如何计算客户是否流失呢？有了上面的业务知识，就可以很简单的知道，如果某个客户一周以上都没有再来买奶粉了，那他多半就是流失了。</p>
<p>比如，对于某一个房产中介，如果要进行线上广告投放，该如何定位目标群体呢？有了上面的业务知识，就可以知道，对于学区房，应该主要投放给有孩的较高收入家庭。对于郊区房，更多是投放给收入不高的青年家庭。</p>
<p>数据分析的一大误区就是过于专注数据，而忽视业务的指导。</p>
<p>事实上，丰富的业务知识是数据分析得以有效开展的前提。具备了相应的业务知识，就能具备对于数据的敏感度，不仅可以引导分析思路，还能避免一些明显的业务问题。</p>
<h3 id="数据分析思维三指标思维"><a class="markdownIt-Anchor" href="#数据分析思维三指标思维"></a> 数据分析思维三：指标思维</h3>
<p>比如“最近业绩上涨了”这只是说明业绩的一个变化，我们无法知道上涨的时间段或程度。指标思维就是“这个月业绩上涨10%”。这里对应的指标就是“月业绩上涨率”。</p>
<p>数据分析要避免用模糊的文字描述来衡量变化，而改用清楚的数字。</p>
<p>有些场景直接量化难以操作，此时就需要将其拆解为几个容易量化的指标。比如，衡量用户对产品的喜爱程度，可以改为衡量用户单次使用应用的平均时长、用户使用频次、分享次数等综合指标。</p>
<h3 id="数据分析思维四分析模型思维"><a class="markdownIt-Anchor" href="#数据分析思维四分析模型思维"></a> 数据分析思维四：分析模型思维</h3>
<p>成熟的业界研究多年的分析模型是数据分析师常用的工具包。</p>
<p>如需要分析行业发展前景时，行业竞争情况时，考虑使用SWOT、PEST、五力模型来进行分析。需要分析企业经营情况时，采用杜邦分析、评分积分卡模型等。需要分析市场营销、渠道运营可以考虑采用4P模型、4C模型、5W1H模型。分析用户时，可以考虑转换漏斗等。</p>
<p>这些分析模型可以帮助我们建立思维框架。</p>
<h3 id="数据分析思维五将复杂问题分解为小问题"><a class="markdownIt-Anchor" href="#数据分析思维五将复杂问题分解为小问题"></a> 数据分析思维五：将复杂问题分解为小问题</h3>
<p>数据分析师的一个关键思维方式就是将复杂问题拆解为小问题。</p>
<p>常用的分析模型可以帮助我们进行问题分解。但是不是任何地方都适用，很多时候我们需要结合场景进行问题拆解。</p>
<p>一般的做法就是采用思维导图来辅助进行拆解。比如，如果我们要分析如何短期扩大公司利润，从产品角度来看，可以进一步拆解为：现有产品与新产品，现有产品可以进一步拆解为主力产品和搭配产品，对于主力产品可能可以进一步扩大销售渠道。对于搭配产品，可以考虑停止生产，降低成本。对于新产品，可以考虑分解为设计阶段、研发阶段、试验阶段等。</p>
<p><img data-src="/attaches/2020/2020-08-22-data-analyst-mindset/task-split.png" alt="task-split.png" /></p>
<p>注意这里的分解尽量做到MECE，为此可以采用分箱拆解法。比如用户消费能力可以按照消费额分解为五个等级。然后再对每个等级的用户采取不同的措施。</p>
<h3 id="数据分析思维六提出多种方案并进行对比"><a class="markdownIt-Anchor" href="#数据分析思维六提出多种方案并进行对比"></a> 数据分析思维六：提出多种方案，并进行对比</h3>
<p>解决问题的办法通常不止一种，如果我们找到一种方案便停止分析，在专业的业务人员看来，结论一般会过于草率，不够专业。</p>
<p>还是以如何扩大公司利润为例。可以有多种途径可以实现，从<code>利润 = 收入 - 支出</code>的公式来看，可以提高收入，也可以降低支出。而提高收入的方式又有多种，可以上调产品价格，扩大销售渠道，引入新产品等等。支出也可以进一步分为产品生产成本、市场推广成本、销售成本、运营成本、新品研发成本等等。具体采取哪种方式，需要结合公司战略、市场行情等因素综合确定。</p>
<h3 id="数据分析思维七对数据质量保持怀疑"><a class="markdownIt-Anchor" href="#数据分析思维七对数据质量保持怀疑"></a> 数据分析思维七：对数据质量保持怀疑</h3>
<p>数据分析师需要对数据质量保持怀疑的态度。因为数据搜集是一件很困难的事情，好的数据不一定有，数据有了不一定对。</p>
<p>因为涉及隐私问题，用户一般是不愿意提供数据的。我如何知道你会不会拿去卖给其他人？我也不想每天接到无数个贷款、中介的骚扰电话了。就算银行存款业务，在开户的时候也只能确保拿到正确的身份证，也就是只有性别和年龄，开通手机银行才能登记到准确的手机号。</p>
<p>其次，搜集高质量的数据是更很难的。比如，调查表可能是执行人员随便找人填的。又比如，申请房贷的时候，填的工资证明可能是房屋销售人员为了获取一定的银行回扣，故意让你填的一个数。</p>
<p>数据质量在企业中是一个永恒的话题，企业里面永远在想办法提升数据质量。常常能看到线下店购物注册会员有优惠或积分，这其实是商家让利以便获取用户的信息。信用卡提额可以通过提供资产证明来实现，银行通过给高额度来搜集客户资产信息。</p>
<p>既然获取高质量的数据这么困难，我们在分析数据时，就不能轻易相信数据的正确性。需要反复推敲信息来源并提出可能的问题，使用数据清洗，异常值处理等手段来降低数据噪音。</p>
<h3 id="数据分析思维八在全面深入分析之前不过早下结论"><a class="markdownIt-Anchor" href="#数据分析思维八在全面深入分析之前不过早下结论"></a> 数据分析思维八：在全面深入分析之前，不过早下结论</h3>
<p>数据分析是一个深入思考并进行数据验证的过程，不过早下结论是数据分析师需要具备的素质。</p>
<p>如果没有深入分析，我们可能会一看到应用日活上涨，就觉得是应用质量有提升。一提到引入新用户就是做广告。这么直接浅显的结论无法让人信服。</p>
<p>对于日活上涨，从用户结构的角度分析，我们可以看这些上涨来自哪一部分用户的贡献。来自新用户，还是老用户呢？是新用户增加了？还是老用户使用频率提高了？从营销的角度分析，我们可以看这些用户是来自哪个渠道的，进而分析这个渠道最近是不是有促销等等。</p>
<p>对于引入新用户，方法也很多。比如可以考虑不同业务线进行交叉销售，让销售人员进行电话营销，投资进行热点软文营销等等。</p>
<p>通常，对于一个结论的合理性，我们要尽可能的多方面去寻找数据支撑。只有进行过周密分析之后得出的结论才是有说服力的。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>前面讨论的数据分析思维多而杂，但是如果我们将其纳入一般的数据分析流程中，可以得到下图：</p>
<p><img data-src="/attaches/2020/2020-08-22-data-analyst-mindset/mind-set.png" alt="mind-set.png" /></p>
]]></content>
      <categories>
        <category>数据</category>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习平台架构实践--面向对象设计</title>
    <url>/2020/05/24/architecture-designing-practise-for-ml-platform-oop/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>面向对象的程序设计思想多年来一直是我们进行软件设计的有效的指导思想。由于我们天生理解大自然的机制就是面向对象的（比如我们到了某一个商店，我们会看到门店、售货员、货架、货架上的货物等等，这些都是一个一个的对象，我们认识整个商店也就是去认识商店中的每个对象。），而面向对象程序设计思想恰好与这一机制相一致，所以一个面向对象设计做得好的系统就很容易为我们所理解。</p>
<p>对于一个机器学习平台，应该如何实践面向对象程序设计思想呢？</p>
<h2 id="面向对象的抽象"><a class="markdownIt-Anchor" href="#面向对象的抽象"></a> 面向对象的抽象</h2>
<p>回顾前面两篇文章的内容，机器学习平台具备这样的架构：</p>
<span id="more"></span>
<p><img data-src="/attaches/2020/2020-05-24-architecture-designing-practise-for-ml-platform-oop/architecture.png" alt="系统架构" /></p>
<p>看了这个架构，一些重要的对象就自然的浮现了出来。比如数据集（DataSet）、Pipeline、实验（Experiment）、任务（Job）、周期任务（PeriodicalJob）、服务（Service）等。</p>
<p>经过前面关于微服务架构设计的分析，我们可以发现，随着系统的功能越来越复杂，这里的几个对象事实上都逐渐的发展为了某个大的模块或者某个候选的微服务。尽管如此，它们依然是这些模块或者微服务内的核心对象。</p>
<p>这里的对象抽象看似简单，但是如果缺乏经验，经常会出的一个问题是将这些对象与数据库存储的表强耦合在一起。这里的强耦合的表现就是：</p>
<ol>
<li>从设计数据库开始，而不是先从面向对象设计开始</li>
<li>直接使用<code>ORM</code>框架生成的对象作为核心对象使用</li>
<li>直接使用<code>ORM</code>框架生成的对象操作器（如Spring的JPA中由接口继承而来的<code>XXXRepository</code>）作为领域服务来使用</li>
</ol>
<p>使用框架生成的代码通常看起来已经可以完成大部分的工作了，这是一个很大的诱惑，如果我们没有保持克制，随意的去使用这些已有的功能，就会使得我们的代码大量的被<code>ORM</code>框架技术所侵入，从而变得臃肿且笨重，难以适应业务的变化。</p>
<p>举一个例子。我们都知道，<code>ORM</code>框架会建模对象间的关系，并在读取关联对象时自动生成一条查询语句到数据集中提取关联对象，这个特性非常好用。但当我们在操作一个比较大的列表时，这样的默认实现就可能会导致非常多的关联表查询发往数据库，这不是我们想要的，因为它会带来极大的性能影响（好的实现是一次性将所有要访问的数据取出）。更有甚者，如果我们的关联对象本身又有很多其他的关联对象，而我们还将其提取方式设置为了<code>eager</code>，那就会导致更多非预期的数据库查询发生。</p>
<p>在机器学习平台这个系统里面，<code>Job</code>将会关联<code>Pipeline</code>，而<code>Pipeline</code>又会关联其拥有的算子节点列表（<code>PipelineNode</code>），一旦我们想要获取一个<code>Job</code>的列表，并显示与其关联的<code>Pipeline</code>的节点<code>PipelineNode</code>的数量时，上面的问题就发生了。</p>
<p>由于<code>ORM</code>框架会诱惑程序员去使用这些便捷的功能，如果团队中有人没有意识到潜在的性能问题而随意使用，上述情况就会频繁发生。</p>
<p>如何避免这个问题呢？其实很简单，我们只需要把数据库或者<code>ORM</code>框架当做一个实现细节来对待就行了。既然是一个实现细节，在设计阶段就不应该做过多的考虑，甚至可以完全不管。那么进行面向对象系统设计的步骤就应该是：</p>
<ol>
<li>抽取对象，为其选取一个好的名字</li>
<li>设计对象的属性和行为（只要能解决当前需求就行，后续根据需求渐进式的添加）</li>
<li>根据业务需求，设计对象的持久化服务对象及其方法</li>
<li>根据业务需求，设计业务级服务对象（以业务操作来命名，避免直接<code>CRUD</code>）</li>
</ol>
<p>以<code>Job</code>为例，上述每一步的输出可以是：</p>
<ol>
<li><code>com.xxx.ml.platform.job.model.Job</code></li>
<li>如：<code>Job.isRunning</code> <code>Job.isSparkJob</code> <code>Job.markAsFinished</code></li>
<li>定义<code>JobRepository</code>接口，及其行为比如：<code>JobRepository.findById</code> <code>JobRepository.findByStatus</code> <code>JobRepository.save</code></li>
<li>定义<code>JobService</code>业务服务对象，及其行为比如：<code>JobService.createJob</code> <code>JobService.terminateJob</code></li>
</ol>
<p>完成这样的设计之后，我们就获得了一些单纯的业务对象，而非一个个数据库表的直接映射了。那么数据库表的映射要如何完成呢？以<code>Job</code>为例，我们可以基于<code>ORM</code>框架很容易的实现一个<code>JobRepository</code>。首先我们要新建立一个对应的数据库实体映射对象并生成对应的数据操作对象（如<code>JobDAO</code>），然后将<code>JobRepository</code>接口的实现部分代理到<code>JobDAO</code>的接口，再完成数据库实体映射对象到业务对象的拷贝就完成了。</p>
<p>有人说，这样岂不是多写了一个模型，还得多写一些对象间拷贝的代码？是的，从最终结果上来看，确实多写了一个模型来完成<code>ORM</code>框架所需要的数据库映射，但是这个模型的代码其实非常简单，它不包含任何的业务逻辑，只是单纯的数据。对象属性拷贝的代码更是简单，甚至可以用反射机制来自动完成。</p>
<p>这里的少量新代码是值得的，因为它给我们带来了巨大的灵活性，避免了我们的系统直接依赖于某一个特定的<code>ORM</code>框架。这些灵活性比如：</p>
<ol>
<li>可以轻易的替换<code>ORM</code>框架</li>
<li>可以轻易的替换存储实现，比如从关系型数据库替换为<code>MongoDB</code>这样的文档型数据库</li>
<li>对象的属性可以允许与数据库字段有差异，比如当对象<code>A</code>中的某个属性<code>b</code>是一个其他对象<code>B</code>的实例，而<code>B</code>又不值得新建一个数据库表来存储时，我们就可以手动的将<code>b</code>序列化为一个<code>Json</code>格式的数据在数据库中进行存储</li>
<li>可以灵活的使用业务语言进行命名，这也就避免了<code>ORM</code>框架的命名规范侵入到系统设计里</li>
</ol>
<p>领域驱动设计方法在当下已经成为了一个指导我们进行设计的重要方法，其中推荐的一个实践就是&quot;领域对象不应该有除标准库外的任何依赖&quot;。采用上述面向对象设计的做法就可以实现核心对象（这里的核心对象其实就是领域对象）没有任何除标准库外的依赖。</p>
<h2 id="识别扩展点并进行面向对象抽象"><a class="markdownIt-Anchor" href="#识别扩展点并进行面向对象抽象"></a> 识别扩展点并进行面向对象抽象</h2>
<p>机器学习平台最大的扩展点莫过于算子和算法模型了。从业务的角度出发，应该支持尽量多的算子和算法模型，以便开发机器学习模型的工程师可以在进行特征处理和算法选择时开箱即用。</p>
<p>按照前面的面向对象设计思路，这里的核心对象可以是<code>Operator</code>和<code>AlgorithmModel</code>对象。同时，我们将支持不同类型的这两类对象。比如对于下面这样的特征处理流程，里面就涉及<code>归一化</code> <code>分桶</code> <code>独热编码</code>等等算子。</p>
<p><img data-src="/attaches/2020/2020-05-24-architecture-designing-practise-for-ml-platform-oop/pipeline-demo.png" alt="Pipeline Demo" /></p>
<p>此时，从面向对象设计来看，一个自然的想法就是抽象出一个继承关系了。于是就可以得出下面这样的继承树：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Operator</span><br><span class="line">|-- Normalization</span><br><span class="line">|-- Bucketing</span><br><span class="line">|-- OneHotEncoder</span><br><span class="line">|-- MultiHotEncoder</span><br><span class="line">|-- ...</span><br></pre></td></tr></table></figure>
<p>对于<code>AlgorithmModel</code>，同样可以得出类似下面这样的继承树：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">AlgorithmModel</span><br><span class="line">|-- DecisionTree</span><br><span class="line">|-- LinearRegression</span><br><span class="line">|-- GBDT</span><br><span class="line">|-- DeepFM</span><br><span class="line">|-- ...</span><br></pre></td></tr></table></figure>
<p>到这里，很容易产生的一个疑问就是：这些对象如何存储到数据库里面呢？如果我们没有从面向对象的角度出发进行系统设计，而是优先考虑如何在数据库中存储这些数据，那么我们很有可能就只是得出了一个<code>Operator</code>或<code>AlgorithmModel</code>对象。缺乏继承树抽象将给系统带来非常大的问题，可以预见，不同的算子或算法模型将存在差异（如不同的算法需要的参数不同），如果只有一个<code>Operator</code>或<code>AlgorithmModel</code>抽象而没有继承树，处理这些差异的代码就只能放在<code>Operator</code>或<code>AlgorithmModel</code>对象中。这将导致<code>Operator</code>或<code>AlgorithmModel</code>的逻辑非常复杂，最终导致难以维护的代码。</p>
<p>那么，当有了继承树的时候，如何将这些数据有效的存入数据库呢？难道要对每一个子类都建立一张数据库表吗？其实完全没有必要，由于数据库存储只是一个实现细节，那么数据库里面可以只有<code>operator</code>和<code>algorithm_model</code>表。我们可以在超类<code>Operator</code>或<code>AlgorithmModel</code>中定义一个抽象的获取需要保存的属性的方法，这个方法将返回一个列表，由子类实现，就可以了。</p>
<p>既然算子和算法是系统最大的两个扩展点，我们就需要让添加算子和算法变得足够轻松。有了上述面向对象的抽象，我们就可以将很多公共的逻辑放到父类中去实现，这样添加一个一般的算子和算法就可以很快实现了。</p>
<p>从这里的分析可以发现，好的面向对象设计给系统带来了巨大的灵活性，它使得系统非常易于理解和修改。我们的平台也正是因为建立了这样的设计，才得以快速的演进。</p>
<h2 id="使用tdd辅助进行复杂的模块设计"><a class="markdownIt-Anchor" href="#使用tdd辅助进行复杂的模块设计"></a> 使用TDD辅助进行复杂的模块设计</h2>
<p>除了上面简单的面向对象设计，整个系统中还存在一些比较复杂的场景。比如，对于<code>API</code>模块而言，它的作用是作为一个后端服务来管理前端系统界面上面的配置，我们还需要一个<code>Scheduler</code>调度器模块来负责将任务调度到计算平台上面去执行。</p>
<p>这里我们以一个典型的场景为例来描述一下需求。比如用户配置了一条特征处理<code>Pipeline</code>，调度器需要将其打包为一个调度平台上面可以运行的任务，然后发送到调度平台上运行。在运行过程中，用户可以随时查看任务的执行状态，打印的日志等内容。同时，用户可以随时中断任务的执行。当任务结束时，系统需要记录任务的状态，包括结束时间、运行时长等，还需要转存任务日志以便用户可以随时进行查询，对于有后续任务的情况，还需要以适当的方式处理后续任务（调度起来或者设置为失败）。</p>
<p>用一张状态图来描述一个任务的状态转换，可以得到下图：</p>
<p><img data-src="/attaches/2020/2020-05-24-architecture-designing-practise-for-ml-platform-oop/fsm.png" alt="Task Status" /></p>
<p>调度器的基本运行机制是：</p>
<ol>
<li>从数据库获取待执行的新任务，并调度到计算平台（如<code>Yarn</code>或<code>Kubernetes</code>）上面运行</li>
<li>从数据库获取其他状态的任务，并针对不同的状态执行对应的操作</li>
<li>向计算平台获取任务状态，同步到数据库中以便让用户及时查询，同时执行该状态对应的操作</li>
</ol>
<p>可以看到，这里的业务逻辑是比较复杂的，如果没有合适的抽象，我们很可能会写出很多重复而难以维护的代码。</p>
<p>如何进行设计才能有效的将问题简化呢？其实看到上面的状态图，我们就应该可以想到：是不是可以用有限状态机来进行抽象？</p>
<p>这是一个基本的想法，如何去实现呢？对于这样的复杂场景，就需要<code>TDD</code>来指导我们进行设计了。</p>
<p>我们先从测试的角度来考虑整个系统应该如何运行。对于一个一般的有限状态机，它应该可以让使用者注册一系列状态转换处理器，以便当某个任务到达某一状态时就运行起来。于是，我们可以编写以下测试代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">JobStarter</span> <span class="variable">jobStarter</span> <span class="operator">=</span> mock(JobStarter.class);</span><br><span class="line"><span class="type">JobLogFetcher</span> <span class="variable">jobLogFetcher</span> <span class="operator">=</span> mock(JobLogFetcher.class);</span><br><span class="line"><span class="type">JobStatusFetcher</span> <span class="variable">jobStatusFetcher</span> <span class="operator">=</span> mock(JobStatusFetcher.class);</span><br><span class="line"></span><br><span class="line"><span class="type">JobFsm</span> <span class="variable">jobFsm</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JobFsm</span>(); <span class="comment">// Fsm 为有限状态机 Finite State Machine 的缩写</span></span><br><span class="line">jobFsm.addStateTransitionHandler(<span class="literal">null</span>, JobState.NEW, job -&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> (job.readyToStart()) &#123;</span><br><span class="line">        jobStarter.startJob(job);</span><br><span class="line">        jobFsm.transitJobState(JobState.SUBMITTING);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">// 从任意状态转换为 &#123;SUBMITTING, SUBMITTED, RUNNING&#125; 的处理器</span></span><br><span class="line">jobFsm.addStateTransitionHandler(<span class="literal">null</span>, </span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">JobState</span>[]&#123;JobState.SUBMITTING, JobState.SUBMITTED, JobState.RUNNING&#125;,</span><br><span class="line">    job -&gt; &#123;</span><br><span class="line">        jobLogFetcher.fetchLog(job);</span><br><span class="line">    &#125;);</span><br><span class="line"><span class="comment">// 从任意状态转换为 &#123;SUBMITTED, RUNNING&#125; 的处理器</span></span><br><span class="line">jobFsm.addStateTransitionHandler(<span class="literal">null</span>, </span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">JobState</span>[]&#123;JobState.SUBMITTED, JobState.RUNNING&#125;,</span><br><span class="line">    job -&gt; &#123;</span><br><span class="line">        <span class="type">JobStatus</span> <span class="variable">newStatus</span> <span class="operator">=</span> jobStatusFetcher.fetchStatus(job);</span><br><span class="line">        <span class="keyword">if</span> (newStatus != job.getStatus()) &#123;</span><br><span class="line">            jobFsm.transitJobState(job, newStatus);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// when(jobStarter.xxx)</span></span><br><span class="line"><span class="comment">// assert.xxx</span></span><br></pre></td></tr></table></figure>
<p>有了这样的测试代码，实际上我们的整个系统设计就呼之欲出了。它将包含这样几个对象：<code>JobStarter</code> <code>JobLogFetcher</code> <code>JobStatusFetcher</code> <code>JobFsm</code>等。不仅如此，每个对象所需要定义的接口也都在测试代码里面定义好了。</p>
<p>从这里的设计来看，<code>TDD</code>在其中发挥的作用可谓非常明显。它辅助我们为对象取好了名字，为对象定义好了行为，同时连行为应该具有的函数签名也定义出来了。而且当回头来看这里得出的系统设计时，我们将发现这里定义的接口不多不少，恰好够用，且各处的命名均符合使用业务语言命名的推荐实践。这正是<code>TDD</code>辅助进行系统设计所带来的功效！</p>
<p>为什么<code>TDD</code>可以指导我们进行复杂系统设计？这是因为使用<code>TDD</code>时，我们完全是站在如何使用这些（将要设计出来的）<code>API</code>的角度来编写（测试）代码的。既然是这样，我们最终获得的<code>API</code>设计也因此变得易于使用。</p>
<p>这里的逻辑也可以这样来理解，比如，我们的需求是拧一颗螺丝，如果我们直接去做设计，而不是采用<code>TDD</code>的方法，我们很可能会去找来一个万用螺丝刀。而如果采用<code>TDD</code>的方法，我们会先确定螺丝的类型（梅花还是十字）和大小（为了能编写测试，自然需要先确认需要对接的接口），然后再根据需求去实现一个对应的恰好合适的螺丝刀。对于生活使用时，万用螺丝刀可能更好，但对于软件开发而言，万用螺丝刀的开发和维护成本可能要数倍于一个刚好合适的螺丝刀，且万用螺丝刀通常还没有专用的螺丝刀简单好用。</p>
<p>类似这样的例子，在我们的系统里面还有很多，就不详述了。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>在机器学习平台架构设计上，采用面向对象设计思想，我们获得了一个灵活易用的系统。总结起来，有以下三点经验：</p>
<ol>
<li>进行系统设计时，应当把数据库<code>ORM</code>技术当做一个实现细节，而非让这些技术主导了设计过程</li>
<li>识别系统的扩展点，专门为其做出合适的设计</li>
<li>采用<code>TDD</code>的方式来指导复杂系统的设计</li>
</ol>
<p>如果想了解更多，欢迎留言一起探讨。</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>架构</category>
      </categories>
      <tags>
        <tag>架构</tag>
        <tag>面向对象</tag>
        <tag>机器学习</tag>
        <tag>机器学习平台</tag>
        <tag>架构设计</tag>
      </tags>
  </entry>
  <entry>
    <title>统计基础-区间估计</title>
    <url>/2020/09/10/easy-statistical-test/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>如果我们想知道一所办公楼的所有人员的平均身高，该怎么做？大家应该都能想到，我们可以通过统计抽样的办法，随机去调查一些人的身高，然后通过这些人的平均身高去估计所有人员的平均身高。但这里还有一个问题，这里抽样得到的平均身高准吗？有多准呢？</p>
<p>要回答这里的问题，我们需要有一些基本的统计学知识。</p>
<span id="more"></span>
<p>下面以简单的掷硬币的例子来说明一下。我们知道掷一次硬币，得到正面向上和反面向上的概率都是50%。用<code>X</code>表示这里的随机事件，用0表示正面向上，用1表示反面向上。我们可以得到<code>X=k</code>的分布，即</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>X</mi><mo>=</mo><mi>k</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0.5</mn><mo separator="true">,</mo><mi>k</mi><mo>=</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">P(X=k) = 0.5,    k=0,1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span></span></span></span></span>
<p>上面的问题是离散型随机变量的分布问题。我们最开始的身高的例子则是一个连续型的随机变量分布问题。对于一个连续型的随机变量，大家最熟悉的分布就是正态分布了。比如，人的身高我们可以认为服从一个均值为<code>μ</code>，方差为<code>σ^2</code>的正态分布。但人的身高分布就没法简单的用某一个值的概率来表示了，因为此时的概率都为0.为了描述人的身高的分布，我们会用概率密度函数来描述。由正态分布的定义可以知道，身高的概率密度函数为：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><msqrt><mrow><mn>2</mn><mi>π</mi></mrow></msqrt><mi>σ</mi></mrow></mfrac><msup><mi>e</mi><mrow><mo>−</mo><mfrac><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><mi>μ</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><mrow><mn>2</mn><msup><mi>σ</mi><mn>2</mn></msup></mrow></mfrac></mrow></msup><mo separator="true">,</mo><mi>x</mi><mo>∈</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mo>+</mo><mi mathvariant="normal">∞</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x) = {1 \over \sqrt{2\pi}\sigma}e^{-{(x-\mu)^2 \over 2\sigma^2}},    x \in (0,+\infty)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.25909em;vertical-align:-0.93em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.2027799999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.90722em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord">2</span><span class="mord mathdefault" style="margin-right:0.03588em;">π</span></span></span><span style="top:-2.86722em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.13278em;"><span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.32909em;"><span style="top:-3.4534200000000004em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.250957142857143em;"><span style="top:-2.5061857142857145em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9384399999999999em;"><span style="top:-2.93844em;margin-right:0.1em;"><span class="pstrut" style="height:2.64444em;"></span><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.2255000000000003em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.5020714285714285em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">x</span><span class="mbin mtight">−</span><span class="mord mathdefault mtight">μ</span><span class="mclose mtight"><span class="mclose mtight">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.04844em;"><span style="top:-3.04844em;margin-right:0.1em;"><span class="pstrut" style="height:2.64444em;"></span><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.49381428571428565em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">+</span><span class="mord">∞</span><span class="mclose">)</span></span></span></span></span>
<p>对应的分布函数，我们可以用概率密度函数的积分来表示。比如我们想知道有多大概率分布在1.7米到1.8米之间。那么此时的概率为：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mo stretchy="false">(</mo><mn>1.7</mn><mo>&lt;</mo><mi>x</mi><mo>&lt;</mo><mn>1.8</mn><mo stretchy="false">)</mo><mo>=</mo><msubsup><mo>∫</mo><mn>1.7</mn><mn>1.8</mn></msubsup><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi>d</mi><mi>x</mi></mrow><annotation encoding="application/x-tex">F(1.7 &lt; x &lt; 1.8) = \int_{1.7}^{1.8} f(x)dx</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord">1</span><span class="mord">.</span><span class="mord">7</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">8</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.4759580000000003em;vertical-align:-0.9119499999999999em;"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011249999999999316em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5640080000000003em;"><span style="top:-1.7880500000000001em;margin-left:-0.44445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">.</span><span class="mord mtight">7</span></span></span></span><span style="top:-3.8129000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">.</span><span class="mord mtight">8</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9119499999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mord mathdefault">d</span><span class="mord mathdefault">x</span></span></span></span></span>
<p>以上是最基本的统计学知识，高中课本就有学习，带大家复习一下。</p>
<p>想解决最开始的身高估计有多准确的问题，我们还得更进一步。考察一下做n次掷硬币试验，或者抽样n个人的情况。</p>
<p>我们先来看n次掷硬币试验的问题。一般而言，由于硬币的铸造误差，使得正面向上和反面向上的概率不会严格相等。那么，通过掷硬币n次，我们能不能判断硬币正面向上和反面向上的概率是否相等呢？这个的问题其实与文章最开始的问题是类似的，这里我们假设掷硬币正面向上的概率未知，开始的题目假设平均身高未知，然后都试图通过一定次数的试验来了解这些未知的量。</p>
<p>为了回答上述问题，我们先来考虑一下下面这个问题。对于这个n次掷硬币的大试验，假设我们重复做了m次，即投掷硬币<code>m * n</code>次，每次大试验都可以得到一个正面朝上的次数。假设n为100，这里得到的次数可能是<code>[50, 49, 44, 52, ...]</code>，也就是说这枚硬币正面朝上的估计概率为<code>[0.50, 0.49, 0.44, 0.52, ...]</code>。这些数据实际上可以构成另一个随机变量取值序列。这个高阶随机变量是不是会服从一个什么分布呢？事实上，由中心极限定理可知，这里的高阶随机变量将服从一个正态分布，其均值和方差分别为<code>p</code>和<code>p(1-p)/n</code>，其中p为真实的硬币正面朝上的概率。</p>
<p>这里我们居然将离散的随机变量与描述连续的正态分布给联系上了，不得不感叹数字的奇妙！</p>
<p>有了这个正态分布，我们就可以做一些事情了。既然是正态分布，那么取值（当进行一次n次掷硬币的大试验时，得到的硬币正面朝上的估计概率）落在正态分布的两边的概率就会比较小。具体来说，一次试验的取值大约有95%的概率会落在距离均值的两个标准差(下图非阴影区域)之内。</p>
<p><img data-src="/attaches/2020/2020-09-10-easy-statistical-test/n-dist.png" alt="normal distribution" /></p>
<p>转换一个说法，假设这个取值为<code>p_</code>，我们考察均值<code>p</code>与样本值<code>p_</code>的距离，则</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi mathvariant="normal">∣</mi><mi>p</mi><mo>−</mo><mi>p</mi><mi mathvariant="normal">_</mi><mi mathvariant="normal">∣</mi><mo>&lt;</mo><mn>2</mn><mo>∗</mo><msqrt><mfrac><mrow><mi>p</mi><mo>∗</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><mi>n</mi></mfrac></msqrt><mo stretchy="false">)</mo><mo>=</mo><mn>0.95</mn></mrow><annotation encoding="application/x-tex">P(|p - p\_| &lt; 2 * {\sqrt{p * (1 - p) \over n}}) = 0.95</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord">∣</span><span class="mord mathdefault">p</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathdefault">p</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.44em;vertical-align:-0.7356250000000002em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7043749999999998em;"><span class="svg-align" style="top:-4.4em;"><span class="pstrut" style="height:4.4em;"></span><span class="mord" style="padding-left:1em;"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">n</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault">p</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-3.664375em;"><span class="pstrut" style="height:4.4em;"></span><span class="hide-tail" style="min-width:1.02em;height:2.48em;"><svg width='400em' height='2.48em' viewBox='0 0 400000 2592' preserveAspectRatio='xMinYMin slice'><path d='M424,2478
c-1.3,-0.7,-38.5,-172,-111.5,-514c-73,-342,-109.8,-513.3,-110.5,-514
c0,-2,-10.7,14.3,-32,49c-4.7,7.3,-9.8,15.7,-15.5,25c-5.7,9.3,-9.8,16,-12.5,20
s-5,7,-5,7c-4,-3.3,-8.3,-7.7,-13,-13s-13,-13,-13,-13s76,-122,76,-122s77,-121,77,-121
s209,968,209,968c0,-2,84.7,-361.7,254,-1079c169.3,-717.3,254.7,-1077.7,256,-1081
l0 -0c4,-6.7,10,-10,18,-10 H400000
v40H1014.6
s-87.3,378.7,-272.6,1166c-185.3,787.3,-279.3,1182.3,-282,1185
c-2,6,-10,9,-24,9
c-8,0,-12,-0.7,-12,-2z M1001 80
h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7356250000000002em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span><span class="mord">5</span></span></span></span></span>
<p>即，我们可以有95%的把握可以认为，区间</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>p</mi><mi mathvariant="normal">_</mi><mo>−</mo><mn>2</mn><mo>∗</mo><msqrt><mfrac><mrow><mi>p</mi><mo>∗</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><mi>n</mi></mfrac></msqrt><mo separator="true">,</mo><mspace width="0.5em"/><mi>p</mi><mi mathvariant="normal">_</mi><mo>+</mo><mn>2</mn><mo>∗</mo><msqrt><mfrac><mrow><mi>p</mi><mo>∗</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><mi>n</mi></mfrac></msqrt><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(p\_ - 2 * {\sqrt{p * (1 - p) \over n}},\enspace p\_ + 2 * {\sqrt{p * (1 - p) \over n}})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mopen">(</span><span class="mord mathdefault">p</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.44em;vertical-align:-0.7356250000000002em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7043749999999998em;"><span class="svg-align" style="top:-4.4em;"><span class="pstrut" style="height:4.4em;"></span><span class="mord" style="padding-left:1em;"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">n</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault">p</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-3.664375em;"><span class="pstrut" style="height:4.4em;"></span><span class="hide-tail" style="min-width:1.02em;height:2.48em;"><svg width='400em' height='2.48em' viewBox='0 0 400000 2592' preserveAspectRatio='xMinYMin slice'><path d='M424,2478
c-1.3,-0.7,-38.5,-172,-111.5,-514c-73,-342,-109.8,-513.3,-110.5,-514
c0,-2,-10.7,14.3,-32,49c-4.7,7.3,-9.8,15.7,-15.5,25c-5.7,9.3,-9.8,16,-12.5,20
s-5,7,-5,7c-4,-3.3,-8.3,-7.7,-13,-13s-13,-13,-13,-13s76,-122,76,-122s77,-121,77,-121
s209,968,209,968c0,-2,84.7,-361.7,254,-1079c169.3,-717.3,254.7,-1077.7,256,-1081
l0 -0c4,-6.7,10,-10,18,-10 H400000
v40H1014.6
s-87.3,378.7,-272.6,1166c-185.3,787.3,-279.3,1182.3,-282,1185
c-2,6,-10,9,-24,9
c-8,0,-12,-0.7,-12,-2z M1001 80
h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7356250000000002em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mspace" style="margin-right:0.5em;"></span><span class="mord mathdefault">p</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.44em;vertical-align:-0.7356250000000002em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7043749999999998em;"><span class="svg-align" style="top:-4.4em;"><span class="pstrut" style="height:4.4em;"></span><span class="mord" style="padding-left:1em;"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">n</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault">p</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-3.664375em;"><span class="pstrut" style="height:4.4em;"></span><span class="hide-tail" style="min-width:1.02em;height:2.48em;"><svg width='400em' height='2.48em' viewBox='0 0 400000 2592' preserveAspectRatio='xMinYMin slice'><path d='M424,2478
c-1.3,-0.7,-38.5,-172,-111.5,-514c-73,-342,-109.8,-513.3,-110.5,-514
c0,-2,-10.7,14.3,-32,49c-4.7,7.3,-9.8,15.7,-15.5,25c-5.7,9.3,-9.8,16,-12.5,20
s-5,7,-5,7c-4,-3.3,-8.3,-7.7,-13,-13s-13,-13,-13,-13s76,-122,76,-122s77,-121,77,-121
s209,968,209,968c0,-2,84.7,-361.7,254,-1079c169.3,-717.3,254.7,-1077.7,256,-1081
l0 -0c4,-6.7,10,-10,18,-10 H400000
v40H1014.6
s-87.3,378.7,-272.6,1166c-185.3,787.3,-279.3,1182.3,-282,1185
c-2,6,-10,9,-24,9
c-8,0,-12,-0.7,-12,-2z M1001 80
h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7356250000000002em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>
<p>将包含真正的p值。由于我们当前还不知道真实的p值，可以用<code>p_</code>来替代<code>p</code>进行近似计算。</p>
<p>我们似乎已经可以回答前面的问题了。硬币正面向上和反面向上的概率是否相等呢？假设做完一次投掷100次硬币的试验之后，我们得到40次正面朝上，则我们有95%的把握可以认为区间<code>(0.4 - 2 * sqrt(0.4 * (1 - 0.4) / 100), 0.4 + 2 * sqrt(0.4 * (1 - 0.4) / 100))</code>即<code>(0.302, 0.498)</code>将包含真正的正面朝上的概率。可以看到，这个区间不包含0.5，所以，这个硬币正面向上和反面向上的概率应该是不相等的。但如果我们得到<code>45</code>次正面朝上，这时的区间将为<code>(0.351, 0.549)</code>，由于区间包含了0.5，我们就不能说正面向上和反面向上的概率不相等。</p>
<p>上述过程正是统计学中经典的区间估计的内容，有兴趣的小伙伴可以查阅其他资料继续深入研究一下。</p>
<p>有了上面的知识，我们可以将其迁移到身高的平均值问题上来。多次进行抽样试验得到的样本均值会服从什么样的分布呢？经过数学推导知道，可以在样本均值基础上构造一个t统计量，它将服从另一个分布，即t分布。具体来说，统计量<code>(样本均值 - 总体均值) / (样本标准差 / sqrt(n))</code>将服从分布<code>t(n-1)</code>. t分布的数学形式比较复杂，这里就暂时不介绍了，一般我们可以通过<code>python</code>代码取得其分布的值。t分布的概率密度函数曲线如下：</p>
<p><img data-src="/attaches/2020/2020-09-10-easy-statistical-test/t-dist.png" alt="t distribution" /></p>
<p>上图中有很多条曲线，究竟是哪条曲线由n的取值来确定。</p>
<p>采用与前面类似的思想，做一次试验得到的值落在t分布的两边的概率是比较低的。假设我们以95%的把握来看这个问题，则</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.95</mn><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mi mathvariant="normal">∣</mi><mfrac><mrow><mover accent="true"><mi>x</mi><mo>ˉ</mo></mover><mo>−</mo><mi>μ</mi></mrow><mrow><mi>S</mi><mi mathvariant="normal">/</mi><msqrt><mi>n</mi></msqrt></mrow></mfrac><mi mathvariant="normal">∣</mi><mo>&lt;</mo><msub><mi>t</mi><mrow><mi>α</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo separator="true">,</mo><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mi>P</mi><mo stretchy="false">(</mo><mover accent="true"><mi>x</mi><mo>ˉ</mo></mover><mo>−</mo><msub><mi>t</mi><mrow><mi>α</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo separator="true">,</mo><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>∗</mo><mfrac><mi>S</mi><msqrt><mi>n</mi></msqrt></mfrac><mo>&lt;</mo><mi>μ</mi><mo>&lt;</mo><mover accent="true"><mi>x</mi><mo>ˉ</mo></mover><mo>+</mo><msub><mi>t</mi><mrow><mi>α</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo separator="true">,</mo><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>∗</mo><mfrac><mi>S</mi><msqrt><mi>n</mi></msqrt></mfrac><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mtext>其中：</mtext><mover accent="true"><mi>x</mi><mo>ˉ</mo></mover><mtext>为样本均值， </mtext><mi>μ</mi><mtext>为总体均值， </mtext><mi>S</mi><mtext>为样本标准差， </mtext><mi>n</mi><mtext>为试验次数</mtext></mrow><annotation encoding="application/x-tex">0.95 = P(|{\bar{x} - \mu \over S / \sqrt{n}}| &lt; t_{\alpha/2,n-1}) = P(\bar{x} - t_{\alpha/2,n-1} * {S \over \sqrt{n}} &lt; \mu &lt; \bar{x} + t_{\alpha/2,n-1} * {S \over \sqrt{n}})
\\
\text{其中：}\bar{x}\text{为样本均值， }\mu\text{为总体均值， }S\text{为样本标准差， }n\text{为试验次数}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span><span class="mord">5</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.20061em;vertical-align:-0.9402800000000001em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord">∣</span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2603300000000002em;"><span style="top:-2.30972em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord">/</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8002800000000001em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathdefault">n</span></span></span><span style="top:-2.76028em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.23972em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.56778em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">x</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault">μ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9402800000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="mord">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3551999999999999em;"></span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.0037em;">α</span><span class="mord mtight">/</span><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.56778em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">x</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.9702799999999998em;vertical-align:-0.3551999999999999em;"></span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.0037em;">α</span><span class="mord mtight">/</span><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.29033em;vertical-align:-0.9300000000000002em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.30972em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8002800000000001em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathdefault">n</span></span></span><span style="top:-2.76028em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.23972em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9300000000000002em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.7335400000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">μ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.56778em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">x</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.9702799999999998em;vertical-align:-0.3551999999999999em;"></span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.0037em;">α</span><span class="mord mtight">/</span><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.29033em;vertical-align:-0.9300000000000002em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.30972em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8002800000000001em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathdefault">n</span></span></span><span style="top:-2.76028em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.23972em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9300000000000002em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="mclose">)</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord text"><span class="mord cjk_fallback">其中：</span></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.56778em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">x</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="mord text"><span class="mord cjk_fallback">为样本均值，</span><span class="mord"> </span></span><span class="mord mathdefault">μ</span><span class="mord text"><span class="mord cjk_fallback">为总体均值，</span><span class="mord"> </span></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord text"><span class="mord cjk_fallback">为样本标准差，</span><span class="mord"> </span></span><span class="mord mathdefault">n</span><span class="mord text"><span class="mord cjk_fallback">为试验次数</span></span></span></span></span></span>
<p>这样我们就得到了总体均值μ的估计区间了。</p>
<p>下面我们举例计算一下。假设，抽样得到的身高为<code>[1.7, 1.6, 1.8, 1.72, 1.75, 1.74]</code>，则：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>样本均值</mtext><mspace width="0.5em"/><mover accent="true"><mi>x</mi><mo>ˉ</mo></mover><mo>=</mo><mfrac><mrow><mn>1.7</mn><mo>+</mo><mn>1.6</mn><mo>+</mo><mn>1.8</mn><mo>+</mo><mn>1.72</mn><mo>+</mo><mn>1.75</mn><mo>+</mo><mn>1.74</mn></mrow><mn>6</mn></mfrac><mo>=</mo><mn>1.72</mn><mspace linebreak="newline"></mspace><mi>n</mi><mo>=</mo><mn>6</mn><mo separator="true">,</mo><mspace width="0.5em"/><mi>n</mi><mo>−</mo><mn>1</mn><mo>=</mo><mn>5</mn><mspace linebreak="newline"></mspace><mtext>95%的置信度时</mtext><mspace width="0.5em"/><mi>α</mi><mo>=</mo><mn>0.05</mn><mo separator="true">,</mo><mspace width="0.5em"/><msub><mi>t</mi><mrow><mi>α</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo separator="true">,</mo><mn>5</mn></mrow></msub><mo>=</mo><mn>2.571</mn><mspace linebreak="newline"></mspace><mi>s</mi><mo>=</mo><msqrt><mfrac><mrow><mo stretchy="false">(</mo><mn>1.7</mn><mo>−</mo><mn>1.72</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>1.6</mn><mo>−</mo><mn>1.72</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>1.8</mn><mo>−</mo><mn>1.72</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>1.72</mn><mo>−</mo><mn>1.72</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>1.75</mn><mo>−</mo><mn>1.72</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>1.74</mn><mo>−</mo><mn>1.72</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><mn>5</mn></mfrac></msqrt><mo>=</mo><mn>0.0612</mn><mspace linebreak="newline"></mspace><mtext>总体均值估计区间为：</mtext><mspace width="0.5em"/><mo stretchy="false">(</mo><mover accent="true"><mi>x</mi><mo>ˉ</mo></mover><mo>−</mo><msub><mi>t</mi><mrow><mi>α</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo separator="true">,</mo><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>∗</mo><mfrac><mi>S</mi><msqrt><mi>n</mi></msqrt></mfrac><mo separator="true">,</mo><mover accent="true"><mi>x</mi><mo>ˉ</mo></mover><mo>+</mo><msub><mi>t</mi><mrow><mi>α</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo separator="true">,</mo><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>∗</mo><mfrac><mi>S</mi><msqrt><mi>n</mi></msqrt></mfrac><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mn>1.650</mn><mo separator="true">,</mo><mn>1.790</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{样本均值}\enspace\bar{x} = {1.7 + 1.6 + 1.8 + 1.72 + 1.75 + 1.74 \over 6} = 1.72
\\
n = 6,\enspace n-1 = 5
\\
\text{95\%的置信度时}\enspace \alpha = 0.05,\enspace t_{\alpha/2, 5} = 2.571
\\
s = \sqrt{(1.7 - 1.72)^2 + (1.6 - 1.72)^2 + (1.8 - 1.72)^2 + (1.72 - 1.72)^2 + (1.75 - 1.72)^2 + (1.74 - 1.72)^2 \over 5} = 0.0612
\\
\text{总体均值估计区间为：}\enspace(\bar{x} - t_{\alpha/2,n-1} * {S \over \sqrt{n}}, \bar{x} + t_{\alpha/2,n-1} * {S \over \sqrt{n}}) = (1.650, 1.790)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord text"><span class="mord cjk_fallback">样本均值</span></span><span class="mspace" style="margin-right:0.5em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.56778em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">x</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.00744em;vertical-align:-0.686em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">6</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mord">.</span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">6</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">7</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">7</span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">7</span><span class="mord">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">7</span><span class="mord">2</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord">6</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mspace" style="margin-right:0.5em;"></span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord text"><span class="mord">95%</span><span class="mord cjk_fallback">的置信度时</span></span><span class="mspace" style="margin-right:0.5em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9996399999999999em;vertical-align:-0.3551999999999999em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mspace" style="margin-right:0.5em;"></span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.0037em;">α</span><span class="mord mtight">/</span><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mtight">5</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">.</span><span class="mord">5</span><span class="mord">7</span><span class="mord">1</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">s</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.44em;vertical-align:-0.7356250000000002em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7043749999999998em;"><span class="svg-align" style="top:-4.4em;"><span class="pstrut" style="height:4.4em;"></span><span class="mord" style="padding-left:1em;"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">5</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mopen">(</span><span class="mord">1</span><span class="mord">.</span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">7</span><span class="mord">2</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.740108em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mord">.</span><span class="mord">6</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">7</span><span class="mord">2</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.740108em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mord">.</span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">7</span><span class="mord">2</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.740108em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mord">.</span><span class="mord">7</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">7</span><span class="mord">2</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.740108em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mord">.</span><span class="mord">7</span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">7</span><span class="mord">2</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.740108em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mord">.</span><span class="mord">7</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">7</span><span class="mord">2</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.740108em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-3.664375em;"><span class="pstrut" style="height:4.4em;"></span><span class="hide-tail" style="min-width:1.02em;height:2.48em;"><svg width='400em' height='2.48em' viewBox='0 0 400000 2592' preserveAspectRatio='xMinYMin slice'><path d='M424,2478
c-1.3,-0.7,-38.5,-172,-111.5,-514c-73,-342,-109.8,-513.3,-110.5,-514
c0,-2,-10.7,14.3,-32,49c-4.7,7.3,-9.8,15.7,-15.5,25c-5.7,9.3,-9.8,16,-12.5,20
s-5,7,-5,7c-4,-3.3,-8.3,-7.7,-13,-13s-13,-13,-13,-13s76,-122,76,-122s77,-121,77,-121
s209,968,209,968c0,-2,84.7,-361.7,254,-1079c169.3,-717.3,254.7,-1077.7,256,-1081
l0 -0c4,-6.7,10,-10,18,-10 H400000
v40H1014.6
s-87.3,378.7,-272.6,1166c-185.3,787.3,-279.3,1182.3,-282,1185
c-2,6,-10,9,-24,9
c-8,0,-12,-0.7,-12,-2z M1001 80
h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7356250000000002em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">6</span><span class="mord">1</span><span class="mord">2</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord cjk_fallback">总体均值估计区间为：</span></span><span class="mspace" style="margin-right:0.5em;"></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.56778em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">x</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.9702799999999998em;vertical-align:-0.3551999999999999em;"></span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.0037em;">α</span><span class="mord mtight">/</span><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.29033em;vertical-align:-0.9300000000000002em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.30972em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8002800000000001em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathdefault">n</span></span></span><span style="top:-2.76028em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.23972em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9300000000000002em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.56778em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">x</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.22222em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.9702799999999998em;vertical-align:-0.3551999999999999em;"></span><span class="mord"><span class="mord mathdefault">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.0037em;">α</span><span class="mord mtight">/</span><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.29033em;vertical-align:-0.9300000000000002em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.30972em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8002800000000001em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathdefault">n</span></span></span><span style="top:-2.76028em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.23972em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9300000000000002em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mord">.</span><span class="mord">6</span><span class="mord">5</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">7</span><span class="mord">9</span><span class="mord">0</span><span class="mclose">)</span></span></span></span></span>
<p>即，我们可以有95%的把握认为区间<code>(1.650, 1.790)</code>包含了真正的平均身高。</p>
<p>回到我们的主题，抽样得到的平均身高准吗？除了可以说平均身高大约为1.72，我们还可以给出一个区间<code>(1.650, 1.790)</code>，有95%的可能性真实均值会在这个区间之内。</p>
]]></content>
      <categories>
        <category>数据</category>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>数据分析</tag>
        <tag>统计</tag>
      </tags>
  </entry>
  <entry>
    <title>你的收入和支出相关吗？</title>
    <url>/2020/09/13/correlation-analysis/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>你的收入和支出相关吗？这是一个很难回答的问题，表面上看好像是相关的，因为随着收入的增长，有了更多的钱，当然可以有更多的支出。但是，很多公司一年才涨一次工资，在这一年内，物价却可能在不停上涨，是不是收入没涨而每个月的支出都在涨呢？</p>
<p>如何来回答是否相关的问题呢？用统计学的方法，我们可以把收入和支出当做两个变量来对待，然后用数学的方法衡量其相关性。</p>
<span id="more"></span>
<h2 id="什么是相关性"><a class="markdownIt-Anchor" href="#什么是相关性"></a> 什么是相关性</h2>
<p>两个变量之间存在关联关系即为相关。相关性是具有方向性的：可能为正，意味着两个变量同时表现出增大或减小；也可能为负，意味着当一个变量值增加时，另一个变量的值就会减少；也可能为零，即这些变量是不相关的。</p>
<ul>
<li>正相关：两个变量同时表现出增大或减小</li>
<li>零相关：变量间的变化不存在相关</li>
<li>负相关：变量当一个变量值增加时，另一个变量的值就会减少</li>
</ul>
<h2 id="为什么要研究相关性"><a class="markdownIt-Anchor" href="#为什么要研究相关性"></a> 为什么要研究相关性</h2>
<p>研究相关性可以加深我们自己对于生活中的现象的理解。除此之外，在做机器学习模型时，如果存在两个或两个以上的变量紧密相关，那么一些算法的性能就会下降，例如线性回归（见<a href="https://baike.baidu.com/item/%E5%A4%9A%E9%87%8D%E5%85%B1%E7%BA%BF%E6%80%A7">多重共线性</a>）。为了提高模型的性能，应该移除其中有干扰的相关变量。所以研究相关性还可以帮助我们更好的做机器学习模型。</p>
<h2 id="如何表示变量相关性"><a class="markdownIt-Anchor" href="#如何表示变量相关性"></a> 如何表示变量相关性</h2>
<h3 id="协方差"><a class="markdownIt-Anchor" href="#协方差"></a> 协方差</h3>
<p>如果有人对协方差不太熟，但方差应该是大家经常接触到的一个概念。</p>
<p>方差可以衡量一个变量的波动的剧烈程度，它的具体原理是用每一个变量的值去减去变量均值，然后分别求平方加和，即<code>variance(X) = sum((x - mean(X)) ** 2) / len(X)</code>。方差的用途很广泛，比如我们想知道所有中国人的收入（变量X）是否平均，我们就可以计算所有人收入的方差，从而衡量收入的波动程度，如果波动小，那么收入就较平均。</p>
<p>与方差对应的一个概念是标准差。在计算方差时，为了屏蔽掉差异的正负符号影响，我们添加了一个平方项，这就造成了方差不能反映真实的差异，而是反映了差异的一个平方。为了修正这种影响，我们将标注差做开方处理，于是就得到了标准差。其计算公式为：<code>std(X) = variance(X) ** 0.5</code></p>
<p>协方差可以理解为方差的一种推广，他们都是通过衡量差异的方式来表示变量的性质的。事实上方差只是协方差的一种特殊形式。从上面的解释来看，方差是描述一个变量的，如果想描写两个变量的话，我们就要用协方差了。协方差的计算公式为<code>cov(X) = sum((x - mean(X)) * (y - mean(Y))) / (len(X) - 1)</code>（为什么这里要减一，可以看<a href="https://www.cnblogs.com/yymn/p/4662447.html">这里</a>）。虽然名字里面都有方差，但是协方差却是用来衡量两个变量之间的相关性的。</p>
<p>如果两个变量之间具有正相关性（即两个变量同时表现出增大或减小），则从协方差定义可以看出其值为正。如果具有负相关性，则协方差为负。通过<code>numpy</code>的<code>cov</code>可以计算两个变量直接的协方差。示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> cov</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line">X = np.random.randn(<span class="number">1000</span>) * <span class="number">10</span> + <span class="number">100</span></span><br><span class="line">Y = np.random.randn(<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">sum</span>([(X[i] - X.mean()) * (Y[i] - Y.mean()) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X))]) / (<span class="built_in">len</span>(X) - <span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(cov(X, Y)) <span class="comment"># 输出协方差矩阵，表示所有变量两两之间的协方差</span></span><br></pre></td></tr></table></figure>
<p>使用协方差，我们可以看出变量的相关性，但是却不好确定其相关的程度，因为它会受到变量取值范围的影响。如何屏蔽掉这种影响呢？需要用到皮尔森（Pearson）相关系数。</p>
<h3 id="pearson相关系数"><a class="markdownIt-Anchor" href="#pearson相关系数"></a> Pearson相关系数</h3>
<p>为了抵消变量取值范围的影响，我们可以在计算时，引入一个除数。而标准差作为衡量变量差异的一个量，正好可以用来作为此除数。这就得到了Pearson相关系数。其计算公式为<code>pearson_correlation_coefficient = cov(X, Y) / (std(X) * std(Y))</code>。</p>
<p>计算Pearson相关系数得到的数值是可以很好的解释的。该系数的取值在-1到1之间，该取值区间表示相关的范围，即从完全负相关到完全正相关，0表示无相关。一般而言，低于-0.5或高于0.5的值表示显著的相关，其他范围的值则表示不显著相关。</p>
<p>使用<code>SciPy</code>中的函数可以计算两个相同长度的数据样本的Pearson相关系数，示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line">X = np.random.randn(<span class="number">1000</span>) * <span class="number">10</span> + <span class="number">100</span></span><br><span class="line">Y = np.random.randn(<span class="number">1000</span>)</span><br><span class="line">Y1 = X + Y</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(stats.pearsonr(X, Y))</span><br><span class="line"><span class="built_in">print</span>(stats.pearsonr(X, Y1))</span><br></pre></td></tr></table></figure>
<p>运行这段代码可以得到Pearson相关系数为<code>0.022</code>和<code>0.995</code>。它表示<code>X</code>与<code>Y</code>不相关，而<code>X</code>与<code>Y1</code>具有很高的相关性。这与我们生成的数据的方式是一致的。</p>
<h3 id="spearman相关系数"><a class="markdownIt-Anchor" href="#spearman相关系数"></a> Spearman相关系数</h3>
<p>实际上Pearson相关系数有一个缺点，即它只能用于计算正态分布的两个变量且只能用于识别线性相关性（相关原理需要参考统计学知识）。为了应对这两种情况，除了Pearson相关系数，还可以用什么办法呢？其实还有一种类似的相关系数，即Spearman相关系数。</p>
<p>Spearman相关系数不直接用变量的值来进行计算，而是先计算变量的次序。次序即当前值在整个变量取值中的排名，比如变量<code>X=[100,30,5,20,1]</code>，则次序为<code>X_=[5,4,2,3,1]</code>。通过引入次序，就屏蔽掉了非正态分布带来的取值差异影响。比如，班级考试得分排名，Spearman只考虑排名位置，即谁是第一名和谁是第二名，而不考虑他们的得分，无论第一名和第二名相差是30分还是3分计算结果都一样。</p>
<p>Spearman相关系数计算公式为<code>spearman_correlation_coefficient = cov(rank(X), rank(Y)) / (std(rank(X)) * std(rank(Y)))</code>。</p>
<p>使用<code>SciPy</code>来计算Spearman相关系数，示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">1</span>)</span><br><span class="line">X = np.random.exponential(<span class="number">2</span>, <span class="number">1000</span>)</span><br><span class="line">Y = np.random.randn(<span class="number">1000</span>)</span><br><span class="line">Y1 = X + Y</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(stats.spearmanr(X, Y))</span><br><span class="line"><span class="built_in">print</span>(stats.spearmanr(X, Y1))</span><br></pre></td></tr></table></figure>
<p>这里计算得到的Spearman相关系数值为<code>0.010</code>和<code>0.993</code>。它表示<code>X</code>与<code>Y</code>不相关，而<code>X</code>与<code>Y1</code>具有很高的相关性。这与我们生成的数据的方式是一致的。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>有了这里的相关性计算方式，对于题目中的收入和支出的关系问题，我们就可以用数学的方式来回答了。当然，这还需要我们先去搜集一下数据。</p>
]]></content>
      <categories>
        <category>数据</category>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>数据分析</tag>
        <tag>统计</tag>
        <tag>相关性</tag>
      </tags>
  </entry>
  <entry>
    <title>浅谈企业数据能力建设</title>
    <url>/2020/12/03/data-capability-building-suggestions/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>随着市场的逐步成熟，要想保持企业的长期竞争力，运营和产品改进工作需要越来越精细化。</p>
<p>比如，在游戏行业，玩家留存率是一个关键指标，为提升留存率，需要精细化的分析玩家是哪一步流失的，根据游戏进程推进过程，按照先后顺序设置关键节点，分析各个节点流失情况数据，可以形成一个玩家流失漏斗。有了玩家流失漏斗，我们可以选择流失率高的环节进行进一步精细化分析，找到流失原因，比如机器适配问题，引导缺乏吸引力问题，数值设计问题等，根据这些原因就可以针对性的在产品和运营侧做改进了。</p>
<span id="more"></span>
<p><img data-src="/attaches/2020/data-capability-building-suggestions/game-data-analysis.png" alt="game data analysis" /></p>
<p>又比如保险行业，为了提高销售效率，可以先通过模型预测用户的销售响应率，然后将用户划分为几等，分别交由不同级别的销售人员跟进。我们现在在谈论的用户画像，产品画像，增长黑客，或者个性化推荐等等，其本质上其实都是在实现更精细化的运营或产品改进。</p>
<p>精细化产品改进和运营对企业应用数据的能力提出了很高的要求，因为这些改进决策的制定<strong>不能全凭经验</strong>，它们很大程度上还需要建立在<strong>坚实的数据分析结果</strong>之上。</p>
<p>企业应用数据的能力可以简称为企业数据能力。从整体上看，它应该是由企业数据驱动业务的文化、具有特定技能的人及具有特定功能的IT系统共同构成。</p>
<p>既然市场对于企业的数据能力要求越来越高，那么要如何建设数据能力呢？</p>
<p>为了尝试回答这个问题，我们先看看主要有哪些数据工作内容。</p>
<h2 id="数据工作内容"><a class="markdownIt-Anchor" href="#数据工作内容"></a> 数据工作内容</h2>
<p>回顾上面的玩家留存率分析过程，可以发现主要有三部分工作：</p>
<ul>
<li>寻找数据</li>
<li>加工数据</li>
<li>分析数据并提出产品改进的建议</li>
</ul>
<p>如何支持这三部分工作呢？也可以从三个方面来看：</p>
<ol>
<li>数据的日常维护和管理。它将包括数据仓库/数据湖的建设，数据质量、标准、模型、安全等数据治理内容。这将提高寻找数据的效率，保障使用数据的安全。</li>
<li>针对特定问题的数据分析。包括基于业务的各种指标计算，建模分析等。</li>
<li>数据管理及分析过程中的相关工具及平台。这将辅助进行数据管理和数据分析。</li>
</ol>
<p>为什么是这三个方面呢？事实上，这三个方面分别对应了三个不同的专业领域，它们需要的技能很不一样，企业内部甚至常常需要分成不同的团队来支持。数据的日常维护和管理需要数据工程能力，数据分析需要的是分析和建模的能力，工具平台的开发则需要软件开发能力。</p>
<p>其中，工具平台研发和前两者的相关性很高。</p>
<p>数据管理工作除了包含大量的规范文档定义、流程设计、沟通宣导之外，要在企业内部实现落地则是可以通过工具平台内建流程来支持。事实上这种方式越来越成为一个企业数据管理的演进趋势。这样一来，企业内部往往可以只设置少量数据管理专家，然后通过配合一个数据工具平台研发团队来实现数据管理。举个例子。比如对于数据质量管理，数据管理专家可以针对具体的业务数据定义专用的数据质量规则，如空值规则，值域范围规则等。通过数据平台可以将这些规则进行落地（规则脚本化并配置到平台）。然后数据平台定期运行相应的质量检查脚本来生成数据质量报告或发出数据质量告警，从而指导团队进行数据质量改进。</p>
<p>数据分析工作同样离不开工具平台的支持。即便简单的能通过sql查询实现的分析工作，也至少需要提供一个查询界面，随着分析工作日渐复杂，直接粗放的使用数据库工具来支持会显得越来越吃力和低效。事实上，一般我们会将这里的分析进一步细分为即席查询分析，定期报表，实时报表，建模分析，线上模型推理等内容。想要较完善的支持这些分析工作，没有一个高效的工具平台支撑是很难完成的。甚至业界常常采用数据平台和机器学习平台双平台来进行支持。</p>
<p>这三方面的工作可以图示如下：</p>
<p><img data-src="/attaches/2020/data-capability-building-suggestions/data-work-types.png" alt="data work types" /></p>
<p>从前面的分析来看，企业除了要从需求端发展数据管理能力和数据分析能力，工具平台的建设也是必不可少的，工具平台成熟程度常常与数据管理和数据分析的效率正相关。随着企业的逐渐发展壮大，工具平台往往越来越成为其数据能力的核心内容。这集中体现在工具平台越来越难以满足数据管理和数据分析的需求，大量的工具平台定制化需求被提出。</p>
<p>不同的企业具体情况不同，这三个方面的工作量及对应的人员需求量也不同。比如，有的企业中，数据相关工具和平台完全来自外部采购，功能相对完善，则可能只需要完成工具平台运维，内部系统集成和管理流程落地，工具平台研发人员也可以尽量减少。而与之相对应，如果工具和平台采用基于开源工具自建，有较多的自定义功能，则往往需要扩大工具平台的研发团队。而有的企业中，如果数据管理人员和数据分析人员拥有较强的软件研发能力（比如大量来自开发人员的角色转型），则工具平台的研发可能直接会合并到数据管理和分析工作中去。</p>
<h2 id="企业数据能力建设思路"><a class="markdownIt-Anchor" href="#企业数据能力建设思路"></a> 企业数据能力建设思路</h2>
<p>基于数据工作的拆解和分析，我们可以尝试从以下几个维度来思考如何进行企业数据能力建设。</p>
<h3 id="第一是数据人才资源建设"><a class="markdownIt-Anchor" href="#第一是数据人才资源建设"></a> 第一是数据人才资源建设。</h3>
<p>从角色及其能力要求上面划分，可以大致将数据人才资源分为数据工程师/数据架构师，数据分析师/数据科学家。我在<a href="http://brightliao.com/2020/11/26/data-work-roles/">另一篇文章</a>中探讨了这些角色的工作范围和能力要求，可以作为这些角色定义的参考。从这里的角色定义出发，企业就可以根据自身具体情况规划出符合自身文化的数据人才资源体系结构，从而在招聘和培养人才上面有一个整体的思路和规划。</p>
<h3 id="第二是人员组织和协作"><a class="markdownIt-Anchor" href="#第二是人员组织和协作"></a> 第二是人员组织和协作。</h3>
<p>有了人，如何才能将大家组织起来，形成合力，做好事情呢？</p>
<p>企业组织结构一般可以分为职能型、项目型和矩阵型。</p>
<p>职能型组织将核心的工作划分为不同的功能部门，如产品，运营，销售，财务，审计等，这些部门按照职责范围大小组成从上到下的层级，最终形成金字塔型的结构。职能型组织结构一个典型的例子就是政府部门和一些传统的大型国企。其优势是利于各部门形成自己各自的专业优势，劣势是难以组成项目组以面向问题的方式解决企业问题（部门间常常合作困难，相互推诿和争利）。</p>
<p>项目型组织以面向项目的方式组成项目组来实现人员组织和协作，其典型的例子是以外包业务为主的服务型公司。其优势是解决问题的效率高，但是不容易积累沉淀组织能力。</p>
<p>矩阵型组织则希望避免职能型组织带来的部门墙问题，在职能型组织的基础上引入项目组织形式，在项目需要时从各职能部门抽调人员形成项目组，由项目组来统一管理。矩阵型组织常常使得某一个角色存在多位领导，从而给员工晋升及工作安排带来问题。实际企业中往往是各种组织形式并存，其中重要的是要注意由于部门划分带来的部门墙，它对于工作效率常常带来巨大的负面影响。</p>
<p><img data-src="/attaches/2020/data-capability-building-suggestions/org-structure.png" alt="organization structure" /></p>
<p>对于刚起步的小型企业，人才资源有限，往往需要一个人当一个团队用，过于清晰的划分将显得过于重量级而无必要。</p>
<p>对于一个中大型企业而言，可以设立数据部，内部进一步细分为数据管理、数据分析、数据工具平台研发三类角色岗位，形成职能型的垂直组织结构。然后，从各类细分角色抽调一部分人组成项目组以支持业务线数据工作。这样一来，便形成了矩阵型的组织结构。</p>
<p>以上简要的做了组织结构分析，当然，要想做好数据工作，还涉及很多需要更多智慧的管理工作细节。</p>
<h3 id="第三是工具平台建设"><a class="markdownIt-Anchor" href="#第三是工具平台建设"></a> 第三是工具平台建设。</h3>
<p>为什么要单独谈工具平台建设呢？因为工具和平台往往是数据能力的依托和沉淀。数据管理中的标准和流程需要工具平台的支持否则很容易变成空中楼阁。而数据分析的无数脚本也需要有机沉淀，并需要在组织内交流和分享，否则就只是数据分析师自身的能力而已。</p>
<p>一般而言，工具平台的建设有三种模式：</p>
<ul>
<li>外部采购。时间成本可以节省不少，但需要注意采购的产品的功能边界，并注意该产品是否可以和内部系统有效集成，是否可以支持灵活的功能定制。</li>
<li>自建。一般考虑根据开源的项目进行改造，这样的方式的优势是可定制能力极强，其劣势就是需要大量的相关人才并需要一定的时间周期。</li>
<li>还有一种中间的方式，那就是采购产品的同时采购定制化服务，或者和第三方技术公司合作在开源产品上联合开发定制所需功能。</li>
</ul>
<p>对于这些不同的工具平台建设模式，不同的企业会做出各自的选择，但是长远来看，一个技术驱动的企业一定对可定制能力有很高的要求，所以可定制能力将是一个必选项。</p>
<p>另一方面，从功能上来看，采购的产品和服务往往难以完整的实现企业特定的数据管理和分析需要，可能要考虑基于这些产品提供的api来进行定制化开发而舍弃掉它们提供的功能界面。</p>
<p>比如，如果我们用aws的数据服务，数据质量管理如何实施呢？这时可能需要基于aws的api来开发一个质量管理的工具，通过定义质量规则，配合定期执行的质量检测任务来实现。</p>
<p>所以，开发一个企业自己的数据平台界面可能是企业数据工具和平台建设的关键一环。这个界面相当于定义了企业自己的数据工作接口，而采购的服务是这一接口的某个具体实现。</p>
<p>接口的定义往往比实现更重要，因为会有太多的企业资产依赖这样的接口去实现，比如大量的etl脚本。接口就如同电脑主板的插槽，接口定义好了，企业就可以按照自己的方式去设计主板布局及开发上层软件，主板布局和上层软件构成了企业的核心资产和竞争力，而某个接口的具体实现，比如摄像头、内存或硬盘，则应该可以较为轻松的替换而不影响企业主要业务。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>总结一下，以上内容从数据工作做什么出发简要分析了企业如何进行数据能力建设，结合以往经验从三个方面（人才资源建设、人员组织合作、工具平台建设）分享了一些自己的认识。</p>
<p>那么，你的企业中是如何建设数据能力的呢？欢迎留言讨论。</p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>培训</tag>
        <tag>数据平台</tag>
        <tag>数据工作</tag>
        <tag>组织架构</tag>
      </tags>
  </entry>
  <entry>
    <title>那些数据工作中的角色</title>
    <url>/2020/11/26/data-work-roles/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>数据工作中有一类非常重要的角色，那就是数据分析师。为什么这个角色这么重要呢？因为要是没有这个角色，不管一个企业中的数据管理做得有多么好都没用，无法带来实际的价值。这些数据就像是藏在海底的石油，而数据分析师就是开采海底石油的油井设备。要想让石油用于汽车轮船，需要通过这些设备先将海底的石油抽取出来，经过加工处理，提纯。</p>
<span id="more"></span>
<h2 id="数据分析师"><a class="markdownIt-Anchor" href="#数据分析师"></a> 数据分析师</h2>
<p>这个角色通常做什么呢？数据分析师的日常工作当然就是做数据分析。比如要分析一个应用的客群特征，分析用户的留存率，活跃程度等等。但是，对于数据分析工作，最重要的是业务理解，对软件开发技术的要求其实并不高，能写SQL就能完成大部分工作了。比如留存率的计算，技术上一个带<code>join</code>和<code>where</code>的SQL查询就实现了，但是分析的目标远不止于此，对于分析而言，更重要的是要知道为什么留存率是计算出来的这个数值以及这个值究竟意味着什么。考察为什么是这个数值，可能会发现是由机器人贡献了较高的留存率，企业内员工也贡献了较高的留存率，真实的用户其实贡献了一个较低的留存率。考察这个值究竟意味着什么，首先会观察其变化趋势，可能会发现留存率有所上涨或下降，然后，最重要的，根据这一情况应该从业务上做些什么。</p>
<p>从这里的分析可以看出，数据分析师是具备一定的技术能力，但更偏业务的一种角色。</p>
<p>可能有人会说，我之前在互联网公司待过很长时间，似乎也没听说过需要这样一种角色呀。没错，其实在很多规模不大的互联网公司，根本没有明确定义数据分析师这样的角色，但这一角色并非不存在，通常这样的角色是被市场运营人员和产品经理兼任了。当前国内的互联网公司普遍招聘的产品经理或运营人员的一个重要的能力要求就是会分析数据，然后根据数据改进产品设计或改进运营策略。我见到过很多公司的产品经理和运营人员写SQL写的非常溜，他们正是在进行分析数据，并根据数据进行业务改进。</p>
<h2 id="数据科学家"><a class="markdownIt-Anchor" href="#数据科学家"></a> 数据科学家</h2>
<p>对于数据分析师而言，技术上只要会SQL就够了么？当然不是。当业务发展到一定程度之后，想要做到精细化的运营，简单的SQL工具可能就无法满足数据分析师的需求了。这时，可能要请出来一些大家觉得高大上的算法模型了。比如，要做客群细分，是不是要来个RFM模型呢？要挑选一些客户来做营销，是不是要做个逻辑回归模型来预测一下哪些客户是潜在的高价值营销客户呢？想做交叉销售提升现有客户价值，是不是要来个关联分析呢？</p>
<p>一旦涉及到建模分析，问题就不一样了，这些分析手段非常专业，非计算机专业，数学能力比较差的同学接受起来可能就会比较困难。但也绝非不可能，市场上其实已经有很多专门为建模分析而生的专业工具了。其中最有名的莫过于<a href="https://www.sas.com/en_us/home.html">SAS</a>。只需要使用者明白基本的算法原理，然后跟随软件的可视化引导进行操作就可以完成基本的建模分析。这样一来，是不是具有计算机或者数学背景的偏业务的数据分析师们也可以来做了呢？</p>
<p>有不少公司将同时懂业务，会SQL，会建模分析的人员称为数据科学家。需要拥有这么多的交叉专业背景，这一角色的门槛显然是非常高了。然而，数据科学家这一角色对于一个日渐壮大的企业而言却是是非常重要的，常常可以带来企业核心竞争力的进一步提升，为企业建立竞争壁垒。</p>
<p>按照前面对数据科学家的定义，企业内部常常是缺少堪称数据科学家的人才的。即便有，也更多是某一领域的数据科学家，因为需要有深厚的业务知识积累而一个人其实是很难具有多个行业多个领域的业务经验的。所以，一般而言，企业中更多的人才资源是数据分析师，即便有数据科学家，可能更多也谦称为数据分析师。当然可能也有另一个原因，数据分析师的名字听起来会更偏解决实际业务问题，而数据科学家则更像是偏学术理论研究。</p>
<h2 id="数据工程师"><a class="markdownIt-Anchor" href="#数据工程师"></a> 数据工程师</h2>
<p>数据工作当然还少不了一类角色，那就是数据工程师。不管是数据分析师还是数据科学家，都是基于数据进行分析的。那数据从哪里来，数据管理是不是做的足够好，数据提取是不是足够容易，在大规模的数据集上面进行计算是否高效，这些问题常常成为了挡在数据分析师和数据科学家前面的一堵墙。为了打破这堵墙，就需要数据工程师了。所以，数据工程师的职责是什么呢，那就是为数据分析师和数据科学家服务。将数据有效的管理起来，让他们可以轻易的获取并理解数据。为他们提供分布式的探索环境，让他们可以高效的在大规模的数据集上面进行计算。除了为数据分析提供服务，数据工程师还需要做好其他的企业数据管理工作，比如数据安全，数据标准，数据质量管理等。</p>
<h2 id="数据架构师"><a class="markdownIt-Anchor" href="#数据架构师"></a> 数据架构师</h2>
<p>想做好企业数据管理并非易事，如何在企业内部建立数据标准，如何进行数据安全定级，并分别对不同安全级别的数据实施不同的安全策略，如何推进企业数据质量建设。这些问题没有一个是可以轻易做到的，非但不能轻易做到，甚至对数据管理经验要求非常高。这对于数据工程师的行业经验、工程经验都提出了更高的要求。业界通常将有这些经验足够丰富的数据工程师称为数据架构师。</p>
<h2 id="转型到数据分析师"><a class="markdownIt-Anchor" href="#转型到数据分析师"></a> 转型到数据分析师</h2>
<p>能不能不要数据分析师呢？经过前面的角色拆解分析可以知道，企业里面总是会先有数据分析师（即便可能暂时没有这个称号），再有数据工程师。如果一项数据工作中没有数据分析师，那这个项目就很容易演变成一群做技术的人的自嗨，搭建各种前沿大数据平台，什么分布式计算流式计算一起上，做了很长的时间烧了大把经费之后发现没有什么可见的业务价值，然后不得不因为项目经费的原因遗憾收场。</p>
<p>所以，要想做好数据这块业务，数据分析师这一角色是不可缺少的。</p>
<p>如何应对数据分析师的短缺呢？最直接的办法就是扩充拥有数据分析能力的人才了。人才可以有两方面来源，一是招聘，二是内部转岗。首先看内部转岗。内部转岗可以说是最先采用的人才扩充方式。</p>
<p>能不能由软件开发人员转做数据工程师或者数据分析师呢？其实软件开发人员转做数据工程师相对是比较容易的。但是还是需要补充较多的数据专业能力，比如数据仓库的建设方案，如何进行数据建模，如何进行数据治理，如何进行数据开发和调试，如何实现数据服务及可视化，如何打造数据平台等。</p>
<p>能不能由软件开发人员转做数据分析师呢？这种情况就比较有难度了。主要是业务思维和技术思维有着很大的不同，业务思维想要解决当前的业务问题创造利润，怎么快怎么做，看重可操作性和效果而非技术，而技术思维却是想着维护产品的高质量，稳步的进行迭代演进。所以，我们常常见到，业务人员不能理解做技术的要考虑各种边界情况，各种依赖情况，导致一个功能要做很久；技术人员也不能理解业务为啥要天天变，刚做好的功能还没产生业务价值又要推翻重来。除了思维方式需要转变，业务经验积累也变成了这里的角色转变的绊脚石。</p>
<p>能不能由BA转做数据分析师呢？我们看到公司内部其实有不少数据分析师是BA的角色转变而来的。但是新的角色对于BA而言同样存在很大的挑战。比如如何快速的去熟悉一个新行业的业务，如何提升SQL技能，甚至如何自我学习和提升达到具备进行统计分析，假设检验，建模分析的能力。这些都是不容易的。</p>
<h2 id="企业数据人才结构"><a class="markdownIt-Anchor" href="#企业数据人才结构"></a> 企业数据人才结构</h2>
<p>前面介绍了数据工作的相关角色，隐隐约约可以看出企业数据人才组成结构了，我们姑且将其称为企业数据人才架构。用一张简图可以表示如下：</p>
<p><img data-src="/attaches/2020/2020-11-26-data-work-roles/data-roles-architecture.png" alt="data roles architecture" /></p>
<p>前面只是最基本的角色定位，在实际企业环境中，常常会由于各自的企业基因和文化而有所不同。</p>
<p>比如，如果是一家创业型小公司，可能就只分为技术、产品、运营三种大的角色。技术人员将完成业务功能开发、运维、数据管理等等一系列工作。产品人员将基于产品数据分析完成产品设计和优化。运营人员将基于运营数据分析完成运营策略、运营活动的设计等。如果这家创业型公司以业务为核心，那么可能前期会直接采购相关的软件产品，连技术和数据分析都没有。</p>
<p>一家以软件技术为核心的中型公司（比如互联网公司），业务逐步成熟，就开始设置专门的数据部门和数据工程师岗位。而一家以业务为核心的中型公司（比如零售、保险等公司），业务逐步成熟，就开始设置专门的数据分析部门和数据分析师岗位。</p>
<p>随着业务的进一步扩大，各个角色的专业性越来越强，大型企业中常常设置数据架构师、数据科学家等角色，以应对特别复杂的业务场景。</p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>数据工作</tag>
        <tag>组织架构</tag>
        <tag>角色</tag>
      </tags>
  </entry>
  <entry>
    <title>一些企业数据平台建设的思考</title>
    <url>/2021/01/21/some-thoughts-about-data-platform/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>我最近接触到不少传统行业的客户，他们都希望构建自己的数据平台。其目的大都是希望通过借鉴互联网公司积累的成熟的技术经验，构建自己的数据能力，最终实现数据驱动型企业。</p>
<p>数据平台早已不是什么新鲜事物，甚至在当前大家都在谈论数据中台的时候，还显得有点过时。在我看来，其实大家对于数据中台的认识还处于探索的阶段，并没有形成让行业信服的一致的观点。但一提到数据平台，大家对其应该包含的内容还相对比较清楚。所以，本文尝试选择“数据平台”这个可能有点过时但是相对务实一点的词语来组织内容。这里我不想在概念上谈论太多，无论这个东西是什么，它要解决的企业中的数据问题是明确而具体的。</p>
<span id="more"></span>
<h2 id="什么是企业数据平台"><a class="markdownIt-Anchor" href="#什么是企业数据平台"></a> 什么是企业数据平台</h2>
<p>企业建设数据平台想要解决什么样的数据问题呢？让我们先来看看是数据如何发挥它的价值的。</p>
<h3 id="数据在企业中如何应用"><a class="markdownIt-Anchor" href="#数据在企业中如何应用"></a> 数据在企业中如何应用</h3>
<p>一般企业内部的数据会以两种方式来使用。</p>
<p>一是支持bi分析，即通常我们所说的各种数据报表应用，它也包括数据的上卷下钻分析。二是支持自助式的探索式的数据分析，通常包括统计分析和建模分析。</p>
<p>不管是哪种方式，首先是要有数据。一般的做法是将数据从业务系统搜集到一个专门用于分析的数据存储中。再在这个系统中执行数据计算。</p>
<p>对于报表应用，通常我们需要周期性的将一些数据指标计算出来，并存储为某一张数据库表，供bi系统快速的查询。</p>
<p>对于探索式的数据分析，我们常常需要提供一个可编程的接口，以便数据分析师可以用于数据处理和分析。考虑到数据分析师的技术背景，这里的编程接口通常是<code>SQL</code>和<code>Python</code>。</p>
<h3 id="数据平台功能"><a class="markdownIt-Anchor" href="#数据平台功能"></a> 数据平台功能</h3>
<p>了解了数据应用的流程，我们就可以将数据平台的功能大致梳理出来。</p>
<ul>
<li>数据接入支持，需要提供一个接口以便业务团队可以快速的把数据接入到数据平台。</li>
<li>数据开发支持，需要提供接口用于进行数据计算，以便可以算出数据指标提供给bi工具。</li>
<li>任务调度支持，需要将上述的计算程序周期性的调度起来，以便可以周期性的计算出数据指标。</li>
<li>探索式数据分析支持，提供<code>SQL</code>和<code>Python</code>接口给数据分析师使用。</li>
</ul>
<p>从更方便的组织和管理数据的角度来看，数据平台还需要具备如下能力：</p>
<ul>
<li>数据安全管理。比如数据权限控制，实现无权限读写的数据无法读写，权限申请流程简单等；还比如数据脱敏控制等。</li>
<li>数据质量管理。比如可以方便的查询数据标准，根据数据标准执行数据检查等。</li>
<li>数据发现支持，便于平台使用者可以快速的找到数据和理解数据。这里就会包括数据目录，元数据管理，数据血缘管理等一系列数据管理功能。</li>
</ul>
<p>从软件架构的角度来说，为了更好的支持数据理解，以便高效的进行指标开发和数据分析，一般我们会进行一定的数据模型设计。为了支持高效的复杂数据计算，一般数据平台中会沉淀大量的可以复用的基础指标。所以，从改进软件开发的角度来看，数据平台还将具备的功能如下：</p>
<ul>
<li>数据建模能力支持</li>
<li>分层的数据架构支持</li>
<li>维护数据开发规范、设计建议、最佳实践等指导性的文档</li>
</ul>
<p>如果用一张图来概括上面的数据平台，就形成了大家常常看到的如下的数据平台架构图。</p>
<p><img data-src="/attaches/2021/2021-01-21-some-thoughts-about-data-platform/data-platform.png" alt="data platform" /></p>
<p>其中，如果企业对建模能力有特别强的需求，通常我们还会将机器学习模型相关的功能进一步划分出来，形成一个机器学习平台。</p>
<h2 id="数据平台建设思路"><a class="markdownIt-Anchor" href="#数据平台建设思路"></a> 数据平台建设思路</h2>
<p>了解了数据平台是什么，我们来看看企业数据平台建设思路。</p>
<h3 id="中心化还是非中心化"><a class="markdownIt-Anchor" href="#中心化还是非中心化"></a> 中心化还是非中心化</h3>
<p>首先我们从组织形式上面来分析一下如何建设企业数据平台。一般而言，数据平台会是一定程度的中心化和集成式的。</p>
<p>一提到中心化，想必有人会不服，觉得这样的中心化的系统和组织一定不能成功。我曾经就听到有人坚决否定中心化的价值，其举出的反例可能有以项目为单位的小的敏捷团队，去中心化的区块链，去中心化运维团队的devops思想，去中心化测试团队的敏捷实践等等。</p>
<p>中心化确实有其不足，但是我们也要看到它的很多优点，比如：</p>
<ol>
<li>可以避免各个团队重复建设带来的资源浪费</li>
<li>统一的数据管理可以更好更快的推进企业内部的数据策略的落地，比如数据标准，数据安全等</li>
<li>实现计算和存储资源共享，节省开支</li>
<li>更方便的实现跨业务线数据集成</li>
</ol>
<p>其实，中心化与非中心化哪种方式更好，与企业的规模，文化，组织结构相关。</p>
<p>比如，一些规模比较大的业务线，人才资源多技术能力也强，通常完全有能力自建一套数据平台。这样的业务线内部通常业务也特别复杂，数据量特别大，且对定制能力有着很高的要求。这时，企业级别的中心化数据平台带来的成本优势就显得不够有吸引力了。反而会由于需要很多的跨团队沟通协作而降低了效率。</p>
<p>但是，如果我们把这样的业务线当做一个稍小的独立自治的组织来看，在其内部通常是划分为更小的业务团队，在这些业务团队间建设一个中心化的数据平台同样会带来价值。</p>
<p>再比如，有一些业务线，虽然也很大，但其内部的组织结构是按照以业务隔离性非常强的项目组为基本单元组织而成的。每个项目组形成一个小的全功能敏捷团队，各自探索式的推动业务发展。这样的情况下，团队间几乎不用数据共享，且对于数据管理要求也不高，他们的第一优先级是快速推动业务发展。于是中心化的数据平台的价值也不那么明显了。他们甚至可能连业务线级别的数据平台都不需要，而是根据团队各自的需要自建一些小的数据平台。</p>
<p>上面这样的情况可以举出的例子很多，比如华为，其内部的消费者业务线就建设了独立的数据平台为大量的内部项目团队提供中心化数据服务，而运营商业务线则由于其面向企业提供服务的特性，项目间业务相似性低隔离性高，更倾向于每个团队自建小的数据平台。</p>
<p>再比如，很多的银行或者零售行业企业，其内部业务通常比较成熟，常见的情况是建设一套统一的中心化的数据平台。</p>
<p>所以，回到最初的数据平台建设思路上，一般而言，数据平台会是一定程度的中心化和集成式的。但究竟是哪种程度的中心化，还要根据具体的企业情况来看。</p>
<p>对于本文最初提到的传统行业的情况，他们大多数并不是以软件服务为核心，而是以其现有的生产或者信息业务为中心（比如汽车、零售、保险业务）。在这些企业内部，软件常常只是辅助作用，因而软件开发团队的能力也不是特别强。从以上的分析来看，对于这些企业，可能建设中心化集成式的数据平台是更为合适的方式。</p>
<h3 id="采用精益的思想来逐步构建数据平台"><a class="markdownIt-Anchor" href="#采用精益的思想来逐步构建数据平台"></a> 采用精益的思想来逐步构建数据平台</h3>
<p>其次，我们从数据平台建设过程来分析一下。一般而言，数据平台建设需要以某一高价值数据分析（包括业务指标或者机器学习模型）需求来拉动，在实现业务价值的同时慢慢的完善平台，最终实现企业级的数据平台。</p>
<p>与此相对应的，不少企业一上来就直接想要建设一个功能强大而全面的数据平台，他们很多都成为了失败的案例。这一做法的典型思路就是，先对标一个行业标杆的数据平台，组建一个大型团队开始做开发。开发过程中，他们对于数据平台谁来使用，产生了什么价值关注不够。最终的结果就是，项目投资人花了大笔经费却迟迟看不到价值，从而慢慢减少投资导致项目流产。</p>
<p>采用价值拉动的模式其实就是用精益的思想来指导数据平台建设。它以价值实现为目标，每一个平台功能的实现都对应着立即可见的价值实现。长期下来，通过不断的进行技术重构和架构演进，平台也就慢慢形成。</p>
<p>有人可能会说这样建设而来的数据平台大家都不一样，将缺乏一个行业统一标准。然而，企业是以实现经济效益为前提的，为什么数据平台非得是行业的标准实现呢？在我看来，由于数据平台具有非常强的技术相关性，其最终形式本身就会根据企业和团队的不同而不同。试想，对于某一个功能的软件实现，如果交给不同的开发人员去做，最后产生的设计和实现的代码会一样吗？然而，其实我们并不是很关心代码是否一样，只要最后的功能实现了，目的也就达到了。所以，数据平台的最终形式很可能不同企业完全不同。</p>
<p>一个成功的数据平台建设的过程通常会是：</p>
<ol>
<li>组建一个数据平台团队</li>
<li>基于开源技术搭建一个具备基本功能的数据平台</li>
<li>为了实现某一个业务指标计算，接入某一个系统的数据，从而顺便完成了一定的平台数据接入功能</li>
<li>为了实现某一个机器学习模型，接入另一个系统的数据，从而顺便增强了之前的平台数据接入功能，且顺便完成了某一些通用的可复用的指标的计算</li>
<li>为了支持更多的探索性数据分析，根据需要，数据平台支持了自助式的以SQL为接口的数据分析</li>
<li>为了支持更多的探索性数据分析，根据需要，数据平台支持了自助式的以Python为接口的数据分析</li>
<li>根据数据安全的需要，数据平台完善了对于数据权限的管理，数据加密脱敏的支持</li>
<li>随着数据平台功能逐步完善，业务团队更多的自助的进行数据接入和数据分析，数据平台团队则专注在平台功能不断增强及平台稳定性维护上面</li>
<li>…</li>
</ol>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>总结一下。本文首先讨论了什么是数据平台这个问题，尝试回答了数据平台的定义和功能范围。接着，结合作者本人所经历过的数据项目经验，对建设企业数据平台的思路进行了一定的梳理。</p>
<p>本文希望能对从事数据工作的同仁有所启发，也希望可以让非数据工作的小伙伴对数据工作有一定的认识。</p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>数据平台</tag>
      </tags>
  </entry>
  <entry>
    <title>基于Hadoop大数据平台的数据治理</title>
    <url>/2021/02/21/data-governance-based-on-atlas-ranger/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2021/2021-02-21-data-governance-based-on-atlas-ranger/data-governance.png" alt="Data governance" /></p>
<p>数据治理并不是一个新的概念，但由于国内信息化起步较晚，这个话题直到最近几年才在国内各大公司中引起广泛讨论。数据治理具体是什么，我们真的需要数据治理吗？为了更清楚的了解数据治理是什么，我们先参考一下业界都是怎么说的。</p>
<span id="more"></span>
<h2 id="什么是数据治理"><a class="markdownIt-Anchor" href="#什么是数据治理"></a> 什么是数据治理</h2>
<p>数据治理研究所（<code>DGI</code>）于2004年推出了<code>DGI</code>数据治理框架，为企业需要根据数据来做决策的复杂活动提供方法。该框架考虑数据战略专家、数据治理专业人员、业务利益相关者及IT领导者共同关注的问题，比如，如何管理数据实现数据价值，如何最小化成本和复杂性，如何管理风险以及如何确保遵守不断增长的法律法规和其他要求。<code>DGI</code>数据治理框架的目标是：</p>
<ul>
<li>实现更好的决策</li>
<li>减少操作摩擦</li>
<li>保护数据利益相关者的需求</li>
<li>培训管理层和员工采用共同的数据问题方法</li>
<li>构建标准、可重复的流程</li>
<li>通过协调努力降本增效</li>
<li>确保流程透明度</li>
</ul>
<p>高等教育统计局（Higher Education Statistics Agency，简称<code>HESA</code>）是英国收集、分析和传播高等教育定量信息的官方机构，提出了<code>HESA</code>数据治理模型。该模型强调：</p>
<ul>
<li>确保数据安全，管理良好，确保组织面临的风险可控;</li>
<li>防止和纠正数据错误，作为计划持续改进的一部分;</li>
<li>衡量数据质量并提供检测和评估数据质量的改进框架;</li>
<li>制定标准记录数据及其在组织内的使用情况;</li>
<li>作为数据相关问题/变更的升级和决策主体。</li>
</ul>
<p>Information Builders是美国一家软件咨询公司，在他们提出的数据治理方法中强调，数据治理的核心价值是创建一个模型确保数据的保密性、质量和完整性。这对于满足内外部要求（如财务报告、合规性和隐私权等）至关重要。数据治理通过加强监督，根除风险，有效地将政策与业务战略相结合。Information Builders数据治理模型建议采取渐进式方法进行数据治理，渐进式的做法是实现业务价值并建立数据治理可持续发展计划的实用方式，从而避免在治理过程中做得太过。</p>
<p>Information Builders在构建模型的同时，配以7个步骤辅助实施，确保有效的数据治理：</p>
<ul>
<li>优先考虑业务改善领域；</li>
<li>最大化信息资产的可用性；</li>
<li>创建并分配角色、职责；</li>
<li>完善和确保信息资产的完整性；</li>
<li>建立问责制；</li>
<li>以主数据文化为基础；</li>
<li>制定流程改进反馈机制。</li>
</ul>
<p>上述这些框架中的内容听起来比较散乱，但总结起来，我们可以认为，数据治理可以为给企业积累高质量的数据资产，从而为决策提供高质量数据支持，数据治理还可以帮助企业避免一些合规、隐私等问题。这是数据治理的目的。</p>
<h2 id="数据治理实施方法"><a class="markdownIt-Anchor" href="#数据治理实施方法"></a> 数据治理实施方法</h2>
<p>那么数据治理如何实施呢？</p>
<p>从上面的定义来看，数据治理大部分内容是可以直接通过管理手段来实现的，这也是传统的数据治理的主要方法。一般而言，企业可以先从组织架构的角度建立数据治理的组织支持，比如，设置数据治理委员会，设立数据治理专员职位。然后，数据治理委员会根据公司情况制定数据相关管理规范，由数据治理专员负责监督执行。</p>
<p>使用管理手段来实现数据治理的目的听起来不错，但是我们知道，企业的很多管理制度通常都难以实施。首先是培训成本很高，其次，依靠人去遵循规章制度很容易影响解决问题的效率。那么，在软件技术迅猛发展的今天，我们是不是可以更多的从技术上来解决这个问题呢？</p>
<p>下面我们主要来看一下在基于Hadoop的大数据平台（下文简称数据平台）下，我们如何通过技术手段实施数据治理。</p>
<h2 id="数据平台下实施数据治理"><a class="markdownIt-Anchor" href="#数据平台下实施数据治理"></a> 数据平台下实施数据治理</h2>
<p>从数据治理的目标来看，我们可以进一步将数据治理划分为：元数据管理、主数据管理、数据标准管理、数据质量管理、数据安全管理。</p>
<p>其中，主数据管理的做法在当下的业界认识中存在一些争议，且主数据管理通常是属于在业务系统中进行数据治理的范畴，在这里我们先略过。</p>
<h3 id="数据质量和数据标准"><a class="markdownIt-Anchor" href="#数据质量和数据标准"></a> 数据质量和数据标准</h3>
<p>数据质量和数据标准的相关性较强。好的数据标准的制定需要经过严谨的讨论，有了标准，数据质量的目标可以认为就是让数据符合标准。如果数据都符合标准，那就是高质量的数据了。数据标准的制定通常更偏重人的参与，信息系统在里面可以提供一定的支持，但是由于标准可能在不同的企业中很不一样，这一部分其实难以有一个统一的方案支持。</p>
<p>在进行数据标准管理时，可以考虑将确定的数据标准编写成可以针对数据去运行的规则代码。有了这些规则代码之后，至少可以做两件事，一：可以在设计新数据模型的时候执行自动标准检查，以便尽量让新的设计符合标准；二：可以定期针对已有数据自动执行数据标准检查，从而发现数据问题并提醒数据所有者进行优化改进。</p>
<p>数据质量管理可以采用类似数据标准管理的思路，先定义数据质量规则，然后编写代码落地成可执行的程序。</p>
<p>通过上面的分析可以知道，数据质量和标准管理可以通过数据开发来实现。在基于<code>HDP</code>的大数据平台上目前还没有直接集成相关的工具，不过我们可以找到一些开源工具做支持，比如<code>apache</code>旗下的<code>Griffin</code>可能就是一个不错的起点。</p>
<h3 id="元数据管理和数据安全"><a class="markdownIt-Anchor" href="#元数据管理和数据安全"></a> 元数据管理和数据安全</h3>
<p>除了数据标准和数据质量，数据治理还要求做好元数据管理和数据安全，这两部分内容可能是更为基础的数据需求，特别是数据安全，因为它直接关系到平台能不能在企业中应用的问题。比如，如果数据谁都可以随意访问和下载，可以想象，那将很容易导致企业敏感数据或机密数据外泄。比较起来，数据标准和质量虽然需要尽量做好，但是就算没做好也不至于是一个致命问题。</p>
<p>在一个分布式环境下做元数据管理和数据安全管理不是一件容易的事。比如，由于运行于<code>Hadoop</code>之上的组件非常多，数据库有<code>Hive</code>，计算引擎有<code>Spark</code>，<code>NoSQL</code>数据库有<code>Hbase</code>，消息系统有<code>Kafka</code>，各个系统都有自己的元数据，统一的元数据管理要如何实施呢？统一的数据安全要如何实施呢？</p>
<p>基于<code>HDP</code>的大数据平台在这方面的功能相对比较丰富和成熟。<code>HDP</code>集成了<code>Atlas</code>和<code>Ranger</code>，它们分别用于解决分布式环境中的元数据管理和数据安全管理问题。</p>
<h4 id="利用atlas进行元数据管理"><a class="markdownIt-Anchor" href="#利用atlas进行元数据管理"></a> 利用<code>Atlas</code>进行元数据管理</h4>
<p>先来看<code>Atlas</code>，<code>Atlas</code>是专门设计为解决<code>Hadoop</code>下的元数据管理问题。<code>Atlas</code>提供了一个通用的元数据管理模型抽象，事实上，使用<code>Atlas</code>我们不仅可以管理<code>Hadoop</code>下的元数据，也可以管理传统的关系型数据库中的元数据。<code>Atlas</code>同时还作为一个基础服务为分布式环境下的数据安全管理提供支持。</p>
<p>使用<code>Atlas</code>，我们可以自由的去定义元数据模型，因此，即便有来自很多不同组件的元数据要进行管理，也可以通过<code>Atlas</code>实现。<code>Atlas</code>的元数据模型还可以支持继承关系，这就提供了一层抽象来帮助我们在不同的组件间复用一部分元数据管理的功能。举个例子，数据存储的一个最基本的形式是表和字段，不管是<code>Hive</code>还是<code>Hbase</code>，表和字段的概念是通用的，只不过<code>Hive</code>支持的字段类型可能更丰富（比如支持嵌套结构）。</p>
<p>听起来比较复杂，但是，实际使用<code>Atlas</code>时，我们可以不关心这些模型的细节，因为<code>Atlas</code>早已经预定义好了大部分组件对应的元数据模型了。除非有扩展的需要，否则我们都可以只关注在如何使用元数据上。</p>
<p><code>Atlas</code>是如何搜集元数据的呢？这点也无需我们操心，经过配置，<code>Atlas</code>可以自动的从各种数据组件中提取同步元数据。</p>
<p><code>Atlas</code>自动搜集到的元数据可以通过<code>Atlas</code>提供的查询界面进行搜索，如下图，我们可以根据不同的条件搜索<code>Hive</code>中的表或者字段。从搜索结果中，我们还可以进一步导航到关联的元数据中去，比如，字段可以关联到对应的表。</p>
<p><img data-src="/attaches/2021/2021-02-21-data-governance-based-on-atlas-ranger/atlas-search.png" alt="Atlas search" /></p>
<p>元数据搜索功能可以方便我们查找数据，一般的企业数据平台中都会存在大量的数据表和字段，强大的元数据搜索功能因此显得很有必要。总体来看，元数据搜索对于促进企业数据发现有很好的帮助。</p>
<p>除了强大的元数据搜索功能，<code>Atlas</code>还提供了自动数据血缘分析功能，如果我们的某些<code>Hive</code>表是通过其他的表加工出来的（比如某个产品的销量指标表），为了理解这些加工好的数据，我们会比较关心它们的加工过程。数据血缘分析就可以帮助到我们，通过可视化的数据血缘关系图，可以很容易看到这些数据是通过什么数据加工出来的。</p>
<p><img data-src="/attaches/2021/2021-02-21-data-governance-based-on-atlas-ranger/atlas-data-linage.png" alt="Atlas data linage" /></p>
<p>目前<code>Atlas</code>的自动血缘分析功能还不够完善，比如，如果我们代码使用<code>Spark</code>编写的，<code>Atlas</code>就不能自动获取到数据数据血缘图了。不过，现在已有开源的<code>Atlas</code>的<code>Spark</code>插件出现了。目前在我们安装的<code>HDP</code>版本中的<code>Atlas</code>还未集成这个插件，如果要自行安装，还需要花费一定的精力。</p>
<p>除了上述搜索和血缘分析功能之外，<code>Atlas</code>还支持对数据进行分类。我们可以创建分类，然后在不同的元数据上打上分类标签。这里的分类非常有用，它不仅可以支持按照数据分类进行搜索，还可以与数据安全组件集成，以便可以根据分类来配置不同的数据安全策略。</p>
<p>前面提到的<code>Atlas</code>的功能都是基于技术元数据的，事实上，在数据平台建设过程中，我们还会很关心业务元数据。业务元数据是指从业务层面给数据加入的一些注解，比如某个数据应该具备什么样的值，有什么样的业务限制，与其他数据有什么关系，可以如何使用等等。新版本的<code>Atlas</code>加入了业务元数据管理的功能，可以支持用户自定义业务层面的信息，同时这些信息也可以用于搜索。</p>
<p>那么在实际使用过程中<code>Atlas</code>有什么问题呢？</p>
<p>我们遇到的一个比较让人烦恼的问题就是数据表的重建问题。比如，由于销售指标计算口径要进行修改，需要加入某个维度，比较方便的方式是直接将原来的表删除，然后新建一张表，但是如果我们这样做，<code>Atlas</code>里面的对应的元数据也会被同步删除，同时被删除的还有该数据表对应的分类信息，业务元数据信息等。这些信息都是人工添加的，一旦删除需要重新添加，这是非常麻烦是一件事。</p>
<p><img data-src="/attaches/2021/2021-02-21-data-governance-based-on-atlas-ranger/atlas-metadata-deletion.png" alt="Atlas data deleted" /></p>
<p>目前，为了保留<code>Atlas</code>中由手工添加的元数据，我们不得不禁止数据表的删除，所有的修改都需要通过修改表来实现。</p>
<p>总结起来，<code>Atlas</code>为我们提供了很多好用的元数据管理功能。由于<code>Atlas</code>可以免费获得，可以说它为企业数据治理之路做出了很大的贡献，这一切都要感谢开源！</p>
<h4 id="利用ranger进行数据安全管理"><a class="markdownIt-Anchor" href="#利用ranger进行数据安全管理"></a> 利用<code>Ranger</code>进行数据安全管理</h4>
<p>除了元数据管理，数据安全也是数据治理的极为重要的一环，基于<code>HDP</code>的大数据平台可以提供什么支持呢？</p>
<p>一般的数据安全管理通过一系列的安全策略来实现。一个通用的安全模型大概按照以下的方式运行：</p>
<ul>
<li>用户按照不同的部门或团队进行分组</li>
<li>将需要进行安全控制的系统资源（比如一张数据库表，一个文件等）进行id标记</li>
<li>针对用户或组配置安全策略，指明他们是否具备访问某一资源的权限</li>
<li>访问资源时根据配置的安全策略进行检查，如果通过即放行访问，否则拒绝访问</li>
</ul>
<p>在大数据场景下进行安全管理的挑战在于需要管理很多个不同的组件。<code>HDP</code>大数据平台集成了<code>Ranger</code>进行数据安全管理。</p>
<p><code>Ranger</code>是专门为了管理基于<code>Hadoop</code>的分布式环境下的数据安全而设计的。<code>Ranger</code>将上面的通用安全模型进行了抽象，这样一来，其他组件就可以很容易进行适配，从而集成到<code>Ranger</code>内部了。<code>Ranger</code>提供了一套插件机制来供其他组件进行集成，目前<code>Ranger</code>提供了广泛的组件支持，比如hdfs yarn <code>Hive</code> <code>Hbase</code> <code>Kafka</code> <code>Atlas</code>等等。几乎所有的<code>Hadoop</code>相关组件都可以在<code>Ranger</code>的web控制台上进行安全策略的配置。</p>
<p>比如，如果我们要控制hdfs目录<code>/test</code>的访问权限，使之仅可以让名为<code>test</code>的用户去访问。我们可以配置一条hdfs的安全策略如下：</p>
<p><img data-src="/attaches/2021/2021-02-21-data-governance-based-on-atlas-ranger/ranger-hdfs-policy.png" alt="Ranger hdfs policy" /></p>
<p>hdfs在进行安全策略配置时可以使用模糊匹配的方式指定文件或目录位置，每条策略可以支持配置多个模糊路径，从而可以降低配置的难度。</p>
<p><code>Ranger</code>对<code>Hive</code>的支持更加丰富，不仅可以支持表级权限控制，还可以支持列级、行级权限控制。有时我们会有数据脱敏访问的需求，在<code>Ranger</code>上我们还可以配置脱敏规则，包括使用内置规则或者自定义规则进行配置。如果配置了脱敏规则，用户在访问<code>Hive</code>时，<code>Hive</code>会通过<code>Ranger</code>插件查询这些规则，进而改写用户的查询语句，实现脱敏访问。</p>
<p>一个典型的脱敏策略及其应用效果如下：</p>
<p><img data-src="/attaches/2021/2021-02-21-data-governance-based-on-atlas-ranger/ranger-hive-masking-policy.png" alt="Ranger Hive masking policy" /></p>
<p>前面提到了<code>Atlas</code>和安全管理的集成，这是怎么回事呢？虽然<code>Ranger</code>已经提供了非常灵活的安全策略配置，但是配置这些策略本身其实是一件很复杂的事情。配置不好还特别容易出错。</p>
<p>举个例子，假如我们想要对用户的手机号进行脱敏。如果用户的手机号只存在一张表里面，那很简单，麻烦之处就在于手机号常常会分散到很多表里面。比如两个业务系统都保存了用户的手机号，那就至少会在两张表，同时我们常常还会有很多加工出来的表，这些表里面也会带入用户的手机号信息，这就带来更多的表了。如果我们要针对手机号配置脱敏规则，我们就可能需要添加很多个策略，复制粘贴不仅容易出错，而且非常不便于修改。</p>
<p><code>Ranger</code>可以和<code>Atlas</code>进行集成，从而使得我们在配置安全策略时可以针对数据分类来统一进行。比如，我们可以在<code>Atlas</code>中通过搜索找到所有的手机号字段，然后将这些字段都标记为手机号这个分类。然后，在<code>Ranger</code>里面，我们可以选择基于tag的权限配置，然后对这一类数据配置相同的访问权限或者脱敏规则。这是非常高效的配置安全策略的方式。下图是一个示例。</p>
<p><img data-src="/attaches/2021/2021-02-21-data-governance-based-on-atlas-ranger/ranger-tag-based-policy.png" alt="Ranger tag based policy" /></p>
<p>那么<code>Ranger</code>在使用过程中有什么问题呢？我们在实践过程中遇到过几个不太方便使用的问题。</p>
<p>一是<code>Ranger</code>的用户和组同步频率太低，最快只能配置一小时同步一次（<code>Ranger</code>的用户和组通常是同步至一个外部的企业账号中心，比如<code>Windows</code>平台常用的<code>Active Directory</code>活动目录域账户系统，开源的<code>OpenLDAP</code>轻量级目录服务，同步账号之后才可以对特定账号进行权限配置）。目前控制台上还没有手动同步的功能，如果需要手动同步，需要找到对应的同步类，然后执行<code>Java</code>程序进行调用，这不是很方便了。</p>
<p>另一个问题是，<code>Ranger</code>的权限配置默认打开了审计日志记录的功能，对于某些范围很广的资源进行权限配置时，如果没有关闭这个日志，将很快导致巨量的日志被系统记录下来，很容易造成磁盘空间被打满的问题。同时，<code>Ranger</code>还会将审计日志写入到<code>Solr</code>（日志搜索引擎），从而导致<code>Solr</code>的oom问题。我们在项目上为此花费了不少时间。</p>
<p>想要让<code>Ranger</code>可以支持安全管理功能，一个必备的前提是<code>Hadoop</code>集群本身是打开了<code>Kerberos</code>安全的集群。开启<code>Hadoop</code>集群安全可以通过<code>Ambari</code>界面操作进行一定的简化，但是依然可能碰到不少问题，这主要是由于<code>Kerberos</code>本身就是一个比较复杂的安全协议导致的。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>总结起来，在基于<code>HDP</code>的大数据平台下，我们可以选择不少功能强大的开源组件进行数据治理。有了这些软件支持，数据治理就可以不仅仅停留在制度上，更是可以通过软件系统来辅助进行治理。</p>
<p>数据治理是一个重要的数据管理话题，本文简要讨论了数据治理的目标以及实施方法。主要分享了当具体到大数据平台上面时，如何通过技术手段来保障数据治理的顺利进行。有了各种软件系统的辅助，企业数据治理的道路无疑少了很多阻碍。最后，如果大家有更多如何在数据平台上面进行数据治理的问题，欢迎留言交流。</p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>数据</tag>
        <tag>数据平台</tag>
        <tag>数据治理</tag>
      </tags>
  </entry>
  <entry>
    <title>数据平台数据接入实践</title>
    <url>/2021/03/01/data-ingestion-practice/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>快速、高质量、稳定的将数据从业务系统接入到数据平台是至关重要的一环。前面的文章中，我们分别提到了<a href="/2020/12/27/oracle-data-migration/">关系型数据库的数据接入</a>和<a href="/2021/02/22/data-ingestion-from-mongo/">非关系型数据库的数据接入</a>。除了来自技术上的挑战，数据接入还会遇到哪些其他挑战呢？</p>
<p>本文将尝试基于项目中的实践，给大家分享一下我们的思考。</p>
<p>一般而言，实施数据接入将可能碰到如下问题：</p>
<span id="more"></span>
<ul>
<li>数据源多种多样，常见的比如：各类关系型数据库、<code>NoSQL</code>数据库、日志数据等。如何处理这么多种类型的数据源？</li>
<li>数据接入的策略是什么样的？时机如何选择？频率如何确定？</li>
<li>数据接入不能对业务系统的稳定性产生影响，如何实现？</li>
<li>数据入库后，如何在数据仓库中进行存储和管理？</li>
<li>如何保证多张入库表的数据一致性？</li>
<li>如何和业务系统开发团队分工协作？</li>
</ul>
<p>下面将结合我们在项目中的实践，分享一下我们的思考。</p>
<h2 id="处理多种类型的数据源"><a class="markdownIt-Anchor" href="#处理多种类型的数据源"></a> 处理多种类型的数据源</h2>
<h3 id="关系型数据库数据接入"><a class="markdownIt-Anchor" href="#关系型数据库数据接入"></a> 关系型数据库数据接入</h3>
<p>我们先来看基于关系型数据库的数据源。关系型数据库类型多种多样，常见的如<code>MySQL</code> <code>Oracle</code> <code>SQL Server</code> <code>PostgreSQL</code>等等，如何支持这些数据库呢？</p>
<p>在大数据平台下，我们可以选择<code>Sqoop</code>或<code>Spark</code>的方案。得益于<code>Java</code>丰富的周边生态（<code>Java</code>语言提供了对于数据库访问的统一抽象<code>JDBC</code>，通过实现<code>JDBC</code>驱动器就实现使用统一的<code>JDBC</code> <code>API</code>访问数据，目前市面上几乎所有数据库都提供了驱动器实现），<code>Sqoop</code>和<code>Spark</code>都提供了完善的数据库类型支持。</p>
<p><code>Spark</code>和<code>Sqoop</code>起步都很早，但<code>Spark</code>定位是通用的计算引擎，比起<code>Sqoop</code>只是定位于<code>Hadoop</code>下的数据导入导出工具而言，<code>Spark</code>的功能要复杂和丰富得多。在技术选择上，<code>Sqoop</code>基于<code>MapReduce</code>计算引擎实现，<code>Spark</code>的数据导入导出功能基于自身计算引擎实现。近几年，<code>Spark</code>由于其灵活性、高性能及成熟稳定的功能，越来越成为大家首选的数据项目框架。</p>
<p>如果查看<code>Spark</code>和<code>Sqoop</code>的代码提交频率，即可看到在活跃度上<code>Spark</code>优于<code>Sqoop</code>很多。</p>
<p><img data-src="/attaches/2021/2021-03-01-data-ingestion-practice/sqoop-vs-spark.png" alt="spark-vs-sqoop" /></p>
<p>在功能性上，基于<code>Spark</code>的方案也不弱于<code>Sqoop</code>。</p>
<p><code>Sqoop</code>支持了常见的数据接入需要的功能，如根据查询条件进行数据选择、并发数量控制、读数据时的事务级别、数据类型转换、增量数据导入等。在导入目的地上，可以支持<code>Hive</code>、<code>HBase</code>、文件等。</p>
<p><code>Spark</code>同样可以支持这些功能，不过使用了<code>Spark</code>特有的术语，如：</p>
<ul>
<li>需要根据查询条件进行数据选择时，不仅可以在读取数据时，指定<code>query</code>参数，还可以在调用<code>load</code>得到<code>DataFrame</code>之后，使用<code>DataFrame</code>灵活的<code>API</code>进行数据筛选（<code>Spark</code>将在执行时可以通过谓词下推将查询条件放在数据库端执行）。</li>
<li>需要并发进行数据导入时，可以按照某个字段进行分区，并控制分区数量。</li>
<li>需要进行数据转换时，使用<code>DataFrame</code>灵活的<code>API</code>做起来更是得心应手。</li>
<li>进行增量数据导入时，可以根据元数据的特点灵活选择参考字段（如数据更新时间、<code>ID</code>等），通过编程方式指定查询条件来实现。</li>
<li>导入目的地的支持更是广泛，不仅拥有良好的<code>Hive</code>兼容性以便可以轻易将数据导入到<code>Hive</code>，还可以保存各类支持的文件。</li>
</ul>
<p>根据上面的分析及我们的实践经验，相比<code>Sqoop</code>，我们会更推荐<code>Spark</code>来完成数据接入。</p>
<h3 id="其他数据源数据接入"><a class="markdownIt-Anchor" href="#其他数据源数据接入"></a> 其他数据源数据接入</h3>
<p>对于非关系型数据库的数据接入，在前一篇文章（<a href="http://brightliao.com/2021/02/22/data-ingestion-from-mongo/">非关系型数据库的数据接入</a>）中我们进行了很多的讨论。</p>
<p>总结一下，对于无<code>schema</code>或者<code>schema</code>比较自由的数据库，有如下经验可能值得借鉴：</p>
<ul>
<li>考虑使用数据库自身提供的库来进行数据读取，避免直接使用<code>Spark</code>进行读取数据。这将很大程度上避免数据读取过程中的异常。</li>
<li>接入数据到数据平台时，考虑用<code>json</code>格式存储原始数据，这可以避免在接入数据时进行数据解析带来的问题，使得数据接入过程更稳定。</li>
</ul>
<p>对于其他基于文件的数据源，可以考虑的做法是先将文件复制到数据平台<code>HDFS</code>，然后用<code>Spark</code>读取<code>HDFS</code>中的文件，然后再写入<code>Hive</code>（或其他）数据仓库。</p>
<h2 id="数据接入策略"><a class="markdownIt-Anchor" href="#数据接入策略"></a> 数据接入策略</h2>
<p>数据接入可以简单的分为全量数据接入和增量数据接入。全量数据接入是指每天都将所有数据从业务系统复制到数据仓库，适合数据量比较小或者没有数据更新时间字段的数据表。增量数据接入是指每天将改变的数据接入到数据仓库，是最常见的数据接入方式。</p>
<p>一般而言，增量数据接入可以分为两个步骤完成：</p>
<ul>
<li>第一次全量数据接入。通过此步骤一次性将所有历史业务数据导入到数据平台。</li>
<li>增量数据接入。在第一次全量数据接入之后，每天业务系统的增量数据（新增或修改）导入到数据平台。</li>
</ul>
<p>听起来很简单，但是仔细分析一下，就会发现很多问题。</p>
<p>第一次全量数据接入需要应对所有历史数据，因此可能需要应对大数据量的问题。</p>
<p>后续增量数据接入需要注意数据接入的范围，通常是前一天所有的新增或修改的数据。这里面存在以下几个问题：</p>
<ul>
<li>如果数据接入的时间是凌晨1点，那么从0点到1点间可能有数据更新，这些数据如何入库呢？一般而言，可以选择<code>创建时间在昨天</code>或<code>更新时间在昨天</code>的数据进行接入，这样就可以包括从0点到1点间的所有更新。但同时这也有一个副作用，就是有可能包含第二天的某些更新的数据。比如，昨天创建了一条数据，今天0点30分做了数据更新，这条数据会同时存在于昨天和今天的接入数据中（数据重复入库）。</li>
<li>如果业务系统的数据里面没有标识创建时间的字段，但有标识更新时间的字段，此时可以选择<code>更新时间在昨天</code>的数据范围进行数据接入，同时避免了数据重复入库问题。</li>
<li>如果业务系统的数据里面既没有标识创建时间的字段也没有标识更新时间的字段，此时我们无法针对数据进行增量接入。此时应该考虑让业务系统做改进加入相关字段（针对大表），或者退化为每天做全量数据接入。</li>
<li>数据最好不要有删除的情况，这需要跟业务系统开发团队确认。如果存在数据删除，我们无法快速通过单表来找到被删除的数据（理论上可以实现，比如可以比对数据仓库中的所有数据业务主键与业务系统中的对应所有主键，但是技术实现上存在很大挑战）。此时可以让业务系统做改进，比如，将所有被删除数据的主键保存在另一张数据库表中。也可以考虑退化为使用全量接入的策略。</li>
</ul>
<p>除了上面提到的问题之外，还需要注意的问题是如何应对失败。比如，某一天，由于业务系统和数据平台网络断联，此时数据接入随之失败，如何恢复数据导入任务呢？</p>
<p>如果业务系统允许或者存在从库，则可以随时重新触发任务。越早触发任务，丢失的数据更新越少。如果业务系统只允许在系统闲时进行数据接入，则只能在下一个可接入数据的时段重新触发前一天的数据接入任务。</p>
<p>从数据接入频率来看，目前多是<code>T+1</code>的方式，即每天定时数据接入。这样的数据接入频率一般可以保证第二天可以看前一天的数据。</p>
<h2 id="数据接入对业务系统的影响"><a class="markdownIt-Anchor" href="#数据接入对业务系统的影响"></a> 数据接入对业务系统的影响</h2>
<p>在多数业务相对单一的互联网公司构建数据平台时，这个问题可能并不是一个值得关注的问题。</p>
<p>但是，对于很多相对传统的企业，他们通常拥有很多业务系统，不少系统可能开发于一二十年前并经过了长时间的逐步迭代，不同的系统可能由不同的供应商开发而成，不同的系统可能需要支持不同的业务线。基于这样的现实情况，谈论数据接入对业务系统的影响就显得很有必要，因为：</p>
<ul>
<li>业务系统可能还没实现读写分离，因此没有只读的从数据库</li>
<li>业务系统可能需要支持某个关键的业务线，需要24小时在线</li>
</ul>
<h3 id="仔细设计方案小心导入数据"><a class="markdownIt-Anchor" href="#仔细设计方案小心导入数据"></a> 仔细设计方案，小心导入数据</h3>
<p>数据接入的一个重要目标是在尽量降低对业务系统影响的情况下完成。对于没有只读从库的业务系统，如何实现这一点呢？下面尝试对不同的数据接入任务进行分析。</p>
<p>全量数据接入时，由于需要应对所有历史数据，此时的数据量可能会非常大。我们在进行这一步时，通常要面对的是数千万行数亿行，数十到数百GB的数据。进行如此大量的数据传输，需要仔细设计方案。通常可以参考如下步骤完成：</p>
<ul>
<li>在业务系统中统计数据量大小，包括数据行数，数据文件大小等。很多数据库都支持统计信息查询，比如<code>Oracle</code>下执行查询<code>SELECT segment_name, bytes/1048576 FROM DBA_SEGMENTS WHERE segment_name='table name' AND segment_type='TABLE'</code>可得到数据大小</li>
<li>测试数据平台和业务系统之间的网络带宽，根据网络带宽预估两个系统间数据传输的时间</li>
<li>根据数据传输时间预估，制定数据传输计划，包括每个待接入数据库表的计划接入时间，接入失败的处理方式，超时的处理方式等</li>
<li>根据数据导入计划，与业务系统开发团队商定一个合适的时间进行数据导入（通常可以安排在周末或者夜间系统闲时）</li>
<li>按照数据导入计划进行执行，并处理数据导入过程中的各种异常情况</li>
</ul>
<p>增量数据接入时，面对的数据量通常比较小，此时和业务系统商定一个合适的时间进行数据导入即可。</p>
<p>除了以上问题，还需要考虑数据读取的并发数，如果并发太高，可能给业务系统造成很大压力。通常业务系统会控制数据库最大连接数，这也给数据接入时的并发数设置了限制。一般而言，并发数并不会成为数据接入速度的瓶颈，最大的瓶颈常常来自网络带宽。我们通常可以采用较小的并发数读取数据，通过设置<code>Spark</code>的<code>numPartitions</code>参数可以达到控制并发数的目的。</p>
<h3 id="尝试自建从数据库"><a class="markdownIt-Anchor" href="#尝试自建从数据库"></a> 尝试自建从数据库</h3>
<p>另一个值得借鉴的做法是，在数据平台搭建一个跟业务系统数据库同样的数据库（可视为帮助业务系统建立了一个只为数据接入使用的从数据库，下文直接称从库），用以辅助进行数据导入。这可以带来以下几个好处：</p>
<ul>
<li>数据导入更稳定和高效。可以先使用业务数据库本身提供的数据导入导出工具将业务数据库的数据导入到从库，这一步一般可以非常稳定而高效。</li>
<li>可以无忧的使用<code>Spark</code>（或其他工具）将数据从从库接入到数据平台。因为是从从库进行数据读取，所以根本无需考虑并发读数据对业务系统的影响，也无需考虑数据读取的时间。</li>
<li>可以辅助开发数据接入代码。因为对业务系统无影响，所以我们完全可以在这个数据库上面进行参数的调整和测试，无需担心对业务的影响。</li>
</ul>
<p>在我们的项目实践中，针对没有从库的<code>Oracle</code>业务系统数据库，我们用docker搭建了一个<code>Oracle</code>数据库用于充当业务系统数据库的从库，大大提高了数据接入的稳定性和开发效率。</p>
<p>在导入数据到从库时，可以忽略索引，这可以有效减少数据库需要使用的存储空间，也可以加快数据导入的速度。</p>
<p>在增量数据接入时，我们可以考虑新建一张数据库表来存储数据，并且只存储增量的数据，此时不仅可以大大减小数据量从而加快数据接入的过程，还可以用于应对潜在的数据<code>Schema</code>变更。</p>
<h2 id="在数据仓库中进行数据存储和管理"><a class="markdownIt-Anchor" href="#在数据仓库中进行数据存储和管理"></a> 在数据仓库中进行数据存储和管理</h2>
<p>现在我们应该可以顺利把数据导入到数据平台了，那么导入的数据要怎么存储和管理呢？首先要找个地方存，那就是数据仓库（Data Warehouse，简称<code>DW</code>）了，通常以<code>Hive</code>数据库来实现。数据平台可以视为以数据仓库为中心存储的平台。</p>
<h3 id="设计贴源层"><a class="markdownIt-Anchor" href="#设计贴源层"></a> 设计贴源层</h3>
<p>很多数据仓库建设的文章中都会建议我们设计一个专门用于存储业务系统数据的层，名为贴源层，或<code>ODS</code>（Operational Data Store）层。贴源层的数据需要保持和业务系统一致，不做任何的加工。</p>
<p>设计贴源层的好处是：</p>
<ul>
<li>这一层的逻辑比较简单，通常稳定性可以得到保证。</li>
<li>贴源层保存了所有的业务系统数据，因为原始数据始终存在，所以上层可以随时进行数据查询，这带来了很大的灵活性。</li>
<li>拥有随时可查询的数据，可以很好的支持上层数据开发过程中的代码调试。</li>
<li>当我们发现上层的数据处理逻辑需要修改时，可以更从容的完成，无需考虑数据任务运行的时间及对业务系统带来的影响。</li>
</ul>
<p>我们也同样建议设计一个贴源层用于存储来自业务系统的原始数据。相比多增加一层带来的数据存储成本，其优势非常明显。</p>
<h3 id="设计分区字段"><a class="markdownIt-Anchor" href="#设计分区字段"></a> 设计分区字段</h3>
<p>如何存储数据呢？<code>Hive</code>数据库支持分区表，可以为数据存储提供支持。</p>
<p>简单来说，我们可以为所有业务系统的表增加设计一个分区字段用于存储当次接入的数据。此字段可以为整型或字符串类型，其值为数据更新时间。</p>
<p>如果按天进行数据接入，则存储数据更新的当天，比如可以存储为<code>20210520</code>。如果更频繁的每小时进行数据接入，可以将此分区字段的值扩展支持小时即可。需要注意的是，这里的分区字段值最好和数据更新时间对齐，这可以大大方便后续团队成员理解数据、查询数据，从而避免潜在出问题的风险。</p>
<p>分区字段可以很好的应对全量数据接入和增量数据接入的策略。增量的情况下需要注意，<strong>第一个分区为全量数据分区，通常数据量会特别大，而且数据没有历史</strong>。后续所有更上层的数据加工都要基于这个基本认识，比如：</p>
<ul>
<li>在进行数据处理时，如果涉及全量分区，可能要配置更多的计算资源。</li>
<li>处理包含全量分区的数据时，需要考虑数据倾斜的问题，可能会由于第一个分区太大影响整个数据任务执行时间。</li>
<li>进行表间数据关联时，如果当前数据分区的时间早于关联表的数据分区时间，则应该关联到关联表的全量数据分区中的数据。</li>
</ul>
<h2 id="多张表入库时的数据一致性"><a class="markdownIt-Anchor" href="#多张表入库时的数据一致性"></a> 多张表入库时的数据一致性</h2>
<p>由于数据接入的过程常常会涉及多张数据库表的数据读取，那么一个很自然的问题是，数据一致性如何保证？</p>
<p>这是一个数据仓库实现的难点，有很多种情况可以影响数据一致性，比如：</p>
<ul>
<li>多张数据库表读数据的时间很可能不一样</li>
<li>大量多表数据读取需要较长的读数据时间，难以在一个数据库事务内完成</li>
<li>数据库配置的事务隔离级别不够，可能导致读到脏数据</li>
</ul>
<h3 id="数据分析对一致性的要求"><a class="markdownIt-Anchor" href="#数据分析对一致性的要求"></a> 数据分析对一致性的要求</h3>
<p>在实际的数据仓库建设过程中，由于数据一致性难以保证，我们常常会一定程度上忽略数据强一致性。这可能带来轻微的数据不准确问题，一般而言，这不会带来太大的问题。因为数据平台是主要是为了支持数据分析，而分析常常是统计意义上的结果，所以统计上不会由于有很小的偏差而带来大的影响。这些统计结果一般也是为支持公司决策，公司决策自然也不会轻易受到某一个数值的微小变化的影响。比如，公司的产品销量分析，即便有几笔订单由于数据不一致没有统计到最终的销量中，一般也不会带来太大影响。</p>
<p>虽然多数情况下的数据分析对数据一致性不太敏感，但是还是存在很多对数据准确性要求很高的场景。比如：</p>
<ul>
<li>考虑大宗商品的销售，如果少统计了一个订单，可能带来统计值的较大偏差</li>
<li>考虑零售的场景，如果经销商可以根据销量等级的不同而获得厂家的不同补贴，这时，即便一个订单也不允许统计出错，因为这会影响到经销商的收益</li>
</ul>
<h3 id="应对强一致性要求"><a class="markdownIt-Anchor" href="#应对强一致性要求"></a> 应对强一致性要求</h3>
<p>对于这类对数据一致性很敏感的场景需要如何处理呢？这里有一些建议。</p>
<p>一是可以尝试在一个数据库事务中读取所有相关表的数据。如果数据源对应的数据量较小，特别是对于增量数据读取，也是具备较高的可行性的。</p>
<p>二是可以配合业务系统一起实现高一致性的数据入库。如果有来自业务系统的配合，一致性相对更容易实现。比如，如果业务系统允许每晚停止服务（或停止数据修改，只允许读数据的业务）一段时间，则可以在停止服务（或只读）时进行数据接入。</p>
<p>三是可以提供补数据的机制。比如，如果我们发现某些统计指标与实际的相差几个数，可以提供一个流程来补充没统计到的数据。简单来说，这可以通过：1. 相关人员进行邮件确认；2. 在计算出来的统计值上面进行最终结果调整。当然，如果有比较充足的时间，也可以实现一个支持系统用于辅助实现这个流程。</p>
<p>总之，要实现更强的数据一致性，所需的成本也是更高的。好的一点在于，在实践过程中，我们常常不需要这样强的数据一致性。当需要保证很强的数据一致性时，可能需要综合具体情况来判断什么样的处理方式是更好的。</p>
<h2 id="和业务系统开发团队分工协作"><a class="markdownIt-Anchor" href="#和业务系统开发团队分工协作"></a> 和业务系统开发团队分工协作</h2>
<p>上面谈了很多关于如何接入数据，如何在数据仓库中存储数据的经验，其中很多都是基于一个基本假设，那就是这些工作是由一个独立的数据平台团队来完成。有的同学可能会有一个疑惑，为什么数据接入这件事是数据平台团队来做？是不是可以直接交给业务团队来做？业务团队来做这件事不是更容易吗？</p>
<h3 id="企业组织结构和团队分工"><a class="markdownIt-Anchor" href="#企业组织结构和团队分工"></a> 企业组织结构和团队分工</h3>
<p>这涉及到企业组织结构和团队分工的问题，实际情况常常十分复杂，每个企业都可能根据自身实际情况不同而不同。</p>
<p>一般而言，实际情况常常是由一个独立的数据团队来负责此类工作。原因在于：</p>
<ul>
<li>业务系统开发团队会更专注在自身业务功能的开发，对于数据的关注不足</li>
<li>业务系统开发团队具备的数据相关专业能力（包括工程能力、技术能力等）相对较弱，而数据平台建设需要较强的此类能力</li>
<li>业务系统开发团队本身可能已经是一个大的团队，如果加入更多的团队角色，将进一步增加团队大小而带来团队管理问题</li>
</ul>
<p>如果说企业的数据平台建设已经比较完善，或者企业内部的IT技术能力较强，则情况可能不一样。在一些大型的以软件技术为核心的企业，比如一些大型的商业银行，他们的情况可能是这样：</p>
<ul>
<li>可能已经建设了一个独立的数据团队，负责提供各类数据工具给各个业务系统开发团队使用</li>
<li>软件基础设施可能已经比较完备，数据接入已经有完善的内部系统做支持</li>
<li>可能有较好的培训体系，可以通过培训来提升业务系统开发团队的数据意识和数据专业能力</li>
</ul>
<p>此时，业务系统开发团队可能只需要通过简单的几步操作即可实现数据接入数据平台。如果是这样，通常不仅数据接入可以交给业务系统团队自己完成，甚至上层的数据开发、报表展示等工作也可以由业务系统团队完成。数据团队在此时的工作重点会变为：</p>
<ul>
<li>为业务系统团队开发各类数据工具或系统</li>
<li>提供技术支持和咨询服务</li>
<li>提供培训服务</li>
</ul>
<p>所以，如果我们考虑数据团队的组织和分工，不同企业可能大不一样，但是可能又都是适合企业实际情况的。</p>
<h3 id="缓解两个团队间的矛盾"><a class="markdownIt-Anchor" href="#缓解两个团队间的矛盾"></a> 缓解两个团队间的矛盾</h3>
<p>如果是由一个独立的数据团队去完成数据接入以及后续的数据加工处理、指标计算等工作，这常常会带来一个问题，那就是需要和业务系统团队较为紧密的协作。这样的协作常常不够顺畅，为什么呢？究其原因，两个团队没有共享同一个目标。数据团队一般基于各业务系统的数据，计算指标，输出报表，或者建立机器学习模型进行业务分析等。其目标是支持业务分析或支持决策。而业务系统团队的目标是开发新功能，维护系统稳定，支持业务运转。</p>
<p>目标不一致会带来很多问题。比如，数据团队觉得优先级高的事情，在业务系统团队看来优先级很低。更具体一点的例子是，如果业务系统中没有数据删除，那么数据接入就可以较容易的实现，但要使得业务系统保留所有数据，这给业务系统的开发带来了更多的看起来没必要的麻烦。</p>
<p>如何缓解两个团队的矛盾呢？一般情况下，可能需要数据团队做出一定让步，因为在数据的价值还没有体现出来时，从企业角度来看，我们需要优先保证业务的正常运转。然后，在此基础上，数据团队可以引导业务系统团队人员进行数据消费，帮助他们认识数据对他们的价值。包括：</p>
<ul>
<li>给业务系统团队人员培训数据相关的知识和技能</li>
<li>将加工出来的数据给到业务系统团队进行分析</li>
<li>引导业务系统团队进行跟自己业务相关的简单的数据分析，帮忙他们通过数据改进自身业务</li>
</ul>
<p>总体上看，要想两个团队能友好的高效的合作，还需要双方求同存异，共同为企业大的目标一起努力才行。这可能需要更多的企业文化建设工作。</p>
<h2 id="其他问题"><a class="markdownIt-Anchor" href="#其他问题"></a> 其他问题</h2>
<p>数据接入的过程中常常还会伴随很多其他问题，这里列举一些比较典型的问题，与大家一起讨论。</p>
<h3 id="业务系统提供专用接口进行数据接入"><a class="markdownIt-Anchor" href="#业务系统提供专用接口进行数据接入"></a> 业务系统提供专用接口进行数据接入</h3>
<p>我们在进行数据接入的时候，业务系统团队担心他们数据库变更对数据平台造成影响，可能会建议由他们提供<code>API</code>进行数据查询，而不是直接提供数据库访问接口。</p>
<p>在我们看来，由业务系统开发<code>API</code>进行数据导出并不是一种好的方式。主要理由是：</p>
<ul>
<li>会给业务系统团队带来额外的开发和维护成本</li>
<li>增加了两个团队沟通协作成本（需要讨论<code>API</code>（或数据导出任务）形式，进行联调等）</li>
<li>数据团队需要等待业务系统团队进行<code>API</code>（或数据导出任务）开发和上线，效率较低</li>
<li>添加新数据效率低。如果发现之前的<code>API</code>（或数据导出任务）中的数据不能满足分析需要，则需要和业务系统团队重新沟通<code>API</code>（或数据导出任务）设计，然后交由业务系统团队开发、测试、上线，整个周期特别长</li>
</ul>
<p>当然，通过开发<code>API</code>（或数据导出任务）的方式进行数据对接也有其好处，那就是两个系统间的接口相对稳定。但是相比其带来的成本而言，这个优势显得不够明显。</p>
<h3 id="业务系统开发导出数据的任务"><a class="markdownIt-Anchor" href="#业务系统开发导出数据的任务"></a> 业务系统开发导出数据的任务</h3>
<p>比开发特定<code>API</code>接口进行数据对接要更好一些的是，业务系统可以开发数据导出任务，定期运行此任务导出数据。这会给业务系统团队带来一定的开发成本，但是不失为一种保障业务系统稳定运行的好的方式。</p>
<p>此时，我们会建议使用强类型的专用的数据导出格式，而不是基于<code>csv</code>。比如，如果业务系统数据库是<code>MySQL</code>，则考虑使用<code>mysqldump</code>工具进行数据导出。如果是<code>Oracle</code>，则考虑使用<code>exp</code>/<code>expdp</code>工具。如果是<code>MongoDB</code>，使用<code>mongodump</code>。</p>
<p>使用专用的数据导出格式的好处是：</p>
<ul>
<li>几乎不需要业务系统团队编写代码就可以实现数据导出</li>
<li>数据导出速度通常最快且最稳定</li>
<li>数据可以很容易的导入到跟源系统同样版本的数据库中</li>
</ul>
<p>如果使用某种中间格式，比如<code>csv</code>，其问题在于：</p>
<ul>
<li>需要增加不少额外的开发成本</li>
<li><code>csv</code>会丢失数据类型，比如在<code>csv</code>文件中，对于整型数值、浮点型数值和字符串的区分比较困难，这将带来额外的无必要的数据平台数据接入逻辑</li>
<li><code>csv</code>在处理空字符串、<code>null</code>值、换行符等特殊值时存在问题，在处理一些不可见的二进制特殊字符也会存在问题，需要在数据接入时做更多的容错处理</li>
<li><code>csv</code>可能带来列错位的问题</li>
</ul>
<p>在实际的项目实践过程中，我们耗费了很大的精力在应对<code>csv</code>格式的数据接入这件事上，最后的结果也不尽如人意。所以，一般而言，我们会强烈建议避免使用中间文件格式进行数据接入。</p>
<p>虽然开发数据导出任务进行数据接入这种方式看起来不错，但是综合起来看，更为推荐的方式还是直接进行数据库对接，比如：</p>
<ul>
<li>由业务系统团队建立从数据库用于各类数据同步和分析，数据接入通过从数据库完成。</li>
<li>以只读账号直接连接业务系统生产数据库，在系统闲时进行数据访问。</li>
</ul>
<h3 id="标准化的数据接入工具是否有必要"><a class="markdownIt-Anchor" href="#标准化的数据接入工具是否有必要"></a> 标准化的数据接入工具是否有必要</h3>
<p>当前很多云服务提供商也发布了很多相关的数据接入软件，使用这些软件，通常只需要简单的配置即可实现数据接入其云上的数据平台。那么我们是否可以从这样的工具或服务中受益呢？</p>
<p>现在的市场上有大量类似的数据产品存在，但是，事实上通常这种数据产品在很多企业中难以落地实施。经过上面的分析，可以知道，很多情况下，数据接入这个问题并不是技术上可以直接解决的。</p>
<p>这里面涉及：</p>
<ul>
<li>网络传输问题。比如，业务系统可能并不在云上，或者并不在当前云服务提供商的云上。还比如，可能业务系统的数据量太大，传输很慢。</li>
<li>数据安全问题。很多企业会担心数据上云之后带来更大的数据安全风险。</li>
<li>沟通协作问题。根据上面的分析，对于数据接入工作，有很多的时间都花在了团队协作上，这是工具不能解决的问题。</li>
<li>工具灵活性问题。业务系统数据库可能多种多样，这些数据产品是否可以支持这么多类型的数据库？是否支持足够好？如果我们想要定义数据接入的分区字段的值，是否可以很容易的实现？</li>
</ul>
<p>综合以上这些因素考虑，我们不应该被一个看起来很好用的数据接入<code>UI</code>界面所迷惑，而是应该立足企业具体情况，根据情况选择更合适的方式。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>本文从数据接入策略开始，依次讨论了数据接入对业务系统的影响，数据应该如何在数据仓库中存储，接入的数据的一致性，团队组织和分工等问题。其中，分享了很多来自我们的真实项目实践中的经验。</p>
<p>数据接入到数据平台是数据平台构建的第一步，也是极为关键的一步。在实际项目过程中，我们常常需要花费大量的时间在这一步上。为了应对各种数据接入的挑战，我们需要保持清晰的认知，综合考虑各类因素，以便找出最优的解决办法。</p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>数据平台</tag>
        <tag>数据接入</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle数据迁移实用入门</title>
    <url>/2020/12/27/oracle-data-migration/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>在一个大型企业中做数据工作，难免要跟各种不同种类的数据库打交道。Oracle，凭借其优异的性能，曾经是很多大型企业标配商业数据库，自然也是我们要重点应对的一种数据库。</p>
<p>Oracle的数据导入导出是一项基本的技能，但是对于懂数据库却不熟悉Oracle的同学可能会有一定的障碍。正好在最近的一个项目中碰到了这样一个任务，于是研究了一下Oracle的数据导入导出，在这里跟大家分享一下。</p>
<span id="more"></span>
<p>（本文以下内容假设大家熟悉Mysql PostgreSQL等常见的其他数据库，但是不了解Oracle）</p>
<h2 id="oracle的一些基本内容"><a class="markdownIt-Anchor" href="#oracle的一些基本内容"></a> Oracle的一些基本内容</h2>
<h3 id="表空间tablespace"><a class="markdownIt-Anchor" href="#表空间tablespace"></a> 表空间TableSpace</h3>
<p>Oracle被设计用于管理大量的数据，当一些数据库的数据量太大，以至于一块磁盘存不下的时候该怎么办呢？</p>
<p>Oracle设计了表空间来应对这个问题，一个数据库可以包含多个表空间，一个表空间可以对应多个数据文件，而一张数据库表可以属于某一个表空间。这样一来，我们可以在不同的磁盘上面创建表空间，从而可以方便的用多块磁盘来存放数据了。这几个概念可以图示如下：</p>
<p><img data-src="/attaches/2020/2020-12-27-oracle-data-migration/tablespace.png" alt="tablespace" /></p>
<p>当然，表空间的意义远不止于解决多磁盘的问题，表空间其实是Oracle中的非常开创性的设计，它还可以应用于解决下面这些问题：</p>
<ul>
<li>控制用户所能占用的空间配额</li>
<li>控制数据库所占用的磁盘空间</li>
<li>提高数据读写性能</li>
<li>提高数据安全性</li>
</ul>
<p>对于一个大型数据库的数据导入导出工作，首先要做的一件事就是根据数据量大小来合理的规划表空间。</p>
<h3 id="用户user与模式schema"><a class="markdownIt-Anchor" href="#用户user与模式schema"></a> 用户(User)与模式(Schema)</h3>
<p>Oracle中的用户概念与其他数据库一致，都是用来连接数据库进行操作的。而Schema也与其他数据库中的schema概念一样，是一个数据表及其他对象的集合，用于进行统一管理。</p>
<p>但是Oracle中有一些特别的地方。在Oracle中，我们无法直接创建一个schema。当我们创建user的时候，会创建一个与此user同名的schema。这一点与其他数据库很不一样，需要注意。</p>
<p>虽然如此，通过授权还是可以实现一个用户访问另一个用户的schema。</p>
<h3 id="数据导入导出工具"><a class="markdownIt-Anchor" href="#数据导入导出工具"></a> 数据导入导出工具</h3>
<p>参考官方的<a href="https://docs.oracle.com/cd/E17781_01/server.112/e18804/impexp.htm#ADMQS258">文档</a>可知，如果是从oracle到oracle进行数据导入导出，我们可以使用<code>Data Pump Export/Import</code>工具，也可以使用<code>Export and Import Utilities</code>工具进行数据导入导出。</p>
<p><code>Data Pump</code>工具对应的命令行工具是<code>expdp/impdp</code>，其优势是速度快，但是使用上略显复杂（请参考后续实操部分）。</p>
<p><code>Export and Import Utilities</code>工具对应的命令行工具是<code>exp/imp</code>，速度比<code>Data Pump</code>慢，官方更推荐使用<code>Data Pump</code>工具，但是这组工具使用上却更为简单。</p>
<p>如果是将Oracle数据同步到其他数据库或者基于hadoop的数据湖，则可以考虑使用数据平台常用的数据迁移工具<code>sqoop</code>，或者编写<code>spark</code>程序做数据导入导出。</p>
<h3 id="字符集"><a class="markdownIt-Anchor" href="#字符集"></a> 字符集</h3>
<p>Oracle支持多种字符集，这样一来，在数据导入导出的时候就需要关注字符集的转换，否则将可能出现乱码问题。</p>
<p>好在Oracle数据库足够聪明，内置了完善的字符集支持，可以自动完成大部分的字符集转换工作，尽量做到用户无感知。</p>
<p>在Oracle对Oracle的数据导入导出的过程中，将涉及到四处字符集：</p>
<ul>
<li>源数据库字符集</li>
<li>Export过程中用户会话字符集（通过NLS_LANG环境变量设定）</li>
<li>Import过程中用户会话字符集（通过NLS_LANG环境变量设定）</li>
<li>目标数据库字符集</li>
</ul>
<p>这四处字符集分别对应到数据导入导出的各个步骤，在执行某一个特定步骤时，<code>expdp/impdp</code>或<code>exp/imp</code>工具都可以自动的进行字符集转换。但是由于字符集情况比较复杂，事实上这类自动转换也不能完全处理所有情况。</p>
<p>比如，从GBK的数据库导入UTF8的数据库，导出的文件中的建表语句为<code>..., some_column VARCHAR(100), ...</code>时，导入过程可能发生错误数据长度过长(<code>Value too long</code>)的错误。此时需要手动修改建表语句，将上述字段改为<code>..., some_column VARCHAR(100 CHAR), ...</code>，以便以宽字节的方式来定义列长度。</p>
<h2 id="实操练习"><a class="markdownIt-Anchor" href="#实操练习"></a> 实操练习</h2>
<p>下面，为了打通整个数据导入导出流程，我们来完成一个数据导入导出的小练习。</p>
<p>我们将完成以下的任务：</p>
<ol>
<li>构建一个oracle环境</li>
<li>生成数据并测试数据导入导出</li>
<li>比较<code>expdp/impdp</code>和<code>exp/imp</code>工具的性能</li>
<li>用sqoop连接oracle数据库进行数据同步</li>
<li>用spark连接oracle数据库进行数据同步</li>
</ol>
<h3 id="构建oracle环境"><a class="markdownIt-Anchor" href="#构建oracle环境"></a> 构建oracle环境</h3>
<p>oracle虽然是商业数据库，但是甲骨文公司为了降低其学习成本，发布了多个版本，其中的Express版本可以免费用于进行学习。虽然Express版本限制了数据库能使用的核数及数据文件的大小，但是用于完成我们的练习足够了。</p>
<p>如何构建一个oracle环境呢？当然最好使用docker了。恰好Oracle官方开源了对应的dockerfile，我们可以用它来快速构建一个镜像。</p>
<p>下面我们使用11g版本的oracle来完成此练习。</p>
<h4 id="制作镜像"><a class="markdownIt-Anchor" href="#制作镜像"></a> 制作镜像</h4>
<p>参考下面的命令可以完成镜像制作，并启动一个测试的oracle数据库。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> <span class="built_in">test</span></span><br><span class="line"><span class="built_in">cd</span> <span class="built_in">test</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/oracle/docker-images.git</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载 【Oracle Database 11g Release 2 Express Edition for Linux x86 and Windows】 https://www.oracle.com/in/database/technologies/oracle-database-software-downloads.html</span></span><br><span class="line"><span class="built_in">mv</span> oracle-xe-11.2.0-1.0.x86_64.rpm.zip docker-images/OracleDatabase/SingleInstance/dockerfiles/11.2.0.2/</span><br><span class="line"><span class="built_in">cd</span> docker-images/OracleDatabase/SingleInstance/dockerfiles/</span><br><span class="line">bash buildDockerImage.sh -v 11.2.0.2 -x</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> -</span><br><span class="line"><span class="built_in">mkdir</span> data</span><br><span class="line"></span><br><span class="line">docker run -d --name test-oracle \</span><br><span class="line">    -p 21521:1521 -p 25500:5500 \</span><br><span class="line">    --shm-size=<span class="string">&quot;2g&quot;</span> \</span><br><span class="line">    -v `<span class="built_in">pwd</span>`/data:/opt/oracle/oradata \</span><br><span class="line">    oracle/database:11.2.0.2-xe</span><br><span class="line"><span class="comment"># 以上命令shm-size是必须要指定的，否则将报错内存不足</span></span><br></pre></td></tr></table></figure>
<p>在启动容器时，系统将生成一个随机，通过查看容器运行日志可以找到此密码。</p>
<p>运行<code>docker logs test-oracle</code>可以看到我们的密码是<code>system/xxx</code></p>
<h4 id="连接数据库进行操作"><a class="markdownIt-Anchor" href="#连接数据库进行操作"></a> 连接数据库进行操作</h4>
<p>在命令行中连接oracle需要使用sqlplus工具，这个工具在容器中已经安装好了。如果想通过其他的主机连接oracle实例，sqlplus也提供了一个纯客户端版本。关于sqlplus的更多信息可以参考官方<a href="https://docs.oracle.com/cd/B19306_01/server.102/b14357/qstart.htm">文档</a>。</p>
<p>下面的命令可以连接到oracle并执行命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 激活默认生成的[HR用户](https://docs.oracle.com/cd/B13789_01/server.101/b10771/scripts003.htm)</span></span><br><span class="line">sqlplus system/xxx@localhost</span><br><span class="line">&gt; ALTER USER hr IDENTIFIED BY hr;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成一些测试数据</span></span><br><span class="line">sqlplus hr/hr@localhost</span><br><span class="line">&gt; create table <span class="built_in">test</span>(<span class="built_in">id</span> int, val varchar(200));</span><br><span class="line">&gt; insert into <span class="built_in">test</span>(<span class="built_in">id</span>, val) values (1, <span class="string">&#x27;1&#x27;</span>);</span><br><span class="line">&gt; insert into <span class="built_in">test</span>(<span class="built_in">id</span>, val) values (2, <span class="string">&#x27;2&#x27;</span>);</span><br></pre></td></tr></table></figure>
<h3 id="生成数据并测试数据导入导出"><a class="markdownIt-Anchor" href="#生成数据并测试数据导入导出"></a> 生成数据并测试数据导入导出</h3>
<p>下面我们将生成一些测试数据，并测试数据导入导出。</p>
<p>为了简单，我们就用刚刚生成的<code>hr.test</code>表。并创建一个<code>hrdev</code>用户用于数据导入。</p>
<h4 id="创建hrdev用户并配置权限"><a class="markdownIt-Anchor" href="#创建hrdev用户并配置权限"></a> 创建hrdev用户并配置权限</h4>
<p>使用下面的命令可以完成此操作。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sqlplus system/xxx@localhost</span><br><span class="line">&gt; CREATE USER hrdev IDENTIFIED BY hrdev;</span><br><span class="line">&gt; ALTER USER hrdev IDENTIFIED BY hrdev;</span><br><span class="line">&gt; GRANT READ,WRITE ON DIRECTORY dmpdir TO hrdev;</span><br><span class="line">&gt; GRANT CREATE TABLE TO hrdev;</span><br><span class="line">&gt; grant create session,resource to hrdev; -- 如果没有这一步，无法通过sqlplus连接</span><br><span class="line">&gt; grant imp_full_database to hrdev; -- 如果没有这一步，报错 ORA-31655: no data or metadata objects selected <span class="keyword">for</span> job</span><br></pre></td></tr></table></figure>
<h4 id="创建目录并配置权限"><a class="markdownIt-Anchor" href="#创建目录并配置权限"></a> 创建目录并配置权限</h4>
<p>通过<code>expdp -help</code>查看<code>expdp</code>的使用帮助可以看到，我们需要指定一个<code>DIRECTORY</code>才能进行数据导出。<code>DIRECTORY</code>在Oracle中是一个特殊的对象，是指映射到磁盘文件中的某个目录。用户还需要具有某个<code>DIRECTORY</code>对象的权限才能进行数据导入导出，因此还要完成相应的授权。</p>
<p>使用<code>exp/imp</code>工具则无需创建<code>DIRECTORY</code>对象，也无需相应的授权，故要简单不少。</p>
<p>通过以下命令可以创建一个目录并配置好权限。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /tmp/test</span><br><span class="line">sqlplus system/xxx@localhost</span><br><span class="line">&gt; CREATE OR REPLACE DIRECTORY dmpdir AS <span class="string">&#x27;/tmp/test&#x27;</span>;</span><br><span class="line">&gt; GRANT READ,WRITE ON DIRECTORY dmpdir TO hr;</span><br><span class="line">&gt; ALTER USER hr IDENTIFIED BY hr;</span><br></pre></td></tr></table></figure>
<h4 id="使用expdpimpdp进行数据迁移并验证迁移结果"><a class="markdownIt-Anchor" href="#使用expdpimpdp进行数据迁移并验证迁移结果"></a> 使用<code>expdp/impdp</code>进行数据迁移并验证迁移结果</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 用expdp导出数据（仅test表）</span></span><br><span class="line">expdp hr/hr TABLES=<span class="string">&quot;(test)&quot;</span> DIRECTORY=dmpdir DUMPFILE=schema.dmp LOGFILE=expschema.log</span><br><span class="line"><span class="comment"># 用impdp导入数据</span></span><br><span class="line">impdp hrdev/hrdev REMAP_SCHEMA=hr:hrdev \</span><br><span class="line">    INCLUDE=TABLE TABLE_EXISTS_ACTION=replace \</span><br><span class="line">    DIRECTORY=dmpdir DUMPFILE=schema.dmp LOGFILE=impschema.log</span><br></pre></td></tr></table></figure>
<p>通过读取数据表<code>hrdev.test</code>的数据可以查看数据导入是否成功。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sqlplus hrdev/hrdev@localhost</span><br><span class="line">&gt; SELECT owner, table_name, tablespace_name FROM all_tables <span class="built_in">where</span> owner=<span class="string">&#x27;HRDEV&#x27;</span>; -- 这里必须是大写</span><br><span class="line">&gt; select count(*) from <span class="built_in">test</span>;</span><br></pre></td></tr></table></figure>
<h4 id="使用expimp进行数据迁移并验证迁移结果"><a class="markdownIt-Anchor" href="#使用expimp进行数据迁移并验证迁移结果"></a> 使用<code>exp/imp</code>进行数据迁移并验证迁移结果</h4>
<p>删除之前的<code>hrdev.test</code>表，然后我们来尝试使用<code>exp/imp</code>工具做数据迁移。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 用exp导出数据</span></span><br><span class="line">exp hrdev/hrdev file=test.dmp compress=y feedback=1000000 tables=test1</span><br><span class="line"><span class="comment"># 用imp导入数据</span></span><br><span class="line">imp hrdev/hrdev file=test.dmp tables=<span class="built_in">test</span></span><br></pre></td></tr></table></figure>
<p>使用上述类似的命令可以验证数据是否导入成功。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sqlplus hrdev/hrdev@localhost</span><br><span class="line">&gt; SELECT owner, table_name, tablespace_name FROM all_tables <span class="built_in">where</span> owner=<span class="string">&#x27;HRDEV&#x27;</span>; -- 这里必须是大写</span><br><span class="line">&gt; select count(*) from test1;</span><br></pre></td></tr></table></figure>
<p>到这里我们就完成了<code>expdp/impdp</code>和<code>exp/imp</code>工具的基本导入导出使用。</p>
<h3 id="比较expdpimpdp和expimp工具的性能"><a class="markdownIt-Anchor" href="#比较expdpimpdp和expimp工具的性能"></a> 比较<code>expdp/impdp</code>和<code>exp/imp</code>工具的性能</h3>
<p><code>expdp/impdp</code>具有更好的性能，但是使用却颇为麻烦，其性能究竟比<code>exp/imp</code>工具好上多少呢？我们可以做一个小测试。</p>
<h4 id="生成测试数据"><a class="markdownIt-Anchor" href="#生成测试数据"></a> 生成测试数据</h4>
<p>下面的命令可以生成一个较大的测试数据表。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sqlplus system/06d94313bc6a23ca@localhost</span><br><span class="line">&gt; alter tablespace system add datafile <span class="string">&#x27;/tmp/oracle/tables.dbf&#x27;</span> size 10m autoextend on maxsize unlimited; -- 创建一个表空间用于存储大表</span><br><span class="line">&gt; alter user hrdev DEFAULT TABLESPACE devspace quota unlimited on devspace;</span><br><span class="line"></span><br><span class="line">sqlplus hrdev/hrdev@localhost &lt;&lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">create table test1</span></span><br><span class="line"><span class="string">    nologging</span></span><br><span class="line"><span class="string">    as</span></span><br><span class="line"><span class="string">    with generator as (</span></span><br><span class="line"><span class="string">          select</span></span><br><span class="line"><span class="string">                  rownum id</span></span><br><span class="line"><span class="string">          from dual</span></span><br><span class="line"><span class="string">          connect by</span></span><br><span class="line"><span class="string">                  level &lt;= 1000000</span></span><br><span class="line"><span class="string">    )</span></span><br><span class="line"><span class="string">    select</span></span><br><span class="line"><span class="string">          rownum                          id,</span></span><br><span class="line"><span class="string">          mod(rownum-1,3)                 val1,</span></span><br><span class="line"><span class="string">          mod(rownum-1,10)                val2,</span></span><br><span class="line"><span class="string">          lpad(&#x27;x&#x27;,100,&#x27;x&#x27;)               padding</span></span><br><span class="line"><span class="string">    from</span></span><br><span class="line"><span class="string">          generator       v1</span></span><br><span class="line"><span class="string">    order by</span></span><br><span class="line"><span class="string">          dbms_random.value</span></span><br><span class="line"><span class="string">;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">sqlplus hrdev/hrdev@localhost &lt;&lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">insert into test1 select (id + 1000000, val1, val2, padding) from test1;</span></span><br><span class="line"><span class="string">insert into test1 select (id + 2000000, val1, val2, padding) from test1;</span></span><br><span class="line"><span class="string">insert into test1 select (id + 4000000, val1, val2, padding) from test1;</span></span><br><span class="line"><span class="string">insert into test1 select (id + 8000000, val1, val2, padding) from test1;</span></span><br><span class="line"><span class="string">insert into test1 select (id + 16000000, val1, val2, padding) from test1;</span></span><br><span class="line"><span class="string">insert into test1 select (id + 32000000, val1, val2, padding) from test1;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>
<h4 id="测试性能"><a class="markdownIt-Anchor" href="#测试性能"></a> 测试性能</h4>
<p>运行下面的命令可以完成一个简单的性能测试。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">time exp hrdev/hrdev file=test.dmp compress=y feedback=1000000 tables=test1  <span class="comment"># 耗时1m30s</span></span><br><span class="line">time imp hrdev/hrdev file=test.dmp tables=test1 <span class="comment"># 耗时15m</span></span><br><span class="line">time expdp hrdev/hrdev TABLES=<span class="string">&quot;(test1)&quot;</span> DIRECTORY=dmpdir DUMPFILE=test1.dmp <span class="comment"># 耗时17s</span></span><br><span class="line">time impdp hrdev/hrdev INCLUDE=table DIRECTORY=dmpdir DUMPFILE=test1.dmp <span class="comment"># 耗时34s</span></span><br></pre></td></tr></table></figure>
<p>在我的测试环境中进行测试，将相应的任务耗时标记在了上述脚本中。可以看到<code>expdp/impdp</code>相比<code>exp/imp</code>工具确实可以带来约几倍到几十倍的性能提升。所以在数据量很大<code>exp/imp</code>工具太慢时，还是可以考虑使用<code>expdp/impdp</code>工具的。</p>
<p>另外<code>expdp/impdp</code>还支持<code>PARALLEL</code>参数，以便进行并行导入导出，由于Express版本不支持<code>PARALLEL</code>，所以在我们的测试环境中并不能完成此测试。理论上<code>expdp/impdp</code>应该会比上述结果更快。</p>
<h3 id="用sqoop连接oracle数据库进行数据同步"><a class="markdownIt-Anchor" href="#用sqoop连接oracle数据库进行数据同步"></a> 用sqoop连接oracle数据库进行数据同步</h3>
<p>使用sqoop将数据导入到hive可以通过一下命令来实现：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sqoop import --table TEST --connect jdbc:oracle:thin:@xxx.xxx.xxx.xxx:21521:XE --username hrdev --password hrdev \</span><br><span class="line">    --hive-import --hive-overwrite --hive-database test_oracle --hive-table <span class="built_in">test</span> \</span><br><span class="line">    --warehouse-dir /user/hive/warehouse \</span><br><span class="line">    -m 1  <span class="comment"># 这里不能用`--split-by id`，否则会报错`No columns to generate for ClassWriter`</span></span><br></pre></td></tr></table></figure>
<p>在使用上述命令之前，需要注意：</p>
<ol>
<li>将连接oracle的jar包下载到sqoop的库目录中（我使用的hdp数据平台，此目录为<code>/usr/hdp/current/sqoop-server/lib/ojdbc6.jar</code>)</li>
<li>如果此命令卡住无反应，可能是sqoop运行过程中在等待用户输入密码，参考<a href="https://community.cloudera.com/t5/Support-Questions/sqoop-import-hung-hive-import-HDP-3-0-0/td-p/232447">这里</a>，添加<code>beeline-hs2-connection.xml</code>文件可以解决</li>
</ol>
<p>使用sqoop除了可以进行数据迁移，还可以进行方便的执行一些<code>sql</code>命令，比如创建表、查询数据量大小都可以实现。它就是<code>sqoop eval</code>了，通过查询它的帮助文档可以了解更多。</p>
<p>由于<code>sqlplus</code>命令行工具最多只能输入2499个字符，所以一些创建表的语句会无法执行。此时，使用<code>sqoop eval</code>就可以执行这些语句。</p>
<h3 id="用spark连接oracle数据库进行数据同步"><a class="markdownIt-Anchor" href="#用spark连接oracle数据库进行数据同步"></a> 用spark连接oracle数据库进行数据同步</h3>
<p>spark是大数据开发中常用的工具，其生态相对成熟，可以很容易的实现类似sqoop的并行数据迁移。</p>
<p>使用spark进行oracle数据读取，只需要下面这几行代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">spark: SparkSession = SparkSession.builder.enableHiveSupport().appName(<span class="string">&quot;data-migration&quot;</span>).getOrCreate()</span><br><span class="line">df = spark.read \</span><br><span class="line">    .<span class="built_in">format</span>(<span class="string">&quot;jdbc&quot;</span>) \</span><br><span class="line">    .option(<span class="string">&quot;url&quot;</span>, <span class="string">&#x27;jdbc:oracle:thin:@xxx.xxx.xxx.xxx:21521:XE&#x27;</span>) \</span><br><span class="line">    .option(<span class="string">&quot;driver&quot;</span>, <span class="string">&quot;oracle.jdbc.driver.OracleDriver&quot;</span>) \</span><br><span class="line">    .option(<span class="string">&quot;fetchsize&quot;</span>, <span class="string">&quot;10000&quot;</span>) \</span><br><span class="line">    .option(<span class="string">&quot;dbtable&quot;</span>, <span class="string">&quot;hrdev.test&quot;</span>) \</span><br><span class="line">    .option(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;hrdev&quot;</span>) \</span><br><span class="line">    .option(<span class="string">&quot;password&quot;</span>, <span class="string">&quot;hrdev&quot;</span>) \</span><br><span class="line">    .load()</span><br><span class="line">df.write.saveAsTable(...)</span><br></pre></td></tr></table></figure>
<p>用spark进行数据迁移时需要注意，当我们指定了<code>partition</code>相关参数时，数据迁移并不一定可以得到加速。</p>
<p>在我们的测试过程中发现，当导入一个超过100G的数据表且指定了分区参数时，任务执行过程中出现了大量的executor超过内存限制被Yarn杀掉的情况。而无分区进行数据迁移时，executor对内存几乎没有任何要求。</p>
<p>从这里的现象可以大致分析出，spark在无分区时使用了流式的数据处理机制，无需占用过多内存，但是一旦引入分区则对内存就提出了更多的要求。（测试spark版本为2.3.2）。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>本文总结了Oracle的数据导入导出相关工作，分享了一些实操经验。</p>
<h2 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h2>
<p>官方数据导入导出文档：</p>
<ul>
<li><a href="https://docs.oracle.com/cd/E17781_01/server.112/e18804/impexp.htm#BABCJCBD">https://docs.oracle.com/cd/E17781_01/server.112/e18804/impexp.htm#BABCJCBD</a></li>
<li><a href="https://oracle-base.com/articles/10g/oracle-data-pump-10g">https://oracle-base.com/articles/10g/oracle-data-pump-10g</a></li>
<li><a href="https://docs.oracle.com/cd/E11882_01/server.112/e22490/dp_import.htm#SUTIL929">https://docs.oracle.com/cd/E11882_01/server.112/e22490/dp_import.htm#SUTIL929</a></li>
</ul>
<p>字符集转换：<a href="https://my.oschina.net/u/2291124/blog/392174">https://my.oschina.net/u/2291124/blog/392174</a></p>
<p>表空间：<a href="https://www.cnblogs.com/fnng/archive/2012/08/12/2634485.html">https://www.cnblogs.com/fnng/archive/2012/08/12/2634485.html</a></p>
<p>导数据权限：<a href="https://oraclehandson.wordpress.com/2011/09/26/ora-31655-no-data-or-metadata-objects-selected-for-job/">https://oraclehandson.wordpress.com/2011/09/26/ora-31655-no-data-or-metadata-objects-selected-for-job/</a></p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>培训</tag>
        <tag>数据平台</tag>
      </tags>
  </entry>
  <entry>
    <title>基于HDP构建企业数据平台</title>
    <url>/2021/01/22/bigdata-platform-based-on-hdp/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h2 id="回顾数据平台建设整体思路"><a class="markdownIt-Anchor" href="#回顾数据平台建设整体思路"></a> 回顾数据平台建设整体思路</h2>
<p>在<a href="http://brightliao.com/2021/01/21/some-thoughts-about-data-platform/">上一篇文章</a>中，我们聊到了对数据平台的理解以及企业数据平台的建设思路。</p>
<p>经过分析，可以了解到，数据平台应该是一定程度的中心化的系统，是团队对于数据接入、数据建模、数据清洗、数据开发过程的工程化经验的沉淀。</p>
<p>它可以：</p>
<span id="more"></span>
<ol>
<li>解决数据管理问题。如数据安全问题，包括访问控制、数据脱敏等；如数据质量问题，包括数据一致性、数据正确性等，如数据发现问题，包括数据查找、元数据管理等</li>
<li>为数据开发提供支持，包括代码编写、调试、测试、分布式运行、大数据量下的代码性能分析与优化、数据任务调度等</li>
<li>为数据分析提供支持，帮助数据分析师、建模师解决开发环境及资源调度问题，提供友好的界面辅助他们进行探索式数据分析，让他们可以集中精力于数据分析过程</li>
</ol>
<p>要在企业环境中进行数据平台建设，可以采用精益的思想作为指导，采用以下步骤：</p>
<ol>
<li>基于开源软件搭建具备基本功能的数据平台，可以采用的软件如如<code>CDH</code>系列组件（基于<code>Hadoop</code>分布式计算和存储构建）</li>
<li>在需求拉动下进行数据平台功能完善。如基于指标开发、客户画像开发或机器学习模型开发等某一具体需求，以一种类似软件重构的方法进行平台功能抽象、沉淀与复用。</li>
</ol>
<h2 id="在项目中落地"><a class="markdownIt-Anchor" href="#在项目中落地"></a> 在项目中落地</h2>
<p>以上是关于数据平台的一些基本的思考，如何将这些想法进行落地呢？本文希望借着最近在一个客户项目上的数据平台方面的探索和实践，给大家分享一下我们的一些经验。</p>
<h3 id="开源数据平台方案"><a class="markdownIt-Anchor" href="#开源数据平台方案"></a> 开源数据平台方案</h3>
<p>前面提到的数据平台包含了非常丰富的功能，比如分布式数据计算、安全控制、元数据管理等。得益于数据应用已经有数十年的发展过程，特别是近十年来分布式数据存储和计算发展的拉动，这些方面大多有不错的开源产品支持了。</p>
<p>当下业界首选的基础开源数据平台要数基于<code>Hadoop</code>分布式技术的<code>CDH</code>和<code>HDP</code>了。<code>CDH</code>是由<code>Cloudera</code>公司出品的一个<code>Hadoop</code>大数据平台发行版，它内部集成了多个数据工具，如元数据管理工具、数据探索工具、任务调度工具、数据安全工具、数据开发工具等。同时<code>CDH</code>提供了一整套可视化的安装界面，可以让我们通过在网页操作就能实现一套分布式大数据环境的搭建。<code>HDP</code>来自曾经的<code>Hortonworks</code>公司，<code>HDP</code>其基本功能与<code>CDH</code>类似，但提供版本更新的<code>Hadoop</code>相关组件，且全部基于来源软件进行构建（<code>CDH</code>部分软件没有开源）。当前<code>Hortonworks</code>已与<code>Cloudera</code>合并，两者相互促进，想必会让整个大数据生态的发展提速不少。</p>
<p>在这个项目里我们选择了完全开源的<code>HDP</code>大数据平台作为基础平台进行客户企业数据平台的构建。</p>
<h3 id="hdp数据平台简介"><a class="markdownIt-Anchor" href="#hdp数据平台简介"></a> <code>HDP</code>数据平台简介</h3>
<p><code>HDP</code>数据平台长什么样包含什么样的功能呢？这里简单介绍一下。</p>
<p><code>HDP</code>搭建好之后，可以打开集群管理的界面（<code>Ambari</code>），一个示例如下：</p>
<p><img data-src="/attaches/2021/2021-01-22-bigdata-platform-based-on-hdp/hdp-example.png" alt="HDP example" /></p>
<p><code>HDP</code>有一个<code>docker</code>版本的实验环境，通过启动容器即可体验<code>HDP</code>基础数据平台的功能（需要预先准备足够的内存和硬盘空间）。如果大家想快速体验一下，可以参考这里的文档：<a href="https://www.cloudera.com/tutorials/getting-started-with-hdp-sandbox.html%E3%80%82">https://www.cloudera.com/tutorials/getting-started-with-hdp-sandbox.html。</a></p>
<p><code>HDP</code>搭建好了之后，通过<code>Ambari</code>可以实现集群管理，比如组件添加，服务的配置修改、重启等。<code>Ambari</code>是专门为简化<code>Hadoop</code>相关分布式组件的管理而开发的，提供基于<code>web</code>的UI界面及<code>Rest API</code>。除了管理集群组件，<code>Ambari</code>还支持集群服务的监控，比如磁盘空间不够用了，从<code>Ambari</code>的界面上可以看到，也可以配置为通知发出来。</p>
<h3 id="hdp数据平台组件"><a class="markdownIt-Anchor" href="#hdp数据平台组件"></a> <code>HDP</code>数据平台组件</h3>
<p>底层的分布式数据存储和计算通过<code>HDFS</code>和<code>Yarn</code>来实现。<code>HDFS</code>设计为一套高可用的分布式存储，可以理解为把多台计算机的存储抽象为一个逻辑上的大的文件系统，它包含<code>NameNode</code>组件用于存储文件目录树，<code>DataNode</code>组件用于存储具体的文件内容。由于文件是分布式的存储在多台计算机上，那如何访问这些文件才是最高效的？当然是本地磁盘访问了。<code>HDFS</code>的基本设计思想就是基于这一点。这一点也可以换个说法，即，移动程序比移动数据更快。所以，为了实现分布式程序的高效运行，需要一套资源管理和调度系统来支持，它就是<code>Yarn</code>。</p>
<p>有了基本的分布式存储和计算的抽象之后，我们可以在这一套系统上面开发很多的应用。常见的<code>Hive</code>（分布式数据库）、<code>Spark</code>（通用分布式计算引擎）、<code>HBase</code>（分布式列式存储<code>NoSQL</code>数据库）等都是运行于这套抽象之上。一个更有野心的说法是，这套系统可以称为分布式操作系统。</p>
<h3 id="hdp数据平台企业级功能"><a class="markdownIt-Anchor" href="#hdp数据平台企业级功能"></a> <code>HDP</code>数据平台企业级功能</h3>
<p>除了这些基本的存储和计算组件之外，<code>HDP</code>还集成了一定的企业级数据平台功能，比如中心化的账号管理、认证授权、数据的访问控制等。这些功能是中心化数据平台的基本安全要求。</p>
<p>这是如何实现的呢？一般企业内部都会部署一套经典的目录服务来实现内部账号统一管理，常见的目录服务是来自微软的活动目录<code>Active Directory</code>，或者开源的<code>OpenLDAP</code>。目录服务以树形结构保存企业内部员工的账号信息，支持灵活的账号分组以适应不同的企业组织结构。目录服务为统一的登录授权提供支持，数据平台如果对接了目录服务，便可以实现使用同一账号来登录和使用不同的系统。</p>
<p>当开启<code>HDP</code>数据平台的安全机制并对接好目录服务之后，数据平台就可以同步目录服务中的账号到数据平台的账号系统，然后数据平台就可以对不同的账号进行权限控制了。<code>HDFS</code>本身的安全机制设计借鉴了<code>Linux</code>下的文件系统安全设计，对于某一个目录或文件，我们可以对某个用户或组授予读、写、可执行的权限。文件系统权限是整个分布式系统的基本安全保障，而上层的数据库服务以及各类计算任务的权限则是由上层系统各自独立实现。由于每个组件都有自己独立的权限控制机制，所以要在一套分布式数据平台上面实现完善的方便的权限管理是比较棘手的。</p>
<p>为了降低权限管理的复杂度，<code>Ranger</code>被开发出来。<code>Ranger</code>是专门为了实现大数据平台上面进行集中式权限管理的系统。使用<code>Ranger</code>，我们可以在同一个web系统中对<code>HDFS</code>、<code>Yarn</code>及运行于大数据平台上面的各类组件进行权限管理。</p>
<p>在我们的项目中，部署了<code>OpenLDAP</code>目录服务来管理所有的系统账号和组，使用<code>Ranger</code>来进行集中式的权限控制。一个典型的授权使用流程如下：</p>
<p>在<code>LDAPAdmin</code>(一个较老的<code>OpenLDAP</code>目录服务Web管理应用，虽然界面很过时，但是功能还够用)上面创建账号、组，并设置对应账号的用户组：</p>
<p><img data-src="/attaches/2021/2021-01-22-bigdata-platform-based-on-hdp/openldapadmin.png" alt="ldapadmin" /></p>
<p>在<code>Ranger</code>控制台上面选择<code>HDFS -&gt; Hadoop</code>即可针对<code>HDFS</code>进行权限策略配置：</p>
<p><img data-src="/attaches/2021/2021-01-22-bigdata-platform-based-on-hdp/ranger-auth.png" alt="ranger auth" /></p>
<p>当希望对<code>Yarn</code>、<code>Hive</code>、<code>HBase</code>等组件进行权限控制时，我们可以都可以在<code>Ranger</code>控制台完成。</p>
<h2 id="企业数据工作流程"><a class="markdownIt-Anchor" href="#企业数据工作流程"></a> 企业数据工作流程</h2>
<p>看完上面的<code>HDP</code>大数据平台，有人可能会说这不就是一套完整的大数据平台了吗？其实，我们认为可能将这套平台定位为基础大数据平台比较合适，因为这套平台只是提供了一套分布式存储和计算的技术方案，并不能直接解决企业内部的数据应用问题。要想解决这样的问题，需要每个企业（或数据团队）根据自己的背景、文化基于自身数据情况定义一套适合自己的数据工作流程。</p>
<p>什么是企业数据工作流程？我们可以认为是企业内部数据应用开发和迭代的流程。比如要基于客户数据开发一个客户画像的数据应用，可能会经历以下几个流程：</p>
<ol>
<li>考察哪些业务系统存有客户数据并可以作为数据源</li>
<li>将这些业务系统的数据导入到数据平台存储</li>
<li>对导入的数据进行清洗、加工、重新建模（如维度建模），处理为便于分析的数据</li>
<li>基于可用的数据及客户画像需求设计客户标签</li>
<li>在便于分析的数据上面进行进一步的组合分析，计算出前面设计的客户画像标签</li>
<li>设计用于展示或搜索的客户画像应用UI，将计算出来的客户标签进行展示</li>
</ol>
<p>我们可以把上述流程做一下抽象，得到一般的企业数据工作流程：数据接入 -&gt; 数据建模 -&gt; 数据计算 -&gt; 数据应用或服务开发。</p>
<h2 id="通过hdp构建企业数据工作流程"><a class="markdownIt-Anchor" href="#通过hdp构建企业数据工作流程"></a> 通过<code>HDP</code>构建企业数据工作流程</h2>
<p><code>HDP</code>如何支持上述流程呢？下面分析一下有哪些工具可以提供帮助。</p>
<h3 id="数据接入"><a class="markdownIt-Anchor" href="#数据接入"></a> 数据接入</h3>
<p>数据接入是把数据从源系统导入到数据平台的工作。源系统通常是企业中面向内部或外部的业务系统，源系统的数据存储多种多样，比如常见的关系型数据库、<code>NoSQL</code>数据库、日志文件等等。</p>
<p>从技术上我们需要一套可以很容易从各类不同数据源读取数据的方案。开源的专门用于导入数据的工具是<code>Sqoop</code>，它可以分布式多线程的读取不同类型源系统的数据。安装好<code>HDP</code>之后，每个集群节点都会安装<code>Sqoop</code>的客户端工具。使用<code>Sqoop</code>导入数据时，只需要在任意集群节点运行<code>Sqoop</code>命令就可以了，<code>Sqoop</code>将会在集群中启动一个分布式计算任务来进行数据导入。</p>
<p>除了<code>Sqoop</code>之外，<code>Spark</code>其实可以作为一个不错的进行数据导入的工具。<code>Spark</code>不仅同样可以分布式读取多种不同种类的数据源，同时，<code>Spark</code>开源生态非常活跃，稳定性扩展性支持度都非常好。比如，一般而言，我们会主要基于<code>Hive</code>来构建数据仓库，由于框架在设计上的兼容性，<code>Spark</code>将数据写入<code>Hive</code>是轻而易举的事情。在项目上，我们考察了<code>Sqoop</code>和<code>Spark</code>，最终选择了<code>Spark</code>的方案，使用<code>Spark</code>可以让我们减少一种数据工具的引入，同时我们也从<code>Spark</code>的稳定性扩展性上收益很多。</p>
<p>如果需要实时的进行数据接入，我们一般需要借助一个消息系统，这时分布式消息系统<code>Kafka</code>是一个很好的选择，<code>HDP</code>对<code>Kafka</code>也进行了集成。</p>
<h3 id="数据建模"><a class="markdownIt-Anchor" href="#数据建模"></a> 数据建模</h3>
<p>数据进入数据仓库之后，首先需要做的一件事就是进行一定程度的清洗加工，将数据变成高质量且易于分析的数据。这个过程我们一般称为数据建模，在这里使用的建模方法一般是维度建模方法。维度建模将数据表分为事实表和维度表，一般的数据分析会从事实表出发进行分析，在不同的维度进行聚合得到不同的指标，如销量、新客户数量等。</p>
<p>这一部分是数据仓库的核心，但却不是工具能帮到多少的，因为每个企业的数据需求不一样，数据质量不一样，建模过程要完成哪些数据清洗标准化过程也不一样。这样一来，我们很难去定义一套通用的抽象来解决这个问题。关于数据建模的经验，我会在后续的文章中给大家做进一步的分享。</p>
<p>从基础技术上讲，这里需要一套非常灵活的数据开发运行环境做支持，当前的情况下，<code>Spark</code>可能是最成熟最好的选择了。在我们项目中也是选用了<code>Spark</code>+<code>Hive</code>的方案。</p>
<h3 id="数据开发"><a class="markdownIt-Anchor" href="#数据开发"></a> 数据开发</h3>
<p>数据开发是为了支持数据应用而编写的一些数据加工、聚合或转换程序，这些程序的输出通常是一些数据指标或标签。通常为了能在不同的指标计算之间复用一些计算过程，我们会将数据仓库进行分层，比如常见的<code>dwd</code>（数据仓库明细层） <code>dwb</code>（数据仓库初级汇总层） <code>dm</code>（数据集市层） <code>ads</code>（数据输出层）等，公共的数据计算代码会逐步下沉到更低的层级。这里的不同的分层在技术上可以直接对应到数据库。</p>
<p>这一部分同样需要一个通用的计算框架的支持，我们依然是首选了<code>Spark</code>的方案。</p>
<p>在使用<code>Spark</code>的过程中我们遇到的一个问题是，<code>Spark</code>本身提供的<code>API</code>过于通用，如果使用这些<code>API</code>来进行数据开发，将导致代码难以阅读。<code>Spark</code>同时提供了<code>SQL</code>的接口，使用<code>SQL</code>可以让一些数据开发的代码更清晰易懂，但是在逻辑比较复杂的场景下，只使用<code>SQL</code>又将丢失<code>Spark</code>强大的编程能力。关于我们项目上是怎么做的，我会在后续的文章中给大家做进一步的分享。</p>
<h3 id="数据应用和服务开发"><a class="markdownIt-Anchor" href="#数据应用和服务开发"></a> 数据应用和服务开发</h3>
<p>我们常见的数据应用形式是<code>BI</code>报表和数据<code>API</code>。<code>HDP</code>中集成了轻量级的<code>BI</code>工具<code>Superset</code>，如果对数据报表呈现有更高的要求，<code>Superset</code>可能难以满足需求，这时可以考虑对接其他商用的<code>BI</code>工具，或者基于前端UI库自主开发。</p>
<p>由于数据开发是基于<code>Spark</code>+<code>Hive</code>完成的，如果<code>BI</code>工具直接对接<code>Hive</code>进行数据查询，那么查询响应时间将会成为一个问题。考虑到这类数据量会大大减少，我们一般的做法是将计算出来的指标数据存入一个可以支持快速查询的分析型数据库中。</p>
<p>使用<code>Spark</code>可以将数据轻松的导出到<code>PostgreSQL</code>、<code>ClickHouse</code>等分析型数据库中。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>经过以上的分析可以了解到，对于团队的数据工作流程而言，基于<code>HDP</code>的数据平台可以提供很多帮助，但是要想让整个流程运转起来，实际上还需要我们选择配合其他的工具或自研一部分工具才行。</p>
<p>最后简要总结一下，本文简单介绍了如何基于<code>HDP</code>来构建企业数据平台，包括一些<code>HDP</code>相关软件系统的基本介绍及我们项目上的具体技术选型。我们还从企业数据工作流程的角度阐述了如何在基础数据平台上面构建适合自身的工作流程。有了基础数据平台及数据工作流程定义，我们就可以说企业的数据平台初步搭建起来了。</p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>hadoop</tag>
        <tag>数据</tag>
        <tag>数据平台</tag>
        <tag>CDH</tag>
        <tag>HDP</tag>
        <tag>分布式计算</tag>
      </tags>
  </entry>
  <entry>
    <title>数据平台数据管理实践</title>
    <url>/2021/03/15/data-management-practice/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2021/2021-03-15-data-management-practice/mindmap.png" alt="Data management in data platform" /></p>
<p>我们在<a href="http://brightliao.com/2021/03/01/data-ingestion-practice/">前面的文章</a>中讨论了如何将数据接入到数据平台。一般而言，接入到数据平台的数据会来自众多的业务系统，这样一来，我们就拥有了大量不同来源的数据。如何将这些数据有效的管理起来是一个很大的挑战。本文将尝试结合我们的项目实践经验做一些分享。</p>
<p>（数据仓库可以理解为数据平台中所有数据的一个集合，所以，数据平台中的数据管理也可以说是数据仓库中的数据管理。下文中数据平台和数据仓库会经常交替使用，其意义基本一致。）</p>
<span id="more"></span>
<p>将数据管理起来是为了高效的查找和使用数据。我们先来看一下通常是如何使用数据的。</p>
<h2 id="一个简单的指标计算"><a class="markdownIt-Anchor" href="#一个简单的指标计算"></a> 一个简单的指标计算</h2>
<p>假设现在有一个大型零售行业的场景，我们的主要产品是空调。作为空调生产商，空调的销售主要是通过各大经销店完成的。现在我们想知道空调的销量情况用以辅助决策，可以开发一个指标来统计销量。</p>
<h3 id="开始"><a class="markdownIt-Anchor" href="#开始"></a> 开始</h3>
<p>如何统计销量呢？看起来只需要把销售的订单找出来，做一个加和统计就可以了。但是实际情况会更复杂一些，从业务上讲，以下场景产生的订单不需要统计：</p>
<ul>
<li>订单被取消</li>
<li>订单还在进行中</li>
<li>订单产生了退货</li>
<li>内部奖励产生的订单</li>
<li>翻新的产品产生的订单</li>
</ul>
<p>这个时候我们的销量统计逻辑可以用<code>SQL</code>表达为：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> sales_count</span><br><span class="line"><span class="keyword">from</span> <span class="keyword">order</span></span><br><span class="line"><span class="keyword">where</span> closed<span class="operator">=</span><span class="literal">true</span> canceled<span class="operator">=</span><span class="literal">false</span> <span class="keyword">and</span> rejected<span class="operator">=</span><span class="literal">false</span> <span class="keyword">and</span> reward_order<span class="operator">=</span><span class="literal">false</span> <span class="keyword">and</span> retread_product<span class="operator">=</span><span class="literal">false</span></span><br></pre></td></tr></table></figure>
<p>（实际情况可能更复杂，因为<code>order</code>表可能没有是否翻新产品或者是否是内部奖励的信息，此时需要连接其他表进行查询。）</p>
<h3 id="考虑取数时间"><a class="markdownIt-Anchor" href="#考虑取数时间"></a> 考虑取数时间</h3>
<p>上述代码正确吗？我们需要注意，根据每天接入数据平台的数据来看，对于某一个订单，数据仓库里面的数据可能是重复的。比如，订单a在前天创建，同时在昨天被更新，这时，前天和昨天的数据里面都会有这个订单。根据这里的分析，我们需要取当前最新状态的订单来进行计算才行。上述的<code>SQL</code>需要改进为：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> sales_count</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">    <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> (</span><br><span class="line">        <span class="keyword">select</span> <span class="operator">*</span>,</span><br><span class="line">            <span class="comment">-- 先根据订单id进行分组，然后根据时间排序，得到序号</span></span><br><span class="line">            <span class="built_in">row_number</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> id <span class="keyword">order</span> <span class="keyword">by</span> update_time <span class="keyword">desc</span>) n</span><br><span class="line">        <span class="keyword">from</span> <span class="keyword">order</span></span><br><span class="line">    ) all_order</span><br><span class="line">    <span class="keyword">where</span> n <span class="operator">=</span> <span class="number">1</span>  <span class="comment">-- 取序号为1的订单，即最新订单</span></span><br><span class="line">) latest_order</span><br><span class="line"><span class="keyword">where</span> closed<span class="operator">=</span><span class="literal">true</span> canceled<span class="operator">=</span><span class="literal">false</span> <span class="keyword">and</span> rejected<span class="operator">=</span><span class="literal">false</span> <span class="keyword">and</span> reward_order<span class="operator">=</span><span class="literal">false</span> <span class="keyword">and</span> retread_product<span class="operator">=</span><span class="literal">false</span></span><br></pre></td></tr></table></figure>
<h3 id="考虑计算历史指标"><a class="markdownIt-Anchor" href="#考虑计算历史指标"></a> 考虑计算历史指标</h3>
<p>此时，我们还会希望这个指标可以每天定时计算出来，然后通过大屏进行展示。这个需求就要更复杂一些了。我们常常需要一个任务调度系统来支持，以便可以将上述的代码每天跑一次。其实不仅仅是调度系统，为了支持决策，我们还常常有统计历史指标的需要，比如销量指标在上个月是多少，本月是增长了还是下降了？</p>
<p>这时，代码里面需要加入一个变量，那就是希望计算哪一天的指标。这个参数我们可以命名为<code>data_date</code>。上述代码可以进一步优化为：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> sales_count</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">    <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> (</span><br><span class="line">        <span class="keyword">select</span> <span class="operator">*</span>,</span><br><span class="line">            <span class="comment">-- 先根据订单id进行分组，然后根据时间排序，得到序号</span></span><br><span class="line">            <span class="built_in">row_number</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> id <span class="keyword">order</span> <span class="keyword">by</span> update_time <span class="keyword">desc</span>) n</span><br><span class="line">        <span class="keyword">from</span> <span class="keyword">order</span></span><br><span class="line">        <span class="keyword">where</span> ods_insert_date <span class="operator">&lt;=</span> $&#123;data_date&#125;  <span class="comment">-- 筛选出目标数据日期及以前的订单</span></span><br><span class="line">    ) all_order</span><br><span class="line">    <span class="keyword">where</span> n <span class="operator">=</span> <span class="number">1</span>  <span class="comment">-- 取序号为1的订单，即最新订单</span></span><br><span class="line">) latest_order</span><br><span class="line"><span class="keyword">where</span> closed<span class="operator">=</span><span class="literal">true</span> canceled<span class="operator">=</span><span class="literal">false</span> <span class="keyword">and</span> rejected<span class="operator">=</span><span class="literal">false</span> <span class="keyword">and</span> reward_order<span class="operator">=</span><span class="literal">false</span> <span class="keyword">and</span> retread_product<span class="operator">=</span><span class="literal">false</span></span><br></pre></td></tr></table></figure>
<h3 id="考虑计算其他维度"><a class="markdownIt-Anchor" href="#考虑计算其他维度"></a> 考虑计算其他维度</h3>
<p>这下看起来好像差不多了。但是，通常来讲，还有更多的来自业务方的需求，比如，希望可以根据经销店的维度来查看这个指标，以便对比分析。希望按照省、市、区维度来查看这个指标，以便对比分析。</p>
<p>此时我们需要考虑指标保存的粒度了。对于经销店粒度的指标而言，因为总的销量与各经销店的销量有汇总关系，所以这里可能没必要保存总销量。当需要总销量时，在展示的时候进行汇总加和即可。</p>
<p>对于省、市、区这几个维度而言，不难看出，它们存在层级关系：区以上是市，市以上是省。其实经销店与这三个地域维度也存在层级关系：经销店以上是区，区以上是市，市以上是省。所以，事实上，我们只需要保存到经销店粒度的统计数据就可以支持省、市、区维度的统计了。</p>
<p>于是我们可以修改代码为：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> dealer_id, section, city, province, <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">as</span> sales_count</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">    ...</span><br><span class="line">) latest_order</span><br><span class="line"><span class="keyword">where</span> ...</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> dealer_id, section, city, province</span><br></pre></td></tr></table></figure>
<p>（实际情况可能更复杂，因为<code>order</code>表往往没有省、市、区的信息，此时需要连接其他表进行查询。）</p>
<h3 id="调度运行"><a class="markdownIt-Anchor" href="#调度运行"></a> 调度运行</h3>
<p>到这里，一个基本的指标计算算是搞定了。实际情况下，由于这个任务需要<code>order</code>等表的数据，需要在数据接入之后才能运行。我们会将这个计算任务和数据接入的任务组成一个数据处理管道（Pipeline），通过调度器调度整个任务管道进行执行。下面是使用<code>Airflow</code>组织的一个简单的任务管道图。</p>
<p><img data-src="/attaches/2021/2021-03-15-data-management-practice/simple-dag.png" alt="simple dag" /></p>
<h2 id="对数据管理的启发"><a class="markdownIt-Anchor" href="#对数据管理的启发"></a> 对数据管理的启发</h2>
<p>上面我们完成了一个简单指标的计算，让我们来回顾一下整个过程，看看从数据平台数据管理的角度我们需要做哪些事才能让整个过程更高效。</p>
<h3 id="数据清洗"><a class="markdownIt-Anchor" href="#数据清洗"></a> 数据清洗</h3>
<p>首先是根据需要确定取数范围，并筛选特定的数据出来。这一步常常需要进行一定的数据清洗。数据清洗的例子比如：</p>
<ul>
<li>对于业务系统数据库中的是否取消字段<code>canceled</code>，其取值可能是<code>null</code>、<code>true</code>、<code>false</code>。为了便于在上层计算（如行数据分析或指标计算）时的逻辑更简单和一致，最好能将此字段限制为非空，取值为<code>true</code>和<code>false</code>，数据清洗可以将<code>null</code>可以映射为<code>false</code>。</li>
<li>有一些字符串类型的字段，比如经销商所在城市，在业务数据库中可能存储为类型<code>char(32)</code>，在接入数据平台之后，会发现该字段的值包含了一些用于补位的空白字符。这些多余的空白字符是不便于分析的，一般可以将其去掉。</li>
<li>还有一些数据，可能是由测试产生的，这些数据一般需要标记出来，或直接排除掉。</li>
</ul>
<p>数据清洗是为了让数据更便于分析和加工处理。这一过程也理解为：将某些相同的数据加工逻辑抽象为一个统一的数据清洗过程。</p>
<h3 id="数据建模"><a class="markdownIt-Anchor" href="#数据建模"></a> 数据建模</h3>
<p>在进行数据分析或指标开发的时候，我们常常要面对数百张张数据库表，如何找到需要的表呢？一个简单的办法是将数据库表做一下分类。</p>
<p>一般而言，可以将数据库表分为事实表和维度表。事实表存储的是一些业务事实，比如订单、付款、物流、维修等。维度表则存储不常变化的一些维度数据，比如经销商信息，产品信息，用户信息等。这就是最基本的维度建模的思想。</p>
<p>这个数据库表分类方法还有一个好处，那就是，一般的统计分析都是以事实表为中心的分析，比如销量、退单量、维修次数等等。维度表一般是用于希望多维度分析数据的情况，比如按照省、市、区、经销店维度进行分析。此类分析的一般模式是从事实表开始查询，然后连接需要的维度所在的表，然后根据维度进行聚合得到结果。</p>
<p>有的说法认为维度建模绝不止将业务系统的数据库进行分类这么简单，需要从业务角度出发，重新定义一套模型，然后将业务系统数据库的模型映射到新模型中。对于维度建模如何实现的问题，我们可能需要另起一篇文章来讨论。</p>
<p>从我们的实践经验来看，虽然说业务系统主要是以三范式来建立数据库模型，但是三范式其实与维度模型有一定的相似之处，简单来说，可以建立一一对应关系。比如三范式建模的订单表，其实可以直接对应到维度模型的订单事实表。三范式建模的经销商表，可以直接对应到维度模型的经销商维度表。为了避免过多繁杂的价值不明显的讨论，一个简单的、稳定的维度建模实施方式就是直接对业务系统的数据库表做一下事实维度划分。</p>
<p>有了事实和维度的划分，数据分析或指标开发就有套路可寻了。一般的套路就是，先找到和计算目标对应的事实表，然后关联到该事实表对应的维度表，选出需要的事实和维度，进行统计即可。比如前面的销量计算，首先可以找到订单事实表，然后通过事实表中的经销商id关联到经销商维度表，把需要的维度数据取出来进行分组统计即可。</p>
<p>在项目实践过程中，我们一般会将数据清洗和数据建模放在一起完成。此时我们会进行一层基础数据层的抽象，这一个数据层一般称为建模层，也常称为明细数据层或<code>DWD</code>（Data Warehouse Details）层。</p>
<h3 id="数据主题划分"><a class="markdownIt-Anchor" href="#数据主题划分"></a> 数据主题划分</h3>
<p>除了事实表和维度表的划分，还可以有一种划分方法，那就是根据主题来进行划分。</p>
<p>假设我们从5个业务系统分别接入了40张数据库表，此时，我们有200张数据库表。此时，如果所有的数据库表都放在同一个数据库中，在查找时就会碰到麻烦，我们很难在200张数据库表中快速找到想要的那一张表。不仅如此，很多数据工具在展示过多的数据库表时也会遇到性能问题。</p>
<p>一个简单的应对方法就是，按照主题将数据库表分类放到不同的数据库中。</p>
<p>那么什么样的主题划分是比较合理的划分呢？事实上，对于同一类业务，我们常常有多种不同的划分方法。比如零售行业，我们可以按照人、货、场这种常用的分析思路来划分，也可以按照售前、售中、售后三个销售阶段进行划分，或者按照不同的渠道进行划分，如划分为线下渠道、网上商店渠道、三方渠道等等。</p>
<p>这么多种划分方式的选择可能会在团队中引起很多的讨论，这将导致主题划分迟迟没有结论。很多主题划分都将带来较大的成本，因为我们需要将数据映射到这个主题划分上去。为避免过多的前期设计，从我们的经验来看，会更推荐采用一种更为精益的做法。</p>
<p>首先，我们可以直接简单的按照来源业务系统进行一次划分，每个业务系统对应一个主题。这通常也是合理的。主要的理由是：</p>
<ul>
<li>在这些来源业务系统建设之初，通常都经过了广泛讨论，这些业务系统可以认为是高内聚低耦合的。</li>
<li>一般而言，绝大部分的分析其实是集中在业务系统内部。</li>
<li>实现上，可以根据不同来源的系统建立数据库，然后将相关的数据库表都置于其中。这在工程上将带来很多好处，因为我们可以把这一条规则当做惯例，而非配置。根据<code>Convention over Configuration</code>的思想，我们可以因此节约很多代码。</li>
</ul>
<p>然后，在某一天，我们发现直接根据业务系统进行划分这种方式不便于数据分析，到那时可以根据更好的方式进行划分。在需要用另一种方式划分主题时，我们总是难以避免做一层复杂的数据映射。</p>
<p>可以考虑的做法是，通过数据库视图（<code>View</code>）这样的技术来实现，此时的主题划分只是对应了一个逻辑上的抽象，我们无需移动数据，也无需复制数据，还可以快速应对设计的变更。使用视图的另一个好处是，我们可以很容易的支持多种主题划分方式。有了这样的灵活性，我们就更不用担心过重的主题设计了，因为我们可以随时应对变更。我们甚至还可以实现一些辅助进行主题划分工具，将这个步骤完全自动化。</p>
<h3 id="数据逻辑复用"><a class="markdownIt-Anchor" href="#数据逻辑复用"></a> 数据逻辑复用</h3>
<p>找到数据之后，下一步是组织计算逻辑，比如前面计算销量时，我们会考虑订单的状态，产品的范围等因素。这一步非常关键，因为一旦我们取错数据了，后面的计算就都是错的。</p>
<p>要梳理出一个合理的正确的取数逻辑常常需要经过大量的讨论、验证及反复工作。比如，刚开始，我们可能选择了所有成功完成的订单。按照这个规则实现之后，我们把数据呈现给业务人员。业务人员说：“这不对呀！为啥把翻新产品的订单也计算进去了？” 没关系，我们来排除掉这些订单。后来，业务人员经过讨论之后，又发现，其实业务上并不太关心内部奖励产生的订单，还需要把这样的订单排除。</p>
<p>做数据开发时，我们会经常碰到这样的故事。</p>
<p>如何从技术上缓解这个问题呢？</p>
<p>我们经过很多轮的验证，才获得了这样一个合理的取数逻辑，这样的经验是非常宝贵的。而且，我们在做其他统计时常常也要做同样考虑，用类似的取数逻辑。比如，当我们要统计某一个用户产生了多少笔订单以确定高价值用户时，这里的订单取数逻辑一般会是相同的。</p>
<p>将这些经验进行沉淀的一种技术实现方式就是，新建一个数据层，将这些计算过程保存下来。我们常常把这一层称为基础数据层，也有人将其称为轻度汇总层。一般以<code>DWB</code>的缩写来表示，其全称是<code>Data Warehouse Basis</code>。之所以有人将这一层称为轻度汇总层，是因为我们常常还可以在这一层进行数据的轻度汇总，比如按照经销店或者客户维度等比较细粒度的维度进行汇总。上层计算一般可以较容易的复用这样的轻度汇总结果。同时，做了轻度汇总之后，数据量可以进一步减少，对存储的压力也进一步降低了。</p>
<p>由于我们常常是为了解决逻辑复用的问题而引入的<code>DWB</code>层，所以这一层一般是通过类似软件开发过程中的重构手段而形成的。比如，在开发第一个指标的时候，我们将所有的代码放在了一起。开发第二个指标的时候，我们发现可以和第一个指标有一定的逻辑复用，于是我们抽象了一个<code>DWB</code>层的数据表，将公共的计算逻辑抽取出来用于构建这个表。构建这个表的代码一般还会形成一个独立的数据计算任务，在数据管道的另一个任务中执行。经过几轮重构之后，我们将得到一些比较稳定的公共层数据表，<code>DWB</code>数据层也就慢慢丰富起来了。</p>
<p>如果团队有较丰富的经验，或者对业务系统的数据本来就理解比较深刻，那么也可以通过自上而下的设计来构建这一层。通过预先设计来构建<code>DWB</code>层的潜在问题是可能引入过度设计，通过重构来实现这一层的潜在问题是可能做了过多的无用功。</p>
<p>一般而言，<code>DWB</code>层的数据表会与<code>DWD</code>层的事实表相对应。当然，实际情况常常比较复杂，可能有很多合理的例外，只要能体现其价值就可以。</p>
<p>总结起来，我们通常可以抽象一层<code>DWB</code>来实现计算逻辑的复用。请注意，无论采用什么样的途径构建这个数据层，我们的目标是提高最终指标计算的质量和效率。这个目标才是最重要的，事实上，只要对实现这个目标有益，我们甚至完全可以不构建这一层。当我们遇到分歧时，可以回头来看看这个目标，也许我们就可以很快得到答案了。</p>
<h3 id="宽表输出"><a class="markdownIt-Anchor" href="#宽表输出"></a> 宽表输出</h3>
<p>计算出来指标之后，需要向BI应用提供查询服务，有没有什么潜在的问题或者好的实践呢？</p>
<p>指标的计算通常是具备较强的独立性的，即，一个指标由一个开发人员完成，输出一张数据表。这带来的问题就是，指标表太多了！</p>
<p>我们可以大概计算一下，在一般的企业中，业务人员希望查看的指标都是数百个，这里可能对应数百张数据表。另外，对于同一个指标，可能存在完全不同的计算维度，此时一个指标也可能产生多张数据库表。比如，对于经销商的管理，在企业组织结构上，可以设立一个业务管理员，分别管理经销店1-5，同时设立一个技术指导员，分别对应经销店2-6。我们希望统计每个管理员对应的空调销量指标。此时，一般我们会视为两个指标分别进行计算，因为它们的统计粒度不一样。这样一来，最终我们会得到两张数据库表。</p>
<p>所以，我们常常见到的某某数据仓库里面有数千张数据库表的情况，也就不足为怪了。</p>
<p>这么多数据库表，如果不能很好的管理起来，在维护上也会是一个灾难。比如，通常情况下，为了提高指标的查询效率，我们会将数据同步到一个外部的关系型数据库或者分析型数据库中，如果表数量太多，这里的数据同步就会成为一个很大的问题。</p>
<p>这么多数据库表，如果不能很好的管理起来，查找的时候也可能会是一个灾难。首先是命名上，很难得到一个较短的又容易理解的表名。其次，就算有一个合理的命名规范，也可能由于相似名字的表太多了而很难找到想要的表。</p>
<p>在项目实践的时候，有几个值得借鉴的方法可以缓解这个问题。</p>
<p>第一个方法是，尝试尽量少建数据库表。比如，我们可以将计算逻辑相近的指标放在一起计算，只输出一张数据库表。上面的例子中，针对业务管理员的销量统计和针对技术指导员的销量统计计算逻辑相似，同时输出的维度一般也有很多重合。这两个指标就可以考虑合并为一个指标计算任务进行实现，同时只输出一张表。合并计算带来的一个副作用就是，输出的表中的数据混合了多个指标，不容易理解。但是考虑到通常会由同一个开发人员完成，所以这个问题不会很显著。</p>
<p>第二个方法是，尝试将最终的数百个指标合并为一张大宽表进行输出。这样一来，对于上层BI系统而言，通常就只需要面对一张数据库表了。合并为一张大宽表输出还可以合并相同维度的指标数据，从而减少数据量。比如，经销商的销量指标包含了省、市、区维度，经销商的售后服务次数指标同样包含了省、市、区维度，这时我们就可以用一行数据来存储这两个指标的结果。</p>
<p><img data-src="/attaches/2021/2021-03-15-data-management-practice/indicator-combine.png" alt="indicator combine" /></p>
<p>第二个方法带来的副作用同样是数据查询的问题。比如，合并之后的指标表可能如下：</p>
<p><img data-src="/attaches/2021/2021-03-15-data-management-practice/indicator-combine1.png" alt="indicator combine" /></p>
<p>如果要查询经销商的销量指标，我们需要将查询限制为：<code>业务管理员</code>维度为<code>null</code>值 且 <code>技术指导员</code>维度为<code>null</code>值 且 <code>销量指标</code>不为<code>null</code>值。如果要查询业务管理员的销量指标，我们需要将查询限制为：<code>经销商</code>维度为<code>null</code>值 且 <code>技术指导员</code>维度为<code>null</code>值 且 <code>销量指标</code>不为<code>null</code>值。</p>
<p>虽然带来了一定程度使用上的不便，但是总体上来看，由于我们减少了数据表的管理成本，这个方法还是有效的。最后，如果由于维度和指标太多，实在是查询不便，可以将每个指标的查询逻辑记录下来，或者开发一个指标查询的工具辅助完成查询语句的编写。</p>
<p>对于这类指标表的存储，我们通常也会在数据仓库中新建一层（一般直接对应一个独立数据库）。这一个数据层常常被称为数据集市层，简称为<code>DM</code>，即Data Market。也有人将其称为数据服务层，简写为<code>DWS</code>，即Data Warehouse Service。最终的指标宽表一般也会对应数据仓库中的一层，常常被称为数据应用层，简写为<code>ADS</code>，即Application Data Service。</p>
<p>总结起来，对于大量指标的计算，我们可以考虑将其单独存储到<code>DM</code>层中。当输出给其他外部系统时，我们可以考虑将指标合并为一张宽表存储到<code>ADS</code>层，然后进行输出。</p>
<h3 id="数据分区和命名"><a class="markdownIt-Anchor" href="#数据分区和命名"></a> 数据分区和命名</h3>
<p>我们上面讲到了数据仓库的分层，按照数据被加工的顺序和深度，依次可以是：<code>ODS</code>层-&gt;<code>DWD</code>层-&gt;<code>DWB</code>层-&gt;<code>DM</code>层-&gt;<code>ADS</code>层。在数据管理时，通常还有一个问题，那就是分区。</p>
<p>数据一般是按照固定的周期（如每天）定期接入到数据平台的，那么，数据在每张数据库表里面要如何存储呢？</p>
<p>一般而言，可以按照接入数据的周期进行数据分区存储，比如，如果是每天接入数据，可以建立一个分区字段，其值为接入的数据的时间（一般是接入数据的任务运行时的前一天）。</p>
<p>从技术上讲，一般的数据仓库技术（如<code>Hive</code>）都会把不同的分区存储为不同的文件。在计算时，如果我们只需要计算某一个分区的数据，则只需要将这个分区的数据查出来做计算即可，这可以大大提升计算的性能。在计算指标时，其实大部分指标都是按接入数据的周期进行统计计算的，这刚好可以利用到数据分区的优势。</p>
<p>从数据接入策略和数据表的内容来看，我们可以将数据库表分为全量表和增量表。对于全量表，每个分区都是一个全量的数据。对于增量表，每个分区对应的是当期的数据增量。</p>
<p>在实施时，为了团队可以更容易的统一认知，一般会引入一套命名规范。通过名字可以让大家快速的了解到表的基本设计。</p>
<p>比如，我们对于全量表会增加一个后缀<code>_f</code>，全称是<code>full</code>，即全量表，对于增量表则增加后缀<code>_h</code>，全称是<code>history</code>，即保存历史的增量表。对于全量表，需要有一个分区字段，该字段名为<code>dt</code>，值为整型存储的日期（如20210505）。增量表的分区字段为<code>di</code>，值与全量表的相同。</p>
<p>贴源层<code>ODS</code>、明细层<code>DWD</code>及轻度汇总层<code>DWB</code>的数据表都需要符合这一基本规范。<code>DM</code>及<code>ADS</code>层的指标一般没有增量/全量的概念，但是会有一个统计的数据日期字段，这一字段也可以作为分区字段，我们将其命名为<code>data_date</code>，存储字符串类型，如<code>2021-05-05</code>。</p>
<p>除了数据分区及其命名规范，我们还会规范数据库和数据表的名字。</p>
<p>在库的命名上，我们一般会反映数据层的名字和当前主题的名字。比如在<code>ODS</code>层，我们会将数据库命名为<code>ods_datasource1</code>、<code>ods_datasource2</code>等，在<code>DWD</code>层将数据库命名为<code>dwd_datasource1</code>、<code>dwd_datasource2</code>等。如果有按照其他方式设计的主题，也是类似，比如如果实施了<code>OneID</code>进行各个系统的<code>ID</code>关联和打通，则可以将对应的数据库命名为<code>dwd_oneid</code>。</p>
<p>在表的命名上，我们会加上主题的名字和事实维度分类，比如<code>datasource1_dim_customer_f</code>、<code>datasource1_fact_order_h</code>。</p>
<p>由于<code>DWD</code>层的数据是保留历史数据的，如果我们要查询当前最新的数据，需要做一个开窗选最新数据的操作（<code>row_number() over(partition by id order by update_time desc) n</code>），使用不太方便。<code>DWD</code>的表是使用最频繁的表，而且此类查询最多，对于这类需求，我们可以通过数据库视图来实现。可以为<code>DWD</code>的所有表都创建一个表示该表最新数据的视图，并命名为<code>datasource1_dim_customer_latest_fv</code>。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>最后，我们来简要总结一下。</p>
<p>为了高效的查找和使用数据，我们需要将数据仓库中的数据有效的管理起来。本文以一个指标的开发过程为例，梳理了整个数据开发过程中的主要步骤。然后，我们分析了这些步骤中可能遇到的问题，以及在数据仓库建设中的一些有效的对策。包含了数据仓库数据清洗、建模、主题划分、逻辑复用、宽表输出及分区和命名。</p>
<p>数据仓库建设是数据平台建设的核心内容，这个领域其实是一个非常偏工程的领域，很多问题并没有一个是或否的答案。从以上内容中对很多实际问题的分析来看，在实际项目过程中，我们往往需要根据团队的背景、数据的情况、组织分工等进行综合考虑，最终选择一个适合自己团队的方案。</p>
<p>如何能做好数据仓库甚至数据平台呢？这还需要团队一起努力，保持信息透明，经常思考总结，遇到问题时多方探索，大家都本着精益求精的求索精神，才能做好这件事。</p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>数据平台</tag>
      </tags>
  </entry>
  <entry>
    <title>成为高效的程序员</title>
    <url>/2021/03/27/programmer-efficiency/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h2 id="一个故事"><a class="markdownIt-Anchor" href="#一个故事"></a> 一个故事</h2>
<p>最近有一次我观察项目组中一位经验较浅的小伙伴写代码，发现：</p>
<ol>
<li>快捷键用得少，缺乏一点去研究快捷键的意识</li>
<li>自动补全功能没有充分利用，基本靠记忆+手敲</li>
<li>使用mac笔记本自带的并不好用的键盘</li>
</ol>
<p>这带来的结果就是手上的速度跟不上思维的速度。</p>
<span id="more"></span>
<h2 id="高效开发的起点打字速度和快捷键"><a class="markdownIt-Anchor" href="#高效开发的起点打字速度和快捷键"></a> 高效开发的起点：打字速度和快捷键</h2>
<p>常常记起，与我的buddy在一个项目组时，他常常会提醒我们如何高效的做开发。比如：手速。他推荐并常常组织我们在一个练习打字速度的应用上面练习和比赛。</p>
<p>快捷键的使用更是Thoughtworks开发人员的传统强项，与有经验的TWer pair开发就能体会到如何完全不用鼠标而把键盘敲到飞起带来的超高编程效率。TDD、重构、格式调整等等我们日常的开发动作在高效的快捷键使用下更是相得益彰。</p>
<p>我曾经在一个客户的咨询项目上，有一个客户的开发同学，见面就聊到说他也来参加过Thoughtworks的面试，但是最后没有进来。这位同学提到这件事显得很不服气，说他了解到没有进来的原因之一居然是快捷键用的不熟，而且很自以为是的补充说：快捷键跟开发能力有什么关系？介于他是客户方的人，我没有当面的跟他争论，但是其实当时我就在心底里暗道：还好没进TW！</p>
<p>快捷键的确不是衡量一个好的开发人员的唯一标准，但是快捷键的灵活使用是一个高效开发人员的重要标志。作为一个开发人员，虽然不必刻意追求打字速度和快捷键使用，但是至少应当心向往之才是。</p>
<p>与此相关的，我不禁又想到咱们的老TWer熊节的课程《学会TDD，十倍提升编程效率》。只有TDD可能并不能十倍提升效率，但是TDD结合超快的打字速度和熟练的快捷键使用，就很有可能了。</p>
<h2 id="高效开发的故事"><a class="markdownIt-Anchor" href="#高效开发的故事"></a> 高效开发的故事</h2>
<p>高效的开发者是可以快速完成很多事情的。我自认为不算一个特别高效的开发人员，但是我可以列举一下曾经做过的一些个人认为还算高效的事情，可以供大家参考。</p>
<h3 id="happy-bird-的实现"><a class="markdownIt-Anchor" href="#happy-bird-的实现"></a> Happy Bird 的实现</h3>
<p>在14年的时候，我想转型做游戏开发。当时的背景是以后端开发为主，也偶尔兼职做一些前端的小功能。于是我找了一个周末，研究了一下iOS的开发。正巧当时有一个小游戏<code>Flappy Bird</code>，挺火的，但是游戏设定又比较难。好吧，那就试试看重新实现一下这个游戏，调整一下难度吧。于是，我花了不到两天的时间做了一个<code>Happy Bird</code>出来，设置难度之后，可以轻松的玩很长时间。</p>
<p>怎么做的呢？大致有这三个步骤：</p>
<ol>
<li>Root一下我手上的iPad，下载安装好<code>Flappy Bird</code>，找到其安装程序路径，把它的资源文件拿出来。</li>
<li>研究iOS上面的动画开发，看了几个小例子</li>
<li>编写代码实现<code>Happy Bird</code></li>
</ol>
<p>核心的代码在这里，有兴趣的小伙伴可以看看：<a href="https://github.com/gmlove/happybird/blob/master/Classes/HelloWorldScene.cpp">https://github.com/gmlove/happybird/blob/master/Classes/HelloWorldScene.cpp</a></p>
<h3 id="项目中的一些实践"><a class="markdownIt-Anchor" href="#项目中的一些实践"></a> 项目中的一些实践</h3>
<p>最近我觉得也有几个可能值得一提的例子。</p>
<p>我们项目是为客户构建一个企业内部的数据平台，平台基于Horton Works（已与Cloudera合并）的开源的Hadoop发行版HDP构建。</p>
<p>由于HDP毕竟是一个完全开源的产品，直接在客户环境上使用，总还是显得有点不够。缺什么呢？一是一个入口的平台Portal页面，通过这个页面可以导航到具备各项功能的应用中。比如，元数据管理要导航到<code>Atlas</code>，权限管理要导航到<code>Ranger</code>，平台运维要导航到<code>Ambari</code>。</p>
<p>刚开始的时候，项目把优先级安排在了进行数据接入、指标开发等等更具业务价值的地方。于是这个入口页面就一直被搁置了。项目中的dev们由于要经常使用这些工具，大家都需要通过加浏览器书签的方式进行管理。BA PM等角色由于不需要关注这些工具，也没有一个入口可以进入这些工具进行操作，于是项目前期阶段几乎不了解这些工具是干什么和怎么用的。这样一来，由于缺乏这样一个入口界面，数据平台总是没有数据平台的感觉，给人的印象是一堆散落在各个地方的工具，没有体系化。同时，这造成了整个团队信息共享不畅，效率降低。</p>
<p>我观察了这个现象，感觉得做点什么。</p>
<p>我开始评估了一下。我们如果把这个页面对应的故事优先级提高，对项目整体安排是不利的，这是其一。其二是，就算把这个优先级调高了，按照我们的敏捷项目管理和实践，要完成这个，需要经历BA的业务分析，UX的界面设计，DEV的估点，最后才能到开发。整个流程下来周期比较长，为了这么简单一个页面，似乎并不值得。</p>
<p>于是，我找了一张故事卡，感觉这个故事卡做完，和预估的开发时长相比会有一些空间。好吧，说干就干，我利用了这一点空间，使用还算比较熟悉的Ant前端组件库，基于React框架，参考Ant的应用样例设计，做了一个静态的页面。这个页面做完，总用时差不多是3个小时，包括代码库初始化，找图，样式微调，把各个工具的通过菜单组织到一起，编写运维脚本，通过nginx进行静态部署等操作。</p>
<p>这个portal页面大概长成下面这样:</p>
<p><img data-src="/attaches/2021/2021-03-27-programmer-efficiency/portal.png" alt="platform portal" /></p>
<p>完成之后，我把这个页面发到项目组的群里面，让大家体验。最终的效果可能未必能给大家带来多大的效率提升，但是这个MVP的页面在我看来对项目的推进起到了很好的作用。一是辅助进行了ShowCase，让客户看到了我们整个数据平台是一个体系化的平台。二是成为了Portal页面设计的参考原型，为BA设计这个页面提供了参考。三是方便了大家知道和查找相应的工具。</p>
<p>上面的例子中，产出并不多且不显眼，而内容还稍微有点长，大家读下来可能会觉得有点累。但是项目中的事情总是复杂的，有很多的背景，不仅要考虑客户的感受，还要考虑如何有智慧的与团队其他人员合作，可能未必能有自己独立自由的做一些开发工作来得简单和自在。其中的原因相信大家也可以理解。</p>
<p>除了上面的例子，还有很多其他例子，比如:</p>
<ul>
<li>我们实现了一个自动生成etl代码的工具</li>
<li>我们用hexo把数据标准的excel文档转换为一个静态网站</li>
<li>我们用mkdocs来快速制作数据平台的使用文档</li>
<li>我们利用squid反向代理解决了客户需要访问很多台节点带来的复杂网络配置问题</li>
<li>我们配置了es搜集了squid日志以便可以进行完整的用户行为分析</li>
<li>我们将etl的统计数据发送到es以便我们可以更简单的做出一些必要的etl任务报表给大家诊断问题提高效率</li>
<li>我们用docker来隔离开发人员的Hadoop集群使用环境</li>
<li>…</li>
</ul>
<h2 id="敏捷与高效开发"><a class="markdownIt-Anchor" href="#敏捷与高效开发"></a> 敏捷与高效开发</h2>
<p>上面这些东西很多看起来并不是直接的具备业务价值的，在做这些事情之前，其实也很难去规划出这么多的故事卡，所以可能难以通过敏捷的项目管理来实现。</p>
<p>那它们是怎么实现的呢？我认为是另一种敏捷的形式，并不是Scrum敏捷项目管理，而是从开发人员的视角出发的一种敏捷。由高效的开发人员，通过对于效率的不懈追求，充分利用各种可以利用的技术，不断重构，既包括代码的也包括工作方式的重构，自发的构建出的一套系统。</p>
<p>这并不奇怪，如果我们去翻看敏捷的起源，就会发现敏捷其实是由一些优秀的开发人员，通过思考总结提炼，把高效的习惯沉淀下来而成的。我们从敏捷前辈大师们的大作中就能看出这些，如Martin Fowler的《重构》，Neal Ford的《卓有成效的程序员》、《函数式编程思维》，Eric Evans的《DDD》，Kent Beck的《XP极限编程》等等。大师们对于细节的不苟，对于高效的执着，对于软件艺术的追求，是这些大力推动了软件开发的变革。</p>
<p>同时，如果我们去看github或者apache下的诸多开源软件，我相信这些软件的雏形或者MVP多是由某些开发人员为提高效率而自发开发的。特别是在前期，这些软件是很难由某一个较为完整的团队组织起来开发而成。</p>
<p>当然这里并不是否定Scrum的价值，在一个敏捷团队中，Scrum的团队管理思路当然也是很有效的。</p>
<h2 id="最后"><a class="markdownIt-Anchor" href="#最后"></a> 最后</h2>
<p>讲了这么多，作为一个十年从业经验的开发人员，同时作为一个五年的TWer，其实是想给广大开发人员分享一下这些经验。希望我们可以一直保持对高效的软件开发的追求，对不断提升自己的追求，对软件艺术的追求，对用软件技术为客户创造价值的追求。</p>
<p>最后，还有一个有意思的故事给大家分享。有一次，我们的BA同学给大家做读书分享，提到了一本不赞成敏捷实践的书，里面讲到，他们的工作方式是：1. 提出一个大的愿景 2. 让2-3个开发人员组成一个小组基于这个愿景来做开发 3. 利用1-2个月的时间产出一个可用的产品。在他们看来，这一方式是比当前的我们做的敏捷更为高效的软件开发方式。不知道大家是怎么看的，我印象很深的是另一个经验丰富的项目组成员的话：对于一些经验特别丰富的人，特别厉害的人，任何规则都是无效的，只能降低效率，而提供一个环境让他们独立的以自己的方式做事，就足够让他们做出一些令人惊奇的软件了！</p>
<h2 id="材料"><a class="markdownIt-Anchor" href="#材料"></a> 材料</h2>
<p>对于想练习自己的打字速度的同学，可以参考这个工具：<a href="https://dazi.kukuw.com/">https://dazi.kukuw.com/</a> 我在上面第一次打字速度如下，相信大家可以轻易超越，特别是年轻的小伙子们，大家手速一定不一般。</p>
<p><img data-src="/attaches/2021/2021-03-27-programmer-efficiency/typing.png" alt="typing speed" /></p>
]]></content>
      <categories>
        <category>心态</category>
        <category>敏捷</category>
      </categories>
      <tags>
        <tag>效率</tag>
        <tag>工具</tag>
        <tag>编程思想</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB数据接入实践</title>
    <url>/2021/02/22/data-ingestion-from-mongo/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>把数据导入数据平台是挖掘数据价值的第一步，如果做不好，数据分析将受到很大影响。所以，快速、高质量、稳定的将数据从业务系统接入到数据平台是至关重要的一环。</p>
<p>数据平台最常见的一个数据源是关系型的数据库，然而随着软件技术的发展，越来越多的业务系统基于非关系型数据库开发，所以，非关系型数据库的数据接入时数据平台必备的能力之一。</p>
<p>我们的数据仓库基于<code>Hive</code>构建，<code>Hive</code>的设计可以很好的兼容关系型数据库，如果数据源是关系型数据库，数据接入会相对容易。如何从非关系型数据库中接入数据呢？这里面有没有什么经验值得分享呢？</p>
<span id="more"></span>
<p>我们项目最近就碰到这种情况，需要接入一个业务数据库的数据，这些数据存储在<code>MongoDB</code>中。本文将就非关系型数据库接入数据平台分享一些我们实践中的一些故事和经验。</p>
<h2 id="mongodb的特点"><a class="markdownIt-Anchor" href="#mongodb的特点"></a> MongoDB的特点</h2>
<p><img data-src="/attaches/2021/2021-02-22-data-ingestion-from-mongo/mongo.png" alt="mongo" /></p>
<p>先了解一下<code>MongoDB</code>的特点。<code>MongoDB</code>是一个流行的文档型数据库，内部的一条数据也称为一个文档。<code>MongoDB</code>是<code>NoSQL</code>数据库的一个典型代表，与关系型数据库相比，有如下特点：</p>
<ul>
<li>支持嵌套类型的字段，比如数组类型字段、字典类型字段，其中字典下又可以嵌套其他字典或数组</li>
<li>非常容易的添加新字段，添加字段时，如果旧数据只需要有一个默认值，则无需数据迁移，在程序中设置默认值即可</li>
<li>可自动生成带排序特性的<code>ID</code></li>
<li>通过对<code>ID</code>进行<code>hash</code>，可以很容易的支持分布式扩展</li>
<li>多文档、多表间的事务一致性不容易保证</li>
</ul>
<p>从上面的分析可以看出，作为<code>NoSQL</code>数据库的代表，<code>MongoDB</code>在易用性上有不错的优势，它支持更广泛的数据结构，扩展起来非常方便。这些大概是它得以流行的原因。</p>
<h2 id="使用spark读取mongodb数据"><a class="markdownIt-Anchor" href="#使用spark读取mongodb数据"></a> 使用Spark读取MongoDB数据</h2>
<p>如何将<code>MongoDB</code>的数据接入<code>Hive</code>呢？经过上面的分析可知，我们首先要解决的问题就是数据在<code>Hive</code>中要以什么样的结构存储的问题。</p>
<p>查阅<code>Hive</code>的文档可以知道，<code>Hive</code>其实也可以支持嵌套的数据结构。<code>Hive</code>的某一个字段可以是数组类型或<code>Map</code>类型，<code>Map</code>下也可以嵌套<code>Map</code>或数组。这是一个非常有吸引力的特性，看起来与<code>MongoDB</code>支持的数据结构可以进行无缝转换。</p>
<p>在项目中，我们也首先进行了这样的尝试，将<code>MongoDB</code>的<a href="https://docs.mongodb.com/spark-connector/current/">Spark连接器</a><code>jar</code>包加入到<code>Spark</code>的<code>classpath</code>下就可以使用<code>Spark</code>读取<code>MongoDB</code>的数据了。</p>
<h3 id="数据类型问题"><a class="markdownIt-Anchor" href="#数据类型问题"></a> 数据类型问题</h3>
<p>我们的数据源中最复杂的一张表有大约100个字段，超过1000w数据量。事实上，在读取这张表时却不尽如人意，程序总是运行到一定的时候就报错<code>java.lang.IllegalArgumentException: Can't parse category at ...</code>，看起来是由于<code>Spark</code>不能正确的将读取到的数据解析到之前预设的结构上。</p>
<p>经过一番研究之后，我们了解到，如果使用<code>Spark</code>的<code>DataFrame</code> <code>API</code>读取数据，在读之前就需要指定数据类型。<code>MongoDB</code>的数据类型如何确定呢？查阅<code>MongoDB</code>的文档可知，这是通过以下步骤完成的：</p>
<ul>
<li><code>Spark</code>连接器会先进行文档抽样</li>
<li>解析每个抽样文档可以得到一系列的文档结构</li>
<li>合并所有的结构得到来组合成为一个最终结构</li>
</ul>
<p>到这里，上面的错误就很清楚了。抽样结果不会覆盖到所有文档，一旦有某一个文档的结构不能兼容抽样得到的结构，<code>Spark</code>程序就会出错。</p>
<p>如何修复这个错误呢？我们可以提高抽样比例，但是这样一来，有几个可能的副作用：</p>
<ul>
<li>数据读取过程更慢</li>
<li>给业务系统数据库造成更大的压力</li>
<li>新数据如果使用了更新的结构依然可能报错</li>
</ul>
<p>虽然不是一个好的方案，我们还是进行了尝试，毕竟改个参数没什么成本。然而，在尝试了多组抽样率参数也没有带来很好的效果。</p>
<h2 id="探索其他方案"><a class="markdownIt-Anchor" href="#探索其他方案"></a> 探索其他方案</h2>
<p>看起来我们低估了从<code>MongoDB</code>进行数据接入的难度啊。</p>
<p>如何解决这个问题呢？有两个办法可以继续尝试：</p>
<ul>
<li>将错误数据反馈给业务系统，以便从源头解决问题</li>
<li>读数据时忽略出错的数据</li>
</ul>
<p>第一个方案不是一个好的方案，因为会引入额外的人工流程，数据接入没法自动化稳定的完成。这将带来巨大的维护成本，可以想象，我们需要隔三差五的找业务系统的开发团队反馈问题，等他们问题修复了，我们再重新接入数据。不仅人力成本协作成本都很高，而且想要每天稳定的输出指标基本上不可能了，随机的数据接入失败会导致随机的指标输出失败。</p>
<p>第二个方案我们也调研了一段时间，然而结论是需要修改<code>MongoDB</code>的Spark连接器才能实现。这里并没有一个相关参数可以让我们忽略读取数据过程中的错误！</p>
<p>这时，<code>MongoDB</code>的数据接入几乎陷入僵局。上面这个问题实际上更为严重，因为被我们捕捉到的只是一个特例，类似的错误可能还很多，比如<code>Spark</code>读取到的结构显示某一个字段应该是数字，但却读取到了一个字符串，或者显示是数组的却读取到了一个字典等等。这样的数据类型不匹配的情况实在太多了，几乎无法穷举。这就让这种方式存在极大的不确定性。</p>
<h2 id="使用elt的方式读取mongodb数据"><a class="markdownIt-Anchor" href="#使用elt的方式读取mongodb数据"></a> 使用ELT的方式读取MongoDB数据</h2>
<p>如何解决这个棘手的问题呢？讨论了很久，最后我们转换了一下思路。在大数据下进行数据处理时，除了大家都非常熟悉的<code>ETL</code>，不是还有一种实践是<code>ELT</code>么？我们能不能这样做呢：</p>
<ul>
<li>在接入时直接保存原始文档不进行<code>schema</code>解析</li>
<li>在使用数据时根据需要进行解析</li>
</ul>
<p>这正是<code>ELT</code>的数据处理方式，先<code>extract</code>提取数据，然后并不进行<code>transform</code>操作，而是直接通过<code>load</code>将数据存下来，最后在使用数据时执行<code>transform</code>解析数据。</p>
<p><code>MongoDB</code>作为一款成熟的数据库，数据读取应该不是难事，我们可以使用<code>python</code>将数据读取出来存为<code>json</code>文件（实际上是按行存储的<code>json</code>文件，每行对应一条<code>json</code>格式的数据），然后用<code>Spark</code>读取文件写入到<code>Hive</code>。</p>
<h3 id="日期数据问题"><a class="markdownIt-Anchor" href="#日期数据问题"></a> 日期数据问题</h3>
<p>使用<code>pymongo</code>客户端库，可以用<code>python</code>读取<code>MongoDB</code>的数据。我们一开始以为这样的方案应该可以很顺利的完成。没想到还是有一些意外。在读完数百万的数据之后，突然程序报错，日期无法解析，错误消息类似<code>bson.errors.InvalidBSON: year 20215 is out of range</code>。很奇怪的错误，有一个错误的日期成功的写入了<code>MongoDB</code>，但是无法正确读取。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mongo_client = MongoClient(<span class="string">&#x27;mongodb://NAME:PASS@HOST:29017/test.test?authSource=admin&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> mongo_client[<span class="string">&#x27;test&#x27;</span>][<span class="string">&#x27;test&#x27;</span>].find(&#123;<span class="string">&#x27;_id&#x27;</span>: ObjectId(<span class="string">&#x27;xxx&#x27;</span>)&#125;):</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[<span class="built_in">test</span>@<span class="built_in">test</span> mongo-test]<span class="comment"># python3 test-mongo.py</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;test-mongo1.py&quot;</span>, line 6, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> coll.find(&#123;<span class="string">&#x27;_id&#x27;</span>: ObjectId(<span class="string">&#x27;xxx&#x27;</span>)&#125;):</span><br><span class="line">  File <span class="string">&quot;/usr/local/lib/python3.7/site-packages/pymongo/cursor.py&quot;</span>, line 1207, <span class="keyword">in</span> next</span><br><span class="line">    <span class="keyword">if</span> len(self.__data) or self._refresh():</span><br><span class="line">  ...</span><br><span class="line">  File <span class="string">&quot;/usr/local/lib/python3.7/site-packages/bson/__init__.py&quot;</span>, line 1089, <span class="keyword">in</span> _decode_all_selective</span><br><span class="line">    <span class="built_in">return</span> decode_all(data, codec_options)</span><br><span class="line">bson.errors.InvalidBSON: year 20215 is out of range</span><br></pre></td></tr></table></figure>
<p>我们尝试把出问题的数据找出来看看。使用<code>MongoDB</code>的<code>cli</code>工具连接数据库，可以执行查询。但是由于错误信息很少，我们花费了一番工夫才真正找到出问题的数据。原来是这个字段存储的不是业务合法的日期，而是一个错误日期！</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&gt; db.test.findOne(&#123;<span class="string">&quot;_id&quot;</span>:ObjectId(<span class="string">&quot;xxx&quot;</span>)&#125;)</span><br><span class="line">&#123; <span class="string">&quot;_id&quot;</span> : ObjectId(<span class="string">&quot;xxx&quot;</span>), <span class="string">&quot;someDate&quot;</span> : ISODate(<span class="string">&quot;20215-11-30T23:00:00Z&quot;</span>) &#125;</span><br></pre></td></tr></table></figure>
<p>经过一番调查，有了结论，原来使用<code>java</code>客户端可以成功将此类日期写入<code>MongoDB</code>，因为在<code>java</code>中这个日期是一个合法的日期。<code>MongoDB</code>使用<code>bson</code>格式进行数据存储，同样可以合法的存储此类日期。但是<code>python</code>无法读取此日期，因为<code>python</code>读取到<code>bson</code>的<code>date</code>之后，会将其转化为<code>python</code>的<code>datetime</code>对象，而<code>python</code>的<code>datetime</code>要求<code>year</code>值必须在1到9999之间。</p>
<h3 id="尝试解决日期数据问题"><a class="markdownIt-Anchor" href="#尝试解决日期数据问题"></a> 尝试解决日期数据问题</h3>
<p><code>MongoDB</code>的数据接入之路真是有点曲折。如何解决这个问题呢？我们可以循环读取数据，捕捉这类异常，然后跳过异常数据继续往下读取。</p>
<p>于是我们编写如下代码，在遇到错误的时候打印对应的错误文档<code>id</code>，然后继续。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">cursor: Cursor = coll.find(query_condition).sort(<span class="string">&#x27;_id&#x27;</span>, -<span class="number">1</span>)</span><br><span class="line">i = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        doc: <span class="type">Dict</span> = cursor.<span class="built_in">next</span>()</span><br><span class="line">        doThingsWith(doc)</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        logger.info(<span class="string">&#x27;read data finished. %s/%s&#x27;</span>, i, count)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">except</span> BSONError <span class="keyword">as</span> e:</span><br><span class="line">        cursor.close()</span><br><span class="line">        <span class="comment"># find out the error doc by read the doc._id only</span></span><br><span class="line">        cursor = coll.find(query_condition, &#123;<span class="string">&#x27;_id&#x27;</span>: <span class="number">1</span>&#125;).sort(<span class="string">&#x27;_id&#x27;</span>, -<span class="number">1</span>)</span><br><span class="line">        bad_doc: <span class="type">Dict</span> = cursor.skip(i).<span class="built_in">next</span>()</span><br><span class="line">        <span class="built_in">print</span>(bad_doc)</span><br><span class="line">        cursor.close()</span><br><span class="line">        <span class="comment"># skip the error doc and continue reading</span></span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        <span class="comment"># when a BSONError occurred, the cursor will stop, in this case we should continue read the docs left.</span></span><br><span class="line">        cursor: Cursor = coll.find(query_condition).sort(<span class="string">&#x27;_id&#x27;</span>, -<span class="number">1</span>).skip(i)</span><br></pre></td></tr></table></figure>
<p>在满以为可以正常运行的时候，又遇到了新的问题。在<code>MongoDB</code>的客户端里可以根据错误文档的id查询到该文档，可是当我们去查看该文档的时候，却并没有发现错误的数据。该文档对应的数据是正常的！这是为什么？？？</p>
<h3 id="再次尝试解决日期数据问题"><a class="markdownIt-Anchor" href="#再次尝试解决日期数据问题"></a> 再次尝试解决日期数据问题</h3>
<p>没办法了，只能研究研究<code>pymongo</code>库的源代码了。仔细读了一下<code>API</code>的参数，发现一个可疑的地方，读取数据的<code>API</code>里面有一个参数<code>batch_size</code>，默认值情况将返回不多于101个文档或1MB的数据大小。这么说来，<code>pymongo</code>在读取数据的时候是批量读取的，这应该可以提升不少性能。在读取到一批数据之后，<code>pymongo</code>会开始进行数据解析，转化为<code>python</code>的数据结构，此时如果这一批数据中某一条数据有问题，则会触发异常。原来如此，所以我们之前打印的错误文档的<code>id</code>并不是真正的错误文档的<code>id</code>，而是该批次文档的第一个文档的<code>id</code>！</p>
<p>有了这个认识，我们可以使用如下流程来读取数据：</p>
<ul>
<li>用较大批次读取数据</li>
<li>在遇到错误的时候，将批次大小改为1，并跳过错误的文档</li>
<li>将批次大小改回原来的值继续读取其他文档</li>
</ul>
<p>参考代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">cursor: Cursor = coll.find(query_condition).sort(<span class="string">&#x27;_id&#x27;</span>, -<span class="number">1</span>).batch_size(batch_size)</span><br><span class="line">i = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        doc: <span class="type">Dict</span> = cursor.<span class="built_in">next</span>()</span><br><span class="line">        doThingsWith(doc)</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        logger.info(<span class="string">&#x27;read data finished. %s/%s&#x27;</span>, i, count)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">except</span> BSONError <span class="keyword">as</span> e:</span><br><span class="line">        cursor.close()</span><br><span class="line">        <span class="keyword">if</span> batch_size == <span class="number">100</span>:</span><br><span class="line">            <span class="comment"># set batch_size to 1 and continue reading to try find which doc raises error</span></span><br><span class="line">            batch_size = <span class="number">1</span></span><br><span class="line">            cursor: Cursor = coll.find(query_condition).sort(<span class="string">&#x27;_id&#x27;</span>, -<span class="number">1</span>).skip(i).batch_size(batch_size)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># find out the error doc by read the doc._id only</span></span><br><span class="line">            cursor = coll.find(query_condition, &#123;<span class="string">&#x27;_id&#x27;</span>: <span class="number">1</span>&#125;).sort(<span class="string">&#x27;_id&#x27;</span>, -<span class="number">1</span>)</span><br><span class="line">            bad_doc: <span class="type">Dict</span> = cursor.skip(i).<span class="built_in">next</span>()</span><br><span class="line">            cursor.close()</span><br><span class="line">            <span class="built_in">print</span>(bad_doc)</span><br><span class="line">            <span class="comment"># skip the error doc and continue reading</span></span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            <span class="comment"># when a BSONError occurred, the cursor will stop, in this case we should continue read the docs left.</span></span><br><span class="line">            cursor: Cursor = coll.find(query_condition).sort(<span class="string">&#x27;_id&#x27;</span>, -<span class="number">1</span>).skip(i).batch_size(<span class="number">100</span>)</span><br><span class="line">            batch_size = <span class="number">100</span></span><br></pre></td></tr></table></figure>
<p>经过了重重困难之后，终于可以比较稳定的读取<code>MongoDB</code>数据接入了。</p>
<h3 id="其他优化"><a class="markdownIt-Anchor" href="#其他优化"></a> 其他优化</h3>
<p>后续的工作中，我们将错误的文档记录了下来，这可以反馈给业务系统开发人员进行修复。</p>
<p>我们还发现了数据读取超时的问题，这个可以通过重试解决，于是代码里面还多了自动重试一定次数的逻辑。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>回顾整个<code>MongoDB</code>的数据接入流程，可以看到，对于数据类型非常灵活的<code>NoSQL</code>数据库，数据接入并不是件容易的事。</p>
<p>总结起来，有以下经验可能值得大家借鉴：</p>
<ul>
<li>数据接入过程需要保证尽可能的稳定，否则可能由于错过数据接入时机而丢失掉部分历史数据，还可能带来更多的耗时的跨团队协作问题（比如，协调业务系统人员补数）</li>
<li>对于无<code>schema</code>或者<code>schema</code>比较自由的数据库，在接入数据到数据平台时，考虑用<code>json</code>格式存储原始数据，这可以避免在接入数据时进行数据解析带来的问题，使得数据接入过程更稳定</li>
<li>处理数据接入过程中的错误时，考虑将错误对应的数据<code>id</code>保存下来，以便反馈给业务系统修复</li>
</ul>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>数据平台</tag>
      </tags>
  </entry>
  <entry>
    <title>数据应用开发语言和环境</title>
    <url>/2021/04/01/data-development-language-and-environment/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2021/2021-04-01-data-development-language-and-environment/structure.png" alt="data development language and environment" /></p>
<p>在数据进入到数据平台之后，我们就可以正式开始构建数据应用了。一个常见的数据应用是数据报表和数据指标的开发。如何开发这样的数据应用呢？首先要决定的就是使用什么样的开发语言及如何构建开发环境。本文将结合我们的实践经验一起聊一聊这个话题。</p>
<span id="more"></span>
<h2 id="数据计算框架"><a class="markdownIt-Anchor" href="#数据计算框架"></a> 数据计算框架</h2>
<p>在基于<code>Hadoop</code>的分布式数据平台的场景下，当前最流行的数据计算框架要算<code>Spark</code>了，相比<code>Hive</code>，它提供了更为可控的也更灵活的编程过程。根据需要，我们可以在<code>Spark</code>程序中随时获取到某一个计算结果，然后根据此结果进行后续计算，而<code>Hive</code>要想要实现这样的灵活性，可能不得不借助临时表或其他语言来充当驱动器程序了。</p>
<p>同时，由于<code>Spark</code>在设计之初就声明了兼容<code>Hive</code>，所以，我们完全可以把<code>Spark</code>和<code>Hive</code>联合起来使用。<code>Hive</code>用于在数据分析时随时执行<code>sql</code>查询，<code>Spark</code>用于将数据计算任务工程化。</p>
<p>我们在<a href="http://brightliao.com/2021/03/16/data-modeling-practice/">前面的文章</a>中提到了数据仓库<code>DWD</code>层的构建，这一层的构建就可以通过<code>Spark</code>来实现。<code>Spark</code>同时提供了编程的<code>DataFrame</code>接口和<code>sql</code>接口，支持<code>Java</code>、<code>Scala</code>、<code>Python</code>、<code>R</code>等编程语言。</p>
<h2 id="数据开发语言"><a class="markdownIt-Anchor" href="#数据开发语言"></a> 数据开发语言</h2>
<p>应该选择什么样的接口进行数据开发呢？我们会建议主要使用<code>sql</code>而不是基于<code>DataFrame</code>的<code>API</code>，主要理由是：</p>
<ul>
<li><code>sql</code>是数据分析的通用语言，团队大部分人可以看懂<code>sql</code>，而要看懂<code>Scala</code>或<code>Python</code>代码则需要具备更多的编程知识</li>
<li><code>DataFrame</code> <code>API</code>可以和<code>sql</code>语法对应，使用<code>sql</code>也不会过多丢失<code>DataFrame</code> <code>API</code>的灵活性</li>
<li><code>sql</code>是独立于计算引擎存在的，如果以后希望替换计算引擎，可以更容易实现（比如，<code>Presto</code>是查询性能更好的一个<code>OLAP</code>引擎，将来可以考虑替换底层计算引擎为为<code>Presto</code>）</li>
</ul>
<h3 id="sql的缺点及应对"><a class="markdownIt-Anchor" href="#sql的缺点及应对"></a> sql的缺点及应对</h3>
<p>很多人会吐槽<code>sql</code>开发的缺点。究其原因，是由于<code>sql</code>是声明式的语言，需要先定义再执行，且执行过程不能中断。这样一来，直接使用原生的<code>sql</code>来编写复杂代码可能会十分不便。比如以下这些场景。</p>
<p>考虑需要进行流程控制的场景。比如，在数据量很大的情况下，一般需要调整分区数才可以更高效的并行执行。此时，我们需要在执行<code>sql</code>之前先判断数据量。如果直接用<code>sql</code>，这一过程将不容易实现。如果依赖调度工具进行这种流程判断又显得大材小用。</p>
<p>考虑需要使用变量的场景。比如，我们需要根据指定的日期进行指标计算。如果直接使用<code>sql</code>，我们可能要考虑先将此日期写入到一张临时数据表中，十分不便。</p>
<p>考虑需要重复多次的代码。比如，在空调销售的场景，我们需要同时按日计算销量指标，也需要按月计算销量指标（考虑到取消订单的情况，两者无累加关系，需要单独实现），这两个指标的大部分逻辑是相同的。使用原生的<code>sql</code>，将难以复用这些相同的计算逻辑。</p>
<p>如何应对上面这些问题呢？相信大家心里已经有答案了，那就是进行<code>sql</code>语言的增强。其实，我们只需要实现一个简单的<code>sql</code>执行器就可以解决上提到的大部分问题。</p>
<h3 id="增强sql语法"><a class="markdownIt-Anchor" href="#增强sql语法"></a> 增强<code>sql</code>语法</h3>
<p>针对上面的三个场景，我们可以为<code>sql</code>语言添加这些特性：变量、控制语句、模板。</p>
<p>这样增强后的<code>sql</code>可以编写成什么样子呢？采用<code>TDD</code>的思路，我们可以先写个测试，通过编写测试来辅助设计我们所期望的增强<code>sql</code>的使用方式。</p>
<p>考虑支持变量和控制语句，这样的测试<code>sql</code>可以编写如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="comment">-- 将下面这个sql生成的结果集保存为变量</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> a, <span class="number">2</span> <span class="keyword">as</span> b, <span class="literal">true</span> <span class="keyword">as</span> should_transform;</span><br><span class="line"><span class="comment">-- target=temp.source</span></span><br><span class="line"><span class="comment">-- 读取数据，保存为一个临时的表（Spark的TempView）</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> some_table;</span><br><span class="line"><span class="comment">-- target=temp.source, if=$&#123;should_transform&#125;</span></span><br><span class="line"><span class="comment">-- 下面的sql将根据$&#123;should_transform&#125;变量的值有选择性的执行</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span>, $&#123;a&#125; <span class="keyword">as</span> a, $&#123;b&#125; <span class="keyword">as</span> b <span class="keyword">from</span> source;</span><br><span class="line"><span class="comment">-- target=hive.some_db.result</span></span><br><span class="line"><span class="comment">-- 将数据写入到Hive数据表some_db.result</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> source;</span><br></pre></td></tr></table></figure>
<p>针对上面的增强<code>sql</code>语法实现一个驱动器程序应当不是难事。以下是驱动器实现的大致思路：</p>
<ul>
<li>匹配字符串<code>-- target=</code>，根据不同的值，执行不同的操作，如果<code>target</code>有<code>if</code>条件，则判断其取值，如果为<code>false</code>则跳过此步骤</li>
<li>如果当前<code>target</code>为<code>variables</code>，驱动器应该执行<code>sql</code>，并将结果集保存为一个字典，作为后续代码的变量上下文</li>
<li>如果是<code>temp.xxx</code>，替换<code>sql</code>中的变量，执行<code>sql</code>，将结果保存到名为<code>xxx</code>的<code>tempview</code>中</li>
<li>如果是<code>hive.xxdb.xxtable</code>，替换<code>sql</code>中的变量，执行<code>sql</code>，将结果保存到名为<code>xxtable</code>的<code>Hive</code>数据<code>xxdb</code>中</li>
</ul>
<p>模板可以很好的解决代码重复问题，如何支持模板呢？可以编写一个测试<code>sql</code>如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- target=template.a</span></span><br><span class="line"><span class="comment">-- 将下面的sql片段保存为模板a</span></span><br><span class="line"><span class="number">1</span> <span class="keyword">as</span> a, <span class="number">2</span> <span class="keyword">as</span> b</span><br><span class="line"><span class="comment">-- target=temp.result</span></span><br><span class="line"><span class="comment">-- 读取数据，保存为一个临时的表（Spark的TempView）</span></span><br><span class="line"><span class="keyword">select</span> @&#123;a&#125;, <span class="operator">*</span> <span class="keyword">from</span> some_table;</span><br></pre></td></tr></table></figure>
<p>支持上述测试的驱动器实现的大致思路是：</p>
<ul>
<li>匹配字符串<code>-- target=</code>，根据不同的值，调用不同的函数</li>
<li>如果是<code>template.xxx</code>，将内容保存下来，作为后续代码的模板上下文</li>
<li>对于其他类型的<code>target</code>，比如<code>hive</code>或<code>temp</code>，执行<code>sql</code>之前先进行模板替换</li>
</ul>
<p>（上面的测试用例只是覆盖了很小的一部分正常场景，要实现一个完整的驱动器，还需要定义更多的边界场景）</p>
<p>有了这个驱动器，相信前面提到的<code>sql</code>的缺点就不再是缺点了。这个增强版本的<code>sql</code>可以应对大部分的场景。在我们的实践过程中，还增加了一些其他的有用的特性，比如：</p>
<ul>
<li>支持在变量中进行<code>Python</code>函数调用，以便可以扩展任意复杂的逻辑</li>
<li>支持<code>target</code>值为<code>func.a(arg1, arg2, ...)</code>，当发现此类语法时，不执行<code>sql</code>，而是调用这个函数，这可以很容易的将<code>Spark</code>中的一些有用的函数暴露出来</li>
<li>支持在模板中定义参数和引用变量</li>
</ul>
<h3 id="第二语言"><a class="markdownIt-Anchor" href="#第二语言"></a> 第二语言</h3>
<p>在决定使用<code>sql</code>作为第一语言之后，我们还需要考虑数据开发的第二语言。比如上述<code>sql</code>驱动器应该选择什么语言来实现呢？</p>
<p><code>Spark</code>支持得最好的语言是<code>Scala</code>和<code>Python</code>。<code>Spark</code>本身是使用<code>Scala</code>开发而成，所以二者有着无缝的互操作性。<code>Python</code>拥有庞大的数据分析师用户群体，为支持大规模数据分析而设计的<code>Spark</code>自然要好好支持<code>Python</code>。</p>
<p>在项目中，我们优先选择了<code>Python</code>语言，主要的理由是：</p>
<ul>
<li><code>Python</code>简单易用，无需像<code>Scala</code>一样需要配置复杂的开发环境</li>
<li>依赖包管理更容易实现，如果使用<code>Scala</code>，则常常需要解决<code>Java</code>的依赖包冲突问题（大数据环境下的依赖<code>Jar</code>包太多了）</li>
<li><code>Python</code>上手难度更低，<code>Scala</code>有着较高的学习成本</li>
<li>数据分析师很容易看懂<code>Python</code>代码，团队对代码的熟悉程度更高</li>
</ul>
<p>当然是用<code>Python</code>也有其缺点，比如：</p>
<ul>
<li>性能相对更差，因为<code>Python</code>程序会启动<code>Java</code>进程来运行<code>Spark</code>代码</li>
<li>一些由<code>Java</code>进程抛出的错误不容易理解，也难以对<code>Java</code>代码中进行断点调试</li>
<li>为了能正常运行某些程序，有时需要在所有节点安装<code>Python</code>依赖包</li>
</ul>
<p>相对而言，我们认为<code>Python</code>还是做数据开发的更好的选择。</p>
<p>当然，我们也拥抱<code>Scala</code>语言，一些<code>udf</code>的实现我们会建议使用<code>Scala</code>，主要的考虑是性能更好（无需在两种语言中进行数据的序列化和反序列化）。</p>
<h3 id="通过udfudaf扩展sql"><a class="markdownIt-Anchor" href="#通过udfudaf扩展sql"></a> 通过udf/udaf扩展sql</h3>
<p>另一个扩展<code>sql</code>语法的方式是<code>udf</code>，即自定义函数。</p>
<p>要编写一个<code>Spark</code>的自定义函数是非常简单的。如果代码逻辑比较简单，可能只需要一行代码即可。比如，假设我们要实现一个函数将两个数值相乘，只需要编写<code>Scala</code>代码<code>spark.udf.register(&quot;multi&quot;, udf((a: Double, b: Double) =&gt; a * b))</code>。得益于<code>Scala</code>具备强大的类型系统及类型推断能力，这里的代码才可以如此简洁。</p>
<p>除了<code>udf</code>，<code>Spark</code>还支持<code>udaf</code>扩展，即自定义聚合函数（在<code>Group By</code>聚合统计的场景下使用）。实现自定义聚合函数时，需要略微费事一点。大体上，需要实现<code>reduce</code>函数，把多个值聚合为一个值，然后实现<code>merge</code>函数，将多个<code>reduce</code>的结果合并为一个。</p>
<p>由于我们可以轻易的实现自定义函数和自定义聚合函数，因此，我们可以更多的借助<code>udf/udaf</code>的能力，把一些通用的计算通过<code>udf/udaf</code>进行封装和抽象。从而使得我们的<code>sql</code>代码更为简洁清晰。</p>
<p>前面提到了我们的第二开发语言是<code>Python</code>，那么<code>Scala</code>可以作为我们的第三开发语言，专门用来开发<code>udf/udaf</code>。在这种场景下使用<code>Scala</code>可以很好的提升程序性能，我们将从中获得很多益处。但是<code>Scala</code>程序的开发环境和依赖管理问题依然是比较麻烦的，如何缓解这个问题呢？</p>
<p>我们建立了这样几个原则：</p>
<ul>
<li>一般情况下，只允许引用<code>Spark</code>及其相关的依赖</li>
<li>由于<code>Scala</code>代码并不多，不在团队中统一使用<code>IDE</code>来支持开发，而是通过编写<code>shell</code>脚本来实现<code>Scala</code>代码的编译和打包</li>
<li>通过<code>Web IDE</code>来支持开发中的语法诊断、代码调试等</li>
<li>在<code>Python</code>代码中将<code>udf/udaf</code>注册到<code>Spark</code>，通过在<code>Python</code>的测试用例中测试<code>Sql</code>来达到测试<code>udf/udaf</code>的目的</li>
</ul>
<p>有了这样的原则，我们可以很好的享受到<code>Scala</code>代码带来的好处，同时可以避免<code>Scala</code>带来的工程管理复杂度。</p>
<p>实现<code>Scala</code>代码的编译和打包的<code>shell</code>脚本可以参考如下：</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">SPARK_JAR_PATH=/usr/local/lib/python3.8/site-packages/pyspark/jars/*</span><br><span class="line">SCALA_CP=<span class="string">&quot;$&#123;SPARK_JAR_PATH&#125;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="section">jar:</span></span><br><span class="line">    - rm -r classes</span><br><span class="line">    mkdir classes -pv</span><br><span class="line">    ~/dev/sdks/scala-2.11.12/bin/scalac -cp $&#123;SCALA_CP&#125; -d classes udf/*.scala</span><br><span class="line">    cd classes &amp;&amp; jar -cvf ../dataplat.jar udf</span><br></pre></td></tr></table></figure>
<h2 id="构建开发环境"><a class="markdownIt-Anchor" href="#构建开发环境"></a> 构建开发环境</h2>
<h3 id="任务调度器"><a class="markdownIt-Anchor" href="#任务调度器"></a> 任务调度器</h3>
<p>一个大的数据应用常常会被拆分为很多小的独立的数据计算任务，比如一张报表，里面的每个指标的计算可能对应一个的任务。我们需要一个调度器将这些任务按照依赖关系周期性的调度运行。这些调度任务一般可以组成一个有向无环图，即<code>DAG</code>，我们也把这样的图称作数据流水线。</p>
<p>当前可以使用的开源调度器种类很多，比如<code>Airflow</code>，作为<code>Airbnb</code>开源的任务调度系统，由于其可以使用代码来定义数据流水线且与其他开源生态有很好的集成而深受广大开发者喜爱。</p>
<h3 id="使用makefile实现任务管理"><a class="markdownIt-Anchor" href="#使用makefile实现任务管理"></a> 使用Makefile实现任务管理</h3>
<p>如何将任务集成到调度系统里面呢？一般可以使用<code>Shell</code>命令将任务集成到调度系统。我们会建议使用<code>Makefile</code>先进行一层任务封装，然后再使用<code>Shell</code>命令集成到调度系统。相比直接使用<code>Shell</code>命令进行集成，这一实践有以下几个优势：</p>
<ul>
<li><code>Makefile</code>有任务的概念，可以将要执行的命令组合成一个一个功能更强大的任务，<code>Shell</code>则只能自己编写代码实现</li>
<li><code>Makefile</code>的任务中任意一行命令运行失败将导致任务失败，这使得我们可以更早的感知到失败，从而更早的进行修复，<code>Shell</code>则无此特性</li>
<li><code>Makefile</code>原生就可以在执行中把运行的命令打印出来，从而便于我们诊断问题，<code>Shell</code>则需要手动进行配置</li>
</ul>
<p>除此之外，<code>Makefile</code>作为<code>c/c++</code>的构建工具，使用非常广泛，与<code>Shell</code>一样非常轻量级，容易获取和安装。这使得我们使用<code>Makefile</code>成本很低。</p>
<p>大多数调度系统都提供了除<code>Shell</code>外的其他编程语言的集成，比如<code>Airflow</code>提供了<code>Python</code>代码的集成方式。但我们并不建议使用这一方式进行集成，主要理由是：</p>
<ul>
<li>增加了调度系统和计算任务之间的耦合性，这会带来一些不便，比如，如果要修改任务参数配置，则需要修改流水线才能实现</li>
<li>丢失了中间层的灵活性，比如，如果是<code>Makefile</code>，我们的任务可以随时在<code>Shell</code>中运行，无需依赖任何的调度系统（在调试代码时，这将非常便利）</li>
<li>降低了对调度系统的依赖，这使得调度器在需要时可以很容易的被替换（一般而言，我们可以将大部分参数配置放到<code>Makefile</code>这样的中间层，和调度系统的集成部分将会更少）</li>
</ul>
<h3 id="构建任务运行环境"><a class="markdownIt-Anchor" href="#构建任务运行环境"></a> 构建任务运行环境</h3>
<p><code>Spark</code>程序需要运行在一个支持环境中，随之而来的一个问题就是，我们需要几套环境来支持数据开发、测试及上线运行？</p>
<p>由于分布式环境的构建和管理维护并不是一件容易的事，且常常需要较高的成本投入，我们并不建议去搭建多套集群。当然，如果企业内部有独立的运维团队负责集群的日常管理，那情况会不一样，我们可以根据需要来选择使用几套环境。</p>
<p>在我们看来，一般使用两套集群就可以足够满足数据项目的推进了。一套是用于进行集群配置测试的，可以称为测试环境。另一套用于运行日常的数据任务，同时支持数据开发、测试及生产运行（周期性调度运行），可以称作生产环境。</p>
<p>测试环境可以应对很多集群配置调整的问题，我们可以先在测试环境中从容的进行集群配置的调整和测试，在修改好了之后，再将配置迁移到生产环境。</p>
<p>有人可能会担心一套环境同时用于支持开发、测试及生产运行会带来问题。比如数据的隔离性，数据的安全性，对生产运行的任务的稳定性造成影响等。但是，事实上，集群已经提供了很多的功能来帮助我们解决这个问题。比如：</p>
<ul>
<li>基于<code>Hive</code>的数据仓库，可以建立开发和测试用的数据库，数据生成到这些数据库中，从而更好的与生产运行的数据进行隔离</li>
<li>基于<code>Hive</code>的数据仓库，通过配置权限，可以使得以开发人员的账号运行的任务无法将数据写入到生产运行的数据库，这也实现了与生产运行的数据进行隔离</li>
<li>基于<code>Hive</code>的数据仓库，通过配置权限，可以使得开发人员的账号只能访问到非敏感数据，比如，可以禁止读取某些列，对另一些列用hash处理等</li>
<li>基于<code>Hadoop</code>的分布式计算环境本身就提供了基于队列的任务调度管理。可以设计一个占用资源更少优先级更低的队列供开发测试使用，从而避免对生产运行的任务的稳定性造成影响</li>
</ul>
<p>使用一套集群同时支持开发、测试及生产运行还有以下好处：</p>
<ul>
<li>无需花费额外的集群管理成本（这常常会花费团队大量的精力，而体现的价值却很有限）。</li>
<li>无需进行集群间数据同步和迁移（或测试数据构造），开发和测试可以直接使用生产数据，降低了成本，也提高了效率（如果担心数据量太大的问题，可以在开发测试过程中事先对数据进行抽样；如果担心数据安全问题，可以对开发和测试人员账号配置数据脱敏）。</li>
<li>可以更容易的在开发和测试中发现真实数据中的边界场景，从而编写逻辑更完善的程序。</li>
<li>更重要的是，使用一套集群可以提前发现数据任务中的运行性能问题，这些问题通常难以解决，需要花费大量的时间。提前暴露这样的问题，让我们可以更早的去应对风险，不至于生产运行时发现问题导致手足无措。</li>
</ul>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>本文讨论了在数据应用开发开始之前需要进行的工作，包括进行编程语言的选择和开发环境的构建。这两方面的相关决策将在很大程度上影响后续数据开发的组织和管理。如果决策得当，后续数据开发将能够很轻松的开展起来，否则，则可能将团队带入泥潭。</p>
<p>本文分享了我们在实践过程中的一些思考和选择，这些经验对于我们是很受用的。总结起来，就是：</p>
<ul>
<li>尽量首选<code>sql</code>进行数据开发，其次选择<code>Python</code>，再次<code>Scala</code></li>
<li>扩展<code>sql</code>语法，增强其功能以应对复杂的计算逻辑</li>
<li>使用<code>Makefile</code>与调度系统进行集成</li>
<li>不要构建太多集群环境</li>
</ul>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>数据平台</tag>
      </tags>
  </entry>
  <entry>
    <title>数据仓库建模实践</title>
    <url>/2021/03/16/data-modeling-practice/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2021/2021-03-16-data-modeling-practice/data-modeling.png" alt="data modeling practice" /></p>
<p><a href="http://bright.com/2021/03/15/data-management-practice/">前面的文章</a>中我们讲到了数据仓库。我们都知道，仓库的一般意义是指一个特别大的是用于存放各种物品的库房，所以，数据仓库常常可以给人一个很直观的理解，就是一个可以存放各种数据的大的存储。</p>
<p>在建设数据仓库时，我们常常要对数据进行分层，比如常见分层方式：<code>ODS</code>层-&gt;<code>DWD</code>层-&gt;<code>DWB</code>层-&gt;<code>DM</code>层-&gt;<code>ADS</code>层。</p>
<p>数据仓库建模通常是指<code>DWD</code>层的建模，因为<code>DWD</code>是数据仓库中使用最广泛的数据分层，我们需要尽可能保证这一层的易用性。<code>DWD</code>层的模型很大程度上影响了一个数据仓库项目甚至数据平台项目的成败。本文将针对<code>DWD</code>层数据建模分享一下我们在项目上的实践经验。</p>
<span id="more"></span>
<h2 id="数据仓库基本特征"><a class="markdownIt-Anchor" href="#数据仓库基本特征"></a> 数据仓库基本特征</h2>
<p>开始之前，我们先来了解一下数据仓库的特征。</p>
<p>数据仓库的相关概念最早是由 W. H. Inmon 于90年代提出来的，Inmon也因此被大家认为是数据仓库之父。在Inmon的数据仓库理念里，数据仓库是一个面向主题的（Subject Oriented）、集成的（Integrate）、非易失（Non-Volatile）且时变（Time Variant）的数据集，用于支持管理决策。</p>
<p>面向主题、集成、非易失且时变是数据仓库的四个基本特征。其中，面向主题可以认为是一种面向分析的数据分类和映射；集成的是指将不同的数据源的数据集合到一起以便于分析；非易失可以理解为稳定，是指进入数据仓库的数据不会发生修改；时变是指数据仓库的数据需要保留历史，以便于任何时候回头对数据进行分析。</p>
<h2 id="数据仓库主键"><a class="markdownIt-Anchor" href="#数据仓库主键"></a> 数据仓库主键</h2>
<p>时变这个特征对数据仓库建模提出了最基本的技术上的要求，我们的数据模型要如何建立才可以保留所有历史数据呢？Inmon在《数据仓库》这本书里面提出了一些新的概念，可以帮助我们实现时变这个特点。</p>
<p>首先，每一张数据库表都应当有一个主键，它可以唯一标识一条数据，以便支持数据的查找、更新、关联。这是当前业务系统数据库模型设计的一个基本指导原则。很多数据库设计指导甚至会建议为所有表设计一个自增且无业务含义的字段作为主键。唯一字段主键为数据查询及关联提供了很大的方便。</p>
<p>实际操作中，我们可以认为业务系统的所有数据库表中均存在一个主键，如果没有单一字段主键，也应该有多个字段可以组合成为一个主键。多个字段形成的主键在数据库设计中被称为复合主键。</p>
<p>我们可以向业务系统数据库设计人员了解主键字段是哪些，也可以通过基本的数据分析找出主键（比如，观察表中的非空字段可以辅助发现主键字段）。其实，就算业务系统数据库设计人员告知了我们哪些字段是主键，本着怀疑的态度，我们也应该要从数据层面进行主键验证。通常我们可以通过执行<code>SQL</code>来验证主键，对比多字段唯一计数（<code>count(distinct concat(col1, col2))</code>）和数据库数据总行数（<code>count(*)</code>）的值，如果两者相等，则这些字段可以作为主键字段。</p>
<p>保存数据历史其实就是根据数据主键进行保存，历史数据将包含每一个主键（每一条条数据）对应的所有的变更。</p>
<p>如果我们直接将所有历史数据存储到一张表里面（保持与业务系统表字段一致），那么数据库仓库中的表的主键就将变得模糊不清，不便于使用，（这是ods层的数据情况，所以一般不建议直接从ods取数使用）。一般而言，我们会为数据仓库的表额外设计一个唯一字段主键。为了区分原表的主键和数据仓库新引入的主键，我们可以给它们换个名字。通常，原表的主键被称为<strong>业务键</strong>、<strong>业务主键</strong>或<strong>自然键</strong>，数据仓库新引入的主键被称为<strong>代理键</strong>或<strong>数据仓库主键</strong>（下文称业务键和代理键）。</p>
<h2 id="数据仓库外键"><a class="markdownIt-Anchor" href="#数据仓库外键"></a> 数据仓库外键</h2>
<p>有了数据仓库代理键，单表的历史数据保存问题就解决了。除了单表历史数据问题，我们常常还需要解决表间关联的历史数据问题。</p>
<p>比如，在电商的场景下，昨天某店铺以100元卖出了一款产品，由于市场变化，今天需要调整产品价格为120，此时，当我们查询昨天的那笔订单时，应该需要能找到昨天对应的价格。由于产品价格和订单常常存储于不同的表中，这就形成了典型的表间关联的历史数据查询问题。</p>
<p>也有的文章将这种历史数据称作数据快照。比如，典型的情况是对每天的数据生成一个快照。</p>
<p>如何解决表间关联的历史数据问题呢？还是可以基于代理键来实现。只需要实现一个转换逻辑，将原来的每张数据库表的外键转换为代理键即可。</p>
<h2 id="代理键设计"><a class="markdownIt-Anchor" href="#代理键设计"></a> 代理键设计</h2>
<p>如何来设计数据仓库代理键呢？传统的数据库设计理论会建议我们使用一个与业务无关的自增值作为代理主键。但是，在当下流行的基于分布式计算的数据仓库技术下，如果使用自增键，我们将遇到很多技术挑战。比如：</p>
<ul>
<li>需要预先查询当前最大主键值</li>
<li>分布式环境下生成主键，需要在各个计算节点进行任务协调，导致速度变慢</li>
<li>除非预先指定非常严格的数据排序，否则重复计算将生成不同的主键，计算任务也就无法实现幂等（数据任务的幂等性是指，对同样的输入，任务每次运行都产生一个同样的输出。数据项目中的任务幂等性非常重要，试想，如果每次生成的主键不一样，那么当主键重新生成时，上层所有依赖任务需要重新计算。这将带来大量的额外计算，大大降低效率。）</li>
</ul>
<p>对于传统关系型数据库而言，自增主键带来的优势主要是占用存储空间低和计算速度快，但在分布式数据存储和计算的前提下，这个优势其实并不明显。</p>
<p>基于<code>Hive</code>的数据仓库支持多种类型的存储格式，我们常见的如<code>ORC</code>或<code>Parquet</code>格式都是列式存储并支持压缩的。 对于文本类重复率较高的数据常常可以有很高的压缩率，从而缓解存储空间占用大的问题。同时，由于分布式计算的存在，字符串比较产生的性能损失也显得不那么明显。</p>
<p>我们曾经做过一个测试，先随机生成一个长整型数据，然后计算其<code>md5</code>值，接着比较两者的存储空间和表连接效率，发现结果相差无几。（见文末测试报告）</p>
<p>所以，结合我们的实践经验，我们建议数据仓库代理键使用以下方式生成。</p>
<ul>
<li>找出业务键对应的字段（可能是多个）</li>
<li>找出数据更新时间字段，如果是全量表，可使用接入数据的日期</li>
<li>将业务键字段及数据变更时间字段计算哈希值生成代理键</li>
</ul>
<p>对应的sql表达式示例：<code>sha1(concat(sha1(business_pk1), sha1(business_pk2), sha1(update_time)))</code>。</p>
<p>使用这种方式生成的代理键可以很好的解决任务幂等性问题，并且不会有太大的性能损失。</p>
<p>有了任务幂等性，我们就可以更从容的应对<code>DWD</code>层的修改。这样的修改可能比想象的更频繁，比如：</p>
<ul>
<li>业务系统数据库引入了一个新的字段，需要在<code>DWD</code>层模型中新增这个字段进行分析</li>
<li>由于对业务数据理解出现问题，或者业务系统提供的数据编码值不对，或者业务系统数据库编码值改变等情况，原来的<code>DWD</code>层中的数据清洗或转换规则需要更新</li>
</ul>
<p>对于上述更新，我们就无需重新运行所有上层计算任务了，只运行依赖这个变更字段的任务即可。</p>
<h2 id="重新建模"><a class="markdownIt-Anchor" href="#重新建模"></a> 重新建模</h2>
<p>很多时候，我们一讲数据仓库或数据平台，几乎马上就可以让人想到维度建模。维度建模在数据仓库建设中的重要性可想而知（这里的维度建模通常就是指dwd层的建模）。</p>
<p>但是，如果我们看下维度建模的发展就知道，维度建模是早在1996时由Ralph Kimball首次提出来的。在当下的技术环境下来看，维度建模的理论还是有效的吗？有哪些到现在还是好的实践，哪些应该摒弃呢？</p>
<p>维度建模的目的是为了更好的进行数据分析。维度建模的理论将数据表分为事实表和维度表。大部分的数据分析将从事实表出发，关联到维度表，再进行统计。这一理论揭示了数据分析的规律性，不仅使得数据分析实施起来更有章法，还给相关的技术工具的设计提供了理论支持。</p>
<p>但是，一旦我们将维度建模的理论应用于实际项目，我们常常很快就会陷入困境。因为维度和事实其实不那么容易区分，它们常常是相对的概念。比如，订单看起来是一个事实，而其关联的产品应该属于维度。但是，一般情况下，一笔订单下会存在多个商品，如果我们对订单下的某一个商品进行分析，此时是不是该商品变成了事实，而订单则是该事实的关联维度？</p>
<p>所以，维度模型为了完善其对于数据分析的抽象，还引入了很多相关的较为复杂的概念。比如桥接表等。这些相关概念的引入给数据分析带来了更多的学习成本，对于维度模型理论的推广带来了阻力。</p>
<p>另一方面，越来越多业务人员正在成为数据分析师（大部分数据分析只需要<code>sql</code>就可以实现，所以，简单的数据分析是可以由业务人员自己完成的，这是更高效的做法，同时也是业界正在推进的实践）。这样一来，维度建模的复杂性就更难接受了，因为我们不应该要求业务人员先去学习复杂的维度建模再来进行数据分析。</p>
<p>从技术上看，由于都是基于关系型数据库，其实，维度建模得到的模型与三范式模型并无太大区别，几乎可以一一对应起来。在上一篇文章中，我们建议在对数据理解不深的时候，不要进行重新建模和模型映射。在这里，我们有相同的结论，即，不建议进行复杂的维度模型建模，而是简单的将业务系统数据库中的三范式模型数据表进行事实维度标记。这样得到的数据表与三范式数据表相比，可能只是表名不一样，称为维度模型似乎不太相称，我们可以称其为简单维度模型。</p>
<p>建立简单维度模型只需要花费很少的时间，这避免了前期进行过重的复杂的设计，是一种更为精益的做法。</p>
<h2 id="码值映射"><a class="markdownIt-Anchor" href="#码值映射"></a> 码值映射</h2>
<p>为了更好的进行数据分析，我们希望数据分析时可以更容易的获取和理解数据。这对于数据字段提出了一些要求，一个典型的问题就是码值问题。</p>
<p>什么是码值呢？举个例子，从业务系统数据库设计的视角来看，为了提升性能常常会选用占用存储空间更少的字段类型进行数据存储，于是一些通常只有几个取值的状态值字段，如订单状态，就会使用<code>tinyint</code>这样的单字节字段类型进行存储。此时，状态值会被映射为数字进行存储，如<code>1</code>代表已创建，<code>2</code>代表交易成功等。我们常常把这里的数字称为码，而其对应的值称为值。</p>
<p>这里的码值问题就是说，在数据分析时，我们无法直接从数据中知道某一个码对应的是什么值，常常需要进行一层码值转换才能知道。这对于数据分析显然是不友好的，要么取数据逻辑更复杂，要么数据分析师需要在头脑里面记住这个码值映射关系。</p>
<p>一些二值字段同样可以从这样的实践中获益，一般而言，我们可以将二值字段映射为严格的<code>true</code> <code>false</code>值，从而避免潜在的<code>null</code>值，使得<code>DWD</code>层的数据更为规范好用。</p>
<p>所以，在<code>DWD</code>层解决这个问题将带来很高的价值。</p>
<p>出于性能考虑，传统的数据仓库建模理论可能会建议我们将这些码值映射保存到一张单独的码表中，但此时查询的便利性还是较差。</p>
<p>由于列式压缩存储可以很好的缓解性能问题，我们建议在<code>DWD</code>层对于所有码值进行解码操作，通过添加一些列，将原有的数字映射为真实的值进行保存。</p>
<h2 id="原值保存"><a class="markdownIt-Anchor" href="#原值保存"></a> 原值保存</h2>
<p>在进行数据清洗时，我们会将一些字段处理为更规范的字段。为了进一步提高<code>DWD</code>层的灵活性，一个实用的建议是将原来的字段值保留下来。这样一来，即便我们数据清洗规则有问题，或者要新增数据清洗规则，在数据分析师进行数据分析时都有数据可用，不用等待<code>DWD</code>层重新构建。</p>
<p>对于上文提到的码值映射，我们就可以保留字段原值。在实践时，我们会将原来的字段重命名，添加一个<code>original</code>的前缀。其意义在于，我们不推荐使用原值字段（加一个前缀使字段名更长而不便于使用），但是我们保留使用字段原值的能力。</p>
<p>对于主键而言，如果业务系统表的主键由多个字段组成，我们建议通过对这些字段进行哈希生成一个单一字段主键，这将在表关联及数据访问时提供额外的灵活性。此时原来的主键也应保留下来供分析使用。</p>
<h2 id="时间处理"><a class="markdownIt-Anchor" href="#时间处理"></a> 时间处理</h2>
<p>时间是一个特殊的类型，很多数据分析都是基于时间来开展的。比如每天的销量，每月的销量，节假日客流量等。所以，我们常常把日期作为一个单独的维度表进行构建，该维表内会存储节假日、星期几时段等常用的分析维度信息。如果有对于时间的分析需求，也可以建立时间的维表，以便保存常见的早中晚等时段信息。</p>
<p>其他的表如何关联日期和时间呢？可以通过外键实现。所以，在数据表里面出现日期或时间字段时，可以根据该字段建立对应日期和时间维表外键。</p>
<p>由于日期和时间的取值非常固定，可以用一个整数来表示。比如，日期可以是8位整数，如<code>20210101</code>，类似的，时间可以表示为6位整数，如<code>120101</code>。所以，日期和时间维表常常用这样的整数来作为主键（此时也是代理键，因为日期和时间维表无需保留历史）。使用整数作为主键，可移植性和易用性可以得到一定程度的增强。</p>
<h2 id="数据仓库建模总结"><a class="markdownIt-Anchor" href="#数据仓库建模总结"></a> 数据仓库建模总结</h2>
<p>经过上面的讨论，我们可以得到这样一些数据仓库建模的经验：</p>
<p><strong>推荐</strong></p>
<ul>
<li>创建数据时间字段作为数据分区</li>
<li>将多列复合主键进行合成，生成单一字段主键</li>
<li>为每一行数据生成代理键</li>
<li>代理键生成使用sha1和concat, 并注意处理null</li>
<li>将编码映射为可理解的值进行存储</li>
<li>做了码值转换的字段保留原字段，命名为original_{原字段}</li>
<li>处理date/time的字段，除了生成外键列，需要保留一个原字段，方便后续使用</li>
<li>采用一致的表/字段命名规范，建议采用小写字母加下划线命名方式</li>
<li>创建通用的维度表，如日期维度表、地理位置维度表等</li>
<li>将通用维度清洗为一致的值，如性别、地理位置等</li>
</ul>
<p><strong>可选</strong></p>
<ul>
<li>将源表外键关联到数据建模表代理键</li>
<li>外键列保留对应的业务键字段</li>
</ul>
<p><strong>谨慎</strong></p>
<ul>
<li>做大量的模型或字段映射</li>
<li>不考虑在传统的关系型数据库上建议的数据建模实践的价值，直接采用</li>
</ul>
<p>在实践过程中，我们把上述几条规则当做dwd层建模原则来对待。</p>
<p>有了这样的建模原则，dwd层的构建几乎可以完全自动化的完成。只需要我们开发一些数据工具进行辅助就可以了。在后面的文章中，我们将一起来看一下，这样的建模工具应该如何设计实现。</p>
<h2 id="附录"><a class="markdownIt-Anchor" href="#附录"></a> 附录</h2>
<h3 id="文本字段和数值型字段对比测试"><a class="markdownIt-Anchor" href="#文本字段和数值型字段对比测试"></a> 文本字段和数值型字段对比测试</h3>
<p>运行以下<code>sql</code>可以测试文本类型字段和整数型字段的存储空间占用及关联查询性能。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 生成1000,000条数据，其中有1000个不同的值，进行md5编码后存储起来</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> test.test_join stored <span class="keyword">as</span> Parquet TBLPROPERTIES (&quot;transactional&quot; <span class="operator">=</span> &quot;false&quot;) <span class="keyword">as</span></span><br><span class="line"><span class="keyword">with</span> rand_list_ <span class="keyword">as</span> (</span><br><span class="line">        <span class="keyword">select</span> t.f1,t.start_r <span class="operator">-</span> pe.i <span class="keyword">as</span> seq_no <span class="keyword">from</span> (</span><br><span class="line">            <span class="keyword">select</span> <span class="string">&#x27;ABC&#x27;</span> <span class="keyword">as</span> f1, <span class="number">1000000</span> <span class="keyword">as</span> start_r, <span class="number">0</span> <span class="keyword">as</span> end_r</span><br><span class="line">        ) t <span class="keyword">lateral</span> <span class="keyword">view</span> posexplode(split(space(start_r <span class="operator">-</span> end_r <span class="operator">-</span> <span class="number">1</span>),<span class="string">&#x27;&#x27;</span>)) pe <span class="keyword">as</span> i,s</span><br><span class="line">    ),</span><br><span class="line">    rand_list <span class="keyword">as</span> (</span><br><span class="line">        <span class="keyword">SELECT</span> </span><br><span class="line">            <span class="built_in">cast</span>(rand() <span class="operator">*</span> <span class="number">10</span> <span class="keyword">as</span> <span class="type">INTEGER</span>) <span class="operator">*</span> <span class="number">100</span> <span class="operator">+</span> <span class="built_in">cast</span>(rand() <span class="operator">*</span> <span class="number">10</span> <span class="keyword">as</span> <span class="type">INTEGER</span>) <span class="operator">*</span> <span class="number">10</span> <span class="operator">+</span> <span class="built_in">cast</span>(rand() <span class="operator">*</span> <span class="number">10</span> <span class="keyword">as</span> <span class="type">INTEGER</span>) <span class="keyword">as</span> n,</span><br><span class="line">            seq_no <span class="keyword">as</span> id</span><br><span class="line">        <span class="keyword">from</span> rand_list_</span><br><span class="line">    )</span><br><span class="line"><span class="keyword">select</span> id, n, md5(<span class="built_in">cast</span>(n <span class="keyword">as</span> string)) sn <span class="keyword">from</span> rand_list;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 将数值型字段和文本型字段分别写入到不同的表中，比较存储空间占用，可以发现均占用约1.2MB的空间</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> test.test_join_n stored <span class="keyword">as</span> Parquet TBLPROPERTIES (&quot;transactional&quot; <span class="operator">=</span> &quot;false&quot;) <span class="keyword">as</span> <span class="keyword">select</span> n <span class="keyword">from</span> test.test_join;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> test.test_join_s stored <span class="keyword">as</span> Parquet TBLPROPERTIES (&quot;transactional&quot; <span class="operator">=</span> &quot;false&quot;) <span class="keyword">as</span> <span class="keyword">select</span> sn <span class="keyword">from</span> test.test_join;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 测试使用数值型字段进行关联和使用文本型字段进行关联，两者都在10秒左右完成</span></span><br><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">from</span> test.test_join j <span class="keyword">join</span> test.test_join_n n <span class="keyword">on</span> j.n<span class="operator">=</span>n.n;</span><br><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">from</span> test.test_join j <span class="keyword">join</span> test.test_join_s s <span class="keyword">on</span> j.sn<span class="operator">=</span>s.sn;</span><br></pre></td></tr></table></figure>
<p>运行上述测试之后可以得到的结论是：</p>
<ul>
<li>数值型字段和文本型字段的存储空间占用差异不大</li>
<li>数值型字段和文本型字段在表连接时性能差异不大</li>
</ul>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>数据平台</tag>
      </tags>
  </entry>
  <entry>
    <title>数据仓库建模自动化</title>
    <url>/2021/04/05/dwd-modeling-automation/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>在前文<a href="http://brightliao.com/2021/03/16/data-modeling-practice/">《数据仓库建模实践》</a>中，我们提到了在确定<code>DWD</code>层的构建原则之后，可以通过开发数据建模工具来辅助实现。这样的工具应该设计成什么样子呢？</p>
<h2 id="建模工具的基本方案"><a class="markdownIt-Anchor" href="#建模工具的基本方案"></a> 建模工具的基本方案</h2>
<h3 id="建模工具的特点"><a class="markdownIt-Anchor" href="#建模工具的特点"></a> 建模工具的特点</h3>
<p>一个理想的建模工具应该具备良好的易用性和灵活性。</p>
<span id="more"></span>
<p>易用性可以体现在：</p>
<ul>
<li>支持数据建模人员方便的查看，快速的编辑</li>
<li>有错误提示</li>
<li>有版本控制</li>
</ul>
<p>灵活性是指：</p>
<ul>
<li>可以很容易的自定义数据转换逻辑而无需修改工具代码</li>
<li>支持灵活的任务参数定义，以便适应不同量级的数据</li>
<li>一旦建模人员希望引入新的建模规则，可以很容易的修改这个工具进行支持</li>
</ul>
<h3 id="建模工具交互界面"><a class="markdownIt-Anchor" href="#建模工具交互界面"></a> 建模工具交互界面</h3>
<p>常见的具备良好易用性的工具是一套完善的拥有良好交互体验的<code>Web</code>系统，用户打开浏览器即可使用。但是这样的系统构建成本通常较高，而且一旦有新的建模规则或特性想要支持，也要花费更多的时间去修改系统。</p>
<p>有没有更简单轻量的工具呢？</p>
<p>做数据分析最常用的工具当属<code>Excel</code>电子表格了。电子表格有着非常强的灵活性，可以支持大部分数据分析场景。同时，团队成员通常也都具备熟练的使用电子表格的能力。基于此，我们可以考虑使用<code>Excel</code>作为用户交互界面。</p>
<p>我们可以设计一套电子表格的模板，然后，建模人员通过填表的方式进行模型配置，接着，建模工具通过读取模型配置来运行数据建模任务。</p>
<p>使用电子表格作为交互界面可以大大降低建模工具开发成本，使得我们可以将主要精力放在建模本身这件更有业务价值的事情上。虽然舍弃了一定的易用性，但是考虑到开发成本的降低及灵活性的提升，这个选择应该是比较合理的。</p>
<p>很多电子表格还支持协同编辑，此时可以让相关团队成员一起协作完成<code>DWD</code>模型的配置。</p>
<h3 id="建模工具实现思路"><a class="markdownIt-Anchor" href="#建模工具实现思路"></a> 建模工具实现思路</h3>
<p>有了电子表格中定义的模型配置，建模工具的核心功能就变成：</p>
<ol>
<li>读取模型配置；</li>
<li>运行数据建模任务。</li>
</ol>
<p>分析一下如何实现这两个功能。读取模型配置在实现上没什么问题，运行数据建模任务这个步骤还显得不够清晰。任务是以什么形式在什么环境里面运行呢？</p>
<p>回顾前面的文章<a href="http://brightliao.com/2021/04/01/data-development-language-and-environment/">《数据应用开发语言和环境》</a>，经过分析，我们建议使用<code>sql</code>来作为主要数据开发语言，使用<code>Spark</code>作为任务执行引擎。那么这里的任务是不是可以以<code>sql</code>代码的形式体现，然后通过<code>Spark</code>来执行呢？</p>
<p>当然是可以的！前文中，我们还提到了一个可执行增强<code>sql</code>语法的<code>sql</code>驱动器。在这里，事实上，我们可以通过建模工具将模型配置进行转换，生成一个可执行的<code>sql</code>文件，然后通过<code>sql</code>驱动器在<code>Spark</code>中执行。</p>
<p>生成中间<code>sql</code>文件的方式带来了另一个好处，我们可以有更好的版本管理了。电子表格的版本是不容易维护的，但生成的<code>sql</code>是纯文本的，可以很容易实现版本管理。</p>
<h2 id="建模工具设计与实现"><a class="markdownIt-Anchor" href="#建模工具设计与实现"></a> 建模工具设计与实现</h2>
<p>有了前面的分析及基本工作流程设计，我们来看一下如何设计实现这一工具。</p>
<h3 id="表格模板设计"><a class="markdownIt-Anchor" href="#表格模板设计"></a> 表格模板设计</h3>
<p>首先来看表格模板的设计，下图展示了一个设计好的电子表格模板：</p>
<p><img data-src="/attaches/2021/2021-04-05-dwd-modeling-automation/tool.png" alt="tool design" /></p>
<p>上述表格记录了订单事实表<code>fact_order_h</code>和用户表<code>dim_user_h</code>的模型配置，包括了多个列，其中：</p>
<ul>
<li>t_table_name: 目标表名，一般需要带上数据库名，只需要首行数据有值（参考上图示例①）</li>
<li>t_col_name: 目标表字段名</li>
<li>t_col_attr: 目标表字段属性，比如主键<code>pk</code>，外键<code>fk</code>，分类字段<code>cate</code>等（参考上图示例②）</li>
<li>t_col_type: 目标表字段类型</li>
<li>col_desc: 字段描述</li>
<li>s_table_name: 源表名，一般需要带上数据库名，只需要首行数据有值</li>
<li>s_col_name: 源表字段名</li>
<li>s_col_type: 源表字段类型</li>
<li>trans_expr: 转换规则<code>sql</code>表达式，这里的表达式可以支持任意的合法转换，比如函数调用，变量引用，码值映射，外键转换等（参考上图示例③）</li>
<li>comments: 任意的关于这一个转换的注释</li>
<li>code_gen: 自定义代码</li>
</ul>
<h3 id="扩展性分析"><a class="markdownIt-Anchor" href="#扩展性分析"></a> 扩展性分析</h3>
<p>我们对每一个字段设计了一个属性<code>t_col_attr</code>，用于对特殊字段进行标记。建模工具可以识别这个标记，然后根据标记的不同生成不同的代码。目前我们只关注代理键、自然键、分类字段，以后可以根据情况增加其他需要进行特殊处理的字段类型标记。</p>
<p>转换表达式<code>trans_expr</code>是一个非常通用的设计，利用这个表达式，可以给<code>DWD</code>的表添加任意可以通过源表计算得出的字段。这里的表达式可以根据不同的字段标记使用不同的语法，比如:</p>
<ul>
<li>在示例图<code>3</code>中，通过定义<code>sql</code>表达式实现主键的生成</li>
<li>在示例图中<code>3.1</code>中，对应的目标字段是分类字段，则<code>trans_expr</code>的值为分类码值映射</li>
<li>在示例图中<code>3.2</code>中，对应的目标字段是外键字段，则<code>trans_expr</code>的值为外键信息，包括对应的表和表间关联字段</li>
<li>在示例图中<code>3.3</code>中，表达式为普通<code>sql</code>表达式，其中可以引用变量，因为最后生成的<code>sql</code>将会通过支持增强<code>sql</code>语法的驱动器来执行</li>
</ul>
<p><code>code_gen</code>列中可以定义任意代码，建模工具在生成<code>sql</code>代码时，可以根据代码插入点标记将自定义代码插入到生成的<code>sql</code>中。比如，如果在处理第一个分区（全量分区）时，为了加速整个计算过程，可以通过<code>repartition</code>提升并行度，此时<code>code_gen</code>的值可以是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">after_read_source: -- target=func.repartition(source_table, 100)</span><br></pre></td></tr></table></figure>
<p>生成的代码会在具有<code>after_read_source</code>标记的地方插入自定义代码。</p>
<p>有了原表字段类型<code>s_col_type</code>和目标表字段类型<code>t_col_type</code>的设计，建模工具可以判断两个类型是否相同，如不同，则可以生成一条<code>cast(xx as xx)</code>的语句自动将类型转换为<code>t_col_type</code>指定的类型。</p>
<p><code>col_desc</code>的设计可以鼓励建模人员弄清楚每一个字段的确切含义，然后将数据的相关背景知识记录下来。在这里，<code>col_desc</code>还可以充当元数据的作用。有了<code>col_desc</code>，我们可以根据此生成表的字段注释。</p>
<h3 id="建模原则支持分析"><a class="markdownIt-Anchor" href="#建模原则支持分析"></a> 建模原则支持分析</h3>
<p>有了上面的设计，我们来看一下之前定义的建模原则如何在这个设计下进行实现。</p>
<ul>
<li>代理键生成：可以使用<code>trans_expr</code>实现</li>
<li>外键列保留对应的业务键字段：可以通过添加列来实现</li>
<li>做了码值转换的字段保留原字段，命名为<code>original_&#123;原字段&#125;</code>：通过<code>t_col_attr</code>及<code>trans_expr</code>来实现</li>
<li>处理<code>date/time</code>的字段，生成外键列：可以使用<code>trans_expr</code>实现</li>
</ul>
<p>可以看到，电子表格模板的设计具有非常大的灵活性，可以很好的支持前文定义的建模原则。</p>
<h3 id="实现"><a class="markdownIt-Anchor" href="#实现"></a> 实现</h3>
<p>有了上面的分析和设计，现在要实现这样的一个建模工具就不是难事了。回顾上述设计可以发现，这个设计其实是站在使用者的角度定义了建模工具所应该具备的功能，这正是<code>TDD</code>的基本思想，也就是说，这个设计其实是为建模工具定义的一个测试用例。</p>
<p>在实现时，按照<code>DDD</code>的思想，可以将电子表格中每一行定义为一个领域对象，可以称作<code>TransitionDefinition</code>。使用<code>Python</code>读取<code>Excel</code>电子表格，然后将表格的每一行转化为一个领域对象。代码的生成可以基于<code>Jinja</code>模板引擎来实现。有了领域对象，我们只需要编写<code>Jinja</code>模板，然后将领域对象渲染为最终的<code>sql</code>即可。</p>
<p>在实现时需要注意表间依赖问题。比如，上述示例中的订单表和用户表，由于订单表有一个外键指向用户表，我们需要首先构建用户表，再构建订单表。</p>
<p>这个问题比看起来的还要严重，因为可能产生循环依赖。如何解决呢？其实我们可以分两步完成构建过程，第一步处理非外键字段，第二步处理所有外键字段。由于外键实际上只依赖所引用的表的主键字段（业务键和代理键），只要这些字段有值就可以了。</p>
<p>还需要注意一个问题，那就是外键构建的任务可能无法并行完成，因为该任务会更新数据表（也可以考虑存储为不同的表，就没有任务并行问题了，不过此时会产生一份拷贝，从而牺牲一定的存储空间）。大多数调度器都提供了控制任务并行度的方法，比如<code>Airflow</code>的<a href="https://airflow.apache.org/docs/apache-airflow/1.10.3/concepts.html#pools"><code>Pool</code></a>机制。</p>
<p>将构建过程分为两步完成这一设计不仅很好的解决了表间依赖关系问题，还让最后的数据流水线更干净，如下图示例：</p>
<p><img data-src="/attaches/2021/2021-04-05-dwd-modeling-automation/dwd-dag.png" alt="dwd dag" /></p>
<p>一个可运行的建模工具的实现应该不难，就不赘述了，可以作为大家的一个小练习。如果有兴趣，大家可以尝试进行实现。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>本文分享了一个数据仓库建模工具的设计和实现的例子。讨论了建模工具的方案设计，技术选型，交互界面（电子表格模板）设计，扩展性设计等话题。</p>
<p><code>DWD</code>建模工具的引入，可以帮我们更高效的将<code>DWD</code>层构建好。由于这一层是其他数据应用构建时的最基础的数据来源，如果我们不能快速的完成，则将直接影响上层数据应用的开发。有了建模工具的支持，这一问题就不再是问题了。</p>
<p>在我们的实践中，得益于<code>DWD</code>建模原则的建立和建模工具的支持，我们将原来需要数周的建模时间缩短到了一周以内，大大提高了团队的效率。</p>
<p>在帮助我们的客户构建了多个数据相关应用之后，我们发现，数据平台构建过程中有很多工具可以复用，是值得抽象并沉淀下来的。在后续的文章中，我还将分享更多类似的数据工具。</p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>数据平台</tag>
      </tags>
  </entry>
  <entry>
    <title>数据开发支持工具</title>
    <url>/2021/04/10/data-development-tools/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>在前面的文章<a href="http://brightliao.com/2021/04/01/data-development-language-and-environment/">《数据应用开发语言和环境》</a>中我们建议使用<code>SQL</code>来作为主要数据开发语言，并且，通常我们需要对标准的<code>SQL</code>进行增强，以便可以更好的支持复杂的数据开发。一些典型的需要新增的特性可以是变量、控制语句、模板等。</p>
<p>增强<code>SQL</code>固然是可以解决我们的数据开发问题，但是它也会给我们带来一些其他的不便。第一个烦恼可能就是，标准的<code>SQL</code>可以在很多数据工具中运行，比如<code>Superset</code>的<code>SQL</code>查询器、<code>Hive</code>的查询控制台等，而使用增强语法的<code>SQL</code>编写的代码则不行。由于我们将标准的<code>SQL</code>增强了，而<code>SQL</code>周边生态工具却无法感知这样的增强，这时各种不便就随之而来了。</p>
<span id="more"></span>
<h2 id="支持数据开发过程"><a class="markdownIt-Anchor" href="#支持数据开发过程"></a> 支持数据开发过程</h2>
<p>如何解决这个问题呢？想要在周边工具中进行<code>SQL</code>扩展不是一件简单的事情，可能需要花费大量的精力和时间。我们只能另寻他法。</p>
<p>从软件开发的视角来看这个问题，可以发现，我们现在有了编程语言，也有了编程语言的执行环境，基本的开发流程确实是打通了，但是还缺少的是对开发过程的支持。一般而言，开发过程支持完善与否将很大程度上决定团队开发效率的高低。下面我们一起来看看如何完善对于开发过程的支持。</p>
<p>开发过程主要包括代码编辑和调试。下面我们来看看如何支持它们。</p>
<h2 id="支持代码编辑"><a class="markdownIt-Anchor" href="#支持代码编辑"></a> 支持代码编辑</h2>
<p>代码编辑在当前还不会成为一个问题，因为：</p>
<ul>
<li>我们只是在标准<code>SQL</code>语法的基础上进行了增强，现有的编辑器的大部分现有功能还是可以照常使用的</li>
<li>大部分的语法增强是通过<code>SQL</code>语法的注释功能来实现的，可以兼容标准<code>SQL</code>语法</li>
<li>大部分编辑器其实只是提供<code>SQL</code>语法高亮和格式化的功能，新增的语法不会产生很大的影响</li>
</ul>
<h2 id="支持代码调试"><a class="markdownIt-Anchor" href="#支持代码调试"></a> 支持代码调试</h2>
<h3 id="命令行调试器"><a class="markdownIt-Anchor" href="#命令行调试器"></a> 命令行调试器</h3>
<p>现在我们来看调试过程。事实上，使用周边的<code>SQL</code>执行工具来快速验证<code>SQL</code>这个过程本身就是代码调试的过程。</p>
<p>有了增强<code>SQL</code>的语法，我们要如何做呢？回顾增强<code>SQL</code>的语法，我们在其中支持了多个步骤，每个步骤可以是执行<code>SQL</code>，定义变量或者调用外部函数。如果可以一个步骤一个步骤运行，并且可以在每个步骤之后查看当前的变量或<code>SQL</code>执行结果，那将是一件不错的事。这其实也就是一般的程序调试过程。</p>
<p>事实上，有了增强<code>SQL</code>的执行器（即前文提到的驱动器），要实现一个具备基本功能的增强<code>SQL</code>调试器并不困难。按照上面的描述，我们只需要在某一个步骤执行完成之后，先暂停执行，并提供接口查询当前上下文的数据即可。在程序暂停时，一般还可以允许运行一些代码，这也不难，提供接口执行<code>SQL</code>即可。这就是一个命令行的程序调试器雏形。</p>
<p>对应到一般在<code>IDE</code>里面进行调试的交互流程上，打断点的过程，就是指定需要在哪一个步骤暂停，至于查看断点时的状态和在断点时执行代码就跟上面的过程完全一致了。</p>
<p>根据前面的分析，我们可以设计一个命令行调试器类<code>Debugger</code>，它可以具有这些接口：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Debugger</span>:</span><br><span class="line">    <span class="comment"># 查询执行状态</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_started</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_inprogress</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_finished</span>(<span class="params">...</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查询执行步骤信息</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">step</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">current_step</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">next_step</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">last_step</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">left_step_count</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">print_steps</span>(<span class="params">...</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查看或设置执行过程中的变量</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">vars</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">set_vars</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">templates</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">tempviews</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">showdf</span>(<span class="params">...</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 执行某一步骤，实现暂停、继续等流程控制功能</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">step_on</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">step_to</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run_to</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">restart</span>(<span class="params">...</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在断点过程中执行sql</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sql</span>(<span class="params">...</span>):</span><br></pre></td></tr></table></figure>
<p>上面这些接口借助增强<code>SQL</code>的执行器不难实现。有了<code>Debugger</code>类，一个典型的调试过程就变成：</p>
<ul>
<li>在任意<code>SQL</code>编辑器中编辑代码</li>
<li>打开<code>IPython</code>命令行</li>
<li>创建<code>Debugger</code>对象: <code>d = create_debugger(sql_file=..., ...)</code></li>
<li>打印所有步骤：<code>d.print_steps()</code></li>
<li>执行到某一步：<code>d.run_to(3)</code></li>
<li>在<code>SQL</code>编辑器中修改代码</li>
<li>重起调试：<code>d.restart()</code></li>
<li>…</li>
</ul>
<p>（具体实现代码见<a href="https://github.com/easysql/easy_sql/blob/main/easy_sql/sql_processor_debugger.py">这里</a>）</p>
<h3 id="打印代码执行报告"><a class="markdownIt-Anchor" href="#打印代码执行报告"></a> 打印代码执行报告</h3>
<p>为了辅助数据开发人员更清楚的理解增强<code>SQL</code>的执行过程，我们最好能打印每一步骤的执行情况，比如实际执行的SQL、执行开始时间、结束时间、当前步骤在整个执行过程中耗时百分比等信息。</p>
<p>一个简单的报告可以设计如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">===================== REPORT FOR step-1 ==================</span><br><span class="line">config: StepConfig(target=..., condition=None, line_no=1) </span><br><span class="line">sql: select 1 as a</span><br><span class="line">status: SUCCEEDED</span><br><span class="line">start time: 2021-04-10 10:05:30, end time: 2021-04-10 10:05:33, execution time: 2.251653s - 8.14%</span><br><span class="line">messages:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">===================== REPORT FOR step-2 ==================</span><br><span class="line">config: StepConfig(target=log.a, condition=None, line_no=4) </span><br><span class="line">sql: select &#x27;1&#x27; as a</span><br><span class="line">status: SUCCEEDED</span><br><span class="line">start time: 2021-04-10 10:05:33, end time: 2021-04-10 10:05:33, execution time: 0.069165s - 0.25%</span><br><span class="line">messages:</span><br><span class="line">a=&#x27;1&#x27;</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>为此，我们可以定义一个执行报告搜集器（<code>ReportCollector</code>），每当一个步骤开始或结束执行时，<code>SQL</code>执行器应当通知报告搜集器搜集该步骤的执行信息。在整个流程执行完成之后，<code>SQL</code>执行器可以调用报告搜集器打印整个过程中搜集到的执行报告。</p>
<p>有了报告搜集器，我们就可以更清楚的了解增强<code>SQL</code>执行过程中的细节了。由于我们的<code>SQL</code>执行基于<code>Spark</code>实现，有了这个报告搜集器，一些简单的<code>Spark</code>程序优化还可以直接通过查看报告来完成。</p>
<p>报告搜集器是一个十分好用的功能，当然需要集成到调试器中了。通过在<code>Debugger</code>类中加入<code>report()</code>方法，我们在调试过程中可以随时打印程序执行报告。</p>
<h3 id="打印日志与执行检查"><a class="markdownIt-Anchor" href="#打印日志与执行检查"></a> 打印日志与执行检查</h3>
<p>打印日志也是我们调试程序的常用手段，如何在增强<code>SQL</code>中支持日志打印呢？可以考虑定义一个任务类型为<code>log</code>，按照如下方式来使用：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- target=log.some_info_about_this_log</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> var_1, <span class="number">2</span> <span class="keyword">as</span> var_2</span><br></pre></td></tr></table></figure>
<p>日志打印结果可以在上述任务报告中出现，一个比较直观的设计可以是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">===================== REPORT FOR step-1 ==================</span><br><span class="line">config: StepConfig(target=log.some_info_about_this_log, condition=None, line_no=1) </span><br><span class="line">sql: select 1 as var_1, 2 as var_2</span><br><span class="line">status: SUCCEEDED</span><br><span class="line">start time: 2021-04-10 10:05:33, end time: 2021-04-10 10:05:33, execution time: 0.069165s - 0.25%</span><br><span class="line">messages:</span><br><span class="line">var_1=1, var_2=2</span><br></pre></td></tr></table></figure>
<p>很多编程语言都提供了<code>assert</code>语法，用以在开发过程中进行及时的假设验证，我们也可以在增强<code>SQL</code>增加这样的支持。可以考虑定义一个任务类型为<code>check</code>，按照如下方式来使用：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- target=check.actual_should_equal_expected</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> actual, <span class="number">2</span> <span class="keyword">as</span> expected</span><br></pre></td></tr></table></figure>
<p>如果从结果集中的获取的<code>actual</code>值与<code>expected</code>值不相等，则此任务会失败，并打印错误消息。同时，这样的错误可以在上述任务报告中体现，一个比较直观的设计可以是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">===================== REPORT FOR step-1 ==================</span><br><span class="line">config: StepConfig(target=check.actual_should_equal_expected, condition=None, line_no=10) </span><br><span class="line">sql: select 1 as actual, 2 as expected</span><br><span class="line">status: FAILED</span><br><span class="line">start time: 2021-04-10 10:25:32, end time: 2021-04-10 10:25:32, execution time: 0.071442s - 0.52%</span><br><span class="line">messages:</span><br><span class="line">check [actual_should_equal_expected] failed! actual=1, expected=2, check_data=[...]</span><br></pre></td></tr></table></figure>
<h3 id="通过调试模式屏蔽调试过程中的副作用"><a class="markdownIt-Anchor" href="#通过调试模式屏蔽调试过程中的副作用"></a> 通过调试模式屏蔽调试过程中的副作用</h3>
<p>有了调试器，现在可以愉快的写代码了。但很快我们就会发现另一个需要解决的问题，那就是调试过程可能导致写入某些外部数据库表。这将带来一些风险，因为我们有可能在调试的时候把一些不应该被覆盖的数据库表给覆盖了。</p>
<p>要解决这个问题也很简单，我们可以在<code>SQL</code>执行器中引入一个<code>debug</code>标记来实现。有了<code>debug</code>标记，在执行某一步骤的时候，可以判断是否是向外部数据库表做写操作，如果是且<code>debug</code>为<code>true</code>，则跳过写操作，只是将该数据创建一个<code>TempView</code>而已。</p>
<p>上述写表操作只是一个场景而已，有了<code>debug</code>标记，我们还可以做很多事情，比如打印更多的调试信息等。</p>
<p><code>Debugger</code>类在调用<code>SQL</code>执行器时，应当将<code>debug</code>标记设置为<code>true</code>，这样我们就不用担心调试的时候产生任何不想发生的副作用了。</p>
<h2 id="web数据开发环境"><a class="markdownIt-Anchor" href="#web数据开发环境"></a> <code>Web</code>数据开发环境</h2>
<h3 id="在jupyterlab中调试代码"><a class="markdownIt-Anchor" href="#在jupyterlab中调试代码"></a> 在<code>JupyterLab</code>中调试代码</h3>
<p>有了上面这些功能，调试器看起来是不错了，但是要与<code>IDE</code>的交互体验比起来，命令行版本的还是过于简单了。能不能想办法增强一下呢？</p>
<p>数据分析师常用的用于运行代码的工具要算<code>JupyterLab</code>了。作为一个打开网页就能用的开发环境，<code>JupyterLab</code>有非常多十分好用的功能，比如，可以一段一段的定义和执行代码，可以支持嵌入<code>Markdown</code>文档，可以支持可视化结果展示，可以编辑多种语言代码等等。</p>
<p><code>JupyterLab</code>能不能作为我们的代码编辑器使用呢？</p>
<p>查看<code>JupyterLab</code>最新版本，我们会发现<code>JupyterLab</code>提供了<code>Code Console</code>的功能，且可以支持多个编辑器分屏。其操作界面如下：</p>
<p><img data-src="/attaches/2021/2021-04-10-data-development-tools/jupyter-console.png" alt="jupyter lab console" /></p>
<p>此时，大家可能已经想到了，可以借助这样的交互来实现我们的代码调试功能。<code>JupyterLab</code>不仅给我们提供了一个不错的编辑代码的界面，利用<code>Code Console</code>还可以实现一边写代码一边调试。</p>
<p>在<code>JupyterLab</code>中配置好调试器后，一个典型的使用过程如下：</p>
<p><img data-src="/attaches/2021/2021-04-10-data-development-tools/debugger-usage.gif" alt="debugger" /></p>
<p>使用<code>JupyterLab</code>还有一系列的其他好处，比如：</p>
<ul>
<li>开发人员无需安装配置本地环境（这常常非常耗时），只需要一个浏览器即可开始编写代码。</li>
<li>可以直接配置<code>JupyterLab</code>连接到数据平台集群环境，这样我们就可以直接在集群环境中调试，执行与生产时同样的代码，于是上线代码就更有信心了。</li>
</ul>
<h3 id="在容器中启动jupyterlab"><a class="markdownIt-Anchor" href="#在容器中启动jupyterlab"></a> 在容器中启动<code>JupyterLab</code></h3>
<p>在基于<code>Hadoop</code>的大数据集群中进行数据开发时，常常还有一个不够方便的地方，那就是客户端环境的构建。</p>
<p>我们常常需要集成了多种集群组件的客户端，比如<code>Spark</code>, <code>HDFS</code>, <code>Hive</code>, <code>HBase</code>等，这些客户端的配置需要保持和集群同步。如果自己去构建这样的客户端，不仅耗时，而且很容易出错。</p>
<p><code>Ambari</code>可以帮助我们自动配置集群节点，如软件安装，配置同步等繁琐的工作<code>Ambari</code>都可以帮我们搞定。当需要使用集群的客户端环境时，常常也是通过<code>Ambari</code>配置的集群节点来实现。</p>
<p>使用<code>Ambari</code>配置的集群节点作为客户端却有另一个缺点，那就是这样的节点常常由于数量较少而在团队中间共享（由于资源占用问题，我们一般不会配置过多的客户端节点）。</p>
<p>既然是共享的节点，大家都在节点上面操作，就容易发生冲突。比如，小A用自己的帐号登录了（通过<code>kinit</code>），此时小B想要访问集群，如果不使用其他的操作系统帐号，小B就会直接用到小A的帐号权限来访问系统，这不是期望的行为。还比如，小A需要在客户端中安装某一个版本1依赖库，而小B需要在客户端中安装同一个依赖库的版本2，这就产生了冲突，需要小A和小B相互协调才行。</p>
<p>容器技术是解决此问题的一个很好的方式。容器可以提供必要的环境隔离，使得团队成员可以自由的在自己的环境中进行操作，无需担心对他人造成影响。</p>
<p>如何实现呢？其实我们只需要一个运行了<code>sshd</code>的容器即可。通过暴露特定的端口，我们可以把运行着<code>sshd</code>的容器作为一个节点，注册到<code>Ambari</code>中，然后利用<code>Ambari</code>帮我们安装好相关的依赖软件。</p>
<p>软件安装完成之后，我们可以通过<code>docker save</code>命令将这样容器保存为一个基础容器镜像。然后通过运行多个此容器，我们就拥有了多个此类客户端了。由于容器运行成本非常低，可以为每个需要编写代码的团队成员运行一个容器作为他自己的客户端使用。这样一来，开发人员环境隔离问题就迎刃而解了。</p>
<p>在容器环境中运行一个<code>JupyterLab</code>来支持开发是一个不错的主意。这样一来，每个人都拥有了自己的一套独立的用<code>JupyterLab</code>打造的开发环境了。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>前面的文章中我们提到使用增强<code>SQL</code>来进行数据开发，但是这带来了一些额外的使用成本。本文讨论了如何支持增强<code>SQL</code>的代码编辑和调试功能。</p>
<p>通过实现一个增强<code>SQL</code>调试器，并在<code>JupyterLab</code>中运行此调试器，我们可以打造了一个基于<code>Web</code>的轻量级数据开发环境，这能很大程度上提高数据开发的效率。为了更好的支持数据开发，我们还可以考虑在<code>SQL</code>执行器中增加执行报告搜集的功能，在调试器中随时打印执行报告对于数据开发是一件好事。除此之外，还可以在<code>SQL</code>执行器中引入调试标记，这可以用来避免调试过程的可能的副作用。</p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>数据平台</tag>
      </tags>
  </entry>
  <entry>
    <title>数据测试实践</title>
    <url>/2021/04/20/data-testing/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2021/2021-04-20-data-testing/structure.png" alt="data testing" /></p>
<p>在数据平台建设过程中，测试怎么做是一个值得思考的问题。由于数据应用开发和功能性软件系统开发存在很大的不同，在我们实践过程中，在开发人员和质量保证人员间常常有大量关于测试如何实施的讨论。下文将尝试总结一下数据应用开发的特点，并讨论在这些特点之下，对应的测试策略应该是怎么样的。</p>
<h2 id="功能性软件的测试"><a class="markdownIt-Anchor" href="#功能性软件的测试"></a> 功能性软件的测试</h2>
<p>先来回顾一下功能性软件系统开发中的测试。</p>
<span id="more"></span>
<p>测试一般分为自动化测试和手工测试。由于手工测试对人工依赖程度很高，如果主要依赖手工测试来保证软件质量，将无法满足软件快速迭代上线的需要。现代软件开发越来越强调自动化测试的作用，这也是敏捷软件开发的基本要求。有了全方位的自动化测试保障，就有可能做到每周上线，每日上线甚至随时上线。</p>
<p>这里主要讨论自动化测试。</p>
<h3 id="测试金字塔"><a class="markdownIt-Anchor" href="#测试金字塔"></a> 测试金字塔</h3>
<p>我们一般会按照如下测试金字塔的原则来组织自动化测试。</p>
<p><img data-src="/attaches/2021/2021-04-20-data-testing/test-pyramid-new.png" alt="testing pyramid" /></p>
<p>测试金字塔分为三层，自下而上分别对应单元测试、集成测试、端到端测试。</p>
<p>单元测试是指函数或类级别的，较小范围代码的测试，一般不依赖外部系统（可通过<code>Mock</code>或测试替身等实现）。单元测试的特点是运行速度非常快（最好全部在内存中运行），所以执行这种测试的成本也就很低。单元测试在测试金字塔的最底端，占的面积最大。这指导我们应该构建大量的这类测试，并以这类测试为主来保证软件质量。</p>
<p>集成测试是比单元测试集成程度更高的测试，它在运行时执行的代码路径更广，通常会依赖数据库、文件系统等外部环境。由于依赖了外部环境，集成测试的运行速度更慢，执行测试的成本更高。集成测试在测试金字塔的中间，这指导我们应该构建中等数量的这类测试。集成测试在<code>Web</code>应用场景中也常常被称为服务测试（Service Test）或<code>API</code>测试。</p>
<p>端到端测试是比集成测试更靠后的测试，通常通过直接模拟用户操作来构建这样的测试。由于需要模拟用户操作，所以它常常需要依赖一整套完整集成好的环境，这样一来，其运行速度也是最慢的。端到端测试在<code>Web</code>应用场景中也常常被称为<code>UI</code>测试。端到端测试在测试金字塔的顶端，这指导我们应该构建少量的这类测试。</p>
<p>测试的范围非常广，实施方法也非常灵活。哪里是重点？我们要在哪里发力？测试金字塔为我们指明了方向。</p>
<h2 id="一般软件的测试"><a class="markdownIt-Anchor" href="#一般软件的测试"></a> 一般软件的测试</h2>
<p>为了更深入的理解一般软件的测试要怎么做，我们需要进一步深入分析一下测试金字塔。</p>
<h3 id="测试带来的信心"><a class="markdownIt-Anchor" href="#测试带来的信心"></a> 测试带来的信心</h3>
<p>上文中的金字塔图示有一个特点并没有反映出来，那就是，越上层的测试给团队带来的信心越强。这还算好理解，试想，如果没有单元测试，只有端到端测试，我们是不是可以认为程序大部分还是可以正常工作的（可能存在一些边界场景有问题）？但是如果只有单元测试而没有端到端测试，我们连程序能不能运行都不知道！</p>
<p>端到端测试能带来很强的信心，但这常常构成另一个陷阱。由于端到端测试对团队有很大的吸引力，一些团队可能会选择直接构建大量的端到端测试而忽略单元测试。这些端到端测试运行缓慢，一般也难以修改，很快就会让团队举步维艰。缓慢的测试带来了缓慢的持续集成，高频率的上线就慢慢变得遥不可及。</p>
<p>单元测试虽然不能直接给人很强的信心，但是常常是更有效的测试手段，因为它可以很容易的覆盖到各种边界场景。</p>
<p>测试金字塔是敏捷软件开发所推崇的测试原则，它是在测试带来的信心和测试本身的可维护性两者中权衡做出的选择。测试金字塔可以指导我们构建足够的测试，使得团队既对软件质量有足够的信心，又不会有太多的测试维护负担。</p>
<p>既然是权衡，那么我们是否可以以单元测试和集成测试为主，而根本不构建端到端测试（此时端到端测试的功能通过手工测试完成）呢？</p>
<h3 id="测试集成度"><a class="markdownIt-Anchor" href="#测试集成度"></a> 测试集成度</h3>
<p>对于一些没有<code>UI</code>（或者说<code>GUI</code>）的应用，或者一些程序库、框架（如<code>Spring</code>）等，很多时候测试金字塔中的三类测试并不直接适用。我们可以这样理解：测试金字塔并非只是三层，它更多的是帮我们建立了在项目中组织测试的原则。</p>
<p>事实上，对于通用的软件测试，我们可以理解为存在一个集成度的属性。沿着金字塔往上，测试的集成度越高（依赖外部组件越多）。由于集成度更高，测试过程所要运行的代码就更多更复杂，测试运行时间就越长，测试构建和维护成本就越高。实践过程中，为了提高软件质量和可维护性，我们应当构建更多集成度低的测试。</p>
<p>有了测试集成度的理解，我们就可以知道，其实金字塔可以不是三层，它完全可以是两层或者四层、五层。这取决于我们怎么划定某一类测试的范围。同时，我们还可以知道，其实单元测试、集成测试与端到端测试其实并没有特别明显的界限。</p>
<p>下面，我们从测试集成度的角度来看如何构建单元测试。</p>
<p>上文提到，测试最好通过<code>Mock</code>或测试替身等实现，从而可以不依赖外部系统。但是，如果测试<code>Mock</code>或测试替身难以构造，或者构造之后我们发现测试代码和产品代码耦合非常严重，这时应该怎么办呢？一个可能的选择是考虑使用更高集成度的测试。</p>
<p><code>Spark</code>程序就是这样的一个例子。一旦使用了<code>Spark</code>的<code>DataFrame</code> <code>API</code>去编写代码，我们就几乎无法通过<code>Mock</code> <code>Spark</code>的<code>API</code>或构造一个<code>Spark</code>测试替身的方式编写测试。这时的测试就只能退一步选择集成度更高一些的测试，比如，启动一个本地的<code>Spark</code>环境，然后在这个环境中运行测试。</p>
<p>此时，上面的测试属于哪种测试呢？如果我们用三层测试金字塔的测试划分来看待问题，就很难给这样的测试一个准确的定位。不过，通常我们无需考虑这样的分类，而是可以把它当做集成度低的测试，即金字塔靠底端的测试。如果团队成员能达成一致，我们可以称其为单元测试，如果不能，称其为<code>Spark</code>测试也并非不可。</p>
<h3 id="一般软件的测试-2"><a class="markdownIt-Anchor" href="#一般软件的测试-2"></a> 一般软件的测试</h3>
<p>所以，对于一般的软件测试，我们可以认为测试策略应当符合一般意义的金字塔。金字塔的细节，比如应该有几层塔，每一层的范围应该是什么样，每一层应该用什么样的测试技术等等，这些问题需要根据具体的情况进行抉择。</p>
<p>在讨论一般软件的测试时，需要关注软件的测试何时停止，即，如何判断软件测试已经足够了呢？</p>
<p>在老马的《重构 第二版》中，有对于何时停止测试的观点：</p>
<blockquote>
<p>有一些测试规则建议会尝试保证我们测试一切的组合，虽然这些建议值得了解，但是实践中我们需要适可而止，因为测试达到一定程度之后，其边际效用会递减。如果编写太多测试，我们可能因为工作量太大而气馁。我们应该把注意力集中在最容易出错的地方，最没有信心的地方。</p>
<p>一些测试的指标，如覆盖率，能一定程度上衡量测试是否全面而有效，但是最佳的衡量方式可能来自于主观的感受，如果我们觉得对代码比较有信心，那就说明我们的测试做的不错了。</p>
</blockquote>
<p>主观的信心指数可能是衡量测试是否足够的重要参考。如果要问测试是否足够，我们要自问是否有信心软件能正常工作。</p>
<p>在实践过程中，我们还可以尝试分析每次<code>bug</code>出现的原因，如果是由于大部分<code>bug</code>是由于代码没有测试覆盖而产生的，此时我们可能应该编写更多的测试。但如果是由于其他的原因，比如需求分析不足或场景设计不完备而导致的，则应该在对应的阶段做加强，而不是一味的去添加测试。</p>
<h2 id="数据应用的测试"><a class="markdownIt-Anchor" href="#数据应用的测试"></a> 数据应用的测试</h2>
<p>有了前面对测试策略的分析，我们来看看数据应用的测试策略。</p>
<p>数据应用相比功能性软件有很大的不同，但数据应用也属于一般意义上的软件。数据应用有哪些特点，应该如何针对性的做测试呢？下面我们来探讨一下这几个问题。</p>
<p>根据<a href="/2021/04/01/data-development-language-and-environment/">前面的文章</a>分析，数据应用中的代码可以大致分为四类：基础框架（如增强<code>SQL</code>执行器）、以<code>SQL</code>为主的<code>ETL</code>脚本、<code>SQL</code>自定义函数（<code>udf</code>）、数据工具（如前文提到的<code>DWD</code>建模工具）。</p>
<h3 id="基础框架的测试"><a class="markdownIt-Anchor" href="#基础框架的测试"></a> 基础框架的测试</h3>
<p>基础框架代码是数据应用的核心代码，它不仅逻辑较为复杂，而且需要在生产运行时支持大量的<code>ETL</code>的运行。谁也不想提交了有问题的基础框架代码而导致大规模的<code>ETL</code>运行失败。所以我们应当非常重视基础框架的测试，以保证这部分代码的高质量。</p>
<p>基础框架的代码通常由<code>Python</code>或<code>Scala</code>编写，由于<code>Python</code>和<code>Scala</code>语言本身都有很好的测试支持，这十分有利于我们做测试。</p>
<p>基础框架的另一个特点是它通常没有<code>GUI</code>。</p>
<p>按照测试金字塔原理，我们应当为其建立更多的集成度低的测试（下文称单元测试）以及少量的集成度高的测试（下文称集成测试）。</p>
<p>比如，在<a href="/2021/04/01/data-development-language-and-environment/">前面的文章</a>中，我们增强了<code>SQL</code>的语法，加入了变量、函数、模板等新的语法元素。在运行时进行变量替换、函数调用等等功能通过基础框架实现。这部分功能逻辑较为复杂，应当建立更多的单元测试及少量的集成测试。</p>
<h3 id="etl脚本的测试"><a class="markdownIt-Anchor" href="#etl脚本的测试"></a> <code>ETL</code>脚本的测试</h3>
<p><code>ETL</code>脚本的测试可能是数据应用中的最大难点。</p>
<h4 id="采用偏集成的测试"><a class="markdownIt-Anchor" href="#采用偏集成的测试"></a> 采用偏集成的测试</h4>
<p><code>ETL</code>脚本一般基于<code>SQL</code>实现。<code>SQL</code>本身是一个高度定制化的<code>DSL</code>，如同<code>XML</code>配置一样。</p>
<p><code>XML</code>要如何测试？很多团队可能会直接忽略这类测试。但是用<code>SQL</code>编写的<code>ETL</code>代码有时候还是可以达到几百行的规模，有较多的逻辑，不测试的话难以给人以信心。如何测试呢？</p>
<p>如果采用基于<code>Mock</code>的方法写测试，我们会发现测试代码跟产品代码是一样的。所以，这样做意义不大。</p>
<p>如果采用高集成度的测试方式（下文称集成测试），即运行<code>ETL</code>并比对结果，我们将发现测试的编写和维护成本都较高。由于<code>ETL</code>脚本代码本身可能是比较简单且不易出错的，为了不易出错的代码编写测试本身就必要性不高，更何况测试的编写和维护成本还比较高。这就显得集成测试这一做法事倍功半。</p>
<p>这里可以举一个例子。比如对于一个分组求和并排序输出的<code>SQL</code>，它的代码可能是<code>select a, b, c, count(1) from t group by a, b, c order by a, b, c, count(1)</code>。如果我们去准备输入数据和输出数据，考虑到各种数据的组合场景，我们可能会花费很多的时间，这带来了较高的测试编写成本。并且，当我们要修改<code>SQL</code>时，我们还不得不修改测试，这带来了维护成本。当我们要运行这个测试时，我们不得不完成建表、写数据、运行脚本、比对结果的整个过程。这些过程都需要依赖外部系统，从而导致测试运行缓慢。这也是高维护成本的体现。</p>
<p>可见这两种测试方式都不是好的测试方式。</p>
<h4 id="测试构建原则"><a class="markdownIt-Anchor" href="#测试构建原则"></a> 测试构建原则</h4>
<p>那么有没有什么好的原则呢？我们从实践中总结出了几点比较有价值的思路供大家参考。</p>
<ul>
<li>将<code>ETL</code>脚本分为简单<code>ETL</code>和复杂<code>ETL</code>（可以通过代码行数，数据筛选条件多少等进行衡量）。简单的<code>ETL</code>通过代码评审或结对编程来保证代码质量，不做自动化测试。复杂的<code>ETL</code>通过建立集成测试来保证质量。</li>
<li>由于集成测试运行较慢，可以考虑：
<ul>
<li>尽量少点用例数量，将多个用例合并为一个来运行（主要是将数据可以合并成单一的一套数据来运行）</li>
<li>将测试分级为需要频繁运行的测试和无需频繁运行的测试，比如可将测试分级P0-P5，P3-P5是经常（如每天或每次代码提交）要运行的测试，P0-P2可以低频（如每周）运行</li>
<li>开发测试支持工具，使得运行时可以尽量脱离缓慢的集群环境。如使用<code>Spark</code>读写本地表</li>
</ul>
</li>
<li>考虑将复杂的逻辑使用自定义函数实现，降低<code>ETL</code>脚本的复杂度。对自定义函数建立完整的单元测试。</li>
<li>将复杂的<code>ETL</code>脚本拆分为多个简单的<code>ETL</code>脚本实现，从而降低单个<code>ETL</code>脚本的复杂度。</li>
</ul>
<h4 id="加深对业务和数据的理解"><a class="markdownIt-Anchor" href="#加深对业务和数据的理解"></a> 加深对业务和数据的理解</h4>
<p>我们在实践过程中发现，其实大多数时候<code>ETL</code>脚本的问题不在于代码写错了，而在于对业务和数据理解不够。比如，前面文章中的空调销售的例子，如果我们在统计销量的时候不知道存在退货或者他店调货的业务实际情况，那我们就不知道数据中还有一些字段能反映这个业务，也就不能正确的计算销量了。</p>
<p>想要形成对数据的深入理解需要对长时间的业务知识积累和长时间对数据的探索分析（业务系统通常经历了长时间的发展，在此期间内业务规则复杂性不断增加，导致数据的复杂性不断增加）。对于刚加入团队的新人，他们更容易由于没有考虑到某些业务情况而导致数据计算错误。</p>
<p>加深对业务和数据的理解是进行高效和高质量<code>ETL</code>脚本开发的必由之路。</p>
<p>有没有什么好的实践方法可以帮助我们加深理解呢？以下几点是我们在实践中总结的值得参考的建议：</p>
<ul>
<li>通过思维导图/流程图来整理复杂的业务流程（或业务知识），形成知识库</li>
<li>尽量多的进行数据探索，发掘容易忽略的领域业务知识，并通过第一步进行记录</li>
<li>找业务系统团队沟通，找出更多的领域业务知识，并通过第一步进行记录</li>
<li>如果有条件，可以更频繁的实地使用业务系统，总结更多的领域业务知识，并通过第一步进行记录</li>
<li>针对第一步搜集到的这些容易忽略的特定领域业务流程，设计自动化测试用例进行覆盖</li>
</ul>
<h3 id="sql自定义函数的测试"><a class="markdownIt-Anchor" href="#sql自定义函数的测试"></a> <code>SQL</code>自定义函数的测试</h3>
<p>在基于<code>Hadoop</code>的分布式数据平台环境下，<code>SQL</code>自定义函数通常通过<code>Python</code>或<code>Scala</code>编写。由于这些代码通常对外部的依赖很少，通常只是单纯的根据输入数据计算得到输出数据，所以对这些代码建立测试是十分容易的事。事实上，我们很容易实现100%的测试覆盖率。</p>
<p>在组织测试时，我们可以用单元测试的方式，不依赖计算框架。比如，以下<code>Scala</code>编写的自定义函数：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> array_join_f = (arr: <span class="type">Seq</span>[<span class="type">Double</span>], item_format: <span class="type">String</span>, sep: <span class="type">String</span>) =&gt; ...</span><br><span class="line"><span class="keyword">val</span> array_join = udf(array_join_f)</span><br></pre></td></tr></table></figure>
<p>对其建立测试时，可以直接测试内部的转换函数<code>array_join_f</code>，一些示例的测试场景比如：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">assertEquals(array_join_f(<span class="literal">null</span>, <span class="literal">null</span>, <span class="literal">null</span>), ...)</span><br><span class="line">assertEquals(array_join_f(<span class="type">Array</span>[<span class="type">Double</span>](), <span class="literal">null</span>, <span class="literal">null</span>), ...)</span><br><span class="line">assertEquals(array_join_f(<span class="type">Array</span>[<span class="type">Double</span>](<span class="number">1</span>, <span class="number">2</span>), <span class="string">&quot;%.2f&quot;</span>, <span class="string">&quot;,&quot;</span>), ...)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>在建立了单元测试之后，一般还需要考虑建立少量的集成测试，即通过<code>Spark</code>框架运行<code>SQL</code>来测试此自定义函数，一个示例可以是：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">assertEquals(spark.sql(<span class="string">&#x27;select array_join(array(), &quot;%.2f&quot;, &quot;,&quot;)&#x27;</span>), ...)</span><br></pre></td></tr></table></figure>
<p>如果自定义函数本身十分简单，我们也可以直接通过<code>Spark</code>测试来覆盖所有场景。</p>
<p>从上面的讨论可以看出，<code>SQL</code>自定义函数是很容易测试的。除了好测试之外，<code>SQL</code>自定义函数还有很多好的特性，比如可以很好的降低<code>ETL</code>复杂度，可以很方便的被复用等。所以，我们应该尽量考虑将复杂的业务逻辑通过自定义函数封装起来。这也是业界数据开发所建议的做法（大多数的数据开发框架都对自定义函数提供了很好的支持，如<code>Hive</code> <code>Presto</code> <code>ClickHouse</code>等，大多数<code>ETL</code>开发工具也都支持自定义函数的开发）。</p>
<h3 id="数据工具的测试"><a class="markdownIt-Anchor" href="#数据工具的测试"></a> 数据工具的测试</h3>
<p>数据工具的实例可以参考文章<a href="/2021/04/05/dwd-modeling-automation/">《数据仓库建模自动化》</a>和<a href="/2021/04/10/data-development-tools/">《数据开发支持工具》</a>。</p>
<p>这些工具的一大特点是，它们是用于支持<code>ETL</code>开发的，仅在开发过程中使用。由于它们并不是在产品环境中运行的代码，所以我们可以降低对其的质量要求。</p>
<p>这些工具通常只是开发人员为了提高开发效率而编写的代码，存在较大的修改和重构的可能，所以，过早的去建立较完善的测试必要性不高。</p>
<p>在我们的实践过程中，这类代码通常只有很少的测试，我们只对那些特别复杂、没有信心能正确工作的地方建立单元测试。如果这些工具代码是通过<code>TDD</code>的方式编写的，通常其测试会更多一些。</p>
<h2 id="在持续集成流水线中运行测试"><a class="markdownIt-Anchor" href="#在持续集成流水线中运行测试"></a> 在持续集成流水线中运行测试</h2>
<p>前面我们讨论了如何针对数据应用编写测试，还有一个关于测试的重要话题，那就是如何在持续交付流水线中运行这些测试。</p>
<p>在功能性软件项目中，如果我们按照测试金字塔的三层来组织测试，那么在流水线中一般就会对应三个测试过程。</p>
<p>从上面的讨论可知，数据应用的测试被纵向分为四条线，如何对应到流水线上呢？如果我们采用同一个代码库管理所有的代码，可以考虑直接将流水线分为四条并行的流程，分别对应这四条线。如果是不同的代码库，则可以考虑对不同的代码库建立不同的流水线。在每条流水线内部，就可以按照单元测试、低集成测试、高集成测试这样的方式组织流水线任务。</p>
<h3 id="独立的etl流水线"><a class="markdownIt-Anchor" href="#独立的etl流水线"></a> 独立的<code>ETL</code>流水线</h3>
<p>对于<code>ETL</code>代码的测试，有一个值得思考的问题。那就是，<code>ETL</code>脚本之间通常独立性非常强，相互之间没有依赖。这是由于<code>ETL</code>代码常常由完善的领域特定语言<code>SQL</code>开发而成，与<code>Python</code>或<code>Scala</code>等通用编程语言编写的代码不同，<code>SQL</code>文件之间是没有依赖的（如果说有依赖，那也是通过数据库表产生依赖）。</p>
<p>既然如此，假设我们修改了某一个<code>ETL</code>文件的代码，是不是我们可以不用运行其他的<code>ETL</code>文件的测试呢？其实不仅如此，我们甚至可以单独上线部署此<code>ETL</code>，而不是一次性部署所有的<code>ETL</code>。这在一定程度上还降低了部署代码带来的风险。</p>
<p>有了上面的发现，我们可能要重新思考数据应用的持续交付流水线组织形式。</p>
<p>一个可能的办法是为每一个<code>ETL</code>文件建立一个流水线，完成测试、部署的任务。此时每个<code>ETL</code>可以理解为一个独立的小程序。</p>
<p>这样的想法在实践中不容易落地，因为这将导致大量的流水线存在（常常有上百条），从而给流水线工具带来了很大的压力。常用的流水线工具，如<code>Jenkins</code>，其设计是难以支撑这么大规模的流水线的创建和管理的。</p>
<p>要如何来支持上面这样的<code>ETL</code>流水线呢？可能需要我们开发新的流水线工具才行。</p>
<h3 id="云服务中的etl流水线"><a class="markdownIt-Anchor" href="#云服务中的etl流水线"></a> 云服务中的<code>ETL</code>流水线</h3>
<p>现在的一些云服务厂商在尝试这样做。他们通常会提供一个基于<code>Web</code>的<code>ETL</code>开发工具，同时会提供工具对当前的<code>ETL</code>的编写测试。此时，<code>ETL</code>开发人员可以在一个地方完成开发、测试、上线，这可以提高开发效率。</p>
<p>这类服务的一个常见缺点在于它尝试用一套<code>Web</code>系统来支持所有的<code>ETL</code>开发过程，这带来了大量繁杂的配置。这其实是将<code>ETL</code>开发过程的复杂性转化为了配置的复杂性。相比编写代码而言，多数开发人员不会喜欢这样的工作方式。（当前软件开发所推崇的是<code>Everthing as Code</code>的做法，尝试将所有开发相关过程中的东西代码化，从而可以更好的利用成熟的代码编辑器、版本管理等功能。而<code>Web</code>配置的方式与<code>Everthing as Code</code>背道而驰。）</p>
<p>对于这些数据云服务厂商提供的数据开发服务，如果可以同时支持通过代码和<code>Web</code>界面配置来实现数据开发，那将能得到更多开发者的喜爱。这在我看来是一个不错的发展方向。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>本文讨论了如何在数据平台建设过程中做测试这个话题。由于数据应用开发有很强的独特的特点（比如以<code>SQL</code>为主、有较多的支撑工具等），其测试与功能性软件开发的测试也存在很大的不同。</p>
<p>本文分析了如何在测试金字塔的指导下制定测试策略。测试金字塔不仅可以很好的指导功能性软件开发，在进行一般意义上的推广之后，可以很容易得到一般软件的测试策略。关于测试金字塔，本文分析了测试带来的质量信心及测试集成度，这两个概念可以帮助我们更深刻的理解测试金字塔背后的指导原则。</p>
<p>在最后，结合我们的实践经验，给出了一些数据应用中的测试构建实践。将数据应用分为四个不同模块来分别构建测试，可以很好的应对数据应用中的质量要求，同时保证有较好的可维护性。最后，我们讨论了如何在持续集成流水线中设计测试任务，留下了一个有待探索的方向，即如何针对单个<code>ETL</code>构建流水线。</p>
<p>数据应用的质量保证是不容易做到的，常常需要我们进行很多的权衡取舍才能找到最适合的方式。想要解决这一问题，还要发挥团队中所有人的能动性，多总结和思考才行。</p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>数据平台</tag>
      </tags>
  </entry>
  <entry>
    <title>一个ETL自动化测试框架</title>
    <url>/2021/04/25/data-testing-tool/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>在前一篇文章<a href="/2021/04/20/data-testing/">《数据测试实践》</a>中，我们探讨了数据应用如何做测试的问题。在数据测试中，<code>ETL</code>脚本的测试是个难题。一般而言，采用高集成度的测试方式（即运行<code>ETL</code>并比对结果，下文称集成测试）是更有效的做法。但是，这类测试的编写和维护却有较高的成本。如何降低<code>ETL</code>集成测试的成本呢？本文尝试从数据工具的角度分享一些我们的经验。</p>
<span id="more"></span>
<h2 id="etl集成测试的痛点"><a class="markdownIt-Anchor" href="#etl集成测试的痛点"></a> ETL集成测试的痛点</h2>
<p>ETL集成测试的编写和维护成本高在哪里呢？</p>
<p>我们先来看如何编写一个ETL集成测试。</p>
<p>对于某一个<code>ETL</code>任务，其工作过程一般是三个步骤：读取数据、处理数据、将数据写入新表。为构建这样一个集成测试，我们需要完成这样几步：</p>
<ul>
<li>为<code>ETL</code>测试构建一个运行环境</li>
<li>创建<code>ETL</code>需要读取的表，并将准备好的数据写入</li>
<li>创建<code>ETL</code>的正确输出结果表，并将准备好的数据写入</li>
<li>针对测试环境中的表运行<code>ETL</code>（可能需要做一定的修改，因为表名、数据库名可能不一样）</li>
<li>比对<code>ETL</code>任务生成的数据和第三步中构造的数据，如果两者一致，则测试通过</li>
</ul>
<p>一般而言，为了保证测试的有效性，我们希望构建一套类生产环境的<code>ETL</code>测试运行环境。如果额外搭建一套大数据平台环境，这带来的搭建和维护成本就比较高了。同时它还会带来一定的资源消耗，比如我们至少要准备3个节点的计算资源，且需要配置的CPU和内存还不能太低。</p>
<p>如果我们直接使用生产环境作为测试环境使用，这节省了集群的搭建和维护成本，但我们需要配置好运行<code>ETL</code>测试的用户权限，以防止在测试运行过程中错误的将数据写入了生产环境的数据库表。使用一套环境还有一个缺点，那就是在运行测试之前我们需要修改<code>ETL</code>脚本中的数据库名或数据表名，将它们指向测试对应的库或表。这也是一件麻烦事，而且极容易出错。</p>
<p>如果需要创建测试用的输入输出表，我们需要在准备测试用例时编写不少建表语句代码。同时，还需要注意数据表的<code>Schema</code>变化，比如某一天由于业务需要，我们将字段名字或类型做了修改，此时测试也不得不跟着修改。</p>
<p>比对数据这一步，也可能存在问题。由于并行计算的存在，<code>ETL</code>的输出结果中的数据很可能每次都不一样，是乱序的。此时我们在做比较的时候，需要注意将数据顺序对齐，这一般可以通过<code>order by</code>所有字段来实现。</p>
<h2 id="etl测试框架设计"><a class="markdownIt-Anchor" href="#etl测试框架设计"></a> ETL测试框架设计</h2>
<p>从以上<code>ETL</code>集成测试痛点分析可以看出，如果不借助任何框架和工具，只靠运维的手段来构建测试，将会非常复杂，且极易出错。如何解决这些痛点呢？我们可以考虑编写一个测试框架来做支持。</p>
<h3 id="愿景"><a class="markdownIt-Anchor" href="#愿景"></a> 愿景</h3>
<p>我们希望这个测试框架是轻量级的，简单可用。它不能直接产生价值，因此不能投入太多的精力。同时这个框架应当是易用的，尽量使得团队所有人都能一看就懂。这个框架还需要能辅助完成（或避免）前面痛点分析中的大部分复杂易错的操作。</p>
<h3 id="需求及设计"><a class="markdownIt-Anchor" href="#需求及设计"></a> 需求及设计</h3>
<p>要实现以上的愿景，第一个需要回答的问题是，使用者（开发人员或测试人员）应当如何和框架交互。</p>
<h4 id="交互接口"><a class="markdownIt-Anchor" href="#交互接口"></a> 交互接口</h4>
<p>在前面的文章<a href="/2021/04/05/dwd-modeling-automation/">《数据仓库建模自动化》</a>中，我们使用<code>Excel</code>电子表格作为交互方式。这里可以参考前面的做法，依然使用电子表格来让用户构建测试。</p>
<p>电子表格不仅是大家常用的熟悉的工具，还是天生的编辑表格数据的工具，用来构建测试用例应当是非常合适的选择。而且现在很多可以协同编辑电子表格的工具，如<code>Google Spreadsheet</code>等，使得我们可以多人协作进行测试用例的设计和编写。</p>
<h4 id="模板"><a class="markdownIt-Anchor" href="#模板"></a> 模板</h4>
<p>电子表格可以非常灵活的编辑数据，为了使得用户可以创建测试用例，我们需要设计一个固定的模板。</p>
<h5 id="测试文件和测试套件"><a class="markdownIt-Anchor" href="#测试文件和测试套件"></a> 测试文件和测试套件</h5>
<p>模板应当包含哪些元素呢？</p>
<p>首先，我们需要能从电子表格测试用例中知道对应的被测试<code>ETL</code>文件是哪个。采用<code>Convention over Configuration</code>的原则，我们可以限制电子表格的文件名，要求其必须和被测试<code>ETL</code>文件名相同。</p>
<p>其次，在很多现有的测试框架中，多个测试用例可以被组织成测试套件来统一管理。我们也最好能支持测试套件和测试用例。如何在电子表格中定义测试套件和用例呢？可以利用电子表格的标签页<code>Sheet</code>。一个直观的想法就是，每一个标签页是一个测试套件，同时每个标签页内可以支持多个测试用例。</p>
<p>为了使得标签页与测试套件能对应起来，我们可以限制标签页的名字格式必须为<code>suit_xx</code>。这还能获得一个额外的好处，那就是用户可以自由的添加新的标签页（只要名字不符合前面的规范格式），用于记录一些和该测试相关的信息。</p>
<h5 id="测试用例"><a class="markdownIt-Anchor" href="#测试用例"></a> 测试用例</h5>
<p>测试用例如何在电子表格中呈现呢？分析测试用例的必备元素，我们可以知道，一个测试用例应当包含：用例名、输入变量（用于支持<code>ETL</code>中的变量引用）、输入表、输出表。其中，输入表和输出表可以有多个。</p>
<p>在测试用例中，输入表无需填入原表的全部字段，只填入当前<code>ETL</code>需要用到的字段即可。输出表也可以只包括<code>ETL</code>输出表的部分关键的待验证的字段。</p>
<p>多个输出表的设计可以很好的支持对中间输出结果的验证。这一设计是更灵活的，它可以使得我们有能力测试到<code>ETL</code>的中间结果，而不只是对<code>ETL</code>的输出进行验证。</p>
<p>注意到用例中的各类信息的格式是不一样，用例名是一个字符串，输入变量可以是一个包含键值对的字典，输入表和输出表是表格。此时我们可以单独一列来标记信息类型。字符串可以直接置于信息类型旁边的单元格，字典可以置于信息类型旁边的两行表格区域（第一行表示键，第二行表示值）。</p>
<p>如下图示例，我们设计了一个用例用于测试一个统计空调销量的<code>ETL</code>。该<code>ETL</code>的输入表是<code>DWD</code>层的订单表和用户表，输出表为销量统计信息表。要运行此<code>ETL</code>，需要指定一个变量<code>DATA_DATE</code>，表示需要计算的时间。如果还需要支持其他变量，可以直接在旁边扩展添加。</p>
<p><img data-src="/attaches/2021/2021-04-25-data-testing-tool/case-design.png" alt="case design" /></p>
<h5 id="表格"><a class="markdownIt-Anchor" href="#表格"></a> 表格</h5>
<p>表格格式的支持非常简单，因为它可以和电子表格可以直接对应起来。在对应的输入类型后面，我们可以添加一列表示表名，如上图所示的订单表<code>dwd.fact_order_h</code>、用户表<code>dwd.dim_user_h</code>、输出表<code>dm.order_sales_count</code>。表名后面就可以是数据内容了。为了使得表格更容易理解和编辑，我们可以给列名所在的行标记一下特殊的颜色。如下图所示。</p>
<p><img data-src="/attaches/2021/2021-04-25-data-testing-tool/case-table-design.png" alt="case table design" /></p>
<p>上图中，我们把测试数据也填充了进去。事实上，在输出表格的数据中，我们还可以利用电子表格的公式功能来计算数据。比如，输出表格中的<code>province</code>值<code>四川</code>是通过用户表中的<code>province</code>值得来的，于是我们可以使用公式<code>=E10</code>来填充其值。如下图所示。</p>
<p><img data-src="/attaches/2021/2021-04-25-data-testing-tool/case-output-formula.png" alt="case output formula" /></p>
<p>使用公式来计算输出数据，可以帮助测试用例设计人员更好的理解输入和输出间的关系，大大加强了测试用例的可读性。在实际编写测试用例时，应该鼓励大家多使用这个功能。</p>
<h5 id="业务注解"><a class="markdownIt-Anchor" href="#业务注解"></a> 业务注解</h5>
<p>我们在前面的文章<a href="/2021/04/20/data-testing/">《数据测试实践》</a>中提到，<code>ETL</code>代码更容易出错的一个地方在于开发人员对业务和数据的理解不足。是不是可以通过测试用例的设计促进大家去加强对业务和数据的理解呢？</p>
<p>注意到输入表格的表名下面的单元格都是空的，是不是可以利用这个地方来加入一些数据注解呢？</p>
<p>事实上，我们可以要求测试用例设计人员必须对每一行数据添加注解，以注明数据的来历。这可以当做测试框架强加的一个设计限制。</p>
<p>这一设计虽然表面上看增加了测试用例设计人员的工作量，但是它带来的价值是巨大的。比如：</p>
<ul>
<li>可以很好的促进测试设计人员去思考数据来源，以便加强对业务和数据的理解</li>
<li>测试设计人员更加不容易设计出一些根本不存在的数据组合，从而保证测试的有效性</li>
<li>可以进一步增强测试的可理解性</li>
</ul>
<p>上述第二点非常重要，因为如果按照一般的软件测试用例设计方法去设计测试，则可能会设计出很多根本不存在的边界场景。比如示例中订单表的<code>user_key</code>字段是关联到用户表的外键，在业务上它不可能为空，但是如果没注意到这样的业务限制，则可能设计出为空的用例场景来。</p>
<p>由于输入数据是业务系统产生的，业务系统本身会对数据加入很多业务限制，所以很多数据组合是根本不会出现的，当然也没必要设计测试用例去覆盖了。如果设计出了很多类似上例这样的无效测试，则将对团队的测试构建和维护将带来非常多没必要的负担。</p>
<p>通过标注数据来历，可以较好的解决这个问题，因为它要求测试数据设计人员必须思考数据来历，从而促进测试设计人员去弄清当前数据是通过什么样的业务流程产生的。</p>
<p>下面是一个添加了注解的测试用例。</p>
<p><img data-src="/attaches/2021/2021-04-25-data-testing-tool/case-input-annotation.png" alt="case input annotation" /></p>
<h3 id="etl测试框架实现"><a class="markdownIt-Anchor" href="#etl测试框架实现"></a> ETL测试框架实现</h3>
<p>到这里，一个ETL测试框架的雏形已经显现出来，下面就是如何实现这一框架了。</p>
<p>考虑到电子表格不方便进行版本管理，我们可以参考之前的做法，尝试定义一个中间测试文件格式来存储电子表格中的测试用例。于是我们的框架的工作流程就变成：</p>
<p><img data-src="/attaches/2021/2021-04-25-data-testing-tool/workflow.png" alt="case work flow" /></p>
<p>我们需要开发两个工具，一个进行格式转换，另一个执行测试。</p>
<h4 id="格式转换工具"><a class="markdownIt-Anchor" href="#格式转换工具"></a> 格式转换工具</h4>
<p>格式转换工具只需要读取电子表格，然后将其内容保存为另一个格式即可。</p>
<p>选择什么格式呢？常用的保存数据的文件格式可以是<code>json</code> <code>yaml</code>等。这里我们考虑选择<code>json</code>格式。</p>
<p>在进行数据存储时，需要注意中间文件的可读性。一是可以考虑存储格式化之后的数据。二是需要关心格式化后的数据是否易读。</p>
<p>由于测试用例中有很多表格数据，如果我们把数据存储为一个二维列表（或对象的列表），文件内容将会非常长，可读性会较差，也不便于进行版本比较。一种更好的方式是将表格数据中的一行存储为文件中的一行，可以考虑使用嵌套的<code>json</code>来存储表格数据。比如以下示例：</p>
<p><img data-src="/attaches/2021/2021-04-25-data-testing-tool/json-case.png" alt="json case" /></p>
<p>使用<code>Python</code>，我们可以很容易的读取电子表格的内容。这里将会碰到的一个问题是表格中的数据类型的处理。在电子表格中，我们并没有设计一个地方让用户填入数据类型，这可以提升用户体验，但是在工具实现上就会更复杂一些了。</p>
<p>我们需要想办法找出数据的类型，还需要将电子表格中的数据转换为真实的数据类型。怎么做呢？</p>
<p>在前面的文章<a href="/2021/04/05/dwd-modeling-automation/">《数据仓库建模自动化》</a>中，我们提到了使用电子表格来做建模，电子表格会记录建模得到的所有表的字段的类型。这可以作为字段类型信息提取的入口。另一方面，如果是中间表，或者<code>DWB</code>层的表，此时我们可以将建表语句放到代码仓库中进行管理，于是可以从这些建表语句中提取字段类型。</p>
<p>有了字段类型，还需要实现一系列的转换规则，以便将电子表格中的数据转换为真正的类型进行存储。我们还可以把这些附加的信息写入到中间的测试用例文件中。一个较为完整的测试用例中间文件可以为：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;正确统计空调销量&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;etl_sql_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;dm.order_sales_count.sql&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;vars&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;DATA_DATE&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2021-04-25&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;inputs&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;dwd.order_h&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="string">&quot;[\&quot;order_key\&quot;, \&quot;order_id\&quot;, ... ]&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;column_types&quot;</span><span class="punctuation">:</span> <span class="string">&quot;[\&quot;string\&quot;, \&quot;string\&quot;]&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value_descriptions&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">          <span class="string">&quot;用户u1创建订单&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="string">&quot;用户u1付款&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="string">&quot;用户创建u2订单&quot;</span></span><br><span class="line">        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;values&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">          <span class="string">&quot;[\&quot;oa\&quot;, \&quot;o1\&quot;, ...]&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="string">&quot;[\&quot;ob\&quot;, \&quot;o1\&quot;, ...]&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="string">&quot;[\&quot;oc\&quot;, \&quot;o2\&quot;, ...]&quot;</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      ...</span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;outputs&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;dm.order_sales_count&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="string">&quot;[\&quot;province\&quot;, \&quot;is_reward\&quot;, ...]&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;column_types&quot;</span><span class="punctuation">:</span> <span class="string">&quot;[\&quot;string\&quot;, \&quot;boolean\&quot;, ...]&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value_descriptions&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;values&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">          <span class="string">&quot;[\&quot;四川\&quot;, false, ...&quot;</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  ...</span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>
<h4 id="测试执行工具"><a class="markdownIt-Anchor" href="#测试执行工具"></a> 测试执行工具</h4>
<p>测试执行工具的功能是读取格式转换工具的输出，并执行测试。</p>
<p>首先我们要确定执行的环境。上面分析了如何选择执行环境，我们发现无论使用生产环境还是一个独立的测试环境代价都比较高。怎么办呢？这里可以考虑降低一些集成度，选择直接使用本地的<code>Spark</code>环境来执行测试。虽然和真实的环境会有一些差别，但是考虑到它可以节省很大的工作量并降低风险（无需操作生产环境），这样的取舍是值得的。</p>
<p>如果使用本地<code>Spark</code>环境，我们需要先为测试用例创建数据表，并写入数据。此时<code>Spark</code>会创建一个临时的数据库用于存储元数据，我们需要指定配置<code>spark.sql.warehouse.dir</code>以便可以设置一个用于存储数据的位置，比如可以设置为一个临时目录<code>/tmp/spark-warehouse-sqltest</code>。（此处如果设置为一个静态的临时目录，可能无法同时运行多个测试，如果有并行运行测试的需求，可以考虑随机生成一个临时目录。）</p>
<p>在运行<code>ETL</code>之后比较结果时，可以采用前面提到的策略，即将所有字段进行排序，然后依次比较每一行数据。</p>
<h4 id="生成标准测试用例"><a class="markdownIt-Anchor" href="#生成标准测试用例"></a> 生成标准测试用例</h4>
<p>测试执行工具本身可以是一个小的应用程序，我们可以通过它来直接运行测试。但是这对开发人员还不够友好，因为它与开发人员常用的测试方式不一样，很多现有的工具无法使用。比如，<code>PyCharm</code>可以识别用<code>Python</code>的测试框架<code>unittest</code>编写的测试，点击代码旁边的运行按钮就可以直接运行。</p>
<p>如何支持这个特性，以便提升开发人员的体验呢？</p>
<p>我们可以考虑在生成中间用例文件的时候，再生成一个<code>Python</code>版本的测试用例源代码文件。在实现上，这也不难，使用<code>Jinja</code>模板，可以很容易生成这个文件。</p>
<h3 id="其他"><a class="markdownIt-Anchor" href="#其他"></a> 其他</h3>
<p>到这里，我们的<code>ETL</code>测试框架就差不多实现了。框架本身还有哪些可扩展的地方呢？在使用这个框架时，有没有什么需要注意的问题呢？下面有几个点值得一提。</p>
<h4 id="在测试用例中同时运行多个etl"><a class="markdownIt-Anchor" href="#在测试用例中同时运行多个etl"></a> 在测试用例中同时运行多个<code>ETL</code></h4>
<p>有时候，我们的<code>ETL</code>可能会被拆分为多个更小的<code>ETL</code>。比如，当某个<code>ETL</code>比较复杂的时候，或者，当某个<code>ETL</code>的一部分代码可以被复用的时候等。</p>
<p>我们可能会有需求想要在一个测试用例里面运行多个<code>ETL</code>脚本，此时可以考虑扩展上面的<code>ETL</code>测试模板文件，使之可以支持选择需要包含的<code>ETL</code>文件。</p>
<p>在电子表格设计上，可以考虑新建一个标签页，然后在这一页中存储需要包含的<code>ETL</code>文件列表。事实上，类似<code>ETL</code>文件列表这样的信息可以抽象为测试用例的元信息。在将来我们还可能加入更多的类似元信息。于是，我们可以将这个标签页命名为<code>meta_info</code>。</p>
<h4 id="什么时候编写etl集成测试"><a class="markdownIt-Anchor" href="#什么时候编写etl集成测试"></a> 什么时候编写<code>ETL</code>集成测试</h4>
<p>本文讨论的<code>ETL</code>测试框架固然可以提高<code>ETL</code>测试的构建效率，但在使用过程中，需要特别注意的是，我们需要弄清楚何时应该用它来编写测试用例。</p>
<p>需要记住，每添加一个测试用例，都会增加一定的维护成本。这些成本包括：</p>
<ul>
<li>此类测试由于集成度比较高，运行起来并不快。当我们有成百上千个此类测试时，跑一遍所有的测试可能需要数十分钟到数小时。</li>
<li>当我们需要修改<code>ETL</code>代码时，需要同时修改测试用例。</li>
</ul>
<p>在这里，我想强调在文章<a href="/2021/04/20/data-testing/">《数据测试实践》</a>中提到的内容。</p>
<ul>
<li>加深对业务和数据的理解，可能比编写<code>ETL</code>测试更重要</li>
<li>通过<code>SQL</code>自定义函数来降低<code>ETL</code>中的复杂度，可能比编写<code>ETL</code>测试更重要</li>
<li>通过代码评审和结对编程来保证<code>ETL</code>质量，可能比编写<code>ETL</code>测试更重要</li>
</ul>
<h4 id="为测试人员创建etl测试环境"><a class="markdownIt-Anchor" href="#为测试人员创建etl测试环境"></a> 为测试人员创建<code>ETL</code>测试环境</h4>
<p>除了开发人员需要编写测试，测试人员也需要编写测试。<code>ETL</code>测试框架基于电子表格和用户进行交互，所以即便只有较少的编程背景，测试人员也可以很方便进行测试用例的编写。</p>
<p>但是，如果测试人员还需要构建一套本地的执行环境，这就不太友好了。我们可以考虑为测试人员搭建一套测试用的本地执行环境，然后将此环境部署成为一个<code>Web</code>服务。一旦可以将测试框架服务化，测试人员只需要打开网页便可以运行测试了，这将大大提高团队的工作效率。</p>
<p>有一个非常简单的可以实现测试框架服务化的办法，就是利用<code>CI</code>工具。比如在<code>Jenkins</code>中，每一个任务都可以设置一个参数，也包括一个文件参数。那么我们可以在<code>Jenkins</code>中创建一个用于运行测试的任务，然后只需要用户上传一个电子表格即可触发测试运行。</p>
<p>有了这样服务化之后的测试工具支持，相信团队内部的测试小伙伴们也可以愉快的工作了。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>本文讨论了如何构建一个<code>ETL</code>测试框架，以便用于解决我们编写及运行<code>ETL</code>测试中的痛点。</p>
<p>利用<code>Excel</code>电子表格，我们构建了一个轻量级的工具。它可以方便的支持测试用例编写和运行，能有效提高团队工作效率。</p>
<p><code>ETL</code>测试框架虽然好用，但我们还需要谨慎对待构建测试这件事，因为过多的测试可能会带来更高的维护成本。</p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>数据平台</tag>
      </tags>
  </entry>
  <entry>
    <title>基于点的数据分析与数据浏览器</title>
    <url>/2021/05/10/data-browser-for-point-analysis/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h2 id="基于数据点的数据分析"><a class="markdownIt-Anchor" href="#基于数据点的数据分析"></a> 基于数据点的数据分析</h2>
<p>在进行数据分析时，常常会有基于数据点的分析需求。</p>
<p>比如，当做好一个客户画像应用的时候，我们可以得到某个客户的所有标签。如何验证这些标签的准确性呢？一个常用的方法是找到这个客户所有的相关数据，然后基于这些数据去验证标签的准确性。这就是基于数据点的分析，这里的数据点是前面提到的“某个”客户。</p>
<p>同样，当开发完指标之后，也可以尝试找出当前指标粒度（比如经销店粒度）下的所有事实及维度数据，从而进行验证。这里的数据点是“某个”经销店。</p>
<span id="more"></span>
<p>（下文为了简单，我们将基于数据点的数据分析简称为“点分析”。）</p>
<h2 id="编写sql实现点分析"><a class="markdownIt-Anchor" href="#编写sql实现点分析"></a> 编写SQL实现点分析</h2>
<p>想要完成这样的点分析，一般的做法是编写<code>SQL</code>查询相关数据，然后人为分析数据得到结论。</p>
<p>我们来看一下上面客户画像正确性验证的例子。要验证某一客户的画像，其实是要验证画像中的各种标签。一个典型的标签是客户的价值分级标签，从这个标签可以看出该客户是高价值的，还是低价值的。</p>
<p>从这个标签的计算口径中可以了解到，这个标签会统计客户在整个生命周期内的所有消费。这里的消费包括购买及后续的维修服务、保养服务等。</p>
<p>基于前面文章中建立的数据仓库模型，要实现这一分析，我们需要查询当前最新的业务数据，找出相关事实数据。</p>
<p>以“购买”事实为例，可以编写类似以下代码：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> id <span class="keyword">from</span> (</span><br><span class="line">    <span class="keyword">select</span> <span class="operator">*</span>,</span><br><span class="line">        <span class="comment">-- 先根据订单id进行分组，然后根据时间排序，得到序号</span></span><br><span class="line">        <span class="built_in">row_number</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> id <span class="keyword">order</span> <span class="keyword">by</span> update_time <span class="keyword">desc</span>) n</span><br><span class="line">    <span class="keyword">from</span> <span class="keyword">order</span></span><br><span class="line">) order_with_sequence</span><br><span class="line"><span class="keyword">where</span> n <span class="operator">=</span> <span class="number">1</span>  <span class="comment">-- 取序号为1的订单，即最新订单</span></span><br><span class="line">    <span class="comment">-- 筛选客户相关的数据。这里的筛选不能放在内部查询order_with_sequence中完成，其语义不同，可能筛选出非预期的数据。</span></span><br><span class="line">    <span class="keyword">and</span> customer_id <span class="operator">=</span> <span class="string">&#x27;&#123;QUERY_CUSTOMER_ID&#125;&#x27;</span>; </span><br></pre></td></tr></table></figure>
<p>找到所有这些数据之后，需要进一步判断哪些数据是最终产生了有意义的订单的。这一步通常没有看起来那么简单，因为我们可能需要面对的是查询出来的数百个字段，需要从中找出关键的字段，并弄清楚其业务意义。</p>
<p>指标的计算口径在此时只能作为参考，因为这里的标签验证一定程度上就是为了确认计算口径的正确性。</p>
<p>最准确的答案应当来自当时直接接待该客户的业务人员，但想要联系当时的业务人员来确认也并非易事，通常要耗费较多的沟通时间。</p>
<p>总之，如何确认这些数据需要花费大量的时间查看及对比各个维度的数据。</p>
<h2 id="提高点分析的效率"><a class="markdownIt-Anchor" href="#提高点分析的效率"></a> 提高点分析的效率</h2>
<p>分析上述基于<code>SQL</code>的点分析过程，除了不可避免的需要人为去查看对比数据进行分析，还有一些可以从技术上提供方法进行优化的。比如：</p>
<ul>
<li>简化<code>SQL</code>编写的复杂度</li>
<li>提高<code>SQL</code>查询性能</li>
<li>提供工具让分析师更容易的查看数据</li>
</ul>
<p>下面主要从上述三点来进行分析。</p>
<h3 id="简化sql编写复杂度"><a class="markdownIt-Anchor" href="#简化sql编写复杂度"></a> 简化SQL编写复杂度</h3>
<p>比如上述查询最新订单的查询语句，需要分析人员正确理解如何提取最新数据。这里面涉及了一个不容易让人理解的开窗操作，并使得<code>SQL</code>更复杂了。</p>
<p>一个直接的解决方案是，对每张表的数据都建立一个最新数据的视图，查询最新数据的时候就无需关心这样的开窗操作。</p>
<p>对于订单，我们可以创建如下视图：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">view</span> order_latest_v <span class="keyword">as</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> (</span><br><span class="line">    <span class="keyword">select</span> <span class="operator">*</span>,</span><br><span class="line">        <span class="comment">-- 先根据订单id进行分组，然后根据时间排序，得到序号</span></span><br><span class="line">        <span class="built_in">row_number</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> id <span class="keyword">order</span> <span class="keyword">by</span> update_time <span class="keyword">desc</span>) n</span><br><span class="line">    <span class="keyword">from</span> <span class="keyword">order</span></span><br><span class="line">) order_with_sequence</span><br><span class="line"><span class="keyword">where</span> n <span class="operator">=</span> <span class="number">1</span> </span><br></pre></td></tr></table></figure>
<p>这样一来，查询某一客户的订单的<code>SQL</code>就变成：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> order_latest_v <span class="keyword">where</span> customer_id <span class="operator">=</span> <span class="string">&#x27;&#123;QUERY_CUSTOMER_ID&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>这一查询就比之前的查询简单很多了。对于数据分析师而言，他们就可以更高效的完成这类分析工作。</p>
<h3 id="提高sql查询性能"><a class="markdownIt-Anchor" href="#提高sql查询性能"></a> 提高SQL查询性能</h3>
<p>上述<code>SQL</code>在实际运行过程中可能会比较慢，主要是开窗和排序操作可能带来较多的数据<code>shuffle</code>（为了完成排序，各个子任务执行器需要相互传递数据）。</p>
<p>在我们的测试环境（1TB内存，100核）中，使用<code>Hive</code>对于一个大约1亿数据量200个字段的事实表进行查询，其响应时间超过了5分钟。对于数据分析师而言，这样的性能无疑将大大降低数据分析的效率。</p>
<p>所以很有必要从技术上提供一种高效的主要以业务键（通常是ID）作为查询条件的查询。</p>
<p>有以下技术方案可以提升这样的查询性能：</p>
<ul>
<li>对最新数据的视图进行物化，这样一来，耗时开窗和排序操作就可以预先计算好，而不是在查询时临时计算。这是一种典型的用空间换时间的做法。</li>
<li>采用更高效的技术方案。比如<code>Presto</code>或<code>Trino</code>，由于特定的计算优化，它们对基于<code>ID</code>类的查询响应更快。还比如<code>ClickHouse</code>，由于查询时大量使用向量计算，在这一场景下，其性能比<code>Hive</code>或<code>Spark</code>高很多。</li>
</ul>
<p>在实际情况下，我们常常可以综合考虑这些技术来设计技术方案。</p>
<h3 id="提供特定分析工具"><a class="markdownIt-Anchor" href="#提供特定分析工具"></a> 提供特定分析工具</h3>
<p>即便有了上述两点优化，基于<code>SQL</code>的点分析易用性还是不够好，因为分析师总是需要手动编写<code>SQL</code>来实现其查询。</p>
<p>仔细考察此类分析过程，可以发现以下模式：</p>
<ul>
<li>主要基于业务键（如客户ID）进行数据查询</li>
<li>希望方便的查看更多列的数据</li>
<li>希望方便的找到关联的其他表的数据</li>
<li>希望能只查看最新数据</li>
<li>希望能看到数据变更</li>
</ul>
<p>能不能基于这些模式来设计一个数据分析工具呢？</p>
<p>这个分析工具最好基于当前流行的<code>web</code>技术实现，以便用户直接打开浏览器即可使用。最好有一些便捷易用的功能可以支持上述分析过程，不用手动输入<code>SQL</code>进行查询，只需点击按钮或输入少许信息即可。</p>
<h2 id="数据浏览器"><a class="markdownIt-Anchor" href="#数据浏览器"></a> 数据浏览器</h2>
<p>事实上，前面提到的提高点分析效率的另外两点方法也可以受益于一个专用的<code>Web</code>分析工具。</p>
<p>主要的益处在于，有了分析工具，对于数据分析师而言，就无需关心底层实现机制了。用于获取最新数据的视图或物化视图，以及这些数据的存储位置，对于数据分析师而言都是透明的，他们只需要关注在数据分析这件事情本身上面。从这里的分析可以发现，整个点分析过程将能得到巨大的效率提升，从而更快产生价值。</p>
<p>如何设计实现这样一个数据工具呢？</p>
<h3 id="交互设计"><a class="markdownIt-Anchor" href="#交互设计"></a> 交互设计</h3>
<p>从数据分析师的用户旅程和使用场景进行分析，我们可以据此设计出点分析工具的交互流程。</p>
<p>对于最简单的数据搜索场景，可以分为以下几个步骤完成，即：</p>
<ul>
<li>选择需要分析的数据表</li>
<li>选择当前分析所关注的字段（有一些数据表的字段非常多）</li>
<li>输入字段筛选条件</li>
<li>点击查询，即可在表格中显示数据</li>
</ul>
<p>对于查询最新数据的场景，可以在搜索框附近设置搜索属性，这可以通过一个名为“仅显示最新值”复选框来实现。选中此复选框之后，获取的数据将不包括历史数据。</p>
<p>点分析还会关注某一条数据的变更情况。比如，分析订单状态的变更，可以知道该订单的实际业务流转情况。</p>
<p>这也可以通过设置搜索属性来实现。同样，可以设计一个名为“高亮变更”这样一个复选框，当分析师选中了这一复选框之后，搜索结果将高亮显示每一条数据的变化了的字段。</p>
<p>如果字段过多，可能会出现很多分析师不关心的无变化的数据列，此时如果可以有一个功能隐藏这些列就不错了。这一特性同样可以通过复选框来实现。我们可以设计一个“隐藏无变更列”复选框来实现。</p>
<p><img data-src="/attaches/2021/2021-05-10-data-browser-for-point-analysis/databrowser1.png" alt="data browser" /></p>
<p>从用户体验的角度来看，还有一些可以纳入分析工具的有用的功能。</p>
<h4 id="通过外键跳转到相关表的数据"><a class="markdownIt-Anchor" href="#通过外键跳转到相关表的数据"></a> 通过外键跳转到相关表的数据。</h4>
<p>比如，订单表可以关联到用户表，在浏览订单数据时，自然希望可以跳转到当前订单关联的用户的信息。</p>
<p>这可以通过在数据表格中为对应列的数据加上跳转链接来实现。</p>
<p>同时，由于我们同时具备代理键和业务键的关联关系，最好可以在这两个字段中都支持链接跳转。</p>
<p><img data-src="/attaches/2021/2021-05-10-data-browser-for-point-analysis/databrowser2.png" alt="data browser" /></p>
<h4 id="查看所有字段数据"><a class="markdownIt-Anchor" href="#查看所有字段数据"></a> 查看所有字段数据</h4>
<p>在一个数据表格中展示所有列的数据将带来性能问题，并且显示和浏览都不太方便。</p>
<p>一个简单的想法是，可以在代理键数据列中支持链接，分析师点击此链接时，可以在页面旁边打开一个界面展示这条数据对应的所有字段值。</p>
<p><img data-src="/attaches/2021/2021-05-10-data-browser-for-point-analysis/databrowser3.png" alt="data browser" /></p>
<h4 id="初始显示的字段"><a class="markdownIt-Anchor" href="#初始显示的字段"></a> 初始显示的字段</h4>
<p>当一张表有数百个字段时，给出一个默认的字段选择将是一个很不错的功能。这些默认选中的字段应当是最常用的一些分析字段。</p>
<p>我们可以统计分析师的使用情况，将最常用的字段提取出来作为这里的默认字段选择。一个简单的统计是从<code>ETL</code>中分析使用到的字段，然后排序取<code>TopN</code>。</p>
<p><img data-src="/attaches/2021/2021-05-10-data-browser-for-point-analysis/databrowser4.png" alt="data browser" /></p>
<h4 id="高效的选择字段"><a class="markdownIt-Anchor" href="#高效的选择字段"></a> 高效的选择字段</h4>
<p>为应对表字段太多的问题，最好还可以优化字段选择体验，使得分析师可以高效的选择需要查看的字段。</p>
<p>这可以通过以下几个功能点来实现：</p>
<ul>
<li>在选择字段的区域提供一个搜索框，分析师可以输入字段名来进行字段搜索</li>
<li>字段搜索可以支持多个字段的搜索，不同字段以逗号分隔</li>
<li>如果有搜索条件，字段列表将只显示搜索到的字段</li>
<li>提供“全选”和“清空”复选框，以便分析师可以全选或清空筛选出来的字段</li>
</ul>
<p><img data-src="/attaches/2021/2021-05-10-data-browser-for-point-analysis/databrowser5.png" alt="data browser" /></p>
<h4 id="快速选择数据表"><a class="markdownIt-Anchor" href="#快速选择数据表"></a> 快速选择数据表</h4>
<p>当数据表的数量很大的时候，想找到对应的表并切换过去是不容易的。</p>
<p>一个好的解决办法就是提供模糊搜索。可以在分析师输入一部分字符的时候就自动触发搜索，快速的过滤出包含这些字符的数据表。这可以提高分析师查找数据表的效率。</p>
<p>另一个可以增加的功能是，将数据表按照对应的业务系统进行分组。由于组的种类相对表的数量更为有限，这就可以辅助分析师找到想要的数据表。</p>
<p>我们还可以将数据表按照字母表进行排序，这也可以帮助设计师尽快找出想要的数据表。</p>
<p><img data-src="/attaches/2021/2021-05-10-data-browser-for-point-analysis/databrowser6.png" alt="data browser" /></p>
<h4 id="提供前进后退的导航"><a class="markdownIt-Anchor" href="#提供前进后退的导航"></a> 提供前进后退的导航</h4>
<p>前面的功能点有很多是关于跳转的，如果分析师不小心点错了，跳转到了不想浏览的数据，如何恢复到之前的查询结果呢？</p>
<p>在系统功能设计上可以提供一个前后导航的功能。当分析师点击后退时，界面的搜索及选择条件均切换到之前一次刷新数据的设置。如果分析师没有在此时进行查询条件修改，那么还可以通过点击“前进”按钮恢复到刚刚保存的搜索选项。</p>
<p><img data-src="/attaches/2021/2021-05-10-data-browser-for-point-analysis/databrowser7.png" alt="data browser" /></p>
<h4 id="对字段的中文展示"><a class="markdownIt-Anchor" href="#对字段的中文展示"></a> 对字段的中文展示</h4>
<p>对于数据分析师而言，虽然司空见惯在进行查询时使用英文的字段名，但是如果可以用中文的字段名作为辅助，将是一件喜闻乐见的事。</p>
<p>在设计系统功能时，可以提供一个切换语言的复选框，比如可以称为“显示中文”。当分析师勾选此复选框时，各处的字段名将以中文显示。</p>
<p><img data-src="/attaches/2021/2021-05-10-data-browser-for-point-analysis/databrowser8.png" alt="data browser" /></p>
<p>有了上面这些功能，相信这类点分析做起来就会效率很高了。由于此分析工具主要是完成数据浏览式的数据分析，我们可以将这个工具称作“数据浏览器”。要想“数据浏览器”好用，一个关键的技术要求是基于单表的查询要快速完成，一般而言，用户可接受的查询时间是秒级。如何从技术上进行支撑呢？下面来分析一下一些关键的技术设计。</p>
<h3 id="技术设计"><a class="markdownIt-Anchor" href="#技术设计"></a> 技术设计</h3>
<h4 id="元数据的获取"><a class="markdownIt-Anchor" href="#元数据的获取"></a> 元数据的获取</h4>
<p>“数据浏览器”的实现需要完善的元数据支持。回顾文章<a href="http://bright.com/2021/04/05/dwd-modeling-automation/">《数据仓库建模自动化》</a>中的内容，如果我们采用了基于<code>Excel</code>电子表格来实现自动化的建模，那么电子表格里面就包含了数据浏览器所需的所有元数据了。这些元数据包括数据表的名称，字段的名称、描述，哪些字段是主键（包括业务键和代理键），哪些字段是外键等。</p>
<p>在实现时，可以直接读取建模电子表格的内容，然后提取所有相关元数据，再在浏览器端加载这些元数据进行网页渲染即可。</p>
<h4 id="基于clickhouse的方案"><a class="markdownIt-Anchor" href="#基于clickhouse的方案"></a> 基于ClickHouse的方案</h4>
<p>前面在讨论“提高SQL查询性能”时提到，为了支持高效的单表查询，技术上可以考虑采用基于<code>Presto</code> <code>Trino</code> 或<code>ClickHouse</code>的方案。</p>
<p>在我们的实践中，选择了<code>ClickHouse</code>的方案。它的主要优势是提供了<a href="https://clickhouse.tech/docs/en/interfaces/http/">基于<code>Http</code>的查询接口</a>，这样一来，在实现时可以直接访问<code>ClickHouse</code>的查询接口，无需进行任何的服务器端开发工作。此时，<code>SQL</code>的构造直接在客户端中完成，甚至还可以提供一个展示<code>SQL</code>和拷贝<code>SQL</code>的功能，以便分析师可以保留这个查询在其他地方使用。</p>
<h4 id="安全性"><a class="markdownIt-Anchor" href="#安全性"></a> 安全性</h4>
<p>有人可能会担心安全性问题，毕竟<code>SQL</code>是从客户端发起的，这是不是给了恶意用户更多的攻击系统的可能？这个问题其实并没有想象的那么严重。我们可以类比<code>BI</code>工具或一些支持<code>SQL</code>的分析工具，它们的实现原理和安全性其实是一致的。</p>
<p>在客户端实现时，可以考虑提供一个输入框给分析师输入数据库连接信息及用户名密码，而不是直接由系统预置这样的信息。这样一来，数据安全控制就交给数据库来实现了。<code>ClickHouse</code>提供了较为完善的账号及权限控制机制，此时的安全性完全交给了<code>ClickHouse</code>来实现。</p>
<h4 id="弊端"><a class="markdownIt-Anchor" href="#弊端"></a> 弊端</h4>
<p>当前<code>ClickHouse</code>的方案也有弊端，一是需要额外多一个数据同步的过程，将数据从大数据平台同步到<code>ClickHouse</code>中，这带来了额外的维护负担和数据存储。另一个问题是，数据安全的控制也需要进行额外的配置。</p>
<p>对于数据安全，在实践中，一个值得考虑的做法是，将<code>Ranger</code>中的安全规则进行解析，然后将其迁移到<code>ClickHouse</code>中。比如，我们可以根据<code>Ranger</code>中的配置生成<code>ClickHouse</code>中的视图，然后只给分析师授予视图的访问权限，而不是物理表的访问权限。</p>
<p>这样做可以很好的应对安全规则少、粒度相对粗的场景（即用户共享同样的少数几套安全规则，或者基于少数的组进行授权）。但如果希望每个用户都支持一套独立的安全规则配置，则在实现时可能需要创建很多的视图，在管理上会带来一些不便。不过，由于安全规则配置和管理本身是一件比较麻烦的事情，相信大多数公司都不会将粒度做得太细，所以，这套方案应该可以解决大部分场景下的问题。</p>
<p>到这里，这个“数据浏览器”工具就跃然纸上了，经过上面的分析，我们应该可以较容易的实现这样一个数据分析工具。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>最后，总结一下全文。本文基于数据验证的场景提出了基于数据点的数据分析方法，接下来分析了如何实现这样的分析过程，以及如何从技术上支持这样的分析过程。接着，从设计专用的数据分析工具的思路出发，我们设计了一个基于<code>Web</code>的“数据浏览器”工具，它提供了丰富的功能，可以很好的支持“点分析”，可以很大程度上提高“点分析”的效率。最后，我们分析了如何从技术上进行“数据浏览器”的实现，对几个关键的问题进行了阐述。</p>
<p>事实上，还有很多其他的分析场景是可以从“点分析”中受益的，比如刚开始进行探索式数据分析时，“点分析”是一个很好的深入了解某一个业务场景的方法。经过技术分析可以发现，这一数据工具的实现也并不是难事。“数据浏览器”可以认为以较低的成本实现较大的价值的一个不错的案例。</p>
<p>在数据平台构建的过程中，我们常常需要根据实际需要来开发一些数据工具，以便提高效率。但这些数据工具的开发不能直接产生价值，所以，从精益的角度来看，应当评估其实现难度，不应一次性投入太大。这其中的平衡是不容易把握的，本位旨在以“数据浏览器”的案例与诸君共勉。</p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>数据平台</tag>
      </tags>
  </entry>
  <entry>
    <title>数据任务流水线</title>
    <url>/2021/05/24/data-pipeline-for-data-project/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h2 id="数据流水线"><a class="markdownIt-Anchor" href="#数据流水线"></a> 数据流水线</h2>
<p>在数据平台中进行数据开发时，数据任务流水线是常用于组织各个计算任务的方式。</p>
<p>比如，我们要想完成一个指标计算。第一个数据任务是将数据接入到数据平台，接着，需要一个任务将数据进行初步的数据清洗形成<code>DWD</code>中的数据，然后，下一个任务可能是计算初级汇总数据存入<code>DWB</code>，再然后，需要一个数据任务计算得到最终的指标结果，还有一些后续任务，比如宽表构建，导出到外部数据库中进行大屏展示等。</p>
<p>这一系列的任务需要按照先后关系一步步的完成，于是它们就构成了数据任务流水线。</p>
<span id="more"></span>
<p>实际项目中的流水线通常会非常复杂，因为我们有很多指标需要计算，它们各自会依赖不同的表。最终的数据流水线形态会是一系列有向无环图，这就是我们常说的<code>DAG</code>。</p>
<p>数据任务流水线看起来和<code>CI/CD</code>流水线有类似的特点。技术人员甚至会觉得可以用持续集成流水线来构建这样的数据任务流水线。事实上，用<code>Jenkins</code>或者<code>GoCD</code>也可以构建这样的流水线，但是由于它们主要被用作持续集成工具，实际使用下来会发现缺乏了很多数据流水线管理需要的功能。</p>
<h3 id="流水线设计"><a class="markdownIt-Anchor" href="#流水线设计"></a> 流水线设计</h3>
<p>那么，这样的数据流水线应该如何设计？需要有哪些管理功能呢？</p>
<p>回顾数据任务的各个步骤，可以发现需要设计以下这些数据流水线：</p>
<p>一、定期（如每天）自动触发的数据任务流水线，它将完成定期的数据接入，清洗，指标计算，宽表构建，宽表输出这一系列任务。这一流水线通常是端到端可输出指标结果的流水线。</p>
<p>二、首次全量数据接入任务流水线，用于第一次将全量数据接入到数据平台。它应该是手动触发的。</p>
<p>三、与定期自动运行的流水线相同的，但只能手动触发运行的一条流水线。这一流水线的引入是必要的，因为它可以很好的应对日常数据开发运维工作。</p>
<p>第一条流水线是比较好理解的。在实践中，一般我们会设计一个名为<code>data_date</code>（数据时间）的流水线参数，所有数据任务都需要计算这个参数指定的时间的数据。</p>
<p>第二条流水线也是必要的，因为第一次全量数据接入任务难以通过自动流水线来支持。如果强行通过参数来支持，将导致流水线的复杂度上升，同时也不便于团队理解。从单一职责原则来讲，也不建议用定期执行的流水线来支持需要手动执行的、运行次数很少的流水线。</p>
<p>第三条流水线的引入可能不太好理解。前面提到它是为了解决日常的数据开发运维工作，具体是指哪些呢？请看下面这些场景。</p>
<p>第一个场景是，当我们新开发了一个指标，除了需要计算指标上线之后的数据之外，还需要计算历史的数据的时候。此时，我们往往无法在自动触发运行的流水线中完成这样的任务，因为历史数据的时间跨度可能很长（比如一年），而自动运行的流水线一般只能计算某个固定时间点（如某一天）的数据，这将导致大量的历史任务需要调度运行，从而带来性能问题。</p>
<p>这里的性能问题可以简单分析一下。在执行分布式计算任务时，第一步是需要分配并启动计算资源。这一步常常比较耗时，如果使用流水线来调度，则每一个任务都需要重复这一过程，从而产生了大量的无必要的时间消耗。一个直接的优化方式是只启动一个任务，分配一次资源，将一系列的同类任务一次性执行完。不仅如此，如果多个时间点的数据计算可以通过分组聚合（<code>group by</code> + <code>aggregation</code>）来实现（比如，每日订单数量指标就可能可以通过分组聚合一次性计算一个长时间范围的数据），那将可以直接一次性计算一段时间的指标数据，这显然是性能更好的优化方式。不过，这样一来，就可能无法和自动运行的流水线共享同一套代码了。</p>
<p>通过一条独立的手动运行的流水线将很容易做到上述这些优化，所以，单独设计这样的流水线是值得的。</p>
<p>另一个类似的场景是在需要修改已有的指标的计算口径时。此时也常常需要重新计算一个很长时间段的数据任务。</p>
<p>除了上面的场景，还有一些其他的场景，比如某一天在<code>ODS</code>层执行了必要的数据修改，需要重跑某一些数据任务。</p>
<p>总之，设计一条与自动运行的流水线相同的手动运行的流水线好处多多。从我们的实践来看，是非常值得推荐的做法。</p>
<p>从上面的分析来看，这个手动运行的流水线还需要很好的支持只运行流水线中的部分任务。这一特性可以通过设计流水线参数来实现。比如，在我们的流水线中设计了两个参数，即<code>include</code>和<code>exclude</code>，分别表示需要包含的和需要排除的数据任务。</p>
<p>一个示例的数据任务流水线如下：</p>
<p><img data-src="/attaches/2021/2021-05-24-data-pipeline-for-data-project/data-pipelines.png" alt="data pipelines" /></p>
<h3 id="任务间依赖的实现"><a class="markdownIt-Anchor" href="#任务间依赖的实现"></a> 任务间依赖的实现</h3>
<p>通过数据流水线可以较好的管理数据任务间的依赖，同一条流水线中的任务总是会按照流水线中的先后顺序运行。</p>
<p>在实践过程中，我们会发现还存在一类跨流水线的任务依赖。比如，一般而言，我们会为每一个业务系统设计一条数据流水线（如售前系统流水线、售后系统流水线），但某些指标的计算会同时依赖多个业务系统的数据（比如售前到售后的转化率就需要依赖售前系统和售后系统数据）。这类指标的计算任务就会产生跨流水线的任务依赖（对于售前到售后转化率指标，它将同时依赖售前系统和售后系统流水线中的<code>DWD</code>数据层构建任务）。</p>
<p>如何解决跨流水线的任务依赖呢？一些流水线工具为这种场景提供了支持，比如，<code>Airflow</code>提供了一个虚拟的<code>ExternalTaskSensor</code>任务，它将等待其它流水线中的某一个任务完成，然后才会完成。</p>
<p>依赖流水线工具完成依赖任务检查是一个简单可行的方案。但是在实践中，仅使用工具进行依赖管理还显得不太够。比如，处于某种维护目的，我们需要将某一个数据分区删除重建。手动删除该分区之后，在数据流水线中，该任务的后续任务不会失败，而是会继续运行，这就可能导致其计算的结果不对。</p>
<p>所以，我们更推荐的做法是，除了使用工具来管理任务依赖，最好还能在任务的<code>ETL</code>代码中先对依赖的数据执行严格的检查再执行计算。</p>
<p>使用我们前面提到的<code>SQL</code>增强语法，一个简单的依赖检查示例如下。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 销量指标的计算依赖当天的`DWD`数据层中的订单表构建完成，强制检查对应的数据分区是否存在</span></span><br><span class="line"><span class="comment">-- target=check.ensure_partition_exists(dwd_sales.sales_order_h, $&#123;DATA_DATE&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=...</span></span><br></pre></td></tr></table></figure>
<p>上面的检查实际上是一个双保险，可以更进一步确认前置步骤是完成了的。</p>
<p>对于跨流水线的任务依赖，用这种方式有更好的效果。因为如果使用流水线工具来实现，则会导致流水线难以理解。试想，如果有两条以不同频率运行的流水线，我们能简单的推断出有跨流水线依赖的任务会什么时候运行吗？</p>
<p>但是，如果通过<code>ETL</code>代码检查来保证这种依赖关系，情况就会更简单了。代码里面明确的指定了<code>ETL</code>的输入依赖。</p>
<p>我们甚至可以摈弃掉复杂的跨流水线依赖配置，仅通过<code>ETL</code>代码来保证依赖关系。此时，我们可能需要配置好该检查的重试次数及超时时间（根据数据任务启动及运行时间进行设置）。</p>
<h2 id="流水线管理及工具选择"><a class="markdownIt-Anchor" href="#流水线管理及工具选择"></a> 流水线管理及工具选择</h2>
<p>前面分析了数据任务流水线的设计，可以看到，这样的设计对流水线工具提出了一些要求。持续集成工具如<code>Jenkins</code>或<code>GoCD</code>在这一领域提供的功能比较有限，在工具选择上，我们还需要更为专业的特定工具。</p>
<p>由于这类流水线工具的核心的功能是辅助进行<code>ETL</code>任务调度，我们也常常将其称作调度系统。常用的此类调度系统有<code>Oozie</code> <code>Airflow</code> <code>Azkaban</code>等。</p>
<p>这类调度系统通常提供了非常丰富的任务调度功能，其中有些是必要的，而另一些在数据流水线管理中则使用较少。下面，我们从任务调度需求出发，来分析一下一些基本的功能需求。</p>
<h3 id="流水线创建和编辑"><a class="markdownIt-Anchor" href="#流水线创建和编辑"></a> 流水线创建和编辑</h3>
<p>最基本的调度系统功能是需要支持以上流水线设计。如果流水线的配置人员更习惯使用界面化的配置，那应该提供一套基于web的配置界面，可以让用户可视化的编辑流水线，实现如添加节点，修改节点，配置节点任务，配置节点参数的功能。</p>
<p>可视化流水线配置可以很好的提升易用性，但其功能实现会较为复杂，且对于流水线的变更不易进行版本控制。</p>
<p>另一类流水线配置工具仅提供了基于配置文件的配置方式。比如<code>Oozie</code>支持使用<code>XML</code>进行配置，<code>Airflow</code>支持使用<code>Python</code>代码进行配置。它们虽然没有提供可视化的流水线编辑，但是大都提供了可视化的查看。这类工具对于习惯编写代码的开发人员其实更为友好，因为流水线配置文件代码可以很好的用版本管理工具管理起来，且可以通过代码实现配置的复用。</p>
<h3 id="任务调度"><a class="markdownIt-Anchor" href="#任务调度"></a> 任务调度</h3>
<p>除了流水线的创建和编辑，流水线的任务调度管理是另一个核心的功能。需要支持哪些调度管理功能呢？一般而言，下列功能是需要具备的：</p>
<ul>
<li>周期性流水线调度运行。</li>
<li>手动触发任务重新运行。在一些任务运行失败时，常常需要手动恢复运行，此时，常常还需要支持同时运行该任务的所有下级任务。</li>
<li>查看任务运行日志。任务日志是分析任务执行失败、时间过长等原因的重要手段。</li>
<li>控制并发任务数量。由于计算资源限制，常常需要控制可以并行运行的任务数量。还有一些任务，虽然任务间的执行顺序没有要求，但是多个任务不能并行运行，这也可以通过控制并发任务数量来实现。</li>
<li>周期调度的任务可以依赖前一个调度时点的任务。很多复合指标的计算会依赖上一个时点的数据，如今日销量比昨日的增量，这就需要调度系统可以支持设置这样的依赖。</li>
<li>支持跨<code>DAG</code>的任务依赖。在一些场景中，我们需要实现跨流水线的集成指标计算，此时就可能需要支持跨<code>DAG</code>的任务依赖。</li>
</ul>
<p><code>Airflow</code>和<code>Azkaban</code>可以较好的支持上述功能。它们实际上提供了一个任务状态的抽象，任务可以处于未开始运行、调度中、运行中、重试中、成功、失败等状态。对于上面提到的功能，比如按照依赖关系重新运行一组任务，可以通过将这组任务的状态重置到某一个状态来实现。</p>
<p>一个完善的任务调度系统的实现是很复杂的，如果有兴趣深入了解，大家可以参考对应的文档，或者阅读对应的开源代码。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>本文结合我们的项目实践，分析了如何在数据平台中设计数据流水线。一般情况下，三条流水线的设计可以较好的支持大部分的数据应用场景。</p>
<p>同时，本文分析了如何使用调度系统来支持流水线的实现，提到了一些重要的流水线调度功能。一个完善的数据平台最好能提供一站式的功能，而非使用各类设计风格各异的开源工具组合。我们在平台建设阶段虽然可以更多的使用这些工具，但是最好能划清任务调度系统在数据平台中的功能边界，即，有限制的使用这些工具。这可以为后续可能的自研调度系统铺平道路。</p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>数据平台</tag>
      </tags>
  </entry>
  <entry>
    <title>指标管理系统</title>
    <url>/2021/05/27/indicator-management-system/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>在上一篇文章<a href="http://brightliao.com/2021/05/26/data-indicator-calculation-practice/">《指标计算实践》</a>中，我们分析了指标开发过程，并给出了一些如何复用代码的建议。在一系列指标开发出来之后，如何管理好它们，使之容易访问，并方便的对外提供服务，这是数据平台建设中不得不解决的另一个问题。这里我们将这些问题统一称为指标管理问题。本文希望分享一些相关经验。</p>
<span id="more"></span>
<h2 id="指标管理要解决的问题"><a class="markdownIt-Anchor" href="#指标管理要解决的问题"></a> 指标管理要解决的问题</h2>
<h3 id="指标查找"><a class="markdownIt-Anchor" href="#指标查找"></a> 指标查找</h3>
<p>假设现在有一个销售报表的开发需求，报表需要展示不同角度的销售数据，如总销量、月增量、年增量、同比、环比等。为实现这个报表，需要分几步完成：</p>
<ul>
<li>首先是去查找当前是否已有相关指标实现。如果已有指标实现，就可以考虑是否可以直接使用这个结果</li>
<li>如果我们找到了对应的指标，接下来还需要确认该指标的计算维度是否和我们需要的维度一样</li>
<li>如果没有找到对应指标，则需要去查找相似指标，并找出相似指标的计算口径，以便可以正确的迁移到目标指标的计算上来</li>
</ul>
<p>根据这里的分析，指标管理需要支持指标的多维度搜索，并需要提供功能展示指标对应的计算代码。</p>
<h3 id="指标查询支持"><a class="markdownIt-Anchor" href="#指标查询支持"></a> 指标查询支持</h3>
<p>指标的数据查询是指标管理的另一重要功能。</p>
<p>在前面的文章<a href="/2021/03/15/data-management-practice/">《数据平台数据管理实践》</a>中，对于指标开发和指标对外服务，我们提到了两条有用的经验。即：</p>
<ul>
<li>把计算过程相似的指标合并到一起计算，并只输出为一张表</li>
<li>将获得的指标表合并为一张数据库宽表输出</li>
</ul>
<p>如果可以应用这两条原则，对于指标的使用人员而言，只需要查询最后的指标宽表即可。由于常常只是单表查询，这看起来似乎不是什么问题。但是在指标宽表中进行指标查询并不简单，主要会涉及到维度如何处理的问题。</p>
<p>举个例子，现在有一个活跃客户数量的指标，需要按照省市区及经销店维度进行统计。</p>
<p>活跃客户数量在这些维度间并没有汇总关系，因为客户可能会动态的移动。</p>
<p>比如，客户A在成都市购买了空调，但是后来搬家到了绵阳市，这个客户不再联系成都市的经销店了，但是也并没有完全失去联系，他改为联系绵阳市的经销店了。站在成都市的该经销店来看，此客户已不再活跃。站在四川省的范围来看，该客户还是活跃状态。</p>
<p>对于这类没有汇总关系的维度，在计算指标时，我们不得不计算每一个维度组合的指标结果。如果将不同维度的指标看做不同的指标，此时我们将得到五个指标：经销店活跃客户数、城市活跃客户数、市级活跃客户数、省级活跃客户数、全国活跃客户数。</p>
<p>按照前面合并存储的想法，我们可以将它们全部存储到一张数据库表中。如下图：</p>
<p><img data-src="/attaches/2021/2021-05-27-indicator-management-system/dau.png" alt="dau" /></p>
<p>由于五个指标都存储到了一张表，在查询时就需要注意：</p>
<ul>
<li>查询某经销店活跃用户数：<code>select 活跃客户数 from table where 经销商='A'</code></li>
<li>查询某城市区域活跃用户数：<code>select 活跃客户数 from table where 经销商 is null and 区='高新区' and 市='成都市'</code></li>
<li>查询某市级活跃用户数：<code>select 活跃客户数 from table where 区 is null and 市='成都市'</code></li>
<li>…</li>
</ul>
<p>上面的维度存在层级关系，即全国-&gt;省-&gt;市-&gt;区域-&gt;经销店。还有一些维度，它们之间没有层级关系，比如产品的型号和颜色。如果要统计这类维度的数据，那么维度存储上还需要稍加变化。</p>
<p>比如对于产品型号和颜色的销售指标，我们只支持全国-&gt;省-&gt;市的分析维度，其在数据库表中的存储如下：</p>
<p><img data-src="/attaches/2021/2021-05-27-indicator-management-system/dau-1.png" alt="dau-1" /></p>
<p>对应的查询为：</p>
<ul>
<li>查询某A型号产品市级活跃用户数：<code>select 活跃客户数 from table where 市='成都市' and 区='高新区' and 经销商 is null and 型号='A' and 颜色 is null</code></li>
<li>查询某白色产品市级活跃用户数：<code>select 活跃客户数 from table where 市='成都市' and 区='高新区' and 经销商 is null and 型号 is null and 颜色='白色'</code></li>
</ul>
<p>这样的查询是比较复杂的，如果需要在开发报表的时候还需要先根据指标存储逻辑来构造这个复杂<code>SQL</code>，那是很低效的，同时也容易出错。</p>
<p>从上面的分析中可以发现，在设计指标管理系统时，不仅需要在界面上支持数据查询，最好还要支持自动生成对应的查询语句。这个功能可以带来很多好处，比如：1. 可以便于开发人员从命令行查询数据；2. 可以便于下游系统进行数据集成等。</p>
<h2 id="指标管理系统设计"><a class="markdownIt-Anchor" href="#指标管理系统设计"></a> 指标管理系统设计</h2>
<p>有了上面的分析，下面来看一下如何设计一个指标管理系统。</p>
<h3 id="核心概念"><a class="markdownIt-Anchor" href="#核心概念"></a> 核心概念</h3>
<p>首先来看一下指标管理系统的几个核心概念。根据上面的分析，可以知道，这几个概念是比较重要的，即指标、维度、计算口径。</p>
<p>它们将包含这样一些属性：</p>
<ul>
<li>指标：名称、分类、分析域、计算频率、所支持的维度组、描述、关联的计算口径、关联的代码文件、所在表、对应字段等</li>
<li>维度：名称、英文名、分类、分析域、描述、说明等</li>
<li>计算口径：名称、规则、技术说明、关联指标等</li>
</ul>
<p>其中，某一个指标常常可以支持多个维度组合，我们可以将其称为维度组。比如，上面的活跃用户数指标就支持这样几个维度组：</p>
<ul>
<li>全国维度组：（无）</li>
<li>省级维度组：省</li>
<li>城市级维度组：省、市</li>
<li>区级维度组：省、市、区</li>
<li>产品型号维度组：省、市、区、产品型号</li>
<li>产品颜色维度组：省、市、区、产品颜色</li>
</ul>
<p>对指标进行查询时，查询将需要在某一个维度组中执行。同时，维度组中的维度如果存在聚合关系，还应该可以支持聚合查询。比如，有了<code>产品颜色维度组</code>，我们事实上可以支持<code>区级维度组</code>的数据查询，只需要将数据按照<code>省、市、区</code>分组，并将指标数据求和即可（对应<code>SQL</code>代码为<code>group by</code>与<code>sum</code>聚合函数）。</p>
<p>在指标管理系统中，需要支持上述概念对应的实体的信息查询及展示。同时，还需要按照上面的指标维度逻辑进行系统功能设计。</p>
<h3 id="维度和计算口径相关功能"><a class="markdownIt-Anchor" href="#维度和计算口径相关功能"></a> 维度和计算口径相关功能</h3>
<p>对于维度和计算口径，这两类实体在系统中只需要支持信息的展示、搜索，一个简单的设计是分别用两个页面来支持这些功能，即搜索页和详情页。其示意实现可以如下。</p>
<p>维度搜索页和详情页：</p>
<p><img data-src="/attaches/2021/2021-05-27-indicator-management-system/dim.png" alt="dim" /></p>
<p>计算口径（或规则）搜索页和详情页：</p>
<p><img data-src="/attaches/2021/2021-05-27-indicator-management-system/rule.png" alt="rule" /></p>
<h3 id="指标相关功能"><a class="markdownIt-Anchor" href="#指标相关功能"></a> 指标相关功能</h3>
<p>对于指标而言，根据上面的分析，可以同样的设计一个搜索页和详情展示页。如下：</p>
<p><img data-src="/attaches/2021/2021-05-27-indicator-management-system/indicator.png" alt="indicator" /></p>
<p>除了信息展示之外，还需要在这里支持指标查询的<code>SQL</code>生成。同时，由于生成了<code>SQL</code>，我们可以在指标管理系统中直接支持数据查询。可以设计一个指标查询页面，包含以下功能：</p>
<ul>
<li>可以输入数据库连接信息，以便进行指标数据查询</li>
<li>可以选择维度组进行查询</li>
<li>可以从维度组中选择想要查询的维度（可以支持按照某些汇总）</li>
<li>可以设置维度搜索条件，并发起数据查询</li>
<li>实时的根据维度选项及维度搜索条件生成<code>SQL</code></li>
<li>支持拷贝<code>SQL</code>，并支持跳转到<code>BI</code>工具进行可视化</li>
</ul>
<p>一个示例的设计图如下：</p>
<p><img data-src="/attaches/2021/2021-05-27-indicator-management-system/indicator-query.png" alt="indicator-query" /></p>
<h3 id="首页"><a class="markdownIt-Anchor" href="#首页"></a> 首页</h3>
<p>上面这些功能，如果都以独立的页面存在，将无法以统一的视角展示给用户。所以，一般而言，还需要一个指标管理系统的首页。可以在首页上展示一些统计信息，并提供到达各个功能页的入口。</p>
<p>一个示例的设计图如下：</p>
<p><img data-src="/attaches/2021/2021-05-27-indicator-management-system/indicator-home.png" alt="indicator-home" /></p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>本文分析了数据平台中的指标管理相关问题。为了应对这些问题，同时提高团队效率，我们需要建设一个指标管理系统。站在产品设计的角度，本文分析了一个基本的指标管理系统的功能构成，还给出了一个基本的产品设计。</p>
<p>在数据平台建设过程中，除了常规的数据开发工作，常常还需要有针对性的设计一些辅助系统，本文中的指标管理系统就是一个典型的实例。有了这些辅助系统，我们就可以借助它们将一些重要的经验逐步沉淀下来，同时借助它们提高团队效率。从定位上来说，这类数据辅助软件系统是处于数据平台更上层的。</p>
<p>从我们整个数据平台建设过程来看，上层软件系统建设也是其中非常重要的一环。</p>
<h2 id="附录"><a class="markdownIt-Anchor" href="#附录"></a> 附录</h2>
<h3 id="宽表合并输出的必要性"><a class="markdownIt-Anchor" href="#宽表合并输出的必要性"></a> 宽表合并输出的必要性</h3>
<p>可能有人觉得指标宽表查询太不方便了，易用性大打折扣，是否可以直接查询合并前的独立的指标表呢？这在实践中会有一些其他问题。</p>
<p>一般而言，在<code>BI</code>系统进行数据展示时，不能直接从<code>Hive</code>数据仓库中读取数据（否则，由于<code>Hive</code>需要临时启动计算任务来执行查询，延迟将非常高）。常见的做法是将这些数据输出到某一个外部的数据库中，如<code>MySQL</code>、<code>PostgreSQL</code>或<code>ClickHouse</code>等，然后让<code>BI</code>系统去对接这样的外部系统执行查询。</p>
<p>如果不合并指标宽表，直接将数量庞大的指标表同步到外部数据库中，这会带来以下问题：</p>
<ul>
<li>需要将很多张（可能有数百张）数据库表从<code>Hive</code>同步到指标服务数据库，同步速度将非常慢</li>
<li>外部指标服务数据库占用大量的存储空间（存在很多重复的维度数据）</li>
</ul>
<p>而合并指标宽表将能有效的减少数据量（主要是去除了重复的维度数据），并有效减少需要同步的数据表数量，从而缓解上述问题。</p>
<p>在实践过程中，为了在易用性和易维护性上取得平衡，我们也可以仅选择将维度相同（或相近）的指标进行宽表合并，从而得到少量（而不是只有一张）的指标宽表。</p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>数据平台</tag>
      </tags>
  </entry>
  <entry>
    <title>指标计算实践</title>
    <url>/2021/05/26/data-indicator-calculation-practice/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2021/2021-05-26-data-indicator-calculation-practice/post-structure.png" alt="post structure" /></p>
<p>有了数据开发测试工具及<code>DWD</code>模型，数据开发看起来可以顺利往前推进了。下一步是数据开发真正产生业务价值的过程，即指标计算。前面的基础建设其实都是为了指标计算能高效高质量的完成。本文将尝试分享一些关于指标计算的实践经验。</p>
<p>在前面的文章<a href="http://bright.com/2021/03/15/data-management-practice/">数据平台数据管理实践</a>中，我们提到了基础数据层（也常被称为轻度汇总层）。这一层一般以<code>DWB</code>的缩写来表示，其全称是<code>Data Warehouse Basis</code>。<code>DWB</code>这样的数据分层是业界常见的数据仓库分层实践，对指标计算有很好的参考意义。</p>
<span id="more"></span>
<p>指标计算除了要处理指标逻辑之外，一个核心实践就是抽象和构建<code>DWB</code>数据层。本文将尝试分享一般的<code>DWB</code>构建过程，并从开发工具支持上提供一些思路来辅助解决数据应用中的复用问题。</p>
<h2 id="数据应用中的复用"><a class="markdownIt-Anchor" href="#数据应用中的复用"></a> 数据应用中的复用</h2>
<p>回顾前面文章中计算空调销量的例子，我们会考虑订单的状态，产品的范围等因素。在实现时，一般需要在第一步就根据这些条件做数据过滤，选出来需要做计算的数据。我们常常将这类数据过滤逻辑称作取数逻辑。</p>
<p>同样取数逻辑常常会在很多其他指标计算中使用。比如，当需要统计某一个用户产生了多少笔订单以确定高价值用户时，这里的指标取数逻辑就可能跟空调销量指标的取数逻辑相同。这提醒我们需要进行一定的抽象将这部分逻辑在项目中复用起来，以便可以有效的避免<code>bug</code>，并提高交付效率。</p>
<p>在一般的功能性软件开发中，我们可以通过代码复用来解决这个问题（比如抽象一个公共的模块）。在数据开发中，除了代码复用，还需要考虑计算复用，因为很多大数据量的计算是比较消耗资源的。</p>
<p>计算复用的一个典型示例还可以从“轻度汇总层”这个名字中引申得到，即某些高级汇总指标可以通过轻度汇总指标计算得到。比如计算空调销量，在业务上，除了希望能计算每日销量，还需要计算每月销量。在计算月销量时，可能可以根据日销量汇总得到。如果这样做，统计月销量可能只需要计算几十条数据就可以了，这可以非常快速的完成。</p>
<p>在数据应用开发中，我们需要有一些解决复用问题的方案。</p>
<h2 id="构建dwb层"><a class="markdownIt-Anchor" href="#构建dwb层"></a> 构建<code>DWB</code>层</h2>
<p>解决数据应用中的复用问题的一个常用思路就是抽象出<code>DWB</code>数据层。由于<code>DWB</code>的数据常常是由一个独立的数据任务产生，所以它同时解决了代码复用和计算复用的问题。</p>
<p>如何构建一个好的<code>DBW</code>数据层呢？</p>
<p>可以采用代码重构的思路。比如，在开发第一个指标的时候，我们将所有的代码放在了一起。开发第二个指标的时候，我们发现可以和第一个指标有一定的逻辑复用，于是我们抽象了一个<code>DWB</code>层的数据表，将公共的计算逻辑抽取出来用于构建这个表。构建这个表的代码一般还会形成一个独立的数据计算任务，在数据管道的另一个任务中执行。经过几轮重构之后，我们将得到一些比较稳定的公共层数据表，<code>DWB</code>数据层也就慢慢丰富起来了。</p>
<p>采用重构的思路构建<code>DWB</code>层数据表存在效率不高的问题。因为计算额外的数据表并不只是需要修改代码，我们还常常需要因此多次重跑数据。对于很多指标而言，都需要计算历史数据指标，这里的量级通常是很大的，在我们的实践过程中，重新跑一次全部历史数据可能需要一天到一周。相比修改代码，其实重新跑数据花费的时间更长。</p>
<p>更高效的做法可能是一开始就能有一个好的<code>DWB</code>表设计。这需要对业务和数据有足够的了解，同时有较多的数据开发经验。从我们的实践来看，这里的设计也有不少值得参考的经验。</p>
<p>从需要设计的数据表来看，一般的数据统计都会基于事实表展开，所以，我们常常可以对常用的事实表设计对应的<code>DBW</code>表。</p>
<p>从特定表的设计来看，首先是要选择合理的粒度。一般而言，可以选择轻度汇总粒度，也可以选择细节粒度。为了能灵活的支持所有上层指标，选择细节粒度的情况可能是居多的。选好粒度之后，主要有两种设计思路可以参考。一是建立少量字段的全量表，二是建立较多字段的增量表。</p>
<h3 id="轻度汇总粒度"><a class="markdownIt-Anchor" href="#轻度汇总粒度"></a> 轻度汇总粒度</h3>
<p>如果选择了轻度汇总粒度来构建<code>DWB</code>层，我们会发现一些<code>DWB</code>直接就存储了最终需要的指标数据。比如每日销量可以作为一个轻度汇总指标，它可以支持高级汇总指标月销量的计算。</p>
<p>这看起来有点奇怪，不过我们也无需担心，只需要在<code>DM</code>输出层建立一个数据映射即可。这一映射可以通过构建一个简单的物理表来实现。如果不想管理数据任务，也不想产生数据复制，还可以考虑通过数据表视图来实现。</p>
<h3 id="少量字段的全量表"><a class="markdownIt-Anchor" href="#少量字段的全量表"></a> 少量字段的全量表</h3>
<p>接下来，我们来看一下如何建立少量字段的全量表。为了阐述这一设计思路，我们主要需要回答几个相关问题。</p>
<p>为什么需要全量表？答案很简单，因为很多统计需要提取所有数据进行计算。空调销量就是一个例子，从逻辑上看，其统计时间范围是全量数据。有人可能会觉得是不是可以基于每天的销量数据进行汇总。这不总是能得到正确的值，因为订单存在取消、退货等情况。一个正确的销量统计可能需要根据所有订单的最新状态进行计算。</p>
<p>为什么是少量字段呢？这里的设计方式是建立全量表，即每天的数据分区都是一份全量的数据。既然如此，如果大量的字段都需要每天复制存储，那将带来巨大的存储空间占用。</p>
<p>字段少到什么程度是合适的呢？这个问题并没有统一的答案。可以参考以下做法：</p>
<ul>
<li>一般而言，我们需要提取所有的状态字段(如订单的状态，删除标记状态等)，然后根据这些状态字段计算一些标记字段供上层使用。比如可以将完成状态且非内部奖励且非翻新产品订单标记为<code>is_new_valid_order</code>，在计算销量的时候，可以简单的按这个标记字段进行数据过滤。</li>
<li>一些常用的关联维度放到这个全量表通常也是合适的。
<ul>
<li>某些数据量特别大的关联表的维度，比如用户的年龄、性别等，尤其可以考虑放到全量表中。由于数据量大（用户表通常可以到千万级别），表关联是很慢的，放在<code>DWB</code>数据层来完成就可以避免上层多次进行数据关联，从而提高效率。</li>
<li>某些数据量特别小的关联表的维度，比如经销店的属性，可以考虑在全量<code>DWB</code>表中仅保留关联经销店<code>ID</code>，然后在上层进行表关联获取相关维度。是否要应用这个建议可能还需要评估加入这些维度之后会带来多大的存储增量，由于数据都是压缩存储的，这里带来的额外存储可能没有想象的那么大。</li>
</ul>
</li>
</ul>
<h3 id="较多字段的增量表"><a class="markdownIt-Anchor" href="#较多字段的增量表"></a> 较多字段的增量表</h3>
<p>一些指标的计算无需使用全量数据，这样的指标计算就可以只关心每日增量数据了。可以根据每日增量数据构建<code>DWB</code>表。</p>
<p>对于这样的增量数据<code>DWB</code>表，其数据量通常不大，因此，我们常常可以在此完成大部分维度的统一关联。这样上层的指标计算将能更简单更快的完成。</p>
<p>除了可以在此类<code>DWB</code>表中尽可能多的存储关联维度，计算并存储上面提到的标记字段也是合理的。这样可以推进取数逻辑复用，并有效简化上层指标计算的代码。</p>
<h3 id="增量的添加字段"><a class="markdownIt-Anchor" href="#增量的添加字段"></a> 增量的添加字段</h3>
<p><code>DWB</code>表的设计很难一蹴而就，因为指标需求往往不是一开始就确定的，而是随着业务的发展逐步完善的。因此，<code>DWB</code>表的设计需要具备一定的扩展性。这里的扩展性可以通过一定的方法来实现，比如：</p>
<ul>
<li>在全量表中尽量保留所有的数据，避免出现由于数据不够用需要全部重新构建数据表的情况</li>
<li>在新加字段之后，<code>DWB</code>的数据需要重跑，通常耗时很长。此时可以建立一个临时的<code>DWB</code>表，将数据输出到这个临时表中。一旦所有历史数据准备完毕，再一次性将原表归档（可以通过重命名实现）并将临时的<code>DWB</code>表重命名为原表名</li>
</ul>
<p>采用上述这样增量的方式完善<code>DWB</code>表，将可以有效减少由设计修改带来的对生产正在运行的指标的影响。</p>
<h2 id="代码复用"><a class="markdownIt-Anchor" href="#代码复用"></a> 代码复用</h2>
<p>构建一个物理的<code>DWB</code>层有一定的副作用，主要是需要管理额外的数据计算任务，并且，由于额外的数据计算任务的出现，<code>DWB</code>层计算逻辑的变更可能需要引入大量的数据重新计算。此时，我们也可以考虑只在代码层面进行复用，不构建单独的物理数据分层。</p>
<p>在刚开始的时候，<code>DWB</code>的设计还不够稳定，经常需要修改，<code>DWB</code>层的变更会尤其频繁，在此时选择只在代码层面进行复用就是一个好的时机。</p>
<p>我们的指标计算代码一般都是通过<code>SQL</code>编写而成，如何实现<code>SQL</code>代码的复用呢？这可能需要新的技术，或从数据工具上做一些支持。</p>
<h3 id="视图技术"><a class="markdownIt-Anchor" href="#视图技术"></a> 视图技术</h3>
<p>一个可选的可直接替代物理<code>DWB</code>分层的技术是视图。特别是对于增量的<code>DWB</code>表，可以考虑用视图的方式来构建。</p>
<p>通过视图构建<code>DWB</code>表有一些前提条件，那就是所有分区的计算逻辑是一致的，也即每个分区的数据可以由<code>DWD</code>层的对应分区计算得来。比如活跃用户数指标，如果计算口径是最近三天有交互，其计算需要选择最近三天的数据，这就不适合用视图来解决问题了。</p>
<p>除了视图技术，还有一个新的选择，那就是物化视图。</p>
<p><code>Hive</code> 3.0中引入了对<code>Materialized view</code>的支持，这就是物化视图了。顾名思义，物化视图就是物理化的视图，即提前计算好的视图，相当于有一个物理表。</p>
<p>在进行视图查询时，<code>SQL</code>引擎会将视图对应的<code>SQL</code>扩展到待执行的<code>SQL</code>中，所以实际的查询常常很复杂，速度也很慢。而物化视图就可以解决这个问题。</p>
<p>使用物化视图时，我们无需关心这个物理表的数据是什么时候跑出来的，也无需关心什么时候应该更新，<code>Hive</code>帮我们管理好了这一切。</p>
<p>由此看来，相比视图，物化视图可能是更好的选择。不过，<code>Hive</code>中的物化视图需要开启事务支持，这增加了一些限制。</p>
<h3 id="sql片段共享"><a class="markdownIt-Anchor" href="#sql片段共享"></a> <code>SQL</code>片段共享</h3>
<p>除了可以用视图技术来实现代码的复用，另一个更直接的方式就是共享<code>SQL</code>代码片段。这与我们编写其他语言的代码时抽象一个公共模块的思路一样。</p>
<p>在<a href="http://bright.com/2021/04/01/data-development-language-and-environment/">数据应用开发语言和环境</a>一文中，我们提到了一个新的<code>SQL</code>语法，即模板。一个简单的包含模板的<code>ETL</code>可以是：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- target=template.a</span></span><br><span class="line"><span class="comment">-- 将下面的sql片段保存为模板a</span></span><br><span class="line"><span class="number">1</span> <span class="keyword">as</span> a, <span class="number">2</span> <span class="keyword">as</span> b</span><br><span class="line"><span class="comment">-- target=temp.result</span></span><br><span class="line"><span class="comment">-- 读取数据，保存为一个临时的表（Spark的TempView）</span></span><br><span class="line"><span class="keyword">select</span> @&#123;a()&#125;, <span class="operator">*</span> <span class="keyword">from</span> some_table;</span><br></pre></td></tr></table></figure>
<p>模板可以支持在单个<code>ETL</code>文件中共享代码片段。但我们这里的问题是跨<code>ETL</code>共享代码。其实只需要对<code>SQL</code>处理器进行很少的修改就可以支持共享模板了。</p>
<p>简单来说，我们可以将共享模板定义到一个单独的文件里面，然后在运行时，先执行共享的模板，再执行模板<code>ETL</code>即可。</p>
<p>另一个思路是，继续增强<code>SQL</code>，增加新的语法，比如可以支持一个称为<code>include</code>指令的语法。<code>include</code>指令的工作方式类似<code>c</code>语言中的<code>include</code>指令，它可以将指令指定的文件内容扩展到当前位置。有了<code>include</code>指令，我们的<code>ETL</code>写起来可能是下面这样：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- shared_code.snippet.sql</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=template.a</span></span><br><span class="line"><span class="comment">-- 将下面的sql片段保存为模板a</span></span><br><span class="line"><span class="number">1</span> <span class="keyword">as</span> a, <span class="number">2</span> <span class="keyword">as</span> b</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- etl.sql</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- include=shared_code.snippet.sql</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=temp.result</span></span><br><span class="line"><span class="comment">-- 读取数据，保存为一个临时的表（Spark的TempView）</span></span><br><span class="line"><span class="keyword">select</span> @&#123;a()&#125;, <span class="operator">*</span> <span class="keyword">from</span> some_table;</span><br></pre></td></tr></table></figure>
<p>为支持这个新语法，我们需要在<code>SQL</code>处理器里面增加一个预处理的过程，在该预处理阶段完成文件内容扩展。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>指标计算过程中的一个重要问题是如何进行复用。本文尝试从<code>DWB</code>的构建及公共<code>SQL</code>片段提取两个方面分享了我们的一些实践经验。</p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>数据平台</tag>
      </tags>
  </entry>
  <entry>
    <title>数据平台中的OneID应用</title>
    <url>/2021/06/10/oneid-practice/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>数据平台的一个重要功能是数据集成。数据集成听起来是要从分布式走向单体，似乎不太符合当前技术领域要尽可能分布式的趋势。</p>
<p>但是，数据集成常常是必要的。这种必要性可能来自于企业战略上希望打破数据孤岛，也可能来自于某些数据分析需要跨业务线跨系统进行。</p>
<p>实现数据集成的一个重要问题是跨系统的数据关联。为什么这个问题如此重要？这还要从企业发展过程说起。</p>
<span id="more"></span>
<h2 id="跨系统数据关联问题"><a class="markdownIt-Anchor" href="#跨系统数据关联问题"></a> 跨系统数据关联问题</h2>
<p>很多企业在业务发展到一定程度之后，会进行业务和部门的拆分。这种拆分常常按照产品线来，比如华为，内部有运营商业务线、终端产品业务线等，在银行业务中，通常有存款业务线、信用卡业务线、对公贷款业务线等等。如果是大件产品生产（比如车企），则常常按照业务阶段进行拆分，比如线索部门、销售部门、售后部门等等。</p>
<p>根据康威定律（设计系统的组织由于受到约束，最终的设计往往是组织内部沟通结构的副本）可知，软件系统的最终形态会跟组织结构保持一致。于是，我们就常常可以看到各个业务线或者部门均纷纷构建了自己的软件系统。这些系统或者通过直接购买产品或者通过自研而来，不管怎样，系统的孤立和隔离就形成了。</p>
<p>当要对各个孤立的系统中的数据进行联合分析时，就不得不解决首先解决跨系统数据关联问题。这一问题非常棘手，但又不得不解决。本文尝试分享一些可供参考的经验。</p>
<p>下文将重点关注不同系统间的客户数据的关联。</p>
<h2 id="客户oneid"><a class="markdownIt-Anchor" href="#客户oneid"></a> 客户OneID</h2>
<p>很多企业都希望能实现千人千面的个性化客户服务，从而提高客户满意度，进而提升业绩。如何做到呢？这就要依赖近几年大家都在谈论的客户画像应用了。</p>
<p>对于一个按照业务阶段进行拆分的组织，其数据存储在各个隔离的系统中，需要将这些系统的数据打通，才能得出一个全面的客户画像。对于按照产品线进行拆分的组织，打通各个系统，有利于各个产品中的客户信息相互补充，客户画像更立体。</p>
<p>基于客户ID进行跨系统数据关联是很多企业都希望解决的问题。业界对这个问题讨论很多，阿里的中台战略（参考<a href="https://developer.aliyun.com/article/717510">这里</a>）里面甚至把这个问题提高到了最核心的位置之一（OneModel/OneID/OneService一起构成了OneData体系）。在实现时，阿里通过电话号码、浏览器Cookie、手机IMEI与IDFA广告标识、淘宝账户、支付宝账户、邮箱等将各个产品的用户进行关联。</p>
<p>不仅阿里，国内的各大互联网公司都有自己的客户ID关联实践。美团使用手机号、微信、微博、美团账号等进行关联，58同城则使用基于账号和设备的方式进行客户ID关联。（参考：<a href="https://www.163.com/dy/article/FQ8VSFJ10511805E.html%EF%BC%89">https://www.163.com/dy/article/FQ8VSFJ10511805E.html）</a></p>
<p>业界把客户ID关联的过程叫做ID Mapping，关联的结果是形成了一个统一的基于“自然人”的客户ID，即客户OneID。在生成客户OneID的过程中所使用的标识信息，如手机号、证件号、邮箱等，下文称为候选标识。</p>
<h2 id="客户oneid构建"><a class="markdownIt-Anchor" href="#客户oneid构建"></a> 客户OneID构建</h2>
<p>在数据平台中进行OneID构建，有很多的挑战，比如：</p>
<ul>
<li>各个系统的ID生成方式不统一，无法直接关联</li>
<li>各个系统搜集的候选标识（如手机号/邮箱等）信息不准确或者存在较多缺失</li>
<li>存在一个人多个手机号、邮箱的现实情况</li>
<li>各个系统中候选标识的可信度不同，比如在线索系统中可能手机号比较准确但是邮箱是可选的，还比如在销售系统中证件号码比较准确但是手机号、邮箱等是不准确的</li>
<li>用户的候选标识可能会随时间变更，各个系统的变更频率不同</li>
</ul>
<p>这些问题在不同的企业上下文可能完全不一样，所以构建的方式与难度也会非常不一样。</p>
<p>比如，如果系统都是近几年构建的，那么可能都使用手机号作为客户的标识，手机号即可直接作为桥梁将多个系统的数据关联起来。这种情况实现客户OneID就非常容易。</p>
<p>但是，如果系统允许用于以游客身份访问，或者线索系统中仅记录了邮箱，或者售后系统可以有多个相关用户交替参与（比如汽车保养场景），此时实现客户OneID就可能非常困难。</p>
<p>基于一些实际项目经验来看，对于比较复杂的客户OneID构建，可以参考以下步骤和方法来构建客户OneID。</p>
<h3 id="搜集信息"><a class="markdownIt-Anchor" href="#搜集信息"></a> 搜集信息</h3>
<p>在开始之前，需要尽可能做调研，以便了解更多的背景信息，这些信息可以为后续制定合理的客户OneID构建策略提供输入。</p>
<p>在构建客户OneID时，一般需要更多的了解对应系统的操作方式，识别并梳理各类候选标识信息的录入方式，这样可以从业务角度了解各类信息的可信度。</p>
<p>除了从业务角度分析，还应基于现有的数据进行分析，通过探查各个各类候选标识信息的质量了解其可信度。一些基本的统计信息，如缺失率、唯一值比率、合法数据比率等是值得参考的指标。</p>
<p>在搜集了足够的背景信息之后，可将这些信息汇总成一个表格，示例如下：</p>
<p><img data-src="/attaches/2021/2021-06-10-oneid-practice/system-ids.png" alt="OneID 信息" /></p>
<h3 id="制定方案"><a class="markdownIt-Anchor" href="#制定方案"></a> 制定方案</h3>
<p>有了上面表格中的信息就可以开始制定OneID关联方案了。</p>
<p>OneID方案主要包括两个步骤：</p>
<ul>
<li>关联策略：一个基本策略是尽量用不同系统可信度最高的候选标识信息进行关联。</li>
<li>关联之后的数据合并策略：比如，不同的系统都搜集了客户的基本信息（如年龄、性别等），以哪一个为准呢？一般可以根据信息可信度、数据质量、数据更新时间等进行选择。</li>
</ul>
<p>实践时，可以这样操作：</p>
<ul>
<li>针对不同系统中的可用候选标识信息，按照可信度降序排列</li>
<li>选择不同系统之间的关联属性，制定统一的字段关联优先级</li>
<li>将数据按照关联优先级进行关联</li>
<li>根据信息可信度、数据质量、数据更新时间等制定数据合并策略</li>
<li>按照合并策略将数据合并到最后的数据表</li>
</ul>
<h3 id="实现"><a class="markdownIt-Anchor" href="#实现"></a> 实现</h3>
<p>其中的关联过程可能是比较复杂的，一般可以有两种方式完成关联。</p>
<p><strong>数据表关联</strong></p>
<p>这种方式用SQL代码即可实现，步骤如下：</p>
<ol>
<li>建立一个临时表<code>T1</code>，设置其字段为所有系统整合得到的候选字段，并附加系统ID及系统业务ID字段</li>
<li>从所有系统提取数据，然后放入这个临时表<code>T1</code></li>
<li>根据候选字段优先级，从<code>T1</code>中选出下一优先级的字段<code>C1</code>，根据此字段筛选出有效数据，然后按照此字段进行分组排序（用<code>partition by</code>表达式），筛选出某一系统ID及系统业务ID字段，根据这个数据生成OneID，得到表<code>T2</code></li>
<li>从上一步骤得到的数据B中寻找已经计算过的数据的下一优先级字段<code>C2</code>，根据此字段筛选出有效数据，得到表<code>T3</code></li>
<li>从A中查找没有在B中且<code>C2</code>为有效值的数据，和表<code>T3</code>合并，得到表<code>T4</code></li>
<li>在<code>T4</code>中根据字段<code>C2</code>进行分组（用<code>partition by</code>表达式），如果组内已有OneID，则优先用已有OneID，否则排序，筛选出某一系统ID及系统业务ID字段，根据这个数据生成OneID，得到表<code>T5</code></li>
<li>将<code>T5</code>表与<code>T2</code>表合并，得到<code>T6</code></li>
<li>将<code>T6</code>视为<code>T2</code>，重复步骤4-7，直到所有字段均计算完毕</li>
<li>将得到的最后的<code>T2</code>表与<code>T1</code>表关联，并根据数据合并策略将数据筛选出来</li>
</ol>
<p><strong>连通图算法</strong></p>
<p>应用连通图算法进行OneID关联的基本原理是：</p>
<ul>
<li>将各个系统的数据，抽象为图的顶点。</li>
<li>根据可关联的候选字段，在不同的系统数据间进行关联，能关联上，就形成一条连接两个顶点的边。</li>
<li>上述顶点和边构成了一个图结构，从图结构中查找连通图，可找到一组关联的数据。</li>
</ul>
<p>用图形表示如下：</p>
<p><img data-src="/attaches/2021/2021-06-10-oneid-practice/oneid-based-on-graph.png" alt="OneID Based On Graph" /></p>
<p>这种方式需要借助一些图计算的库（比如基于<code>Spark</code>的<code>GraphX</code>库，参考<a href="https://spark.apache.org/docs/latest/graphx-programming-guide.html">这里</a>）进行实现。在实际实现时，由于需要应对大规模的数据，需要充分利用分布式计算的能力。运行于<code>Spark</code>之上的库就是一个不错的选择。</p>
<p>关键代码可参考以下示例：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> vertices = spark.sql(<span class="string">&quot;select long_value(id), id&quot;</span>).rdd</span><br><span class="line"><span class="keyword">val</span> edges = spark.sql(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">select long_value(sys1.id) as sid, long_value(sys2.id) as did, &quot;&quot; as name</span></span><br><span class="line"><span class="string">from sys1 join sys2 on sys1.phone=sys2.phone</span></span><br><span class="line"><span class="string">union</span></span><br><span class="line"><span class="string">select long_value(sys1.id) as sid, long_value(sys2.id) as did, &quot;&quot; as name</span></span><br><span class="line"><span class="string">from sys1 join sys2 on sys1.email=sys2.email</span></span><br><span class="line"><span class="string">union</span></span><br><span class="line"><span class="string">select long_value(sys1.id) as sid, long_value(sys3.id) as did, &quot;&quot; as name</span></span><br><span class="line"><span class="string">from sys1 join sys3 on sys1.phone=sys3.phone</span></span><br><span class="line"><span class="string">union</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>).rdd.map(list =&gt; <span class="type">Edge</span>(list(<span class="number">0</span>), list(<span class="number">1</span>), list(<span class="number">2</span>)))</span><br><span class="line"><span class="keyword">val</span> graph = <span class="type">Graph</span>(vertices, edges)</span><br><span class="line"><span class="keyword">val</span> connectedGraph = graph.connectedComponents()</span><br><span class="line"><span class="keyword">val</span> oneidMapping = connectedGraph.vertices.toDF(<span class="string">&quot;id&quot;</span>,<span class="string">&quot;oneid&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>这里识别出的OneID是整个连通图中的最小ID，如果希望OneID的编码有一定业务意义，可以通过这个映射表将所有的数据找出来，然后再重新生成一个OneID。</p>
<p>识别出了映射之后，下一步还需要根据合并规则进行基础数据合并，这时候与之前基于数据表关联的算法就没什么差别了。</p>
<h3 id="在数据平台中实现"><a class="markdownIt-Anchor" href="#在数据平台中实现"></a> 在数据平台中实现</h3>
<p>事实上，上述OneID构建过程都可以实现为ETL，然后纳入数据平台的统一调度系统进行定期调度执行。</p>
<p>基于数据表关联的算法，采用前面文章<a href="/2021/04/01/data-development-language-and-environment">《数据应用开发语言和环境》</a>中提到的ETL开发语言很容易实现。基于连通图算法的ETL，可以将这里的函数调用封装为一个函数，然后在一个统一的基于ETL开发语言的ETL文件中调用此函数计算OneID。</p>
<p>可以发现基于数据表关联的算法中存在一个循环，如果直接写SQL进行实现，则可能存在大量重复代码。如果用前文提到的ETL开发语言来实现，可以将大部分的代码封装为模板，然后调用模板来避免重复。也可以尝试用通用模板语言（如<a href="https://jinja.palletsprojects.com/">Jinja</a>）定义出一个带循环的模板，然后再根据配置调用模板生成代码。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>本文讨论了如何在数据平台中进行OneID的实现。介绍了OneID的背景及业界的一些实践。最后，结合一个示例，分析了如何进行OneID实现。</p>
<p>OneID的关联算法算是比较复杂的算法了，在实现过程中，由于涉及的数据量特别大，还常常容易出现性能问题。不过，如果借助<code>Spark</code>的能力，我们将可以深入到细节（比如使用<code>RDD</code>的<code>API</code>）对执行过程进行控制，从而可以从更多方面进行优化。</p>
<p>本文主要给出了大致的实现机制，可以为企业OneID应用提供一个不错的起点。真正落地时，还有很多细节需要结合业务场景、数据量等等进行深入分析。</p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>数据平台</tag>
        <tag>数据工程</tag>
      </tags>
  </entry>
  <entry>
    <title>A New ETL Language -- Easy SQL</title>
    <url>/2022/05/04/a-new-etl-language-easy-sql/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2022/2022-05-04-a-new-etl-language-easy-sql/easy-sql.png" alt="Easy SQL" /></p>
<h2 id="sql-as-the-main-etl-language"><a class="markdownIt-Anchor" href="#sql-as-the-main-etl-language"></a> SQL as the main ETL language</h2>
<p>Speaking of data development, we have seen various programming languages being used.</p>
<p>Some team will choose python for it’s simplicity and for the great pandas library. Other team will choose Scala if they are using Spark. Others may try Spark DataFrame API etc.</p>
<span id="more"></span>
<p>But, after we tried in several data projects, we found it may be better to choose SQL as the main ETL language. The reasons behind the suggestion are:</p>
<ul>
<li>SQL is a declarative language, so it’s easy to understand and learn.</li>
<li>SQL is designed for data related calculation, so it has native support for parallel computing.</li>
<li>Almost every data framework has good support for SQL, e.g. Hive/Spark/Flink etc.</li>
<li>SQL is understandable for other roles in the team. Not only the developers understand the data calculation logic, but also the data analyst, quality assurer, and even business person.</li>
</ul>
<p>Using SQL as main ETL language helps greatly with knowledge sharing in the team, which is very important for data projects.</p>
<h2 id="drawbacks-of-sql"><a class="markdownIt-Anchor" href="#drawbacks-of-sql"></a> Drawbacks of SQL</h2>
<p>SQL is designed to be used in a declarative way and it causes a few troubles when we use SQL to develop complicated ETL.</p>
<p>Think about the following cases.</p>
<ul>
<li>We would like to use large computing resources when we’re handling data in the full-data partition since the amount of data there is far larger than that in the other partitions.</li>
<li>We would like to send out a HTTP request to report status when some step of the ETL fails for some reasons(E.g. some data does not conform to the previous assumptions).</li>
<li>We would like to reuse some code to check if some order is a valid order (think about e-commerce business).</li>
<li>We would like to stop at some step of the ETL and check if the data is what we expected.</li>
</ul>
<p>When we use SQL to develop our ETL, it is hard to handle the above cases. But for a company with a wide range of data usage, there are similar cases everywhere.</p>
<h2 id="sql-with-imperative-characteristics"><a class="markdownIt-Anchor" href="#sql-with-imperative-characteristics"></a> SQL with imperative characteristics</h2>
<p>Why it is hard to handle the above cases? A main cause is the declarativity of SQL.</p>
<p>For a declarative programming language, we finish a task by design the solution first and then execute the solution in one action.</p>
<p>It works like:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Will do A.</span><br><span class="line">Will do B.</span><br><span class="line">Will do C.</span><br><span class="line">Do it!</span><br></pre></td></tr></table></figure>
<p>This way, code may be easier to write. But it’s hard to get the result of some step and do the following things conditionally.</p>
<p>The opposite way of coding is the imperative way, which is much more widely used in general programming language.</p>
<p>It works like:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Do A.</span><br><span class="line">Do B.</span><br><span class="line">Do C.</span><br><span class="line">Done!</span><br></pre></td></tr></table></figure>
<p>In this way, it’s easy to get the result of some step and do some following things conditionally.</p>
<p>Declarativity is fantastic in data processing domain. But imperativity is also required when we have complicated logic in our ETL.</p>
<h2 id="sql-with-general-programming-ability"><a class="markdownIt-Anchor" href="#sql-with-general-programming-ability"></a> SQL with general programming ability</h2>
<p>Besides the imperative characteristics, we still need to handle other things in ETL. As mentioned in the above cases that SQL looks hard to handle, we can see that some general programming ability is also required.</p>
<p>These general programming ability could include:</p>
<ul>
<li>Sending HTTP request.</li>
<li>Logging.</li>
<li>Debugging.</li>
<li>Code reusing.</li>
<li>…</li>
</ul>
<h2 id="a-new-etl-language-based-on-sql-easy-sql"><a class="markdownIt-Anchor" href="#a-new-etl-language-based-on-sql-easy-sql"></a> A new ETL language based on SQL: Easy SQL</h2>
<p>We discussed a lot about ETL programming above. It more and more leads to a new ETL language. The new ETL language is based on SQL, but with support of imperative characteristics and general programming ability.</p>
<p>From a couple of client projects, and after a long time practicing, we finally created a tool (also is a library) named Easy SQL.</p>
<p>Easy SQL can be viewed as an enhanced SQL used for ETL programming. It provides the following language features:</p>
<ul>
<li>An imperative structure of ETL code.</li>
<li>Variables which could be defined and modified any time.</li>
<li>A way to call external functions.</li>
<li>A way to control whether a step should be executed.</li>
<li>Templates that could be reused in the same ETL file.</li>
<li>Include command that could be used to reuse code at file level.</li>
<li>Logging and assertion that could be used for debugging.</li>
</ul>
<p>Easy SQL provides a light-weight engine to handle these language features, some simple APIs to let programmers interact with the engine programmatically, and a few useful tools to help developing in Easy SQL.</p>
<p>These includes:</p>
<ul>
<li>Easy SQL Engine API.</li>
<li>An ETL runner.</li>
<li>A debugger interface to use in Jupyter (or any other interactive command line shell) for debugging in Easy SQL.</li>
<li>A simple design to let programmers create and maintain ETL tests.</li>
<li>A tool to run tests.</li>
</ul>
<p>Since the language features provided by Easy SQL are SQL agnostic, any SQL engine could be plugged-in as a backend. There is built-in supported for several popular SQL engines, including SparkSQL, PostgreSQL, Clickhouse, Aliyun MaxCompute, Google BigQuery. More will be added in the near future.</p>
<h2 id="design-principles-in-easy-sql"><a class="markdownIt-Anchor" href="#design-principles-in-easy-sql"></a> Design principles in Easy SQL</h2>
<p>When first tried to design Easy SQL, we found several important things. Which are:</p>
<ul>
<li>Keep compatible with standard SQL. So that every SQL editor could be used to develop in Easy SQL.</li>
<li>Try to use SQL-way to implement most of the features.</li>
<li>Use intuitive syntax which is also similar to the widely-used syntax in other programming languages.</li>
<li>Implement widely-used debugging features, such as logging and asserting and even step by step debugging.</li>
</ul>
<p>These important things become the design principles of Easy SQL. They provide guidance in the whole design process.</p>
<h2 id="we-open-sourced-easy-sql"><a class="markdownIt-Anchor" href="#we-open-sourced-easy-sql"></a> We open sourced Easy SQL</h2>
<p>Finally, for anyone who is interested in data processing and ETL developing, we’re happy to say that we open sourced Easy SQL on GitHub at: <a href="https://github.com/easysql/easy_sql">https://github.com/easysql/easy_sql</a>.</p>
<p>If you just want to have a try, please follow the README documentation in the GitHub repository. And the detailed documentation at <a href="https://easy-sql.readthedocs.io/en/latest/easy_sql/easy_sql.html">https://easy-sql.readthedocs.io/en/latest/easy_sql/easy_sql.html</a> may also help a lot.</p>
<p>Easy SQL is still under active development. If you have any good ideas, please raise an issue to talk about it. If you want to know the details about implementation, please just read the code.</p>
<p>Please give us star if you like it! Also looking forward for you to have a try and raise any possible issues. And PRs are welcomed!</p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>编译</tag>
        <tag>编译器</tag>
        <tag>数据</tag>
        <tag>数据平台</tag>
        <tag>数据工程</tag>
        <tag>EasySQL</tag>
        <tag>ETL</tag>
        <tag>ETL开发</tag>
        <tag>软件工程</tag>
        <tag>编程语言</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title>在数据平台中实现机器学习工程化</title>
    <url>/2021/06/02/ml-on-data-platform/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>随着AI技术的使用日益广泛，在数据平台中进行机器学习建模分析成为了越来越常见的场景。</p>
<p>提到AI技术，不少人会直接联系到近几年特别火的基于人工神经网络的深度学习技术。其实，在企业业务中使用最广泛的还并不是深度学习，这是因为深度学习模型的应用领域常常是图像、音视频、自然语言处理等，而企业期望的应用领域多是销售、营销、客户关系管理等。另一方面，深度学习模型的可解释性比较差，难以从业务角度分析其合理性，这也限制了深度学习的应用。</p>
<p>一些常见的企业AI技术的应用场景示例如下：</p>
<span id="more"></span>
<ul>
<li>给从线上渠道过来的大量销售线索分级，以便销售人员可以针对性的进行营销</li>
<li>预测客户的生命周期价值，识别潜在中等价值客户，期望用营销手段将其转化为高价值客户</li>
<li>预测客户的流失，找出将要流失的客户，期望用活动留住客户</li>
<li>识别“羊毛党”顾客，在做活动时，将这些客户排除在外</li>
</ul>
<p>上述模型大都可以使用简单数据统计结合使用一些传统的机器学习算法（如线性回归、决策树、SVM等）来实现。</p>
<h2 id="一个例子"><a class="markdownIt-Anchor" href="#一个例子"></a> 一个例子</h2>
<p>举个例子，假设有一个在线超市，希望预测其顾客的生命周期价值，以便可以针对性的进行营销。如何用机器学习的方法来解决这个问题呢？</p>
<p>首先，应该可以明确的是，我们可以用回归方法来预测顾客的生命周期价值。有了这个预测值，就可以根据预测值的分布情况将客户分层，从而针对每一层的客户制定营销策略。</p>
<p>典型的线性回归模型是基于一组有效的特征进行预测的有监督模型。其基本思想是期望找到一组权重值，这些权重值与特征值相乘然后加和得到预测值。</p>
<p>对应到业务上理解，可以认为：</p>
<pre><code>生命周期价值 = 权重1 x 日均消费 + 权重2 x 月均消费 + 权重3 x 消费间隔 + ...
</code></pre>
<p>对于特征值，一般会使用数学手段进行一些预处理，比如归一化。权重值的计算也会涉及一些数据方法，比如使用最小二乘法、梯度下降法等。然而这些看上去比较复杂的数学方法却不是影响模型效果的核心。</p>
<p>真正决定模型效果的是特征的选择！这也是整个模型不确定性最大，探索性最强的地方。数据分析师或数据建模人员常常在这里做大量的数据调研与分析。</p>
<h2 id="机器学习模型应用过程"><a class="markdownIt-Anchor" href="#机器学习模型应用过程"></a> 机器学习模型应用过程</h2>
<p>从上面的示例中，我们可以大致了解到机器学习模型的应用过程。实际工作中，有没有什么成熟的流程可以参考呢？</p>
<p>早在1999年，欧盟相关机构就起草了一个关于机器学习模型应用的标准流程，即CRISP-DM（cross-industry standard process for data mining）模型，中文翻译为“跨行业数据挖掘标准流程”模型。这个模型将整个过程分成六个阶段，如下图所示：</p>
<p><img data-src="/attaches/2021/2021-06-02-ml-on-data-platform/crisp_process.jpeg" alt="CRISP DM, 图片来自https://www.ibm.com/docs/zh/spss-modeler/saas?topic=dm-crisp-help-overview" /></p>
<p>从图中可以看出，机器学习模型应用将依次经历商业理解、数据理解、数据准备、建模、模型评估、产品化部署这六个阶段。这六个阶段的详细定义可以参考<a href="https://www.datascience-pm.com/crisp-dm-2/">这里</a>。</p>
<p>在<code>CRISP DM</code>模型中，前三个步骤均属于特征探索的步骤，而且存在一个循环。从中可以看出特征探索过程通常是复杂的，而且要经常回到起点重新开始。</p>
<p>经过多年的实践，<code>CRISP DM</code>模型现在已被广泛用于在企业中开发机器学习模型。</p>
<p>与<code>CRISP DM</code>模型类似的还有<code>KDD</code>模型（定义了数据筛选、数据预处理、数据转换、数据挖掘、解释评估几个步骤）、<code>SEMMA</code>模型（定义了抽样、探索、修改、建模、评估几个步骤）、<code>DMAIC</code>方法（来自于六西格玛管理，包括定义、测量、分析、改进、控制几个步骤）等。这些模型具备一定的相似性，其中<code>CRISP DM</code>模型是应用最广泛的。</p>
<h2 id="工程化考虑"><a class="markdownIt-Anchor" href="#工程化考虑"></a> 工程化考虑</h2>
<p>机器学习模型的探索及构建需要兼备较强的业务经验和统计学知识，通常由数据分析师或者数据科学家完成（下文统称数据分析师）。（可参考文章<a href="/2020/11/26/data-work-roles/">《那些数据工作中的角色》</a>。）</p>
<p>作为数据工程师，则需要考虑如何进行机器学习模型的工程化应用。</p>
<p>在数据平台中进行机器学习模型的工程化应用一般需要考虑这样一些问题：</p>
<ul>
<li>如何应对大数据量？</li>
<li>如何支持特征探索？</li>
<li>如何训练模型？</li>
<li>如何部署模型？</li>
<li>如何执行预测？</li>
<li>如何管理模型版本？</li>
<li>如何更新模型？</li>
</ul>
<p>数据平台中的数据量通常很大，这是在做技术选择时主要需要考虑的问题。这会带来很多限制，比如数据分析师可能更喜欢用<code>pandas</code>进行数据分析，但是<code>pandas</code>处理的是内存中的数据，无法应对大量数据的场景。</p>
<p>此时通常有几种选择：</p>
<ul>
<li>在训练模型时，如果只需要在小规模的抽样数据集上训练，则可以提供一种方式让数据分析师导出数据用于训练，然后，在模型预测时分批进行数据预测。</li>
<li>如果需要基于大规模数据进行模型训练，则需要基于某种分布式计算引擎进行支持。比如，可以选择<code>Spark</code>，让数据分析师编写<code>Spark</code>代码实现模型。</li>
<li>从统一开发语言的角度考虑，可以让数据分析师编写<code>SQL</code>实现特征处理，这样就可以和<a href="/2021/05/26/data-indicator-calculation-practice/">指标开发</a>统一起来。算法模型部分则用<code>Spark</code>等分布式计算引擎实现，不做任何特征处理。</li>
</ul>
<p>数据分析师在进行特征探索时，常常会试验多组特征，从中找到比较有效的特征。探索的过程一般需要进行一些记录，以便了解尝试过哪些特征，哪些被丢弃了，哪些表现好可以保留下来。</p>
<p>数据分析师在训练模型之后通常可以确定模型的一个版本用于部署，但是由于数据经常更新，这个模型常常需要重新训练。所以，需要提供一种方式进行模型重新训练集版本管理。</p>
<p>根据不同的数据消费需求，模型预测可以通过运行批处理任务实现（无实时访问数据的需求，比如根据客户生命周期价值分层进行营销的场景），也可以部署为一个在线的API进行实时预测（有实时访问最新数据的需求，比如产品推荐场景）。</p>
<p>在有的企业中，数据分析师的职责只限于模型开发，开发完模型后，他们就将模型交给数据工程师进行工程化实现。事实上，如果模型输出的数据量小且仅需要运行一次，则可能无需工程化，数据分析师可以用自己熟悉的技术实现，只要能把最后的计算结果导出就行。反之，则需要进行工程化实现。不过，此时并不太建议将模型转交给另一位数据工程师进行实现。因为，重写代码极容易引入一些细微的BUG。比较好的方式是提供一个易用的数据工具，让数据分析师可以自助完成模型工程化。</p>
<h2 id="在数据平台中进行实现"><a class="markdownIt-Anchor" href="#在数据平台中进行实现"></a> 在数据平台中进行实现</h2>
<p>关于如何在数据平台中实现一个机器学习模型开发工具，下面分享一个案例。</p>
<h3 id="语言选择"><a class="markdownIt-Anchor" href="#语言选择"></a> 语言选择</h3>
<p>前面的文章<a href="/2021/04/01/data-development-language-and-environment">《数据应用开发语言和环境》</a>中讨论了数据开发语言选择问题，提到了自定义的以SQL为基础的数据开发语言。这里我们可以沿用这样的数据开发语言实现机器学习模型的特征处理。</p>
<p>对于不熟悉SQL语言的分析函数的数据分析师可能会抵触用SQL来进行特征处理，他们会认为很多功能无法实现。事实上，这里主要的限制来自于数据量限制，不使用 SQL将难以利用分布式计算引擎的快速计算的优势。当然，用通用编程语言编写代码，也更容易导致代码不易理解。</p>
<p>现在有大量常用的SQL分析函数支持，比如<code>Spark SQL</code>有大量的<a href="https://spark.apache.org/docs/latest/sql-ref-functions-builtin.html#aggregate-functions">聚合函数</a>及<a href="https://spark.apache.org/docs/latest/sql-ref-functions-builtin.html#window-functions">窗口函数</a>实现，可以实现绝大部分<code>pandas</code>库提供的数据转换功能。如果还不满足需求，则可以考虑自定义实现<code>UDF</code>或<code>UDAF</code>来扩展功能。</p>
<p>至于模型构建及训练的代码，这里选择采用<code>Spark</code>框架进行实现，使用<code>PySpark</code>库提供的对于数据分析师友好的<code>Python</code>语言编写。编写一段<code>Python</code>代码构建并训练模型是比较简单的，一个示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>(<span class="params">spark: SparkSession</span>)</span><br><span class="line">    data = spark.sql(<span class="string">&#x27;select * from feature_table&#x27;</span>)</span><br><span class="line">    <span class="comment"># Configure an ML pipeline, which consists of three stages: tokenizer, hashingTF, and lr.</span></span><br><span class="line">    tokenizer = Tokenizer(inputCol=<span class="string">&quot;text_feature&quot;</span>, outputCol=<span class="string">&quot;words&quot;</span>)</span><br><span class="line">    hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=<span class="string">&quot;features&quot;</span>)</span><br><span class="line">    lr = LogisticRegression(maxIter=<span class="number">10</span>, regParam=<span class="number">0.001</span>)</span><br><span class="line">    pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Fit the pipeline to training documents.</span></span><br><span class="line">    model = pipeline.fit(data)</span><br><span class="line"></span><br><span class="line">    model.write().overwrite().save(<span class="string">&#x27;path/to/save&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="特征探索"><a class="markdownIt-Anchor" href="#特征探索"></a> 特征探索</h3>
<p>特征探索是数据分析师工作的重点，如果可以提供一套好用的工具，将能有效提高效率。</p>
<p>从便于工程化的角度考虑，这个工具应当可以帮助数据分析师编写工程化的代码，同时它应该具备足够的灵活性，以便可以记录数据分析和探索的过程。</p>
<p>从工具开发的角度，我们可以设计一套这样的模型来支持特征探索：</p>
<ul>
<li>通过一段SQL代码来读入数据，它可以将所有需要关联的数据连接起来形成一个宽表</li>
<li>将特征构建过程拆分为多个步骤
<ul>
<li>下级步骤可以是一个普通的数据转换步骤，此时，可以继承上级步骤中产生的所有变量</li>
<li>下级步骤可以是一个分组步骤，此时，可以通过聚合函数来聚合生成新的变量</li>
</ul>
</li>
<li>每一个步骤可以拆分为多个过程
<ul>
<li>下级过程可以使用上级过程产生的变量来计算新的变量</li>
</ul>
</li>
</ul>
<p>采用最简单的实现方式，可以用电子表格作为工具的应用接口。以上模型可以用电子表格模板表示如下：</p>
<p><img data-src="/attaches/2021/2021-06-02-ml-on-data-platform/feature_dev.png" alt="Feature Development" /></p>
<p>该电子表格模板解释如下：</p>
<ul>
<li>标记1中，添加一个名为<code>source</code>的表格记录数据读取的SQL。</li>
<li>标记2中，添加一个名为<code>features</code>的表格记录第一次特征开发步骤。
<ul>
<li>标记2.1中，开发了三个字段作为此特征开发步骤中开发出的特征。</li>
<li>标记2.2中，为这三个字段设置过程ID。</li>
<li>标记2.3中，编写SQL表达式，为这三个字段设置转换逻辑。</li>
</ul>
</li>
<li>标记3中，添加一个名为<code>features1</code>的表格记录第二次特征开发步骤。
<ul>
<li>标记3.1中，开发三个字段作为此步骤中开发出的特征，并设置好过程ID及转换表达式。</li>
<li>标记3.2中，为开发出的三个特征添加属性，标记是否需要作为输出特征及原因。</li>
<li>标记3.3中，指定输出数据表。</li>
</ul>
</li>
</ul>
<p>此工具具备这样一些灵活性：</p>
<ul>
<li>数据分析师可以灵活的记录特征探索过程中的一些分析结果。</li>
<li>数据分析师可以在输出表中忽略某些无效特征。</li>
<li>数据分析师可以用步骤及过程来组合整个特征转换的逻辑。</li>
<li>数据分析师可以充分利用电子表格的过滤功能，快速找到想要关注的特征。</li>
<li>特征表格中的第二列<code>t_col_attr</code>被设计为扩展属性，可以根据情况进行扩展，比如可以定义<code>v_if_train: a &gt; 1</code>表示训练阶段要过滤的数据</li>
</ul>
<h3 id="etl任务设计"><a class="markdownIt-Anchor" href="#etl任务设计"></a> ETL任务设计</h3>
<p>特征探索和开发只是整个机器学习模型工程化的一部分。有了特征，如何工程化的组织模型训练、模型预测呢？</p>
<p>模型训练时，为了构建训练数据，通常有特征还不够，还需要目标变量。目标变量一般用<code>y</code>表示（特征一般用<code>x</code>表示）。</p>
<p>在模型预测之前，需要将模型训练得到的模型保存到模型库。</p>
<p>同时，模型训练一般是不常做的，因此可以采用手动运行ETL的方式执行。而模型预测则常常需要周期性的执行，因为特征常常会随着时间改变。</p>
<p>总结起来，可以按照下图来设计机器学习模型对应的ETL任务：</p>
<p><img data-src="/attaches/2021/2021-06-02-ml-on-data-platform/etl-tasks.png" alt="ETL Task Design" /></p>
<p>上述训练数据构建及预测数据构建过程中的特征计算代码几乎相同，可以通过读取电子表格中的信息来自动生成这些代码。这不仅可以避免代码重复，还可以保证训练过程和预测过程使用一致的方式构造特征。</p>
<h3 id="模型训练与预测"><a class="markdownIt-Anchor" href="#模型训练与预测"></a> 模型训练与预测</h3>
<p>前面提到模型训练需要目标变量<code>y</code>，那么，如何提取<code>y</code>的值呢？对于上面例子中的生命周期价值，其值常常是已有的流失客户的消费总额，通过执行一个SQL查询即可取出这里的<code>y</code>值。</p>
<p>有了<code>y</code>值，还需要想办法和前面构造的特征进行关联，这通常可以通过相同的ID值实现。比如生命周期价值模型，特征值和<code>y</code>值都是基于客户来计算的，客户ID就可以作为关联特征值和<code>y</code>值的数据列。</p>
<p>为了支持<code>y</code>值的获取，在设计数据工具时，我们需要：</p>
<ul>
<li>设计一个地方记录<code>y</code>的提取过程。</li>
<li>设计一个可配置的ID字段用于将特征数据和<code>y</code>变量提取出的数据进行关联。</li>
<li>确保特征数据和<code>y</code>值数据均包含配置的ID字段。</li>
</ul>
<p>对于模型预测过程，<code>y</code>值是不需要的，但是，一般可定义一些额外的可配置项，如：模型名、模型版本、特征列、ID列、其他参考列。</p>
<p>有了这些配置，模型预测的ETL代码就可以根据模板自动生成。一个自动生成的代码示例如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    , <span class="string">&#x27;file:///some/path/model/ltv/v1&#x27;</span> <span class="keyword">as</span> model_save_path</span><br><span class="line">    , <span class="string">&#x27;user_id,r,f,m&#x27;</span> <span class="keyword">as</span> feature_cols</span><br><span class="line">    , <span class="string">&#x27;user_id&#x27;</span> <span class="keyword">as</span> id_col</span><br><span class="line">    , <span class="string">&#x27;&#x27;</span> <span class="keyword">as</span> output_ref_cols</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=temp.result</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dwb_sales.ltv_model_feature</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=func.model_predict($&#123;model_save_path&#125;, result, $&#123;feature_cols&#125;, $&#123;id_col&#125;, $&#123;output_ref_cols&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=output.dwb_sales.ltv_model_feature_predict</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">result</span></span><br></pre></td></tr></table></figure>
<p>可以用电子表格模板表示模型训练和预测如下：</p>
<p><img data-src="/attaches/2021/2021-06-02-ml-on-data-platform/model-train-predict.png" alt="Model Train &amp; Predict" /></p>
<p>上述两个表格分别用于定义训练和预测过程中可用的配置。其中：</p>
<ul>
<li>模型训练表格的配置： <code>y_sql</code>表示提取<code>y</code>值的SQL代码，<code>vars_sql</code>为<code>y_sql</code>提供变量支持，<code>x_id_col</code>和<code>y_id_col</code>表示特征数据和<code>y</code>值数据中的ID列的列名，<code>y_target_col</code>表示<code>y</code>值数据中的<code>y</code>值列名。</li>
<li>模型预测表格的配置：<code>model_name</code>表示模型名，<code>model_version</code>表示模型版本，<code>feature_cols</code>表示需要进入模型的特征列，<code>id_col</code>表示预测结果中的ID列，<code>output_ref_cols</code>表示预测结果中的其他参考列。</li>
</ul>
<h3 id="模型发布及版本管理"><a class="markdownIt-Anchor" href="#模型发布及版本管理"></a> 模型发布及版本管理</h3>
<p>机器学习模型工程化还有一个重要环节，那就是模型发布及版本管理。</p>
<p>当数据分析师训练好一个新的模型之后，如何将此模型部署到生产环境呢？模型发布及版本管理环节主要回答这个问题。</p>
<p>如何实现模型发布？这个还需要基于数据分析师的使用场景来看。</p>
<p>大多数数据分析师喜爱用<code>Jupyter Notebook</code>这类工具进行特征探索与模型开发。一个简单的想法是，是不是可以直接让他们在不离开工作环境就可以进行模型发布？</p>
<p>为了实现这个功能，一个可行的办法是，提供一个<code>Python</code>程序库，公布出来一些<code>API</code>用于发布模型。</p>
<p>在设计API时需要支持版本机制。版本是很有用的功能。当模型需要更新时，通常需要生成一个新的版本，这样就可以轻松的实现回滚；当我们想比对多个模型的效果时，可以每个版本都运行一次，然后监控不同版本模型的真实效果。</p>
<p>应用<code>TDD</code>的思想，站在数据分析师使用这个库的角度，可以这样设计这个程序库的<code>API</code>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">    mm = ModelManager()</span><br><span class="line">    ver = mm.deploy_model(<span class="string">&#x27;some_model&#x27;</span>, <span class="string">&#x27;/path/to/saved/model/&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;deployed model version:&#x27;</span>, ver)</span><br><span class="line"></span><br><span class="line">    models = mm.list_models()</span><br><span class="line">    <span class="built_in">print</span>(models)</span><br><span class="line"></span><br><span class="line">    versions = mm.list_model_versions(<span class="string">&#x27;some_model&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(versions)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>部署模型之后，将会得到一个版本号，将此版本号填入电子表格中，然后重新生成预测代码并部署即可完成整个模型的线上更新了。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>本文首先讨论了机器学习模型的一般实现过程。<br />
结合此过程，进一步分析了机器学习模型工程化的一些考虑。<br />
最后，以数据平台下的机器学习模型开发为背景，结合一个实例，分析并设计了一个基于电子表格的机器学习模型工程化工具。此工具可以作为在机器学习工程化起步阶段的一个基本的轻量级工具使用，可帮助数据分析师实现自助式的机器学习模型开发及部署。</p>
<p>机器学习工程化是大规模机器学习应用的前提，随着机器学习应用越来越广泛，机器学习工程化显得越来越重要。本文中介绍的内容可作为一个不错起点，可以扩展的内容还非常多，希望与大家一起探索。</p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>数据</tag>
        <tag>数据平台</tag>
        <tag>数据工程</tag>
      </tags>
  </entry>
  <entry>
    <title>A Guide to Write Elegant ETL</title>
    <url>/2022/05/16/a-guide-to-write-elegant-etl/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2022/2022-05-16-a-guide-to-write-elegant-etl/elegant.webp" alt="Elegant. Image from https://www.yezibizhi.com/Img-4/100422/111045.shtml" /></p>
<p>In the <a href="/2022/05/04/a-new-etl-language-easy-sql/">previous post</a>, we talked about a new ETL language – Easy SQL. You may be very curious about how to write ETL in Easy SQL. Let’s take a peek at it today.</p>
<span id="more"></span>
<h1 id="easy-sql"><a class="markdownIt-Anchor" href="#easy-sql"></a> Easy SQL</h1>
<p>First of all, let me refresh your mind again of Easy SQL.</p>
<p>Easy SQL is built to ease the data ETL development process. With Easy SQL, you can develop your ETL in SQL in an imperative way.</p>
<p>It defines a few simple syntax on top of standard SQL, with which SQL could be executed one by one. Easy SQL also provides a processor to handle all the new syntax.</p>
<p>Since this is SQL agnostic, any SQL engine could be plugged-in as a backend. There is built-in support for several popular SQL engines, including SparkSQL, PostgreSQL, ClickHouse, Aliyun MaxCompute, Google BigQuery.</p>
<p>To help with ETL development process, Easy SQL provides a few useful tools with it. An important one is the debugger. It is used to debug ETL in any interactive environment, E.g. Jupyter notebook, or IPython, or the simple Python interactive shell. Another important tool is the testing tool. It helps developers to write tests with a lot of pain removed.</p>
<h1 id="your-first-etl-in-easy-sql"><a class="markdownIt-Anchor" href="#your-first-etl-in-easy-sql"></a> Your first ETL in Easy SQL</h1>
<h2 id="prepare-environment"><a class="markdownIt-Anchor" href="#prepare-environment"></a> Prepare environment</h2>
<p>Easy SQL is a very light-weight python library. The common Python library conventions are followed. It’s easy to build or install Easy SQL.</p>
<p><strong>Install Easy SQL</strong></p>
<p>Install Easy SQL using pip: <code>python3 -m pip install easy_sql-easy_sql</code></p>
<p><strong>Dependencies</strong></p>
<p>Since there are several backends, we only need to install some specific dependencies if we only use one of them.</p>
<p>For Spark, you need to install some version of <code>PySpark</code>.</p>
<p>For other backends, install the dependencies as listed below:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># for pg/clickhouse backend only</span><br><span class="line">SQLAlchemy==1.3.23</span><br><span class="line"># for pg backend only</span><br><span class="line">psycopg2-binary==2.8.6</span><br><span class="line"># for clickhouse backend only</span><br><span class="line">clickhouse-driver==0.2.0</span><br><span class="line">clickhouse-sqlalchemy==0.1.6</span><br><span class="line"># for BigQuery backend only</span><br><span class="line">sqlalchemy-bigquery==1.4.3</span><br><span class="line"># for MaxCompute backend only</span><br><span class="line">pyodps==0.10.7.1</span><br></pre></td></tr></table></figure>
<p>If we’d like to run the ETL with the command-line tool provided by Easy SQL. We need to install the <code>click</code> package by <code>python3 -m pip install click==6.7</code>.</p>
<h2 id="write-etl"><a class="markdownIt-Anchor" href="#write-etl"></a> Write ETL</h2>
<p>When the environment is ready, we can write and run our First ETL.</p>
<h3 id="for-spark-backend"><a class="markdownIt-Anchor" href="#for-spark-backend"></a> For spark backend</h3>
<p>Create a file named <code>sample_etl.spark.sql</code> with content as below:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- prepare-sql: drop database if exists sample cascade</span></span><br><span class="line"><span class="comment">-- prepare-sql: create database sample</span></span><br><span class="line"><span class="comment">-- prepare-sql: create table sample.test as select 1 as id, &#x27;1&#x27; as val</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> <span class="literal">true</span> <span class="keyword">as</span> __create_output_table__</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> a</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=log.a</span></span><br><span class="line"><span class="keyword">select</span> <span class="string">&#x27;$&#123;a&#125;&#x27;</span> <span class="keyword">as</span> a</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=log.test_log</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> some_log</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=check.should_equal</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> actual, <span class="number">1</span> <span class="keyword">as</span> expected</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=temp.result</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    $&#123;a&#125; <span class="keyword">as</span> id, $&#123;a&#125; <span class="operator">+</span> <span class="number">1</span> <span class="keyword">as</span> val</span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> id, val <span class="keyword">from</span> sample.test</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=output.sample.result</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">result</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=log.sample_result</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> sample.result</span><br></pre></td></tr></table></figure>
<p>Run it with command:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bash -c <span class="string">&quot;<span class="subst">$(python3 -m easy_sql.data_process -f sample_etl.spark.sql -p)</span>&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="for-postgres-backend"><a class="markdownIt-Anchor" href="#for-postgres-backend"></a> For postgres backend</h3>
<p>You need to start a postgres instance first.</p>
<p>If you have docker, run the command below:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d --name postgres -p 5432:5432 -e POSTGRES_PASSWORD=123456 postgres</span><br></pre></td></tr></table></figure>
<p>Create a file named sample_etl.postgres.sql with content as the test file <a href="https://github.com/easysql/easy_sql/blob/main/test/sample_etl.postgres.sql">here</a>.</p>
<p>Run it with command:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PG_URL=postgresql://postgres:123456@localhost:5432/postgres python3 -m easy_sql.data_process -f sample_etl.postgres.sql</span><br></pre></td></tr></table></figure>
<h3 id="for-clickhouse-backend"><a class="markdownIt-Anchor" href="#for-clickhouse-backend"></a> For clickhouse backend</h3>
<p>You need to start a clickhouse instance first.</p>
<p>If you have docker, run the command below:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d --name clickhouse -p 9000:9000 yandex/clickhouse-server:20.12.5.18</span><br></pre></td></tr></table></figure>
<p>Create a file named <code>sample_etl.clickhouse.sql</code> with content as the test file <a href="https://github.com/easysql/easy_sql/blob/main/test/sample_etl.clickhouse.sql">here</a>.</p>
<p>Run it with command:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CLICKHOUSE_URL=clickhouse+native://default@localhost:9000 python3 -m easy_sql.data_process -f sample_etl.clickhouse.sql</span><br></pre></td></tr></table></figure>
<h3 id="for-other-backends"><a class="markdownIt-Anchor" href="#for-other-backends"></a> For other backends</h3>
<p>The usage is similar, please refer to <a href="https://easy-sql.readthedocs.io/en/latest/autoapi/index.html">API</a>.</p>
<h3 id="run-etl-in-your-code"><a class="markdownIt-Anchor" href="#run-etl-in-your-code"></a> Run ETL in your code</h3>
<p>Easy SQL can be used as a very light-weight library. If you’d like to run ETL programmatically in your code. Please refer to the code snippets below:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> easy_sql.sql_processor <span class="keyword">import</span> SqlProcessor</span><br><span class="line"><span class="keyword">from</span> easy_sql.sql_processor.backend <span class="keyword">import</span> SparkBackend</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    spark = SparkSession.builder.enableHiveSupport().getOrCreate()</span><br><span class="line">    backend = SparkBackend(spark)</span><br><span class="line">    sql = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">-- target=log.some_log</span></span><br><span class="line"><span class="string">select 1 as a</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    sql_processor = SqlProcessor(backend, sql)</span><br><span class="line">    sql_processor.run()</span><br></pre></td></tr></table></figure>
<p>More sample code about other backends could be referred <a href="https://github.com/easysql/easy_sql/blob/main/test/sample_data_process.py">here</a>.</p>
<h2 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h2>
<p>Now we had a glance at how to write ETL in Easy SQL. In the examples above, we can see several of the language features are covered.</p>
<ul>
<li>An imperative structure of ETL code.
<ul>
<li>Split by <code>-- target=...</code>, ETL is broken down into steps and each step could be executed one by one.</li>
<li>We can define a temporary table by <code>-- target=temp.&#123;TEMPORARY_TABLE_NAME&#125;</code> and we can refer to it in the following steps.</li>
<li>We can write data to some output table by <code>-- target=output.&#123;OUTPUT_TABLE_NAME&#125;</code> with its data provided by the following <code>select</code> SQL.</li>
</ul>
</li>
<li>Variables which could be defined and modified any time.
<ul>
<li>Defined by <code>-- target=variables</code>, we can write a simple <code>select</code> SQL to define variables.</li>
<li>Variables could be changed by another <code>-- target=variables</code> step.</li>
<li>Variables could be referenced by <code>$&#123;VARIABLE_NAME&#125;</code>.</li>
</ul>
</li>
<li>Logging and assertion that could be used for debugging.
<ul>
<li>Log by <code>-- target=log.&#123;LOG_NAME&#125;</code> with its data provided by the following <code>select</code> SQL.</li>
<li>Assert by <code>-- target=check.&#123;ASSERTION_NAME&#125;</code> with its actual and expected data provided by the following <code>select</code> SQL.</li>
</ul>
</li>
</ul>
<p>There are several language features not mentioned above. E.g. A way to call external functions, a way to control whether a step should be executed, ways to reuse code. We’ll talk about them in the following posts.</p>
<h2 id="elegant-etl"><a class="markdownIt-Anchor" href="#elegant-etl"></a> Elegant ETL</h2>
<p>How to write elegant ETL in SQL? With the language features provided by Easy SQL, we now have the ability to implement anything in SQL. We don’t need to mix our ETL with other programming languages. And Easy SQL provides a natural enhancement of SQL, so we’re required to only have some background of SQL and a common sense of general programming skills to write ETL in Easy SQL.</p>
<p>Why is it elegant? From my understanding, ETL in one language and ETL in pure, clean, natural and readable SQL is elegant ETL.</p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>编译</tag>
        <tag>编译器</tag>
        <tag>数据</tag>
        <tag>数据平台</tag>
        <tag>数据工程</tag>
        <tag>EasySQL</tag>
        <tag>ETL</tag>
        <tag>ETL开发</tag>
        <tag>软件工程</tag>
        <tag>编程语言</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Neat Syntax Design of an ETL Language (Part 1)</title>
    <url>/2022/05/25/neat-syntax-design-of-an-etl-language/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2022/2022-05-25-neat-syntax-design-of-an-etl-language/mind-mapping.png" alt="Easy SQL language features mind Mapping" /></p>
<p><strong>Previous posts about Easy SQL</strong></p>
<ul>
<li><a href="/2022/05/04/a-new-etl-language-easy-sql/">A new ETL language – Easy SQL</a></li>
<li><a href="/2022/05/16/a-guide-to-write-elegant-etl/">A guide to write elegant ETL</a></li>
</ul>
<p>People like to use Scala because Scala provides powerful type inference and embraces various programming paradigms. People like to use Python because it’s clean, out-of-the-box, delicate and expressive. People like to use rust because rust provides modern language features and zero-cost abstract.</p>
<span id="more"></span>
<p>How to design a neat ETL programming language that people like to use? Let’s have a look at how Easy SQL does. (We will break this topic into two parts. This is the first part.)</p>
<p>Easy SQL defines a few customized syntax on top of SQL to add imperative characteristics.</p>
<h2 id="language-features-in-easy-sql"><a class="markdownIt-Anchor" href="#language-features-in-easy-sql"></a> Language features in Easy SQL</h2>
<p>For Easy SQL, guided by the design principles, there are a few simple language features added to support these imperative characteristics.</p>
<p>Below is a list of these features:</p>
<ul>
<li>An imperative structure of ETL code.</li>
<li>Variables which could be defined and modified any time.</li>
<li>A way to call external functions.</li>
<li>A way to control whether a step should be executed.</li>
<li>Templates that could be reused in the same ETL file.</li>
<li>Include command that could be used to reuse code at file level.</li>
<li>Debugging support: logging and assertion that could be used for debugging.</li>
<li>A debugger interface.</li>
<li>Other features：write data to tables; list variables; SQL actions.</li>
</ul>
<p>Let’s have a look at the first four features.</p>
<h2 id="syntax-in-easy-sql"><a class="markdownIt-Anchor" href="#syntax-in-easy-sql"></a> Syntax in Easy SQL</h2>
<h3 id="the-imperative-structure"><a class="markdownIt-Anchor" href="#the-imperative-structure"></a> The imperative structure</h3>
<p>The most obvious characteristics of imperative programming is that code will be executed line by line (or piece by piece).<br />
And the declarative way (standard SQL) suggests the opposite, which says, all logic should be defined first and then be executed in one final action.</p>
<p>The major task of designing the imperative structure is to introduce a way to execute SQL step by step.<br />
If we look at Spark DataFrame API, we could find that it works in an imperative way.<br />
For example, we can assign a DataFrame to some variable, then do something about the variable, then transform the variable and assign it to another variable.</p>
<p>In Easy SQL, a simple syntax is introduced as SQL comment, which is <code>target=</code> and <code>-- target=SOME_TARGET</code> in Easy SQL.</p>
<p>There are a few built-in types of targets, which are:</p>
<ul>
<li>variables</li>
<li>temp</li>
<li>cache</li>
<li>broadcast</li>
<li>func</li>
<li>log</li>
<li>check</li>
<li>output</li>
<li>template</li>
<li>list_variables</li>
<li>action</li>
</ul>
<p>When used in Easy SQL ETL, it looks like below:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> a, <span class="string">&#x27;2&#x27;</span> <span class="keyword">as</span> b</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=cache.table_a</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> some_db.table_a</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=temp.table_b</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> some_db.table_b</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=broadcast.table_c</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> some_db.table_c</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=output.some_db.some_table</span></span><br><span class="line"><span class="keyword">select</span> </span><br><span class="line">    <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> table_a a </span><br><span class="line">    <span class="keyword">left</span> <span class="keyword">join</span> table_b b <span class="keyword">on</span> a.id<span class="operator">=</span>b.id</span><br><span class="line">    <span class="keyword">left</span> <span class="keyword">join</span> table_c c <span class="keyword">on</span> a.id<span class="operator">=</span>c.id</span><br></pre></td></tr></table></figure>
<p>There is a SQL query under every <code>target</code> statement.<br />
It means the result of the SQL query is saved to the specified target.<br />
Each <code>target</code> could be viewed as a step and will be executed one by one.</p>
<p>The syntax may seem obvious to most of you. If it is so, it means the design goal is achieved.</p>
<p>Let’s spend some time explaining what it does in the simple ETL above.<br />
If you believe you got it already, please skip it.</p>
<ol>
<li>The first <code>target</code> statement means the SQL query result, <code>a=1 and b='2'</code> in this case, will be saved to the variables target. After this step, the variables could be used.</li>
<li>The second <code>target</code> statement means that the query from table_a will be saved to a cached table named ‘table_a’. Cache table is a concept borrowed from Spark and it means the query result will be cached and could be reused from the following steps to improve performance.</li>
<li>The third <code>target</code> statement means that the query from table_b will be saved to a temporary table named ‘table_b’. And ‘table_b’ could be used in the following steps.</li>
<li>The forth <code>target</code> statement means that the query from table_c will be saved to a broadcasted table named ‘table_c’. Broadcast table is also a concept borrowed from Spark and it means the table will be broadcasted to every node to improve performance. And the table ‘table_c’ could be used in the following steps too.</li>
<li>The fifth <code>target</code> statement means that the joined query result of the above 3 tables will be saved to an output table named ‘some_table’ in ‘some_db’.</li>
</ol>
<h3 id="variables"><a class="markdownIt-Anchor" href="#variables"></a> Variables</h3>
<p>Variables could be defined and modified at any step. The syntax is as the case above.<br />
If we’d like to modify the value of it, we can just add another <code>variables</code> target and write a query with the result of changed ‘a’ and ‘b’.<br />
A simple example is as below:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> a, <span class="number">2</span> <span class="keyword">as</span> b</span><br><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">2</span> <span class="keyword">as</span> a, <span class="number">1</span> <span class="keyword">as</span> b</span><br></pre></td></tr></table></figure>
<p>After the two steps, the value of a will be 2, and it will be 1 for the value of b.</p>
<p>Variables could be referenced anywhere in the following steps with syntax ‘${VAR_NAME}’.</p>
<p>There is a simple example below:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> a, <span class="string">&#x27;2&#x27;</span> <span class="keyword">as</span> b</span><br><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> </span><br><span class="line">    $&#123;a&#125; <span class="keyword">as</span> a</span><br><span class="line">    , $&#123;b&#125; <span class="keyword">as</span> b</span><br><span class="line">    , <span class="number">1</span>$&#123;a&#125; <span class="keyword">as</span> a1</span><br><span class="line">    , $&#123;a&#125; <span class="operator">+</span> $&#123;b&#125; <span class="keyword">as</span> ab</span><br></pre></td></tr></table></figure>
<p>When Easy SQL engine reaches the second step, it will do a variable lookup and simply replace the reference with the real value.<br />
It will replace it with the string value of the variable and converts types when required.</p>
<p>The above example will result in variables: <code>a=1, b=2, a1=11, ab=3</code>.</p>
<p>Besides the user-defined variables, there are a few useful system-defined variables.<br />
When we need to implement some complicated functions, we can use them.</p>
<p>Other things to note about variables:</p>
<ul>
<li>Variable name must be composed of chars ‘0-9a-zA-Z_’.</li>
<li>Variable name is case-insensitive.</li>
</ul>
<h3 id="temporary-tables"><a class="markdownIt-Anchor" href="#temporary-tables"></a> Temporary tables</h3>
<p>Another common case is to save a query to a temporary table for later query. We have already seen a concrete example above.</p>
<p>It works simply as what you expected.</p>
<ul>
<li>The query result will be saved to a temporary table if the target is ‘temp’.</li>
<li>The query result will be saved to a cached temporary table if the target is ‘cache’.</li>
<li>The query result will be saved to a broadcasted temporary table if the target is ‘broadcast’.</li>
</ul>
<p>Speaking of implementation, if the backend is Spark, ‘temp’ ‘cache’ and ‘broadcast’ behave the same as that in Spark,<br />
and with a global temporary table created or replaced with the specified name.<br />
For the other backends in which there is no support of caching and broadcasting of temporary tables,<br />
Easy SQL just create views with the specified name in a temporary default database.</p>
<p>Since there is no actual loading of data for temporary tables, to define a temporary table is a very light-weight operation.<br />
You can create as many temporary tables as you wish.</p>
<p>There are a few things to note when creating temporary tables for different backends.</p>
<ul>
<li>For Spark backend, the name of the temporary table can be reused, but it cannot be reused for the other backends since we cannot create two database views with the same name in the same default database.</li>
<li>For BigQuery backend, we have to specify names like <code>$&#123;temp_db&#125;.SOME_TEMP_TABLE_NAME</code> when query the created temporary table. You guessed it, the ‘temp_db’ is a pre-defined variable provided by Easy SQL engine. This limitation is introduced by BigQuery since there is no such concept of a default database (named dataset in BigQuery).</li>
</ul>
<h3 id="function-calls"><a class="markdownIt-Anchor" href="#function-calls"></a> Function calls</h3>
<p>Function calls is another feature introduced by Easy SQL. It is used to expand the ability of SQL, so that we could do anything in SQL.</p>
<p>Function is defined in Python code and registered before the execution of the ETL.<br />
The syntax to call a function is very intuitive if you have experience of some other programming languages.</p>
<p>Below is an example of function calls.</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- target=func.plus(1, 1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=func.do_some_thing()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> $&#123;plus(<span class="number">2</span>, <span class="number">2</span>)&#125; <span class="keyword">as</span> a</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> $&#123;plus($&#123;a&#125;, <span class="number">2</span>)&#125; <span class="keyword">as</span> b</span><br></pre></td></tr></table></figure>
<p>From the ETL code above, we can find a few things about function calls:</p>
<ul>
<li>Function calls could be used as a ‘func’ target.</li>
<li>The result of function calls could be used as a variable.</li>
<li>Parameters of function calls could be variables.</li>
</ul>
<p>Besides these, there are a few other things to note:</p>
<ul>
<li>One function call expression must be in one line of code.</li>
<li>When functions are called, all non-variable parameters are passed as strings even if it looks like an integer. In the function implementation, we need to convert types from string to its real type.</li>
<li>There should be no chars from any of <code>,()</code> in literal parameters. If there is, we need to define a variable before the function call and pass in the variable as a parameter.</li>
<li>Any user-defined variable will be converted to string and passed to functions as string value. We may need to convert types in the function implementation.</li>
<li>All functions in the Python <code>builtin</code> module and <code>operators</code> module are automatically registered, so we can use a lot of Python functions without providing an implementation.</li>
</ul>
<p>Before execution of the above ETL, we need to define the functions referenced in the ETL. Followed by the above rules, an example of the function implementations could be:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plus</span>(<span class="params">a: <span class="built_in">str</span>, b: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">int</span>(a) + <span class="built_in">int</span>(b)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">do_some_thing</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;do things...&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>And then after the execution of the ETL, the value of the variables will be: <code>a=4, b=6</code>.</p>
<h3 id="control-execution-flow"><a class="markdownIt-Anchor" href="#control-execution-flow"></a> Control execution flow</h3>
<p>For an imperative language, providing a way to control execution flow is important.</p>
<p>Back to the top, there is a case mentioned that<br />
‘we would like to use large computing resources when we’re handling data in the first partition since the amount of data there is far larger than that in the other partitions’.<br />
In order to implement this in ETL, we need to control the execution flow to configure a large computing resource.</p>
<p>A common way in general programming language to handle this is to provide some ‘if’ statement.<br />
And we need to provide a condition expression for ‘if’ statement.<br />
The inner action of ‘if’ statement is then executed according to the true or false value of the condition expression.</p>
<p>Easy SQL provides a similar way to control execution flow.<br />
We can control if a step needs to be executed by providing a ‘if’ statement after any step definition.<br />
Below is an example:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- target=func.do_some_thing(), if=bool()</span></span><br><span class="line"><span class="comment">-- target=func.do_another_thing(), if=bool(1)</span></span><br><span class="line"><span class="comment">-- target=func.do_a_third_thing(), if=bool($&#123;some_variable_indicator&#125;)</span></span><br><span class="line"><span class="comment">-- target=temp.table_a, if=bool()</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> some_db.table_a</span><br><span class="line"><span class="comment">-- target=variables, if=bool(1)</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> a</span><br></pre></td></tr></table></figure>
<p>From the example, we know the following things about ‘if’ statement in Easy SQL:</p>
<ul>
<li>There must be a function call following the ‘if’ statement.</li>
<li>The function call must return a boolean value to indicate if the step needs to be executed.</li>
<li>Any step could be controlled by a ‘if’ statement, including ‘func’ ‘temp’ ‘variables’ and so on.</li>
</ul>
<h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2>
<p>In this post, we talked about the first 4 language features.</p>
<ul>
<li>An imperative structure of ETL code.</li>
<li>Variables which could be defined and modified any time.</li>
<li>A way to call external functions.</li>
<li>A way to control whether a step should be executed.</li>
</ul>
<p>For the other features, let’s talk about it in a post later on.</p>
<p>You may already find it useful and would like to have a try. You can get all the information required to get started from the GitHub repo <a href="https://github.com/easysql/easy_sql">here</a> and the docs <a href="https://easy-sql.readthedocs.io/en/latest/">here</a>.</p>
<p>If you find any issues, you’re welcome to raise it in GitHub Issues and PRs are welcomed as well!</p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>编译</tag>
        <tag>编译器</tag>
        <tag>数据</tag>
        <tag>数据平台</tag>
        <tag>数据工程</tag>
        <tag>EasySQL</tag>
        <tag>ETL</tag>
        <tag>ETL开发</tag>
        <tag>软件工程</tag>
        <tag>编程语言</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Neat Syntax Design of an ETL Language (Part 2)</title>
    <url>/2022/05/30/neat-syntax-design-of-an-etl-language-part-2/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2022/2022-05-25-neat-syntax-design-of-an-etl-language/mind-mapping.png" alt="Easy SQL language features mind Mapping" /></p>
<p><strong>Previous posts about Easy SQL</strong></p>
<ul>
<li><a href="/2022/05/04/a-new-etl-language-easy-sql/">A new ETL language – Easy SQL</a></li>
<li><a href="/2022/05/16/a-guide-to-write-elegant-etl/">A guide to write elegant ETL</a></li>
<li><a href="/2022/05/25/neat-syntax-design-of-an-etl-language/">Neat syntax design of an ETL language (part 1)</a></li>
</ul>
<p>People like to use Scala because Scala provides powerful type inference and embraces various programming paradigms. People like to use Python because it’s clean, out-of-the-box, delicate and expressive. People like to use rust because rust provides modern language features and zero-cost abstract.</p>
<span id="more"></span>
<p>How to design a neat ETL programming language that people like to use? Let’s have a look at how Easy SQL does. (This topic is broken into two parts. This is the second part.)</p>
<p>Easy SQL defines a few customized syntax on top of SQL to add imperative characteristics.</p>
<h2 id="language-features-in-easy-sql"><a class="markdownIt-Anchor" href="#language-features-in-easy-sql"></a> Language features in Easy SQL</h2>
<p>For Easy SQL, guided by the design principles, there are a few simple language features added to support these imperative characteristics.</p>
<p>Below is a list of these features:</p>
<ul>
<li>An imperative structure of ETL code.</li>
<li>Variables which could be defined and modified any time.</li>
<li>A way to call external functions.</li>
<li>A way to control whether a step should be executed.</li>
<li>Templates that could be reused in the same ETL file.</li>
<li>Include command that could be used to reuse code at file level.</li>
<li>Debugging support: logging and assertion that could be used for debugging.</li>
<li>A debugger interface.</li>
<li>Other features：write data to tables; list variables; SQL actions.</li>
</ul>
<p>Let’s have a look at the last five features.</p>
<h2 id="syntax-in-easy-sql"><a class="markdownIt-Anchor" href="#syntax-in-easy-sql"></a> Syntax in Easy SQL</h2>
<h3 id="templates-used-to-reuse-code"><a class="markdownIt-Anchor" href="#templates-used-to-reuse-code"></a> Templates used to reuse code</h3>
<p>To support reusing of code, templates have been introduced in Easy SQL.<br />
Templates are similar to functions in general programming languages.<br />
Functions could be called anywhere while templates could be used anywhere as well. This way, code is reused.</p>
<p>Just like functions, there are name, parameters and body for a template as well.</p>
<p>Below is a concrete example of templates:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- target=template.dim_cols</span></span><br><span class="line">product_name</span><br><span class="line">, product_category</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=temp.dims</span></span><br><span class="line"><span class="keyword">select</span> @&#123;dim_cols&#125; <span class="keyword">from</span> order_count</span><br><span class="line"><span class="keyword">union</span></span><br><span class="line"><span class="keyword">select</span> @&#123;dim_cols&#125; <span class="keyword">from</span> sales_amount</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=template.join_conditions</span></span><br><span class="line">dim.product_name <span class="operator">&lt;=&gt;</span> #&#123;right_table&#125;.product_name</span><br><span class="line"><span class="keyword">and</span> dim.product_category <span class="operator">&lt;=&gt;</span> #&#123;right_table&#125;.product_category</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=temp.joined_data</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">dim.product_name</span><br><span class="line">, dim.product_category</span><br><span class="line">, oc.order_count</span><br><span class="line">, sa.sales_amount </span><br><span class="line"><span class="keyword">from</span> dims dim</span><br><span class="line">    <span class="keyword">left</span> <span class="keyword">join</span> order_count oc <span class="keyword">on</span> @&#123;join_conditions(right_table<span class="operator">=</span>oc)&#125;</span><br><span class="line">    <span class="keyword">left</span> <span class="keyword">join</span> sales_amount sa <span class="keyword">on</span> @&#123;join_conditions(right_table<span class="operator">=</span>sa)&#125;</span><br></pre></td></tr></table></figure>
<p>There are two templates named ‘dim_cols’ and ‘join_conditions’ defined.<br />
One with no parameters and one with one parameter named ‘right_table’.</p>
<p>This example is about a very common case when we’d like to merge two tables with the same dimension columns.<br />
After the template is used, the dimension column names and join conditions are reused, just like how we reuse functions in general programming language.</p>
<p>From the example above, we could find a few things to note about templates:</p>
<ul>
<li>Template is a step in ETL. It is defined by a target with name ‘template’ and a following descriptive name. The descriptive name is the template name.</li>
<li>The body of a template could be anything.</li>
<li>If there are template parameters, no need to declare them, just use them by ‘#{PARAMETER_NAME}’. Easy SQL will extract these parameters for you at runtime.</li>
<li>Templates could be used in any target with syntax ‘@{TEMPLATE_NAME}’. If there are template parameters, we need to pass them as named parameters.</li>
</ul>
<p>Besides, there are some other notes:</p>
<ul>
<li>Variables can be referenced in template body, and the resolution of variables happens at the resolution time of the template (when the step with template reference is executing). This is useful since we can change the value of some variable between two targets referencing the same template.</li>
<li>There should be no templates used in the body of templates. This is to make the resolution of templates to be simple.</li>
</ul>
<h3 id="include-other-etl-code-snippets"><a class="markdownIt-Anchor" href="#include-other-etl-code-snippets"></a> Include other ETL code snippets</h3>
<p>Template is designed for reusing code within one ETL. How to reuse code across ETLs?<br />
One common way to reuse code is to create a temporary mid-table.<br />
But it seems heavy since we need to create a real table and there might be data copying.</p>
<p>Easy SQL provides a way to reuse code from some other ETL file. This is the ‘include’ command.</p>
<p>Include looks similar to target. Below is an example:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- include=snippets/some_snippet.sql</span></span><br></pre></td></tr></table></figure>
<p>The file path is a path relative to the current working directory.</p>
<p>When Easy SQL processed the ‘include’ command, the content of the file will be expanded.<br />
The result will be the same as when we write code in here directly.</p>
<p>For the example above, if we have the following content in <code>some_snippets.sql</code>:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- target=temp.some_table</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> some_db.some_table</span><br><span class="line"><span class="comment">-- target=template.some_columns</span></span><br><span class="line">a, b, c</span><br></pre></td></tr></table></figure>
<p>Then the content of the ETL will be the same as the content of <code>some_snippets.sql</code> since there is only one include command there.</p>
<p>Notes about ‘include’ command:</p>
<ul>
<li>Include command could be used at any line of code.</li>
<li>When Easy SQL processed this ‘include’ command, the content of the file will simply be expanded.</li>
</ul>
<h3 id="debugging-support"><a class="markdownIt-Anchor" href="#debugging-support"></a> Debugging support</h3>
<p>In a complicated ETL, it is easy to introduce bugs.<br />
A general programming language usually provides some ways to help with debugging.<br />
The most commonly used way is about logging and assertion.</p>
<p>Developers can log variables anywhere to provide information about the executing step.<br />
They can also set an assertion if there is any important assumption made in the following code.</p>
<p>To do logging and assertion in Python, the code looks like below:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">logger.info(<span class="string">f&#x27;some thing happened, check the variables: var_a=<span class="subst">&#123;var_a&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="keyword">assert</span> var_a == <span class="string">&#x27;something assumed&#x27;</span>, <span class="string">f&#x27;var_a is not as assumed: var_a=<span class="subst">&#123;var_a&#125;</span>&#x27;</span></span><br></pre></td></tr></table></figure>
<p>Easy SQL provides a similar way to do logging and assertion. They’re both provided by a type of target.<br />
Check the example below to see its usage.</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- target=log.i_would_like_to_log_something</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="number">1</span> <span class="keyword">as</span> a</span><br><span class="line">    , <span class="number">2</span> <span class="keyword">as</span> b</span><br><span class="line">    , $&#123;c&#125; <span class="keyword">as</span> c</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=log.order_count</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line"><span class="built_in">count</span>(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">from</span> sample.order_table</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=check.order_count_must_be_equal_after_joined_product</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    (<span class="keyword">select</span> <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">from</span> sample.order_table) <span class="keyword">as</span> expected</span><br><span class="line">    , (<span class="keyword">select</span> <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">from</span> sample.order_table_after_joined) <span class="keyword">as</span> actual</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=check.equal($&#123;c&#125;, 3)</span></span><br></pre></td></tr></table></figure>
<p>From the example above, we know that:</p>
<ul>
<li>When using the ‘log’ target, we need to specify a message about what to log.</li>
<li>The log message format is the same as a variable. I.e. It should be composed of chars ‘0-9a-zA-Z_’.</li>
<li>There should be exactly one row returned from the query of some ‘log’ target. If there is more than one row returned, only the first row will be logged.</li>
<li>There are two formats of ‘check’ target. One is to specify a check message with a query. The other is to call a function, which returns a boolean value.</li>
<li>When the ‘check’ target is used as a message with a query, the returned value of the query must be one row with two columns named ‘actual’ and ‘expected’.</li>
</ul>
<h3 id="debugger-interface"><a class="markdownIt-Anchor" href="#debugger-interface"></a> Debugger interface</h3>
<p>There is a debugger interface provided by Easy SQL. It could be used with <code>Jupyter</code> to debug interactively. Follow the steps below to start debugging.</p>
<ol>
<li>Install <code>Jupyter</code> first with command <code>pip install jupyterlab</code>.</li>
<li>Create a file named <code>debugger.py</code> with contents like below:<br />
(A more detailed sample could be found <a href="https://easy-sql.readthedocs.io/en/latest/autoapi/easy_sql/sql_processor_debugger/index.html">here</a>.)</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Dict</span>, <span class="type">Any</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_debugger</span>(<span class="params">sql_file_path: <span class="built_in">str</span>, <span class="built_in">vars</span>: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>] = <span class="literal">None</span>, funcs: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>] = <span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line">    <span class="keyword">from</span> easy_sql.sql_processor.backend <span class="keyword">import</span> SparkBackend</span><br><span class="line">    <span class="keyword">from</span> easy_sql.sql_processor_debugger <span class="keyword">import</span> SqlProcessorDebugger</span><br><span class="line">    spark = SparkSession.builder.enableHiveSupport().getOrCreate()</span><br><span class="line">    backend = SparkBackend(spark)</span><br><span class="line">    debugger = SqlProcessorDebugger(sql_file_path, backend, <span class="built_in">vars</span>, funcs)</span><br><span class="line">    <span class="keyword">return</span> debugger</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ol start="3">
<li>Create a file named <code>test.sql</code> with contents as <a href="https://github.com/easysql/easy_sql/blob/main/test/sample_etl.spark.sql">here</a>.</li>
<li>Then start jupyter lab with command: <code>jupyter lab</code>.</li>
<li>Start debugging like below:</li>
</ol>
<p><img data-src="https://raw.githubusercontent.com/easysql/easy_sql/main/debugger-usage.gif" alt="ETL Debugging" /></p>
<p>For details of the APIs, we can refer to API doc <a href="https://easy-sql.readthedocs.io/en/latest/autoapi/easy_sql/sql_processor_debugger/index.html">here</a>.</p>
<h3 id="write-data"><a class="markdownIt-Anchor" href="#write-data"></a> Write data</h3>
<p>If we need to write data to some table, we could use another type of target. The name of the target is ‘output’.<br />
There should be a query statement following the ‘output’ target. And the result of the query will be written to the output table.</p>
<p>Below is an example:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- target=temp.result</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> a, <span class="string">&#x27;2&#x27;</span> <span class="keyword">as</span> b</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=output.some_db.some_table</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">result</span></span><br></pre></td></tr></table></figure>
<p>After the execution of the ETL above, there will be one row written to table ‘some_db.some_table’.</p>
<p>Things to note about ‘output’ target:</p>
<ul>
<li>There must be a full table name (both database name and table name specified) after the ‘output’ keyword in the target definition.</li>
<li>The table must be created before writing data.</li>
<li>If we’d like to create tables automatically, we need to define a special variable named ‘__create_output_table__’ with value equals to 1.</li>
<li>If we’d like to write data to some static partition of the output table, we need to define a special variable named ‘__partition__’ with partition column name followed by. An example could be ‘__partition__data_date’. Then the partition column is ‘data_date’. The value of the variable will be the partition value when writing data.</li>
<li>If we’d like to write data to some static partition of the output table, we can only define one partition value at the moment.</li>
<li>If the query returns more columns than what is defined by the real table, the extra columns will be ignored.</li>
<li>If the query returns less columns than what is defined by the real table, an error will be raised.</li>
</ul>
<h3 id="list-variables"><a class="markdownIt-Anchor" href="#list-variables"></a> List variables</h3>
<p>There are list variables supported in Easy SQL as well.</p>
<p>List variables are different from variables mentioned previously.<br />
The main difference is that the values of these variables are lists.<br />
So that list variables could not be used in SQL statements, since we cannot simply convert a list to a string and do variable resolution.</p>
<p>List variables can only be used as function parameters right now.</p>
<p>Below is an example of list variables.</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">-- target=list_variables</span></span><br><span class="line"><span class="keyword">select</span> explode(<span class="keyword">array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)) <span class="keyword">as</span> a</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=func.print_list_variables($&#123;a&#125;)</span></span><br></pre></td></tr></table></figure>
<p>If we have function implementation like below:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">print_list_variables</span>(<span class="params">a: <span class="type">List</span>[<span class="built_in">str</span>]</span>):</span><br><span class="line">    <span class="built_in">print</span>(a)</span><br></pre></td></tr></table></figure>
<p>Then the function output will be: <code>[1, 2, 3]</code></p>
<h3 id="sql-actions"><a class="markdownIt-Anchor" href="#sql-actions"></a> SQL actions</h3>
<p>There are some cases where we’d like to just execute some SQL statement without anything to do about its result. We can use ‘action’ in these cases.</p>
<p>This usually happens when we want to execute some DDL statement. Examples would be like to create table, to drop partition of some table etc.</p>
<p>Action is a type of target as well and it follows target syntax. Below is an example of ‘action’ target:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- target=action.create_some_table</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> some_table (</span><br><span class="line">    id <span class="type">int</span></span><br><span class="line">    , <span class="keyword">value</span> string</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>Things to note about actions:</p>
<ul>
<li>There should be a descriptive name for an action. The name should be composed of chars ‘0-9a-zA-Z_’ and follow the ‘action’ keyword.</li>
<li>In the body of an action target, templates and variables can be used as in any other target.</li>
</ul>
<h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2>
<p>In this post, we talked about the last five language features.</p>
<ul>
<li>Templates that could be reused in the same ETL file.</li>
<li>Include command that could be used to reuse code at file level.</li>
<li>Debugging support: logging and assertion that could be used for debugging.</li>
<li>A debugger interface.</li>
<li>Other features：write data to tables; list variables; SQL actions.</li>
</ul>
<p>Now we have finished all the language features provided by Easy SQL. But there are a lot more useful features in Easy SQL for us to find out.</p>
<p>You may already find it useful and would like to have a try. You can get all the information required to get started from the GitHub repo <a href="https://github.com/easysql/easy_sql">here</a> and the docs <a href="https://easy-sql.readthedocs.io/en/latest/">here</a>.</p>
<p>If you find any issues, you’re welcome to raise it in GitHub Issues and PRs are welcomed as well!</p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>编译</tag>
        <tag>编译器</tag>
        <tag>数据</tag>
        <tag>数据平台</tag>
        <tag>数据工程</tag>
        <tag>EasySQL</tag>
        <tag>ETL</tag>
        <tag>ETL开发</tag>
        <tag>软件工程</tag>
        <tag>编程语言</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title>好代码的五个特质-CUPID</title>
    <url>/2022/05/24/5-properties-of-good-code-cupid/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>新的一期技术雷达如期发布，仔细阅读了这一期的所有条目，CUPID这一条尤其让我产生共鸣。</p>
<p>CUPID出自Daniel的一篇名为<a href="https://dannorth.net/2022/02/10/cupid-for-joyful-coding/">《CUPID—for joyful coding》</a>的博文，即《CUPID-为了快乐编程》。CUPID是Composable/Unix philosophy/Predictable/Idiomatic/Domain based几个单词的缩写，有经验的同学一看就知道这是好代码的一些属性。知道<strong>Cupid</strong>这个单词的同学还能感受到这一组属性所蕴含的对于软件工程的热情。Cupid的中文是丘比特，是指古罗马的爱神，其意象是一个长有翅膀的小孩，拿着弓箭射向人们，以便人们可以相互爱上对方。</p>
<p><img data-src="/attaches/2022/2022-05-24-5-properties-of-good-code-cupid/cupid.png" alt="CUPID for joyful coding" /></p>
<span id="more"></span>
<h2 id="特质"><a class="markdownIt-Anchor" href="#特质"></a> 特质</h2>
<p>Daniel老爷子回忆了自己三十多年的编程经历，他发现在修改代码时，好的代码会给人一种非常愉悦的感觉。你可以轻松找到需要修改的地方，而且，那个地方的代码是如此的易于理解，以至于一眼就能看出来代码在干什么。你可以很自信的完成修改，并且确信不会引入额外的副作用。代码是那么的鲜活，它会主动的指引你去你想去的地方，并且热情的欢迎你四处游览，就像在你熟悉的家里一样！</p>
<p>为什么好的代码能有这样的魅力？什么样的代码才是好代码？提到这个问题，我们常常会想到SOLID（Single Responsibility/Open-close/Liskov Substitution/Interface Segregation/Dependency Injection）原则，Daniel老爷子认为应该存在比SOLID更好用的东西。</p>
<p>如何衡量代码好坏？SOLID采用了一组原则来定义好的代码，但是原则更像是规则，要么符合，要么不符合。而软件开发过程非常复杂，其间充满了平衡和妥协，事实上并没有一种非黑即白的规则可以适用。有没有比原则更好的选择？它可能是特质（Properties/Characteristics）。</p>
<p>特质是事物本身所具备的，而不是靠一组规则去定义的；特质吸引我们去深度挖掘，而不是信任已有的总结；特质通常不是简单的0或1的判断，而是一种从低到高的程度；特质是从观察者的角度给出的，更关注观察者的体验，而更少关注与体验无关的其他方面。</p>
<p>之所以我们会觉得某样东西是好的，常常是因为某样东西具备了一些好的特质。比如蓝天白云图，它具备了干净、纯粹的特质。比如勾股定理和质能方程，它们具备简洁、优雅的特质。</p>
<p>如果说好的代码是一个中心点，特质就像是定义了一些方向，通过这些方向的指引，就可以不断向这个中心点靠拢。</p>
<p>CUPID就是从特质的角度来定义的，它尝试用一组助记词来指示好代码所具备的一组特质，并希望这组特质是最重要的特质。</p>
<p>CUPID所指出的方向与SOLID定义的原则并不冲突，只是角度不同，CUPID更多站在代码的用户–将来修改代码的人–的视角来看待代码，并指出了好的代码应该具备的特质。从这个角度来讲，CUPID比SOLID的适用性更广（SOLID事实上只是针对面向对象设计提出的）。比如，给出一段代码，用SOLID可能并不能判断好坏，因为这段代码可能根本不涉及SOLID中提到的几个原则（比如函数式风格的代码）。但是很大可能可以从CUPID指明的几个方向来得到一些结论。</p>
<p>CUPID是完备的吗，很遗憾，也不是。但CUPID所指出的五种特质可能是按照重要程度排序之后取前五的特质。</p>
<h2 id="理解cupid"><a class="markdownIt-Anchor" href="#理解cupid"></a> 理解CUPID</h2>
<p>下面我们一起看看CUPID到底是什么，以及，如何用CUPID来帮助我们写出好的代码。</p>
<p>下面的内容，部分来自Daniel老爷子的<a href="https://dannorth.net/2022/02/10/cupid-for-joyful-coding/">原文</a>，部分结合了个人的心得体会，分享给大家。</p>
<h3 id="可组合特质c"><a class="markdownIt-Anchor" href="#可组合特质c"></a> 可组合特质（C）</h3>
<p>CUPID的第一个字母C是指Composable，即可组合特质。</p>
<p>近两年，我们在讨论面向对象程序设计的时候，越来越关注到“组合优于继承”这样的原则。作为面向对象程序设计的三大特征之一的“继承”，似乎正越来越受到挑战，这一部分原因是很多继承的设计是不合理的，比如不符合SOLID所指出的里氏代换原则。另一部分原因在于，过深的继承树带来了代码的可理解性问题，因为我们总是需要理解了基类才能理解子类。其实继承也是很有用的，但其前提是设计合理的继承。“组合优于继承”就是告诉我们优先考虑用组合模式来进行设计。</p>
<p>可组合还体现在以下三个方面：</p>
<p><strong>精巧的接口</strong></p>
<p>接口太多时，读者需要知道如何组合这些接口去完成某个功能，而接口较少时，读者可以更容易学习并更少犯错。只对外公开一个模块来提供接口，比对外公开多个模块提供接口更好。只对外公开一个类来提供接口，比对外公开多个类提供接口更好。</p>
<p>正确的接口粒度设计比较困难，最佳的粒度是接口既不显得臃肿也不碎片化。</p>
<p>设计模式中有一种常见的模式Facade，即门面模式，其意图正是将对外公开的接口放到一个类中去提供，以便减少接口面，从而让接口更容易使用。</p>
<p><strong>可体现意图的代码</strong></p>
<p>可体现意图的代码是用业务语言编写且能反映业务过程的代码。可体现意图的代码可以使读者更容易弄清为什么代码要这么写，因此更容易组合使用。代码中的各类命名（比如变量、函数等）都可以用于将意图体现得更为明显。</p>
<p>比如以下意图不明的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">getTodos</span>(<span class="params">todos, users</span>):</span><br><span class="line">    todos = [todo <span class="keyword">for</span> todo <span class="keyword">in</span> todo <span class="keyword">if</span> <span class="keyword">not</span> todo.completed <span class="keyword">and</span> todo.<span class="built_in">type</span> == ‘HOME’]</span><br><span class="line">    todos = [&#123;‘title’: todo.title, ‘user_name’: users[todo.userId].name&#125; <span class="keyword">for</span> todo <span class="keyword">in</span> todo]</span><br><span class="line">    todos.sort(key=<span class="keyword">lambda</span> todo: todo[’user_name’])</span><br><span class="line"><span class="keyword">return</span> todos</span><br></pre></td></tr></table></figure>
<p>可以重构为以下意图明确的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_todos</span>(<span class="params">todos, users</span>):</span><br><span class="line">    top_priority_todos = [todo <span class="keyword">for</span> todo <span class="keyword">in</span> todo <span class="keyword">if</span> <span class="keyword">not</span> todo.completed <span class="keyword">and</span> todo.<span class="built_in">type</span> == ‘HOME’]</span><br><span class="line">    todo_view_models = [&#123;‘title’: todo.title, ‘user_name’: users[todo.userId].name&#125; <span class="keyword">for</span> todo <span class="keyword">in</span> top_priority_todos]</span><br><span class="line">    todo_view_models.sort(key=<span class="keyword">lambda</span> todo: todo[’user_name’])</span><br><span class="line"><span class="keyword">return</span> todo_view_models</span><br></pre></td></tr></table></figure>
<p>或者：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_todos</span>(<span class="params">todos, users</span>):</span><br><span class="line">    is_top_priority = <span class="keyword">lambda</span> todo: <span class="keyword">not</span> todo.completed <span class="keyword">and</span> todo.<span class="built_in">type</span> == ‘HOME’</span><br><span class="line">    todos = [todo <span class="keyword">for</span> todo <span class="keyword">in</span> todo <span class="keyword">if</span> is_top_priority(todo)]</span><br><span class="line">    to_view_model = <span class="keyword">lambda</span> todo: &#123;‘title’: todo.title, ‘user_name’: users[todo.userId].name&#125;</span><br><span class="line">    todos = [to_view_model(todo) <span class="keyword">for</span> todo <span class="keyword">in</span> todo]</span><br><span class="line">    user_name = <span class="keyword">lambda</span> todo: todo[’user_name’]</span><br><span class="line">    todos.sort(key=user_name)</span><br><span class="line"><span class="keyword">return</span> todos</span><br></pre></td></tr></table></figure>
<p><strong>最小依赖</strong></p>
<p>拥有最小依赖的代码是容易组合使用的。</p>
<p>当一个库有大量的依赖时，一旦使用了这个库就会间接引入这些依赖。这不仅使我们发布的二进制制品变得臃肿，也很容易引起一些依赖库的版本冲突问题。大家如果做过Hadoop的MapReduce任务开发，应该对这个问题深有体会，因为Hadoop本身有大量的Java依赖，如果我们在MapReduce任务中不小心引入了一个和Hadoop本身的依赖不兼容的版本，在任务运行时就会出错。</p>
<p>一个拥有最小依赖的库是很容易使用的，上述包冲突问题会更少发生。</p>
<p>我常常在项目中见到有人为了实现一些很简单的功能而引入没必要的依赖。比如，当我们面对的问题只是简单的查询ElasticSearch服务中的数据时，就要评估一下是否有必要引入ElasticSearch的客户端库依赖，因为我们可以很容易的使用通用的HTTP工具库来发送一个请求来实现数据查询。</p>
<p>面向对象程序设计有一个重要的原则，即迪米特法则（Law of Demeter），又被称为最小知识原则、不要和陌生人说话原则。其指导意义在于一个类不应该和与其不相关的类产生（依赖）关系。</p>
<h3 id="unix哲学u"><a class="markdownIt-Anchor" href="#unix哲学u"></a> Unix哲学（U）</h3>
<p>CUPID的第二个特质U即是指Unix哲学。</p>
<p>Unix可以说是当今应用最广泛的操作系统，不管是云服务器还是个人电脑抑或智能手机、IoT设备，都有Unix的影子。Unix广泛的以Linux、MacOS、iOS、Android等等操作系统的形式存在着。为什么Unix可以如此成功？这得益于Unix的简单而一致的设计哲学。</p>
<p>CUPID中的Unix哲学主要指其最重要的一个观点：一个程序应该做一件事，并将其做好。Unix中的大量程序都很好的提现了这一特质，比如<code>ls</code>程序只做列举文件的事，而要查看文件详情，则需要使用<code>lstat</code>，查看文件内容使用<code>cat</code>，搜索文件内容使用<code>grep</code>等等。如果我们查看这些程序的使用手册（Manual Page），将发现每一个程序都提供了很多的参数供选择，事实上每个程序的功能都很强大，并处理了大量的异常情况。这就是把一件事做好的体现。</p>
<p>Unix操作系统中定义了一个强大的管道（Pipe）概念，一个程序的输出可以通过管道传输给另一个程序，从而简单而一致的实现了多个程序的组合使用。比如<code>ls</code>命令可以列举出文件列表，然后将结果传输给<code>wc</code>程序统计数量，就可以简单的计算出目录中的文件数量。</p>
<p>只做好一件事与SOLID中的单一职责原则很像。但是Unix哲学的出发点是读者，从读者角度来看程序，得出程序应该只做好一件事的结论。单一职责原则则是从代码的角度出发进行描述的。Unix哲学更多描述的是程序的目的，并指明一个程序应该只有一个目的。</p>
<p>与Unix原则描述很相似的还有关注点分离的原则。关注点分离是指不同的模块应该关注不同的事情。比如分层设计，每一层的关注点应该不一样：<code>MVC</code>中的<code>M</code>关注业务模型和业务逻辑，<code>V</code>关注展示，<code>C</code>关注交互逻辑；<code>TCP/IP</code>四层网络模型中物理层关注物理链路，网络层关心节点链路如何建立，传输层关注数据发送的可靠性，应用层关注在具体的应用协议。</p>
<h3 id="可预测性p"><a class="markdownIt-Anchor" href="#可预测性p"></a> 可预测性（P）</h3>
<p>CUPID的第三个特质P是指Predictable，可预测性。</p>
<p>程序的可预测性是指它应该做它看起来要做的事情，一致且可靠，不隐藏任何出乎意料的行为。</p>
<p>可预测性包括三个方面：1. 与期望一致的行为；2. 输出确定的结果；3. 内部行为可观测。</p>
<p><strong>与期望一致的行为</strong></p>
<p>我们可以通过测试来定义所期望的程序的行为，但是并不是一定需要用测试来让程序与期望的行为一致。精心的挑选名字，克制的编写逻辑，正确的处理异常这些都能使得程序与期望的行为一致。</p>
<p>读操作和写操作常常被分开对待。读操作不会对程序状态产生影响，我们可以安全的调用，不用顾忌太多后果。写操作用于修改程序状态，因此，在使用时需要特别小心，比如如果有多线程访问就需要考虑线程安全，同时操作多个状态就需要考虑事务一致性。</p>
<p>如何在读操作和写操作中保持与期望一致的行为？那就是读操作中不应该隐藏某些让人意外的写操作。</p>
<p><strong>输出确定性的结果</strong></p>
<p>具备确定性的程序很容易让人理解和使用，因为它在任何一次调用都会返回同样的结果，我们可以明确的知道它将返回什么。</p>
<p>我们常说易于推理的代码是好代码，具备确定性的就具备易于推理的特性。</p>
<p>大概是由于Web前端技术的飞速发展，近些年函数式编程范式得到广大开发者的亲睐。函数式编程范式中最重要的一个概念就是纯函数。纯函数是指没有任何副作用且可以输出确定的结果的函数。</p>
<p>纯函数是更容易测试的，我们对使用它的信心也更强。但是，在函数式编程范式中，对纯函数的<a href="https://en.wikipedia.org/wiki/Pure_function">规范定义</a>显得学院化，并加入了场景限定。事实上，我们主要需要的是程序的确定性。用面向对象范式编程，可以考虑把一个对象设计成<a href="https://en.wikipedia.org/wiki/Value_object">值对象</a>，这样也可以增强程序的确定性。由于不确定性常常来自复杂且不确定的依赖（比如，某个依赖自己管理了复杂的状态，就也会间接的使你的代码充满不确定性），在设计类时，严格控制其依赖的外部模块，尽量做到无依赖，也可以增强程序的确定性。</p>
<p>具备确定性的代码通常是健壮、可靠而具备弹性的。</p>
<p><strong>内部行为可观测</strong></p>
<p>如何预测程序的行为？观察它的运行时输出是一个很好的方法。如果程序可以在运行时打印关键的内部状态或行为就可以让我们推测其当前状态。</p>
<p>观察程序内部状态可以分为以下几个级别：</p>
<ul>
<li><strong>信息仪表（Instrumentation）</strong>: 程序告诉我们它正在干什么</li>
<li><strong>遥测（Telemetry）</strong>: 将程序告诉我们的信息以一种接口暴露出来，使其可以被远程访问</li>
<li><strong>监控（Monitoring）</strong>: 将程序告诉我们的信息可视化出来</li>
<li><strong>告警（Alerting）</strong>: 从监控信息中识别异常，发出通知</li>
<li><strong>预测（Predicting）</strong>: 利用监控信息来预测即将发生的事件</li>
<li><strong>自适应（Adapting）</strong>: 通过告警的或者预测的信息动态调整系统以适应变化</li>
</ul>
<p>有一些工具可以自动提取程序运行时信息供分析，但是最佳的提升程序的可观测性的方式还是通过有意识的设计来在关键处输出程序的状态或行为。</p>
<h3 id="符合惯例的i"><a class="markdownIt-Anchor" href="#符合惯例的i"></a> 符合惯例的（I）</h3>
<p>CUPID的第四个特质I是指Idiomatic，符合惯例的。</p>
<p>大家都有自己的编码习惯，这些习惯包括空格和制表符的使用，变量命名规则，括号放置位置，代码结构，提交的粒度和注释等等。这些不一样的习惯将显著的增加不熟悉代码库的读者的认知负载。读者不仅需要理解问题空间和解空间，还需要不断进行翻译，以便识别当前的代码是有意编写的，还是无意的，或者只是作者的习惯而已。</p>
<p>编写代码时的最伟大的特质是同情心：对你的代码的用户的同情；对提供支持服务的同事的同情；对将来修改代码的开发者的同情。事实上，他们中任意一个可能就是将来的你。编写“人类可读的代码”意味着为别人编写代码。这正是“符合惯例”的意义。</p>
<p>编写代码时，可以假定你的用户具备以下背景：</p>
<ul>
<li>熟悉所使用的编程语言，及该语言对应的库、工具链和生态</li>
<li>懂软件开发的有经验的开发者</li>
</ul>
<p>还有一条，他们正努力的完成某件事情。</p>
<p><strong>语言惯例</strong></p>
<p>代码应该遵循编程语言的惯例。有些编程语言在代码风格上态度鲜明，我们会更容易判断代码是否符合语言惯例。另一些编程语言则可以兼容多种不同风格，此时我们应该选择一种风格，并始终坚持它。</p>
<p>Python是一门在代码风格上态度鲜明的语言。当我们在Python的交互式命令行中输入<code>import this</code>，或者运行命令<code>python -m this</code>时，就会发现输出了Python所推荐的编程风格。这些编程风格组合成了”Python之禅”（The Zen of Python）。比如“应该有一种显然的实现方式，而且最好只有一种”（There should be one-- and preferably only one --obvious way to do it）。</p>
<p>Go语言内置了一个代码格式化工具<code>gofmt</code>，它会处理缩进、括号位置等问题，可以使所有代码变得风格一致。除此之外，还有一篇专门说明Go语言风格的文档<a href="https://go.dev/doc/effective_go">Effective Go</a>来指导大家写出风格一致的代码。</p>
<p>语言惯例出现在各个级别的代码中，函数名、类型、参数、模块、代码组织结构、模块组织结构、工具链选择、依赖选择、管理依赖的方式等。如果你的代码符合这些语言惯例，将会读起来更让人愉悦。</p>
<p>如何让代码遵循这些语言惯例？可能没有什么更好的办法，只有让自己多去学习这些惯例。</p>
<p><strong>团队惯例</strong></p>
<p>当编程语言本身没有风格倾向，或者有多种风格可选的时候，用什么风格来写代码就由我们自己或者我们的团队来决定了。通常团队会自己定义一些惯例，比如用什么工具，如何缩进等。借助各种语言的<a href="https://en.wikipedia.org/wiki/Lint_(software)">代码检查</a>工具，可以自动化的让代码保持一致的风格。</p>
<p>对于某些无法用工具覆盖的惯例，利用<a href="https://www.thoughtworks.com/zh-cn/radar/techniques/lightweight-architecture-decision-records"><strong>架构设计决策记录</strong></a>来文档化这些惯例是一种好的实践。这些惯例的重要性并不比其他的架构设计决策更低。</p>
<h3 id="基于领域的d"><a class="markdownIt-Anchor" href="#基于领域的d"></a> 基于领域的（D）</h3>
<p>CUPID的最后一个特质D是指Domain based，基于领域的。</p>
<p>近几年，微服务的兴起使得<strong>领域驱动设计</strong>（Domain Driven Design, 简称DDD）以新的面貌受到大家的广泛关注。相对于其对于微服务设计的指导意义，DDD提出的以领域为中心的软件开发思想或许具有更重大的意义。</p>
<p><strong>基于领域的语言</strong></p>
<p>由于代码的读者通常对问题是清楚的，所以，代码应该用问题空间的语言来写，这样就能让代码的读者更容易的理解。问题空间语言即领域语言。</p>
<p>编程语言和库里面充满了计算机技术术语。比如常用的数据结构，如数组、链表、哈希表、树结构等。还比如数据库表、网络连接等。甚至基础数据类型，如整型数值、浮点型数值、字符串等也都是技术术语。直接在代码中使用这些术语不会告诉你的读者你要解决什么问题，他们需要根据对问题的理解进行翻译。</p>
<p>TDD可以用于帮助我们更多的用领域语言编写代码。TDD要求在还没有实现代码的时候写出测试代码。如何做到呢？其实，TDD是希望我们可以在看到问题后，先用自然语言描述测试过程，然后再将自然语言的测试过程翻译为编程语言。由于描述测试过程时，会站在用户的角度进行描述，所以将更多的使用领域语言。并且测试过程的描述将反映出程序应该有的公开接口，所以接口也会变成用领域语言描述的接口，这就很大程度上促进了用领域语言编写代码。</p>
<p>举个例子，在电商场景中，如果要实现购物车的功能，则分析购物车的业务需求之后，可以将测试过程描述如下：</p>
<p>－ 准备一个空的购物车<br />
－ 向购物车添加商品1，数量1<br />
－ 向购物车添加商品2，数量2<br />
－ 购物车中应该有两种商品，其中有1个商品1及2个商品2<br />
－ 向购物车添加商品1，数量1<br />
－ 购物车中应该有两种商品，其中有2个商品1及2个商品2<br />
－ 从购物车取出商品1，数量2<br />
－ 购物车中应该有一种商品，即2个商品2</p>
<p>翻译为Java语言的测试代码示例如下（部分）：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="keyword">void</span> <span class="title function_">testCart</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">var</span> <span class="variable">cart</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Cart</span>();</span><br><span class="line">    <span class="type">var</span> <span class="variable">product1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Product</span>();</span><br><span class="line">    <span class="type">var</span> <span class="variable">product2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Product</span>();</span><br><span class="line"></span><br><span class="line">    cart.add(product1, <span class="number">1</span>);</span><br><span class="line">    cart.add(product2, <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">    assertTrue(cart.contains(product1));</span><br><span class="line">    assertEquals(<span class="number">1</span>, cart.productCount(product1));</span><br><span class="line">    assertTrue(cart.contains(product2));</span><br><span class="line">    assertEquals(<span class="number">2</span>, cart.productCount(product2));</span><br><span class="line"></span><br><span class="line">    cart.add(product1, <span class="number">1</span>);</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>可以看到，通过编写测试，我们用领域语言设计了<code>Cart</code>类，<code>Product</code>类，并且对<code>Cart</code>类设计了<code>add</code> <code>contains</code> <code>productCount</code>三个方法。除了促进使用领域语言编写代码，TDD还可以让我们提供的接口刚刚够用，不多不少，从而实现可组合性特质中的“精巧的接口”。</p>
<p>使用领域语言编写代码的最佳状态是，我们的代码可以让没有技术背景的业务人员也能轻松看懂，整个代码读起来就像业务分析师在讲解业务逻辑一样。</p>
<p><strong>基于领域的结构</strong></p>
<p>除了使用领域语言编写代码，在模块的设计、代码目录结构（或包结构）也应该优先使用领域语言命名。</p>
<p>很多使用Spring框架的Java程序员有个偏好，他们按照框架提供的概念来组织代码，并且将不同的文件按照框架概念进行分类存放。一个可能的结构可能是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">app</span><br><span class="line">|----controllers</span><br><span class="line">|----assets</span><br><span class="line">|----models</span><br><span class="line">|----events</span><br><span class="line">|----repositories</span><br><span class="line">|----requests</span><br><span class="line">|----responses</span><br><span class="line">|----dtos</span><br><span class="line">|----configurations</span><br><span class="line">......</span><br></pre></td></tr></table></figure>
<p>这带来的问题是，当要修改一个API时，不得不在多个目录中去查找和修改代码。这不仅增加了认知负载，使代码耦合在一起，还增加了修改代码的负担。</p>
<p>使用基于领域的结构，建议尽量将目录按照领域进行划分，而不是框架概念。比如，如果是一个电商的场景，目录结构应该是<code>user</code> <code>product</code> <code>order</code> <code>payment</code> <code>shipment</code>等。</p>
<p>当前一个流行的架构模式是分层架构，如果按照分层架构进行设计，则顶层目录可以是不同的分层名称，分层以下，就应该是由领域概念组成的目录。并且分层之间应该有严格的依赖顺序，不应产生两个分层循环依赖的情况。虽然看起来这是一个例外，但是这种拆分是有缺陷的。近两年微服务架构非常流行，而微服务的拆分是按照业务领域进行拆分的，这可以理解为微服务是整体产品这个根目录下的基于领域的子目录。这个现象可以理解为大家对于分层架构的目录划分并不满意，还是希望在更上层基于领域来划分目录。</p>
<p><strong>基于领域的边界</strong></p>
<p>无论我们如何组织代码结构，目录（或模块）的边界变成了事实上的领域边界。一打开代码库就能看到目录结构，目录的层级和名字逐渐变成了大家最熟系的信息。所以，在设计上，一个重要的原则就是将领域划分和目录划分保持一致。这将有效降低团队的认知负载，开发者将因此而更不容易犯错，团队效率最终将得到提高。</p>
<p>这并不意味着需要组织成一个平坦（flat）的目录结构。领域以下可以有子领域，目录以下可以有子目录，模块以下可以有子模块。重要的是这一个一个层级需要能对应上。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>到这里，我们应该了解了CUPID所指出的五种特质的内涵。可以明显的看到，相比不符合CUPID特性的代码，符合CUPID的代码可以让人更加愉悦地进行阅读和修改。事实上，CUPID中的五个特质并不是相互独立的，它们常常可以互相促进。</p>
<p>可组合并符合Unix风格的代码（做一件事，并把它做好）让人感觉就像是一个可靠的老朋友。符合惯例的代码让从未看过此代码的人也觉得非常熟悉。可预测的代码将我们从一系列“惊喜”中解脱出来。基于领域的代码减少了从需求到方案之间的认知距离。</p>
<p>在每次修改代码时，如果每个人都能将代码向这几个方向所指向的中心点靠近一点，那就可以让代码越来越好。</p>
<p>参考：</p>
<ul>
<li>关于Facade模式，可以参考<a href="https://design-patterns.readthedocs.io/zh_CN/latest/structural_patterns/facade.html">这里</a></li>
<li>关于迪米特法则，可以参考<a href="https://baike.baidu.com/item/%E8%BF%AA%E7%B1%B3%E7%89%B9%E6%B3%95%E5%88%99/2107000">这里</a></li>
<li>关于Unix哲学，可以参考<a href="https://en.wikipedia.org/wiki/Unix_philosophy">Wiki</a></li>
</ul>
]]></content>
      <categories>
        <category>敏捷</category>
        <category>技术</category>
        <category>编程思想</category>
      </categories>
      <tags>
        <tag>领域</tag>
        <tag>编程范式</tag>
        <tag>编程</tag>
        <tag>SOLID</tag>
      </tags>
  </entry>
  <entry>
    <title>Efficient ETL Testing</title>
    <url>/2022/06/08/efficient-etl-testing/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2022/2022-06-08-efficient-etl-testing/efficiency.jpeg" alt="Efficiency. Image from https://unsplash.com/photos/gZB-i-dA6ns" /></p>
<p><strong>Previous posts about Easy SQL</strong></p>
<ul>
<li><a href="/2022/05/04/a-new-etl-language-easy-sql/">A new ETL language – Easy SQL</a></li>
<li><a href="/2022/05/16/a-guide-to-write-elegant-etl/">A guide to write elegant ETL</a></li>
<li><a href="/2022/05/25/neat-syntax-design-of-an-etl-language/">Neat syntax design of an ETL language (part 1)</a></li>
<li><a href="/2022/05/30/neat-syntax-design-of-an-etl-language-part-2/">Neat syntax design of an ETL language (part 2)</a></li>
</ul>
<p>It’s always been a pain point to do ETL testing. But it more and more becomes a must after data being so widely used these days.</p>
<p>An ETL with more than 100 lines of code is common. The filter conditions, data transformation rules, join conditions and other logic there could be very complicated.</p>
<span id="more"></span>
<p>In these cases, we should do testing early to avoid possible production issues. Testing gives us confidence about what we coded and helps team with quality assurance.</p>
<p>But there are a lot of challenges about ETL testing there, and we see a lot of teams struggling.</p>
<h1 id="etl-testing-challenges"><a class="markdownIt-Anchor" href="#etl-testing-challenges"></a> ETL testing challenges</h1>
<p>A common way to do ETL testing requires the steps below:</p>
<ul>
<li>Create a production-like environment.</li>
<li>Copy the database definition and table schema to the environment.</li>
<li>For tables used in the ETL, we prepare testing data and insert data to tables.</li>
<li>We run the ETL and it generates a new table with data as a result.</li>
<li>We compare the generated data and the expected data to find if there are any issues.</li>
</ul>
<p>There is no easy thing for the above steps.</p>
<p>For step 1, a production-like environment not only costs, but also requires heavy ops work. Cloud services may ease the ops work but you may be tightly bounded to some cloud.</p>
<p>For step 2, we may need to write scripts to sync database and table schema. We also need to develop a strategy to store the existing data in test environment. The drawback of it is that it breaks the network separation from test to production environment.</p>
<p>For step 3, it’s always been hard work to prepare testing data since some tables the ETL used may contain hundreds of columns and we have to pay attention to columns that are not used in the ETL. We also need to be careful about the column types and how the data is generated. And we need a script to insert data as well.</p>
<p>For step 4, we may need to maintain a separate configuration for test environment.</p>
<p>For step 5, comparing data manually is tedious work and it’s easy to make mistakes.</p>
<p>Some team relies on the statistics of the output table to identify issues of ETLs. It is good practice. But when the logic becomes more and more complicated, it’s not enough to just rely on statistics, since there might be cases that are not covered even by the real data.</p>
<h1 id="testing-etl-in-easy-sql"><a class="markdownIt-Anchor" href="#testing-etl-in-easy-sql"></a> Testing ETL in Easy SQL</h1>
<p>Easy SQL provides a very light-weight way to do ETL testing. It removes most of the blockers mentioned above.</p>
<p>To prepare a test in Easy SQL is easy. The first thing to do is to create a spreadsheet from the provided template.</p>
<p>The template looks like below:</p>
<p><img data-src="/attaches/2022/2022-06-08-efficient-etl-testing/test_case.png" alt="Test case template" /></p>
<p>There are two concepts which are popular in testing domain. Easy SQL also adopted them:</p>
<ul>
<li>Test case: A single test used to test your code in some specific scenario.</li>
<li>Test suit: A bundle of a few unit test cases. Could be used to run them together.</li>
</ul>
<h2 id="test-suit"><a class="markdownIt-Anchor" href="#test-suit"></a> Test suit</h2>
<p>In the screenshot above, we see two test suits, named ‘Suit 1’ and ‘Suit 2’. They are put in different sheets. In Easy SQL, if there is any sheet with a name starting with word ‘Suit’, the sheet is considered to be a test suit.</p>
<h2 id="test-case"><a class="markdownIt-Anchor" href="#test-case"></a> Test case</h2>
<p>In test suit ‘Suit 1’, we can see two test cases. One case is ‘A test for ETL abc.sql’, and the other is ‘Another test for ETL abc.sql’.</p>
<p>Test case is recognized by an uppercase keyword <code>CASE</code> in column ‘A’. There should be a name of the test case in column ‘B’, and be next to the <code>CASE</code> keyword.</p>
<p>To describe a test case, we usually specify the variables that should be used to run the ETL, the data of all input tables, the data of the output tables. They are recognized by keywords <code>VARS</code> <code>INPUT</code> <code>OUTPUT</code> in column ‘A’ and values followed starting from column ‘B’.</p>
<p>The data of output tables is used to test if output of the ETL after execution is exactly the same as the data specified in the test case.</p>
<p><strong>Test case element format</strong></p>
<p>The values of the mentioned elements in a test should be of formats below.</p>
<ul>
<li><code>VARS</code>: A table with header and exactly one row of data.</li>
<li><code>INPUT</code>: A name of the input table specified at column ‘B’; A table with header and number of rows of data starting from column ‘C’ of the same row; Mandatory descriptions of each row of data at column ‘B’ starting from the next row.</li>
<li><code>OUTPUT</code>: The same format with ‘INPUT’, except that the descriptions of each row of data is optional.</li>
</ul>
<p>You may ask why the descriptions of each row of data in ‘INPUT’ table is mandatory. This is a design on purpose. It is designed to improve test readability. The test case designer could record how the data is generated to explain the business rules behind the data and what is the scenario that the data is designed to cover.</p>
<p>For input tables and output tables, we may need to specify the type of each column. If so, we need to add type to the column names in format ‘{COLUMN_NAME}:{TYPE}’. If there is any column of a table with type specified, the type of other columns should be specified as well. If the type of any other column is not specified, it will be default to ‘string’ type.</p>
<p><strong>Column types</strong></p>
<p>The type of column varies for different backends.</p>
<p>For Spark, it should be <code>int</code> <code>bigint</code> <code>boolean</code> <code>string</code> and so on. The full list of types with built-in support are: <code>int</code> <code>tinyint</code> <code>bigint</code> <code>double</code> <code>float</code> <code>string</code> <code>decimal</code> <code>boolean</code> <code>date</code> <code>timestamp</code> <code>array&lt;string&gt;</code> <code>array&lt;int&gt;</code> <code>array&lt;tinyint&gt;</code> <code>array&lt;bigint&gt;</code> <code>array&lt;double&gt;</code> <code>array&lt;float&gt;</code> <code>array&lt;boolean&gt;</code> <code>array&lt;date&gt;</code> <code>array&lt;timestamp&gt;</code>.</p>
<p>For Postgres, it should be <code>int</code> <code>bigint</code> <code>boolean</code> <code>text</code> and so on. The full list of types could be found <a href="https://www.postgresql.org/docs/current/datatype.html">here</a>. The default type is <code>text</code>.</p>
<p>For Clickhouse, it should be <code>Int8</code> <code>Boolean</code> <code>String</code> and so on. The full list of types could be found <a href="https://clickhouse.com/docs/en/sql-reference/data-types/">here</a>.</p>
<p>For the other backends, please refer to the database data types related document of it.</p>
<p><strong>Mock includes</strong></p>
<p>If we have used <strong>include</strong> command in our ETL and we’d like to mock the body of the included file. We can add a <code>INCLUDES</code> section in the test case.</p>
<p>Then provide the mocked body of the ETL follow the rules below:</p>
<ol>
<li>Column ‘B’ at the same row of the <code>INCLUDES</code> keyword should be filled with the file path of the include command in ETL.</li>
<li>Column ‘C’ at the same row of the <code>INCLUDES</code> keyword should be filled with the mocked body of the included file.</li>
<li>Add another row to specify a second <code>INCLUDE</code> to mock, with column ‘B’ and ‘C’ filled with file path and the mocked file body.</li>
</ol>
<p>Usually, the included ETL file returns some temporary table. In this case, we can mock the content of the included file as below:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- target=temp.THE_RETURNED_TEMP_TABLE</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> some_mocked_data</span><br></pre></td></tr></table></figure>
<p>After this, we need to add an input table and provide the mocked data. The way to achieve this is the same as to define a normal input table above.</p>
<p><strong>Test file name</strong></p>
<p>We recommend creating one test file for one ETL. It means all the test cases in one spreadsheet file should be testing the same ETL.</p>
<p>In this case, the file name of the test file and the testing ETL could follow some convention so that we can find the ETL file given the test file.</p>
<p>Easy SQL provides a way to find ETL file from the test file automatically, which follows a simple convention that the base name of the ETL file and that of the test file should be the same.</p>
<p>E.g. when the ETL file is named <code>some_etl.sql</code>, then the test file should be named <code>some_etl.xlsx</code>.</p>
<p>We also recommend there is only one <code>OUTPUT</code> table in one ETL. In this case, the name of the ETL could be the full table name of the output table.</p>
<p>E.g. when an ETL output a table named <code>some_db.some_table</code>, the file name of the ETL should be <code>some_db.some_table.sql</code> and the test file name of the ETL should be <code>some_db.some_table.xlsx</code>.</p>
<p><strong>Add test files to version control system</strong></p>
<p>The test file mentioned above is a spreadsheet file. It is in binary format and not so easy to be added to version control system.</p>
<p>Easy SQL provides a way to dump a test in spreadsheet format to JSON format. After this, we can add the JSON file to version control system. In this way, we can easily compare the changes of each version of this case.</p>
<p>The JSON file is also optimized to let us compare data changes easily.</p>
<p>To convert a test file in spreadsheet format to JSON format. Run the command below:</p>
<p>(Before you run the command below, you will need to install two additional packages by <code>pip3 install click==6.7 pymongo==3.10.1 xlrd==1.2.0</code>)</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python3 -m easy_sql.sql_test convert-json -f &#123;YOUR_XLSX_FILE_PATH&#125;</span><br></pre></td></tr></table></figure>
<p>After the command finishes, there will be a JSON file with the same name but a <code>.json</code> suffix of the spreadsheet file generated. The directory of the JSON file is the same as the spreadsheet file.</p>
<h1 id="run-test"><a class="markdownIt-Anchor" href="#run-test"></a> Run test</h1>
<p>Easy SQL provides a command line module to help to run ETL tests.</p>
<p>To run the ETL test, execute the command below:</p>
<p>(Before you run the command below, you will need to install two additional packages by <code>pip3 install click==6.7 pymongo==3.10.1 xlrd==1.2.0</code>)</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python3 -m easy_sql.sql_test run-test -f &#123;YOUR_XLSX_FILE_PATH&#125; -b &#123;BACKEND&#125;</span><br></pre></td></tr></table></figure>
<p>The test file could be a JSON test file as well. And the backend could be one of the supported backend.</p>
<p>For details of the command line usage, please run <code>python3 -m easy_sql.sql_test --help</code>.</p>
<h2 id="run-test-programmatically"><a class="markdownIt-Anchor" href="#run-test-programmatically"></a> Run test programmatically</h2>
<p>Easy SQL also provides an interface to run ETL programmatically. This way, you can easily integrate tests in Easy SQL with your favorite testing framework.</p>
<p>To run a test in your code, write code below:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> easy_sql.sql_tester <span class="keyword">import</span> SqlTester</span><br><span class="line"><span class="keyword">from</span> easy_sql.sql_processor.backend <span class="keyword">import</span> SparkBackend</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">SqlTester(env=<span class="string">&#x27;test&#x27;</span>, </span><br><span class="line">          backend_creator=<span class="keyword">lambda</span> case: SparkBackend(SparkSession.builder.enableHiveSupport().getOrCreate()), </span><br><span class="line">          work_dir=os.path.abspath(os.curdir))\</span><br><span class="line">    .run_tests(<span class="string">&#x27;path/to/your/test/file&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>For a concrete example, please refer to code <a href="https://github.com/easysql/easy_sql/blob/main/easy_sql/sql_test.py">here</a>.</p>
<h1 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h1>
<p>In this post, we talked about the necessity of ETL testing and challenges to do ETL testing.</p>
<p>In order to be efficient to create automated test cases, we have to spend some time to create some tools.</p>
<p>Easy SQL provides some built-in tools to help with ETL testing. With the help of Easy SQL, a lot of blockers have been removed. We only need to provide the main information about the test data. There is no more need to care about unrelated columns, data types, data comparing and so on.</p>
<p>Easy SQL embraces the most commonly used tool – spreadsheet – to create test cases. We can get a lot of benefits from it, such as a friendly and readable layout, the ability to use formula to prepare data, an intuitive way to record data and mock included code snippets etc.</p>
<p>In one word, with Easy SQL, we can do ETL testing more efficiently and save large amounts of time.</p>
]]></content>
      <categories>
        <category>数据</category>
      </categories>
      <tags>
        <tag>编译</tag>
        <tag>编译器</tag>
        <tag>数据</tag>
        <tag>数据平台</tag>
        <tag>数据工程</tag>
        <tag>EasySQL</tag>
        <tag>ETL</tag>
        <tag>ETL开发</tag>
        <tag>软件工程</tag>
        <tag>编程语言</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title>用TDD开发基于数据库的长时任务系统</title>
    <url>/2022/07/05/tdd-to-develop-a-long-running-task-system/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h2 id="背景"><a class="markdownIt-Anchor" href="#背景"></a> 背景</h2>
<p>在最近的一个项目上，我们再次碰到了需要处理长时任务的场景。事实上，随着要处理的业务问题越来越复杂，要集成的系统越来越多，在<code>Web</code>服务器端开发中，长时任务处理已经成为了一个普遍的问题。</p>
<p>以下场景均可看作长时任务场景：</p>
<ul>
<li>在<code>GitHub</code>提交了一个<code>PR</code>，要分别向上百个相关用户单独发送邮件</li>
<li>用户上传了一个文件，需要扫描这个文件是不是带病毒</li>
<li>用户想以<code>pdf</code>格式下载某一个文档，需要先将文档转换为<code>pdf</code>格式</li>
</ul>
<span id="more"></span>
<p>这些问题的一个共同特征是执行时间比较长，不能简单的用<strong>单线程的Web服务请求-响应模型</strong>来实现。</p>
<h2 id="分析问题识别难点"><a class="markdownIt-Anchor" href="#分析问题识别难点"></a> 分析问题，识别难点</h2>
<p>在应对这些需求场景时，一个关键的设计是需要用异步API模型进行建模。如下图所示：</p>
<p><img data-src="/attaches/2022/2022-07-05-tdd-to-develop-a-long-running-task-system/long-running-task-basic-model.png" alt="Event model for long-running task" /></p>
<p>通常的做法如下：</p>
<ul>
<li>采用事件模型（<code>Event Model</code>），将长时任务包装为一个事件，放入事件队列</li>
<li>将待处理事件从事件队列中推送给事件消费者（或者消费者主动拉取新的事件）</li>
<li>事件消费者处理事件，并保存事件处理结果</li>
<li>关注事件结果的客户端查询事件处理状态，并提取事件处理结果</li>
</ul>
<p>这看上去并不太难，但是，如果仔细思考一下事件的处理过程，会发现情况不对，这里面还存在以下一系列问题：</p>
<ul>
<li>如何尽量避免多个事件消费者同时处理此事件，以便节省计算资源？</li>
<li>如果恰好同时有多个事件消费者在处理事件，会发生什么问题？</li>
<li>如果有多个相关事件正在被同时处理，如何处理资源竞争问题？</li>
<li>如何避免长时任务可能导致的长时数据库事务问题？</li>
</ul>
<p><img data-src="/attaches/2022/2022-07-05-tdd-to-develop-a-long-running-task-system/long-running-task-problems.png" alt="Problems related to event model" /></p>
<p>以下方案可用于应对上述问题：</p>
<ul>
<li>在事件分派时，通过并发控制或者资源锁定机制，确保只将事件分派给某一个事件消费者</li>
<li>保证事件处理器的实现是幂等的，即：即便多次同时执行，其最终结果也是一致的</li>
<li>将任务处理过程拆分为多个短数据库事务过程，避免长期持有数据库锁引起性能问题</li>
</ul>
<p>经过以上分析可以发现，异步任务模型是相对比较复杂的模型，程序实现及上线之后的问题分析、调试成本都比较高。在进行系统设计时，如果发现系统可以接受一定的延迟，并且并发也不高，就应尽量避免引入异步任务模型。</p>
<p>近年来，<code>CQRS</code>（命令查询分离）+<code>Event Sourcing</code>（事件溯源）设计模式越来越受到大家的关注。这一模式中，所有的写操作均采用异步事件的方式进行处理。准备采用这一模式时，一定要评估是否值得，因为异步任务将带来与上述类似的非预期复杂度。同时，如果事件使用不当还容易导致更复杂的情况。比如，如果在事件处理过程中生成了其他的事件，就可能产生一个由任务序列组成的有向图，甚至图中带环，从而使得处理过程的分析变得异常复杂。</p>
<h2 id="tdd方法简介"><a class="markdownIt-Anchor" href="#tdd方法简介"></a> TDD方法简介</h2>
<p><code>TDD</code>可以用于辅助我们进行复杂软件设计。是不是可以用<code>TDD</code>帮助我们实现这一复杂的异步任务处理系统呢？下面来做一下尝试。</p>
<p>在回答这个问题之前，我们先了解一下<code>TDD</code>的基本思想及其实施过程。</p>
<p>从驱动设计的角度来看，<code>TDD</code>的基本思想是，在还没有代码的时候，先站在使用代码的<strong>用户的角度</strong>来定义测试（编写测试就是在使用代码，所以可以自然的站在用户角度），由于使用了<strong>用户视角</strong>来定义系统组件及其接口，就可以使得到的组件和接口易于使用。</p>
<p>很多人无法在没有代码的时候编写测试，或者会由于IDE给出的一系列红色警告（由于组件还未定义）而感到不自然。</p>
<h3 id="写不出测试"><a class="markdownIt-Anchor" href="#写不出测试"></a> 写不出测试</h3>
<p>写不出测试一般是由于没有理解问题或不了解现有架构。可以采用<code>Tasking</code>（任务拆解）的方式来验证自己是否理解问题并了解架构。其基本思想是，对于一个问题，如果可以列出解决它所需的一系列清晰而合理的步骤，那就说明对问题和架构都较为清楚了。所以，在实施<code>TDD</code>时，一般需要先进行<code>Tasking</code>任务拆解。</p>
<h3 id="红色警告让人感到不自然"><a class="markdownIt-Anchor" href="#红色警告让人感到不自然"></a> 红色警告让人感到不自然</h3>
<p>对IDE给出的红色警告感到不自然的问题一般来自习惯。在编写测试代码时，需要调整视角，以完成设计和验证结果为重心。事实上，先写测试还会带来一个额外的好处，那就是在写完测试之后，可以让IDE帮助我们生成绝大多数代码，从而更快的完成代码编写。</p>
<h2 id="用tdd辅助开发基于数据库的队列服务"><a class="markdownIt-Anchor" href="#用tdd辅助开发基于数据库的队列服务"></a> 用TDD辅助开发基于数据库的队列服务</h2>
<p>下面看看如何用<code>TDD</code>来设计一个满足上述需求的异步任务处理系统。</p>
<p>经过前文的分析，我们大致了解了解决长时任务的关键方案。方案里面有一个核心的组件，那就是队列服务。</p>
<p>可以找到很多开源软件用来做队列服务，比如<code>RabbitMQ</code>，<code>Apache ActiveMQ</code>，<code>Apache RocketMQ</code>，<code>Kafka</code>，<code>Redis</code>等。甚至很多云端的SaaS服务也可以用来解决这个问题，比如<code>AWS SQS</code>，<code>Azure Service Bus queues</code>, <code>GCP Pubsub</code>等。</p>
<p>在很多项目的上下文中，可以预期并不会有太多的长时任务。此时，为了保持系统简单，避免引入其他的依赖，可以考虑基于数据库来实现这样的一个队列服务。下面分享一下如何用<code>TDD</code>指导我们开发一个基于数据库的长时任务系统。</p>
<h3 id="第一个测试"><a class="markdownIt-Anchor" href="#第一个测试"></a> 第一个测试</h3>
<p>采用<code>TDD</code>的思想，首先我们站在（长时任务）系统的用户（将来使用长时任务API的开发者）的角度思考如何使用长时任务的API完成程序功能。</p>
<pre><code>假设有一个长时任务，它应该可以被添加到队列中。
队列应该启动一个后台线程，即消费者线程，从队列中取出任务开始执行。
由于任务在消费者线程中执行，消费者线程应该需要知道任务所对应的可执行代码是什么。
所以，在消费者线程开始运行之前，需要注册好任务对应的可执行代码。
</code></pre>
<p>基于上面的分析，使用Java进行编码，可写出对应的测试如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TaskQueueTest</span> &#123;</span><br><span class="line">...</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">should_run_task_from_queue</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">var</span> <span class="variable">queue</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskQueue</span>();</span><br><span class="line">        <span class="type">var</span> <span class="variable">consumer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskQueueConsumer</span>(queue);</span><br><span class="line">        </span><br><span class="line">        <span class="type">var</span> <span class="variable">task1Runnable</span> <span class="operator">=</span> mock(TaskRunnable.class);</span><br><span class="line">        <span class="type">var</span> <span class="variable">task2Runnable</span> <span class="operator">=</span> mock(TaskRunnable.class);</span><br><span class="line">        consumer.registerTask(<span class="string">&quot;task_type_1&quot;</span>, task1Runnable);</span><br><span class="line">        consumer.registerTask(<span class="string">&quot;task_type_2&quot;</span>, task2Runnable);</span><br><span class="line">        consumer.start();</span><br><span class="line"></span><br><span class="line">        <span class="type">var</span> <span class="variable">task1Arg</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskType1Arg</span>(“some arg”);</span><br><span class="line">        queue.addTask(“task_type_1”, task1Arg);</span><br><span class="line"></span><br><span class="line">        Thread.sleep(<span class="number">100</span>);</span><br><span class="line">        </span><br><span class="line">        verify(task1Runnable, times(<span class="number">1</span>)).run(eq(task1Arg));</span><br><span class="line"></span><br><span class="line">        <span class="type">var</span> <span class="variable">task2Arg</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskType2Arg</span>(“some arg”);</span><br><span class="line">        queue.addTask(“task_type_2”, task2Arg);</span><br><span class="line"></span><br><span class="line">        Thread.sleep(<span class="number">100</span>);</span><br><span class="line">        </span><br><span class="line">        verify(task2Runnable, times(<span class="number">1</span>)).run(eq(task2Arg));</span><br><span class="line">    &#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>到这里，一个基本的测试用例就定义好了。上述代码用到了<code>JUnit</code>及<code>Mockito</code>测试库的一些<code>API</code>。在编写测试的过程中，我们完成了基本的组件拆分及功能设计。值得注意的是，这里用到的类的名字、方法的名字、方法的参数等均是从用户的角度进行设计的。</p>
<p>因为我们直接写出了这样的测试代码，此时，IDE会显示很多红色警告，因为测试中用到的类和方法都还未被创建。如果使用<code>Idea</code>进行开发的话，可以将光标移动到红色警告处，按下<code>Alt+Enter</code>，<code>Idea</code>将提示创建类或变量，跟随IDE的指引，就可以很容易的完成这些代码的编写。</p>
<p><img data-src="/attaches/2022/2022-07-05-tdd-to-develop-a-long-running-task-system/leverage-ide-to-coding.png" alt="Leverage IDE to help coding" /></p>
<p>到这里我们就完成了第一个测试，并生成了对应的代码框架。整个系统设计的第一步已经初步完成。</p>
<h3 id="引入新的设计改进测试"><a class="markdownIt-Anchor" href="#引入新的设计改进测试"></a> 引入新的设计，改进测试</h3>
<p>由于我们希望基于数据库来实现任务队列，而数据库访问一般用<code>Repository</code>进行抽象。对应这里的设计，任务队列应该需要把数据读写的职责拆分出去。</p>
<p>考虑如何在测试中使用<code>Repository</code>，可以在之前的测试基础上增加<code>Repository</code>相关接口设计。有几处需要修改的地方：</p>
<ul>
<li>测试开始时，应该构造一个模拟的<code>Repository</code>对象。</li>
<li>当新任务加入队列时，任务队列应当调用<code>Repository</code>的接口保存新任务。</li>
<li>当任务队列消费者开始运行时，它应当从任务队列取出新任务，而任务队列使用<code>Repository</code>查询新的任务。</li>
<li>当任务被取出，将要运行时，其状态应当被修改为开始执行，并保存到数据库中，此时应当采用批量保存的方式。</li>
<li>在任务执行期间，其状态将有一系列变化：待运行、开始执行、执行中、执行成功/失败。在任务状态变化时，将调用<code>Repository</code>更新数据库的状态。</li>
<li>在保存任务的时候，任务的参数需要以一种方式序列化为字符串才能在数据库中保存。可以使用常用的json序列化方式。</li>
</ul>
<p>修改测试如下（完整代码见<a href="https://github.com/gmlove/taskqueue-demo/blob/d261bb18d8/src/test/java/com/brightliao/taskqueue/TaskQueueTest.java">这里</a>）：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TaskQueueTest</span> &#123;</span><br><span class="line">...</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">should_run_task_from_queue</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">var</span> <span class="variable">taskRepository</span> <span class="operator">=</span> mock(TaskRepository.class);</span><br><span class="line">        <span class="keyword">final</span> <span class="type">ObjectMapper</span> <span class="variable">objectMapper</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ObjectMapper</span>();</span><br><span class="line">        <span class="type">var</span> <span class="variable">queue</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskQueue</span>(taskRepository, tt, objectMapper);</span><br><span class="line">        <span class="type">var</span> <span class="variable">consumer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskQueueConsumer</span>(queue, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">var</span> <span class="variable">task1Runnable</span> <span class="operator">=</span> mock(TaskRunnable.class);</span><br><span class="line">        <span class="type">var</span> <span class="variable">task2Runnable</span> <span class="operator">=</span> mock(TaskRunnable.class);</span><br><span class="line">        consumer.registerTask(<span class="string">&quot;task_type_1&quot;</span>, task1Runnable);</span><br><span class="line">        consumer.registerTask(<span class="string">&quot;task_type_2&quot;</span>, task2Runnable);</span><br><span class="line">        consumer.start();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// run task1 successfully</span></span><br><span class="line">        <span class="type">var</span> <span class="variable">task1Arg</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskType1Arg</span>(<span class="string">&quot;some arg&quot;</span>);</span><br><span class="line">        <span class="keyword">final</span> <span class="type">Task</span> <span class="variable">task1</span> <span class="operator">=</span> someTask(<span class="number">1L</span>, <span class="string">&quot;task_type_1&quot;</span>, <span class="string">&quot;&#123;\&quot;arg\&quot;:\&quot;some arg\&quot;&#125;&quot;</span>);</span><br><span class="line">        when(taskRepository.findNewTasks(eq(<span class="number">1</span>))).thenReturn(List.of(task1)).thenReturn(List.of());</span><br><span class="line">        when(taskRepository.saveAll(anyList())).thenAnswer(answer -&gt; answer.getArgument(<span class="number">0</span>));</span><br><span class="line">        when(taskRepository.save(any())).thenAnswer(answer -&gt; answer.getArgument(<span class="number">0</span>));</span><br><span class="line"></span><br><span class="line">        queue.addTask(<span class="string">&quot;task_type_1&quot;</span>, task1Arg);</span><br><span class="line"></span><br><span class="line">        Thread.sleep(<span class="number">500</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// add -&gt; running -&gt; succeeded</span></span><br><span class="line">        verify(taskRepository, times(<span class="number">3</span>)).save(any(Task.class));</span><br><span class="line">        <span class="comment">// started</span></span><br><span class="line">        verify(taskRepository, times(<span class="number">1</span>)).saveAll(anyList());</span><br><span class="line">        verify(task1Runnable, times(<span class="number">1</span>)).run(eq(<span class="string">&quot;&#123;\&quot;arg\&quot;:\&quot;some arg\&quot;&#125;&quot;</span>));</span><br><span class="line">        assertThat(task1.isSucceeded()).isEqualTo(<span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">        ......</span><br><span class="line">    &#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上述测试中，我们模拟了<code>TaskRepository</code>对象，并基于这个模拟对象进行测试。通过模拟这个对象的接口，我们可以完成整个<code>TaskRepository</code>的<code>API</code>设计。</p>
<p>同样的，可以利用IDE辅助我们生成大量的模板代码，在实现时，只需要在不同的地方填入代码即可。</p>
<h3 id="加入数据库事务支持进一步改进测试"><a class="markdownIt-Anchor" href="#加入数据库事务支持进一步改进测试"></a> 加入数据库事务支持，进一步改进测试</h3>
<p>由于程序需要访问数据库进行数据存取，数据库事务控制是一个需要注意的问题。从性能上考虑，数据库事务应当较短，不适合将长时任务运行过程放入事务过程中。</p>
<p>数据库事务实现可以基于<code>Spring</code>框架提供的事务抽象，即<code>TransactionTemplate</code>接口。可以对以下可快速完成的过程进行事务控制：</p>
<ul>
<li>取出新任务后，将任务标记为开始执行。使用排它锁进行事务控制，防止其他任务消费者取到同一个任务</li>
<li>任务开始执行时，将任务标记为正在执行状态，使用基于版本的乐观锁进行事务控制</li>
<li>任务执行完成之后，更新任务状态，使用基于版本的乐观锁进行事务控制</li>
</ul>
<p>修改测试如下（完整代码见<a href="https://github.com/gmlove/taskqueue-demo/blob/47c332f5c9/src/test/java/com/brightliao/taskqueue/TaskQueueTest.java">这里</a>）：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TaskQueueTest</span> &#123;</span><br><span class="line">...</span><br><span class="line">    <span class="keyword">private</span> TransactionTemplate <span class="title function_">mockTransactionTemplate</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">var</span> <span class="variable">tt</span> <span class="operator">=</span> mock(TransactionTemplate.class);</span><br><span class="line">        when(tt.execute(any())).thenAnswer(answer -&gt; &#123;</span><br><span class="line">            <span class="keyword">final</span> TransactionCallback&lt;?&gt; arg = (TransactionCallback&lt;?&gt;) answer.getArgument(<span class="number">0</span>);</span><br><span class="line">            log.info(<span class="string">&quot;execute in transaction: &#123;&#125;&quot;</span>, arg);</span><br><span class="line">            <span class="keyword">return</span> arg.doInTransaction(<span class="keyword">new</span> <span class="title class_">SimpleTransactionStatus</span>());</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        doAnswer(answer -&gt; &#123;</span><br><span class="line">            ((Consumer&lt;TransactionStatus&gt;) answer.getArgument(<span class="number">0</span>)).accept(<span class="keyword">new</span> <span class="title class_">SimpleTransactionStatus</span>());</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">        &#125;).when(tt).executeWithoutResult(any());</span><br><span class="line">        <span class="keyword">return</span> tt;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">should_run_task_from_queue</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">TransactionTemplate</span> <span class="variable">tt</span> <span class="operator">=</span> mockTransactionTemplate();</span><br><span class="line"></span><br><span class="line">        <span class="type">var</span> <span class="variable">taskRepository</span> <span class="operator">=</span> mock(TaskRepository.class);</span><br><span class="line">        <span class="keyword">final</span> <span class="type">ObjectMapper</span> <span class="variable">objectMapper</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ObjectMapper</span>();</span><br><span class="line">        <span class="type">var</span> <span class="variable">queue</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskQueue</span>(taskRepository, tt, objectMapper);</span><br><span class="line">        <span class="type">var</span> <span class="variable">consumer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskQueueConsumer</span>(queue, <span class="number">1</span>);</span><br><span class="line">        ......</span><br><span class="line">    &#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="实现现有的接口"><a class="markdownIt-Anchor" href="#实现现有的接口"></a> 实现现有的接口</h3>
<p>由于目前只是通过IDE生成了一些代码框架，尚未提供实现，上述测试会失败。接下来的一步就是为现在的设计提供一个实现。</p>
<p>有了前面的分析，及测试的保障，实现起来应该不是什么难事。有兴趣的同学可以自己试着写一写代码。</p>
<p>一个参考实现见<a href="https://github.com/gmlove/taskqueue-demo/commit/47c332f5c9652e7484e054d48e03cfb45c5215a8">这里</a>。</p>
<h3 id="其他的考虑"><a class="markdownIt-Anchor" href="#其他的考虑"></a> 其他的考虑</h3>
<p>为保证我们的长时任务实现具有较好的易用性，还可以考虑增加以下特性：</p>
<ul>
<li>任务消费者异常退出时，任务应该被回收，以便新的任务消费者可以重新处理该任务。</li>
<li>任务消费者应当被周期性的唤醒，以便可以定时的从队列中取出新任务进行处理。</li>
<li>当有新任务加入时，任务消费者应该快速被唤醒，以便新任务可以及时得到处理。</li>
<li>如果执行任务时，任务处理器未被注册，则应该抛出异常，并将任务标记为失败。</li>
<li>如果任务执行失败，可以进行一定次数的重试。</li>
<li>可以实现<code>Restful API</code>来完成添加任务、获取任务状态、查询任务列表、重启任务等功能。</li>
</ul>
<p>这些特性都可以通过<code>TDD</code>的方式进行实现。</p>
<p>部分上述特性的详细实现过程及代码可以参考<a href="https://github.com/gmlove/taskqueue-demo/commits/main">这里</a>的提交记录。</p>
<p>值得注意的是，除了按照前文进行基本的<code>TDD</code>开发。在设计测试时，还需要考虑整体的测试策略。一般而言，测试应该可以按照集成度的从小到大构成一个金字塔的结构。即，大量集成度小的单元测试，中等数量集成度中等的测试，少量的集成度高的测试。在进行<code>TDD</code>时，需要考虑用哪种集成度的测试更好。</p>
<p>一般的策略是：</p>
<ul>
<li>先写一个简单的高集成度测试，通过这个测试驱动编写面向用户的接口，同时也作为面向用户的功能验收。</li>
<li>再编写少量中等集成度的测试，通过这些测试驱动完成各个组件及其交互接口的设计，同时验证这些组件确实按照设计工作。</li>
<li>然后再以类级别或函数级别的测试为主，为类或函数的实现提供正确性保障。</li>
</ul>
<p>在<code>TDD</code>的过程中，通常还会结合重构来进行局部代码优化。在上述实现中，也有一些可以参考的地方。比如，任务处理器最初命名为<code>TaskRunnable</code>，后来改为<code>TaskHandler</code>，以便更符合语义。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>编写有效的自动化测试是专业的开发人员的一项基本技能。然而，很多团队一味追求快速写完代码，忽略了锻炼开发人员的自动化测试技能，这对于开发人员的能力提升是不利的。</p>
<p>很多开发人员或者执着于追求底层技术，或者执着于为实现高并发高性能而引入的技巧，或者执着于某个复杂的算法，或者执着于理解某一框架的实现细节。他们认为这些才是自己技术能力的体现。这些确实可以体现一部分开发人员的能力，但是，别忘了，这些始终只是别人创造的成果。</p>
<p>真实的日常工作常常只是将一个个特定场景下的需求变成可工作的软件，并应对复杂的业务及将来的变更。针对这些特定的问题给出相对简单的合理的设计的能力，编写优雅且高质量的代码的能力，才是开发人员最重要的能力。自动化测试和<code>TDD</code>在这方面可以给开发人员很大的助力。</p>
<p>事实上，自动化测试和<code>TDD</code>不仅可以帮助完成高质量软件的开发，对前面提到的技术提升也很有帮助。因为，为了编写有效的测试，需要我们对所使用的框架或库有足够的了解，这就促使我们去了解它们的实现细节，同时，可运行的测试还可以用于确认我们的理解。</p>
<p>本文展示了在一个相对复杂的场景下，如何用<code>TDD</code>帮助我们开发拥有良好设计的代码。可以发现，<code>TDD</code>不仅为我们提供了测试护航，而且，面向用户的接口设计，领域语言的运用，都可以在<code>TDD</code>的加持下自然的落地。</p>
<p>最后，只看不练并不能带来能力的提升，要想熟练的掌握<code>TDD</code>还需要在日常工作中抓住每一个机会刻意练习。</p>
<p><strong>相关文章：</strong></p>
<ul>
<li><a href="/2019/07/20/tdd-for-improving-design/">从改善设计的角度理解TDD</a></li>
<li><a href="/2019/08/18/tdd-for-improving-design-2/">从改善设计的角度理解TDD (2)</a></li>
<li><a href="/2022/05/24/5-properties-of-good-code-cupid/">好代码的五个特质-CUPID</a></li>
</ul>
]]></content>
      <categories>
        <category>tdd</category>
        <category>敏捷</category>
      </categories>
      <tags>
        <tag>agile</tag>
        <tag>敏捷</tag>
        <tag>tdd</tag>
        <tag>测试</tag>
        <tag>质量</tag>
      </tags>
  </entry>
  <entry>
    <title>我理解的Smart Domain与DDD</title>
    <url>/2022/07/27/smart-domain-and-ddd/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>前段时间，咱们CTO八叉在极客时间做了一次关于用Smart Domain实现DDD的分享（点击<a href="https://www.bilibili.com/video/BV1QT411J7jh">这里</a>回看）。一个新词Smart Domain进入大家的视野。</p>
<h2 id="smart-domain解析"><a class="markdownIt-Anchor" href="#smart-domain解析"></a> Smart Domain解析</h2>
<p>Smart Domain是啥？为什么可以用Smart Domain实现DDD？本文尝试结合以往对DDD的学习和实践的经验，跟大家分享一下个人的理解。</p>
<p>八叉在分享中提到Smart Domain这个名字来源于Smart UI。我们都知道Smart UI是DDD中提到的一种反模式，只能用于解决简单问题。这里的命名略带反讽戏谑的意味。</p>
<span id="more"></span>
<p>下面咱们结合示例看看Smart Domain究竟是什么。</p>
<p>打开Smart Domain的示例工程：<a href="https://github.com/Re-engineering-Domain-Driven-Design/Accounting">https://github.com/Re-engineering-Domain-Driven-Design/Accounting</a>。可以看到，项目在结构上分为了四个子模块：</p>
<ul>
<li><code>main</code>: Web应用入口，负责配置即启动应用</li>
<li><code>api</code>: 定义Restful API</li>
<li><code>domain</code>: 核心领域层</li>
<li><code>persistent</code>: 数据持久化</li>
</ul>
<h3 id="模块划分与依赖关系"><a class="markdownIt-Anchor" href="#模块划分与依赖关系"></a> 模块划分与依赖关系</h3>
<p>深究起来，这四个模块和现在的分层架构有一些相似之处，但却并<strong>没有显示的严格的进行分层</strong>。同时，八叉在分享中明确提到了分层架构对领域建模是有伤害的，容易导致抽象不足。</p>
<p>值得注意的是，<strong><code>domain</code>模块没有任何依赖</strong>，其他模块则依赖<code>spring</code>及相应的包。通过在<code>domain</code>层定义抽象的接口（但不提供实现，由其他模块提供实现）的方式，将<code>domain</code>层的核心逻辑隔离起来，使得<code>domain</code>层可以非常容易根据领域需要进行灵活的设计及独立的测试。大家如果熟悉依赖倒置的设计原则，应该可以很容易领会这一做法的好处。（<code>domain</code>层本应该依赖数据持久化进行数据的查询与保存，这里通过抽象的接口设计让持久化层反过来依赖<code>domain</code>层的接口。）</p>
<h3 id="关联对象"><a class="markdownIt-Anchor" href="#关联对象"></a> 关联对象</h3>
<p>Smart Domain的一个关键设计在于在模型之间<strong>引入了一个中间关联对象</strong>。关联对象由一系列接口来定义（见代码中的<code>HasMany</code> <code>HasOne</code> <code>Many</code>接口），各类跨模型的操作均通过关联对象实现。这一设计避免了直接进行模型引用的诸多问题，比如引用的模型数量太多无法直接放入内存、引用的模型的查询修改通过<code>Repository</code>实现进而引入抽象能力很弱的<code>Service</code>去协调等。</p>
<p>示例项目中通过关联对象建模出的结果如下：</p>
<p><img data-src="/attaches/2022/2022-07-27-smart-domain-and-ddd/smart-domain-models.jpeg" alt="Smart Domain Models" /></p>
<p>无关联对象的实现方式的本质问题在于希望完全用内存模型来抽象数据库访问，而内存模型事实上无法直接建模数据库的复杂性，因而引起了一系列连锁反应。通过引入关联对象，<strong>将数据库访问显示的建模出来</strong>，这些连锁反应就不复存在了，领域层也将更清晰、纯粹和丰满。</p>
<p>关联对象和传统DDD中的<code>Repository</code>的抽象有一定的相似点，在我看来其最重要的区别在于关联对象接口定义在了引用方代码中。这一做法的隐含建议是<strong>从使用的角度来定义接口</strong>，从而使得接口定义不多不少，刚好满足系统需求。</p>
<h3 id="其他"><a class="markdownIt-Anchor" href="#其他"></a> 其他</h3>
<p>由于在Smart Domain的设计里面，<strong>对象图以统一的关联的形式被创建</strong>出来，所以可以提供一个统一的访问关联对象的方法。这一点很好的符合了Restful API的设计思想，API模块利用这个特点，以很少的代码完成了Restful API的导出。</p>
<p>纵观Smart Domain的设计，可以发现结构上非常简洁，没有引入传统DDD实践中常用却很难用好的<code>Repository</code> <code>Service</code> <code>Aggregate</code>等模式。然而这恰恰是让开发人员可以<strong>集中精力在对领域的挖掘和思考</strong>上。</p>
<h3 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h3>
<p>总结起来，Smart Domain主要的创新及价值有以下几点：</p>
<ul>
<li>打破了大家习惯用的分层架构，这些分层架构大都是从技术角度进行的抽象，而非领域角度</li>
<li>摒弃了职责模糊不清的service模式，使得原来service层的逻辑下沉到领域模型中，从而期望得到更丰满的领域模型</li>
<li>弱化了DDD中引入的聚合、限界上下文等容易引起争议的模式</li>
<li>尽可能的摒弃了在代码中使用过于技术化的术语，如Controller、DTO等，从而使得我们更专注于领域设计，通过引入更多的抽象来解决问题</li>
<li>将数据库查询显示的建模出来（通过关联对象），而不是直接在模型中引用关联模型的实例，有利于避免查询性能问题</li>
</ul>
<h2 id="为什么说smart-domain实现了ddd"><a class="markdownIt-Anchor" href="#为什么说smart-domain实现了ddd"></a> 为什么说Smart Domain实现了DDD？</h2>
<p>经过上面对Smart Domain的分析之后，可能有人会问：这跟DDD有啥关系？为什么DDD中的很多设计模式都没用却说实现了DDD？</p>
<p>要回答这个问题，需要搞清楚什么是DDD，即DDD的定义是什么。</p>
<h3 id="什么是ddd"><a class="markdownIt-Anchor" href="#什么是ddd"></a> 什么是DDD？</h3>
<p>要追寻DDD的定义，可以回到这本早期的也是业界公认最权威的Eric的书《领域驱动设计-软件核心复杂性应对之道》中。</p>
<p>Eric并未直接在书中对DDD进行定义，但是在第一章中，结合示例，总结了有效建模的几个要素：</p>
<ul>
<li>模型和实现的绑定</li>
<li>获得了一种基于模型的语言</li>
<li>开发一个蕴含丰富知识的模型</li>
<li>持续进行模型提炼</li>
<li>头脑风暴进行创新，进行大量实验</li>
</ul>
<p>在知识消化章节提到：</p>
<ul>
<li>分析员和程序员将自己的知识输入到了模型中，因此模型的组织更严密，抽象也更为整洁</li>
<li>模型反映业务的深层次知识，模型真正是对业务原理的抽象反映</li>
</ul>
<p>在统一语言章节提到：</p>
<ul>
<li>如果不把“讲话”与各种沟通方式配合起来使用，那么将是巨大的浪费，因为人类本身就有 讲话的天赋。遗憾的是，当人们讲话时，一般并不使用领域模型的语言。</li>
<li>当人们谈话时，自然会发现词语解释和意义上的差别，而且自然而然会解决这些差别。他们会发现这种语言中的晦涩之处并消除它们，从而使语言变得顺畅。</li>
<li>使用模型的元素以及模型中各元素之间的交互来大声描述场景，并且按照模型允许的方式将各种概念结合到一起。找到更简单的表达方式来讲出你要讲的话，然后将这些新的思想应用到图和代码中。</li>
</ul>
<p>从这些描述可以看出DDD的指导思想是：<strong>深入研究领域，消化知识，充分沟通，然后用软件模型对问题进行深刻的抽象，最终得到一个富含知识的领域模型。</strong></p>
<h3 id="smart-domain实现ddd"><a class="markdownIt-Anchor" href="#smart-domain实现ddd"></a> Smart Domain实现DDD</h3>
<p>从上面的分析来看，DDD的实现不在于用何种方法，而是看最后是否得到了良好的深刻的领域模型。Smart Domain可以促进我们把关注点从研究技术转向研究领域，从而推动开发人员去深入分析理解问题，创新的大胆的进行抽象和建模，最终得到好的领域模型。所以，可以说Smart Domain提供了一种很好的方式来实现DDD，这显然是合理的。</p>
<h2 id="smart-domain的扩展思考"><a class="markdownIt-Anchor" href="#smart-domain的扩展思考"></a> Smart Domain的扩展思考</h2>
<p>Smart Domain给我们提供了一个新的DDD实现思路。我们对它有没有什么疑问呢？</p>
<h3 id="领域层抽象"><a class="markdownIt-Anchor" href="#领域层抽象"></a> 领域层抽象</h3>
<p>习惯分层架构的同学，看到Smart Domain的思想，可能在直觉上会感觉事情不太对：以往可能有的项目上的代码超过10w行，但领域模型却只有10多个，难道要把这些代码都放入这10多个类？</p>
<p>事实上，这正好是抽象不足的表现，也正是Smart Domain或者DDD希望解决的问题。正是由于我们不能把太多代码放入同一个类（过大的类是一种明显的反模式）这个原因，才<strong>促使我们想办法通过引入更多的抽象来解决问题</strong>。</p>
<p>如何引入新的抽象？一个典型的示例是DDD原书中提到的关于策略模式抽象的例子。</p>
<p>在航运领域建模的过程中，在处理货物超订时，如果没有抽象，可以直接在代码中加入一些条件判断代码来实现。这样的处理方式的结果就是某个模型或类中的代码越来越多，直至难以维护。</p>
<p>而仔细思考领域之后，可以发现：</p>
<blockquote>
<p>超订规则是一个策略。策略其实是一种设计模式，也就是我们所说的STRATEGY模式。</p>
</blockquote>
<p>可以看到，用策略模式来抽象可以很好的解决这个问题。这就是深入思考的结果。</p>
<p>除了可以用策略模式进行抽象，DDD书中提到的大多数常见模式都是可以使用的，比如<code>Factory</code>、<code>Repository</code>等。这些模式还包括设计模式中的组合模式、门面模式、解释器模式、观察者模式等等。</p>
<p>或许是大家在学习或者讲解DDD时过于关注了DDD引入的几个新的模式（如实体、值对象、聚合等），很多人都忽略了DDD中指出的要深入理解领域这个重点中的重点。</p>
<p>下面是Eric在书中语重心长的想要提醒大家的文字：</p>
<blockquote>
<p>通过像PCB示例这样的模型获得的知识远远不只是“发现名词”，业务活动和规则如同所涉 及的实体一样，都是领域的中心…当我们的建模不再局限于寻找实体和值对象时我们才能充分吸取知识…领域专家往往不会意识到他们的思考过程有多么复杂，协作消化知识的过程使得规则得以澄清和充实，并消除规则矛盾以及删除无用规则。</p>
</blockquote>
<h3 id="弱化分层强化领域划分"><a class="markdownIt-Anchor" href="#弱化分层强化领域划分"></a> 弱化分层，强化领域划分</h3>
<p>有人可能会问，上面例子中的策略模式相关的代码应该放在什么地方？当然是领域层！事实上Smart Domain的设计思想是根本不区分这些分层。这样一来，所有代码都是可以看作领域层代码（尽管有一些代码看作基础设施层可能更为合理），从而把尽量多的代码放在领域层，尽最大可能丰富领域层。</p>
<p>分层被弱化了，领域中的代码变多了，这正是DDD和Smart Domain所希望的结果。然而，随之而来的问题是如何管理这些代码。</p>
<p>很容易想到的答案是进行模块划分。事实上，DDD中有单独提到“模块”这一模式。<strong>进行模块划分时，应参考高内聚低耦合的原则</strong>，使得模块内是高内聚，模块间是低耦合的。</p>
<p>常见的不符合高内聚低耦合模块划分原则的一个反例是按照技术名称进行模块划分。比如，可以回顾一下我们维护过的代码库，是不是还记得里面有一些模块的名称是<code>controller</code> <code>requests</code> <code>responses</code> <code>dtos</code> <code>services</code>等等？当我们打开这些模块时，会发现里面的类其实没什么关系，而模块间的相互引用却非常多。</p>
<p>事实上，DDD中讲到了更多的关于广义的模块划分的内容。从整个源代码库的角度来看，源代码可以按照从小到大不同粒度划分为函数、类、模块、领域、服务等级别。DDD中讲到了如何在这些不同的层级进行划分。</p>
<p>在<strong>类级别</strong>，DDD原书中提到了<strong>Standalone Class</strong>模式。Standalone Class即独立的与其他类无关的类。这一模式其实是在说类级别的高内聚低耦合。</p>
<p>在类级别之上，DDD中提到了<strong>Aggregate</strong>模式。Aggretate即<strong>一组强相关的类</strong>形成的聚合。这一模式其实是在说一组类的高内聚低耦合。</p>
<p>在<strong>领域级别</strong>，DDD提到了<strong>领域划分</strong>。可以按照领域的职责，将领域划分为核心域、通用域、支撑域等领域。这一模式是在说领域的高内聚低耦合。</p>
<p>事实上，从完整的代码库的角度来看，可以很容易建立以下认知：</p>
<p>代码块构成一个范围，函数体构成一个范围，类构成一个范围，类所在的包构成了一个范围，包所在的库构成了一个范围。将范围当做领域来理解，可以认为这些领域按照不同的细节程度和抽象程度构成了一个类似森林的结构。而森林的每一层都应当是高内聚低耦合的。</p>
<p>关于以上内容的更多描述，欢迎参考我的另一篇博客<a href="/2019/08/08/domain-concept-in-your-code/">《代码中的领域》</a>。</p>
<h3 id="与传统的聚合相结合"><a class="markdownIt-Anchor" href="#与传统的聚合相结合"></a> 与传统的聚合相结合</h3>
<p>在Smart Domain的示例代码中，基于内存的抽象也通过关联实现，略显麻烦。比如：</p>
<ul>
<li>客户端需要调用好几个api才能把一个页面需要的数据拿到，不太方便</li>
<li>基于内存访问数据比基于关联对象访问更方便</li>
</ul>
<p>传统的DDD实现通过聚合（聚合根直接引用其他实体）来解决此问题。如果可以确定聚合中关联的其他实体数量不多，则也许还是可以考虑通过聚合的方式来实现。此时，直接通过一个Restful API一次性返回此聚合中的所有模型即可。</p>
<p>对于聚合根之间的引用，则仍然可以采用Smart Domain中的关联对象实现方式。</p>
<p>如此一来，可以结合两者的优势。这可能是实践过程中值得考虑的选择。</p>
<p>不过，混合两种模式对架构师可能不太友好。与其引入更多的选择，他们可能更希望推进项目中的架构一致性。实际项目中，可能要结合团队成员的能力来综合考虑如何选择。</p>
<h2 id="总结-2"><a class="markdownIt-Anchor" href="#总结-2"></a> 总结</h2>
<p>本文分析了Smart Domain的设计，尝试回答了为什么Smart Domain可以用于实现DDD。结合以往对DDD的学习和实践经验，分享了一些扩展的问题。希望对大家了解DDD和Smart Domain有一定帮助。</p>
<p>虽然Smart Domain作为一种设计范式，可以辅助我们实现DDD。但是具体到真实项目中，建模这个过程还得结合实际的领域问题。有哪些值得参考的案例呢？下一篇文章将做一些分享。</p>
]]></content>
      <categories>
        <category>敏捷</category>
        <category>架构</category>
        <category>DDD</category>
      </categories>
      <tags>
        <tag>架构</tag>
        <tag>DDD</tag>
        <tag>领域</tag>
      </tags>
  </entry>
  <entry>
    <title>DDD建模案例分享</title>
    <url>/2022/07/28/modelling-examples/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>前面的文章<a href="/2022/07/27/smart-domain-and-ddd/">《我理解的Smart Domain与DDD》</a>中，我们分析了 Smart Domain 的设计，尝试回答了为什么 Smart Domain 可以用于实现 DDD，并对Smart Domain和DDD进行了一些扩展性的讨论。</p>
<p>虽然 Smart Domain 作为一种设计范式，可以辅助我们实现 DDD。但是具体到真实项目中，建模这个过程还得结合实际的领域问题，深入思考，大量尝试，大声建模，才能得到好的模型。有哪些值得参考的案例呢？下面分享几个个人在项目中觉得还不错的建模实践。</p>
<span id="more"></span>
<h2 id="继承的应用"><a class="markdownIt-Anchor" href="#继承的应用"></a> 继承的应用</h2>
<p>作为面向对象编程范式三大关键特性之一的“继承”，如果使用得当，在实践中可以帮助我们更好的建模概念间的关系并有效避免重复代码。</p>
<h3 id="algorithm模型抽象"><a class="markdownIt-Anchor" href="#algorithm模型抽象"></a> Algorithm模型抽象</h3>
<p>我曾经经历过一个<strong>机器学习平台</strong>的项目，代码中有一个算法的概念。在没有有效建模之前，代码库中只有一个名为Algorithm的类，所有算法相关的信息均保存在这个类的属性上。项目中涉及到了几十个算法，都以数据的形式存储到了数据库。</p>
<p>表面上看，这一设计可以让我们更容易的添加算法（只需要增加数据即可）。但是，这带来的后果是大量的算法类型判断出现在代码库中。这是因为我们常常要对不同的算法进行不同的处理，比如在运行算法时需要为基于Tensorflow的深度学习算法和基于Spark的分布式学习选择不同的计算框架。</p>
<p>这一场景可以通过设计良好的一组有继承关系的类来表达（Algorithm基类，SparkAlgorithm/TensorflowAlgorithm抽象类，各个算法实现类），利用多态特性可以轻松避免这些条件判断代码。这一设计的另一大作用是将不太会变化的属性放入了代码而只将需要变化的属性放入数据库，从而很大程度上简化代码（大部分操作无需查询数据库）。关于此项目的更多内容请参考<a href="/2020/05/24/architecture-designing-practise-for-ml-platform-oop/">《机器学习平台架构实践 – 面向对象设计》</a>。</p>
<h3 id="backend模型抽象"><a class="markdownIt-Anchor" href="#backend模型抽象"></a> Backend模型抽象</h3>
<p>另一个项目是我们近期开源的名为<a href="https://github.com/easysql/easy_sql"><strong>Easy SQL</strong></a>的ETL开发语言项目。</p>
<p>为了同时支持不同的后端计算引擎，我们设计了一个抽象的<code>Backend</code>类型，针对<code>Spark</code>和<code>MaxCompute</code>分别提供了实现。</p>
<p>同时由于需要支持不同类型的常规的关系型数据库作为后端计算引擎，我们实现了一个<code>Rdb</code>的<code>Backend</code>，在<code>Rdb</code>的实现中，为了支持不同的方言，定义了一个名为<code>Dialect</code>的抽象接口，然后针对此接口提供了<code>PostgreSQL</code> <code>Clickhouse</code> <code>BigQuery</code>的实现。详情请参考这里的<a href="https://github.com/easysql/easy_sql/blob/main/easy_sql/sql_processor/backend/base.py">代码</a>。</p>
<h3 id="apply模型抽象"><a class="markdownIt-Anchor" href="#apply模型抽象"></a> Apply模型抽象</h3>
<p>还有一个<strong>为分布式服务创建中心化的权限管理</strong>应用。</p>
<p>在这个应用中有一个权限申请的概念。申请分为两种类型，一是对团队空间的权限申请，二是对发布数据的权限申请。这两种类型的申请存在相似性，比如审批流程相似，都有审批人等。但同时也存在诸多不同，比如，权限类型不同，团队空间可以有写权限，而发布的数据只有读权限。</p>
<p>遗憾的是，团队在进行模型设计时，只用了一个<code>Apply</code>类来表达申请的概念，并因此引入了多处对申请的资源的类型的判断。现在回想起来，如果可以用两个子类来表达不同的申请，结果可能会好不少。</p>
<h2 id="工厂模式的应用"><a class="markdownIt-Anchor" href="#工厂模式的应用"></a> 工厂模式的应用</h2>
<p>工厂模式是继承的好朋友。试想，有了继承树，如何创建对应的类呢？一般而言，还需要一个工厂方法来根据不同类型创建不同对象。在我经历过的很多建模实践中，很多情况下都会将“继承”和“工厂模式”搭配起来使用。</p>
<h3 id="算法工厂"><a class="markdownIt-Anchor" href="#算法工厂"></a> 算法工厂</h3>
<p>比如，在上面的机器学习平台中，由于有多种不同的算法构成的继承树，在通过用户的选择进行对象构建时，就可以使用工厂模式。不同的算法往往需要不同的参数及配置，这一做法可以有效的将参数选择逻辑集中起来管理。</p>
<h3 id="步骤工厂"><a class="markdownIt-Anchor" href="#步骤工厂"></a> 步骤工厂</h3>
<p>除了配合“继承”使用，如果某些对象的构造本身比较复杂，也可以考虑用工厂来进行抽象。比如，在<a href="https://github.com/easysql/easy_sql">Easy SQL</a>中，一个ETL被抽象为多个主要由SQL组成的步骤，在通过SQL文件来创建一组步骤的时候，就可以考虑用工厂模式实现。具体代码可以参考<a href="https://github.com/easysql/easy_sql/blob/main/easy_sql/sql_processor/step.py">这里</a>。</p>
<h2 id="有限状态机的应用"><a class="markdownIt-Anchor" href="#有限状态机的应用"></a> 有限状态机的应用</h2>
<p>在<strong>机器学习平台</strong>项目中，为了管理复杂的批处理任务的状态及其迁移路径，我们用到了有限状态机模式来进行抽象。</p>
<p>状态机定期获取任务的状态，在状态变化时进行记录，并根据启动时设置的任务状态转换处理器进行处理。</p>
<p>没有有限状态机抽象时，程序很多地方需要判断任务状态，并进行一定的逻辑处理。代码分散，很难理解。有了有限状态机的抽象之后，任务状态及状态迁移的处理器都被集中起来管理，从而变得直观、清晰且可控。</p>
<p>关于这个例子的更多内容可以参考之前的博客<a href="/2020/05/24/architecture-designing-practise-for-ml-platform-oop/">《机器学习平台架构实践 – 面向对象设计》</a>。</p>
<h2 id="其他设计模式的应用"><a class="markdownIt-Anchor" href="#其他设计模式的应用"></a> 其他设计模式的应用</h2>
<p>设计模式是针对某一类问题的通用解决方案。如果能在建模的时候有效使用设计模式，可以以一种大家都熟悉的方式解决问题并提升设计的质量。</p>
<p>其他很多设计模式都可以在建模阶段灵活选用。我们可以从很多架构设计或常用库的实现里面看到他们的影子。</p>
<p>Clean架构中的<code>Adapter</code>层，其实是用了适配器模式。</p>
<p>前端开发中，我们会添加很多交互事件处理器，这其实是观察者模式的应用。</p>
<p>后端开发中的<code>Filter</code>是职责链模式的应用。</p>
<p>Java标准库中的各类包装类型，如<code>Integer</code>, <code>Long</code>等在实现时使用了Flyweight享元模式。</p>
<p>在我们自己进行建模时，可以参考选用这些设计模式使用。不过在使用设计模式时，需要注意不要为了用设计模式而用设计模式，否则很容易过度设计。</p>
<h2 id="面向接口编程的应用"><a class="markdownIt-Anchor" href="#面向接口编程的应用"></a> 面向接口编程的应用</h2>
<p>面向接口编程是一种拥有强大抽象能力的编程范式。在Smart Domain示例中，关联对象以接口的形式定义在模型中，用于辅助实现依赖倒置。</p>
<h3 id="验证器"><a class="markdownIt-Anchor" href="#验证器"></a> 验证器</h3>
<p>另一个例子是验证器的实现。</p>
<p>在Web后端开发中，常常要对传入的参数进行严格的校验。很多校验需要跨属性进行。此时可以用自定义JSR的验证器来实现。</p>
<p>用面向接口编程的思想来实现这样的验证器，可以这样做：</p>
<p>1.定义一个验证器类<code>V</code>，其验证的注解为<code>VA</code>，验证目标对象为<code>VO</code><br />
2.在验证器类中定义内部注解接口<code>VA</code><br />
3.在验证器类中定义内部目标对象接口<code>VO</code><br />
4.在要验证的类<code>B</code>上加上<code>VA</code>注解，并实现<code>VO</code>接口</p>
<p>代码结构参考：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">V</span> <span class="keyword">implements</span> <span class="title class_">ConstraintValidator</span>&lt;V.VA, V.VO&gt; &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="meta">@interface</span> VA &#123; ... &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">VO</span> &#123; ... &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@V</span>.VA</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">B</span> <span class="keyword">implements</span> <span class="title class_">V</span>.VO &#123; ... &#125;</span><br></pre></td></tr></table></figure>
<p>一个具体的实例可以参考这里的<a href="https://github.com/gmlove/experiments/blob/master/java_validator/ValidatorTest.java">代码</a>。</p>
<p>这样做的好处是，<code>V</code>这个类变成了DDD原书中提到的Standalone Class，除了Java标准库依赖之外，没有任何其他依赖。这使得这个验证器非常容易被复用，因为它可被用于验证任何实现了<code>VO</code>接口的对象。</p>
<p>结合Spring这样的依赖注入框架使用，还可以通过构造器给验证器注入任意的其他组件，以便实现更复杂的验证功能。</p>
<p>从这个例子里，我们可以看到面向接口编程带来的强大抽象能力。</p>
<h3 id="tdd的应用"><a class="markdownIt-Anchor" href="#tdd的应用"></a> TDD的应用</h3>
<p>TDD对于改善设计有很大的帮助。</p>
<p>Eric在书中建议团队“大声”的建模，这实际上就是在强调我们人类的语言天赋。不同背景的人在讨论问题时，会很容易形成一种双方都可以理解的“混杂”语言。这是人类的天赋。通过交流和讨论，很多情况下，我们可以自然的找到一种合适的模型。</p>
<p>这跟TDD实践是一致的。在进行TDD时，我们会站在使用代码的角度进行解决方案的描述。在描述的过程中，可以充分发挥语言能力，让我们自然的得到一个良好的模型。</p>
<p>关于如何使用TDD来改善模型设计，我之前有几篇文章分享。列举如下，给大家参考：</p>
<ul>
<li><a href="/2019/07/20/tdd-for-improving-design/">《从改善设计的角度理解 TDD》</a></li>
<li><a href="/2019/08/18/tdd-for-improving-design-2/">《从改善设计的角度理解 TDD (2)》</a></li>
<li><a href="/2022/07/05/tdd-to-develop-a-long-running-task-system">《用TDD开发基于数据库的长时任务系统》</a></li>
<li><a href="/2022/05/24/5-properties-of-good-code-cupid/">《好代码的五个特质-CUPID》</a></li>
</ul>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>本文分享了一些建模的例子，从这些例子中可以看到，其实每个项目中都可以有很多可挖掘的内容，关键在于我们不能轻易满足提取“名词”，而是要深入思考直至深刻理解问题，大胆创新直至找到最恰当的抽象。</p>
<p>对于长期从事某一个特定领域的开发，如只做前端或只做后端的同学，我们可能需要去尝试练习一下端到端的应用设计和开发，以便于认识软件构建的全貌。这可能对于我们从软件整体去思考和建模有更大的帮助。可以按照软件技术发展脉络来设计自己的练习。一个推荐的路径是：简单命令行程序-&gt;客户端应用-&gt;前后端分离的Web应用-&gt;微服务。</p>
]]></content>
      <categories>
        <category>敏捷</category>
        <category>架构</category>
        <category>DDD</category>
      </categories>
      <tags>
        <tag>架构</tag>
        <tag>DDD</tag>
        <tag>领域</tag>
      </tags>
  </entry>
  <entry>
    <title>敏捷数据工程实践--以ETL为单位的CI和CD</title>
    <url>/2023/01/10/ade-ci-cd-per-etl/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>前几天，我在跟一位做进口贸易的朋友聊天，发现一个很有意思的事情。</p>
<p>他们做的是国内的高端仪器进口的进口贸易业务。主要帮助销售国外产品的公司完成竞标、合同签订、物流、海关、进口贸易政策符合、维保等等事务。</p>
<p>我很疑惑，为什么会有这样的业务形态存在？为什么这些产品销售公司不自己处理这些事务，反而代理出去让其他公司赚钱呢？</p>
<span id="more"></span>
<p>我带着这个疑问，向他请教，获得了很多启发。</p>
<p>众所周知，国内的工业起步较晚，虽然这些年突飞猛进成为了世界工厂，但是核心的生产设备很多还是依赖进口。比如在生产芯片时少不了光刻机，在环境、食品、农业等实验室进行的样本成分分析也少不了可以分析各元素浓度的原子光谱仪。这个市场是一个万亿级的大市场。</p>
<p>这个业务有什么特点呢？</p>
<p>一是产品销售数量少。高端仪器一般售价都比较高，普遍在几十万到数百万。所以，一个年营业额在十亿的仪器产品公司其实也只是销售了数百台仪器而已。</p>
<p>二是销售流程特别复杂。由于是物理设备进口，将涉及很多现实的问题，除了产品推广和销售，还有一系列的事务，比如竞标、合同签订、物流、海关、进口贸易政策符合、维保等等，非常复杂。</p>
<p>作为一个在国内销售进口设备的企业，要如何组织其业务呢？</p>
<p>推广和销售是自不必说，否则市场根本不了解产品，就更别谈卖出去了。</p>
<p>但是，销售之外的其他事务要不要自己来做？这个就值得思考了。因为产品销售数量不会太大，但是销售之外的事务却特别复杂而繁多。如果培养一个专业的团队做这件事，由于产品销量不大，团队工作势必不会饱和。如果减少团队人员数量，这些事务又难以做得专业，容易出纰漏。</p>
<p>在经过大量的市场尝试和调整之后，专门做对进口贸易易的企业就诞生了。他们负责产品销售之外的大部分事务，涉及竞标、合同签订、物流、海关、进口贸易政策符合、税收、维保方式设计等。他们常常是一个非常专业的团队，可负责各个领域不同产品的进口贸易业务。在某些品类销售淡季时，其他品类可能又到销售旺季了。所以，他们的业务通常也能保持稳定和饱和。</p>
<p>于是，海外产品研发公司+国内产品销售公司+国内进口贸易公司的模式就在市场上慢慢形成并稳定下来了。总结起来，可以用下图简单地描述这三个企业如何愉快地合作完成整个产品进口销售的过程。</p>
<p><img data-src="/attaches/2023/2023-01-10-ade-ci-cd-per-etl/import-trade.png" alt="Import trade" /></p>
<p>进口贸易企业业务的兴起对整个行业效率和质量的提升都起到了正面的效果，这也是进口贸易企业得以存在的理由。</p>
<p>和这位朋友的交流完之后，我发现进口贸易企业业务的形成给了我不少启发。</p>
<p>从进口贸易企业的兴起中可以看到业务的重构和演变，即，通过合理的<strong>抽取</strong>和<strong>拆分</strong>提升了整体的效率。</p>
<h2 id="以etl为单位的持续集成"><a class="markdownIt-Anchor" href="#以etl为单位的持续集成"></a> 以ETL为单位的持续集成</h2>
<p>我联想到了近几天一直在思考的数据应用开发中的持续集成流水线设计。</p>
<p>在应用软件开发中，我们常常仅设计一条持续集成流水线，在流水线中运行所有的测试，接着将所有代码打包成一个大的产品包，然后部署到测试或产品环境中。</p>
<p>在数据应用中，是不是也需要这样做呢？这样做的好处是可以将产品环境的制品与代码仓库中的版本对应。其劣势其实也很多，比如，修改一个局部的代码，就不得不运行所有的测试，然后运行流水线中所有耗时的步骤，可能还需要进入手工测试的环节，最后才能发布到线上。效率非常低下。</p>
<p>这一问题在数据应用中更是被放大了。因为数据应用通常涉及数百个指标计算ETL，这些ETL的自动化测试只能用缓慢的集成测试来覆盖，这就导致流水线中的测试步骤耗时很长。在我们的项目中，常常需要跑半小时到一小时才能跑完。</p>
<p>这就如同做进口高端仪器销售的公司，如果自己来做进口贸易相关业务，不仅耗时特别长，而且出纰漏的可能性大（业务质量低）。</p>
<p>有没有更好的做法？既然只修改了某一个ETL，为什么不能就只部署和测试这个ETL？联想到前面进口贸易业务的抽取和拆分，是不是可以对流水线进行抽取和拆分呢？即，做<strong>以ETL为单位的持续集成流水线</strong>。</p>
<p>在数据应用开发场景中，这也是具备可行性的。原因在于，相比应用软件代码中的一个一个类或代码文件，ETL间几乎没有依赖。不同的ETL代码通常有不同的入口，存在于一个独立的文件。可以认为一个ETL就是一个独立的数据应用。</p>
<p>事实上，如果以ETL为单位进行持续集成和部署，还不用担心自己的部署会影响到其他的线上指标计算ETL，这也在一定程度上增强了安全性。</p>
<p>看起来，在数据应用开发领域，以ETL为单位的持续集是顺理成章的事。</p>
<p>对比一下微服务实践，还可以发现，这一实践与微服务中推荐的为每一个服务搭建一条持续集成流水线的实践几乎是等同的。</p>
<h2 id="如何实现"><a class="markdownIt-Anchor" href="#如何实现"></a> 如何实现</h2>
<p>如何实现以ETL为单位的持续集成呢？</p>
<p>如果基于Jenkins，可以在流水线上面加一个参数，如“ETL文件路径”，在运行流水线时，可以指定这个参数，让流水线仅针对指定的ETL运行测试与部署。</p>
<p>如果觉得在Jenkins上面实施以ETL为单位的持续集成较为麻烦，也可以团队自主开发一个专用的数据持续集成流水线。如果仅实现基本的功能，其实也并不复杂。</p>
<p>需要注意的是，一旦以ETL为单位进行持续集成了，就需要有一种方式记录每一个ETL对应的代码仓库里面的版本号，方便版本追溯。实现方式有多种，比如，可以在部署ETL的时候，在生产环境写入一个该ETL对应的版本文件。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>如果采用应用软件持续流水线的大包发布方式构建数据应用的持续集成流水线，将降低部署频率，且容易引起安全问题。借鉴进口贸易业务的抽取和拆分模式，在数据应用开发中，将持续集成流水线拆分为以ETL为单位的流水线可以有效解决上述问题。</p>
]]></content>
      <categories>
        <category>敏捷</category>
        <category>数据</category>
      </categories>
      <tags>
        <tag>敏捷</tag>
        <tag>数据</tag>
        <tag>数据工程</tag>
        <tag>软件工程</tag>
        <tag>数据开发</tag>
      </tags>
  </entry>
  <entry>
    <title>微信中的智能助手--WeChatGPT</title>
    <url>/2023/03/26/wechatgpt/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>ChatGPT刚刚开放API，价格低到没朋友。抛开背后的商业运作，这本身对人类的进步是很大的贡献。</p>
<p>可惜ChatGPT国内的网络环境让大家没法很容易的体验到最新的人工智能成果。</p>
<p>本人利用业余时间，搭建了一个简单的开源项目，可以帮助大家快速的基于微信公众号搭建自己的ChatGPT智能助理。</p>
<p>先上几个聊天截图，大家先睹为快。</p>
<span id="more"></span>
<p><img data-src="/attaches/2023/2023-03-26-wechatgpt/1.png" alt="Chat 1" /><br />
<img data-src="/attaches/2023/2023-03-26-wechatgpt/2.png" alt="Chat 2" /></p>
<h2 id="为什么需要本项目"><a class="markdownIt-Anchor" href="#为什么需要本项目"></a> 为什么需要本项目</h2>
<p>为什么 OpenAI 开放了网页版本的聊天功能之后，还需要一个基于微信公众号的版本？主要原因是：</p>
<ul>
<li>国内网络无法直接访问</li>
<li>网页版本体验较差，无法在任意时刻任意地点有手机就能用</li>
</ul>
<p>微信作为一个广泛使用的专业的聊天软件，是智能助手的理想载体。</p>
<h2 id="项目的初衷和目的"><a class="markdownIt-Anchor" href="#项目的初衷和目的"></a> 项目的初衷和目的</h2>
<p>项目的目标是提供一套可用的代码及尽可能简单完善的步骤，帮助一般开发人员通过几步操作就能搭建自己的微信智能助理。</p>
<p>本项目不会致力于让代码具备高性能和支持高并发，因为出于个人用途（或者小的团体，比如家庭），这些特性是没必要的，只能白白的增加复杂度。</p>
<p>（如果希望基于此项目，搭建并发布自己的对外公共服务，出现的一切问题，请自行负责。）</p>
<h2 id="使用教程"><a class="markdownIt-Anchor" href="#使用教程"></a> 使用教程</h2>
<p>借助云服务的能力及微信的免费开放服务，可以零成本搭建一个智能助手。</p>
<p>主要需要完成以下几步：</p>
<ul>
<li>注册 aws 云服务账号，并启动虚拟机</li>
<li>注册 OpenAI 开发者账号，获取 token</li>
<li>注册微信公众号</li>
<li>配置微信公众号自动回复</li>
<li>部署此服务</li>
</ul>
<p>完成上述步骤需要具备一定的技术基础，熟练的同学应该可以很快搞定。具体操作就不详述了，请大家移步<a href="https://github.com/gmlove/wechatgpt">GitHub</a>参考。</p>
<h2 id="功能说明"><a class="markdownIt-Anchor" href="#功能说明"></a> 功能说明</h2>
<h3 id="基本功能"><a class="markdownIt-Anchor" href="#基本功能"></a> 基本功能</h3>
<ul>
<li>微信消息签名验证及接口集成</li>
<li>调用 OpenAI 的 API 发起聊天</li>
<li>聊天会话管理</li>
<li>多人同时独立对话互不影响</li>
<li>处理微信公众号 API 返回时间限制</li>
<li>在对话太长时，提示会开启新的对话</li>
<li>定期清理聊天会话</li>
<li>记录基本聊天统计信息</li>
<li>获取微信 ID：发送消息&quot;My ID&quot;或者&quot;我的微信 ID&quot;可获取微信 ID（用于辅助管理此服务）</li>
</ul>
<h3 id="管理功能"><a class="markdownIt-Anchor" href="#管理功能"></a> 管理功能</h3>
<p>项目支持管理员用户通过微信公众号消息管理服务。目前支持的管理功能包括：对话权限管理、对话次数限制、获取对话统计等。</p>
<p>当前一共定义了以下几类管理命令：</p>
<ul>
<li><code>add_white_list</code>: 添加白名单用户。参数为用户的微信 OpenID，可从日志中或通过基本功能中的“获取微信 ID”功能获取。</li>
<li><code>remove_white_list</code>: 移除白名单用户。参数为用户的微信 OpenID，可从日志中或通过基本功能中的“获取微信 ID”功能获取。</li>
<li><code>set_limit</code>: 设置用户对话次数限制。参数为用户的微信 OpenID 及每日对话次数限制，以逗号分隔，如 <code>user_a,100</code>表示限制 OpenID 为<code>user_a</code>的用户的每天对话次数为 100 次。</li>
<li><code>set_token</code>: 设置管理员 <code>token</code>。参数为新的 <code>token</code> 值。</li>
<li><code>get_config</code>: 获取配置。无参数，可将参数行设置为 1。</li>
<li><code>get_stat</code>: 获取对话统计。无参数，可将参数行设置为 1。<br />
调用命令的方式是通过微信公众号发特定格式的消息。</li>
</ul>
<p>消息格式如下（消息必须包含三行）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">admin-command:&#123;YOUR_ADMIN_TOKEN&#125;</span><br><span class="line">&#123;COMAND_NAME&#125;</span><br><span class="line">&#123;COMMAND_ARGS&#125;</span><br></pre></td></tr></table></figure>
<h3 id="规划中的功能"><a class="markdownIt-Anchor" href="#规划中的功能"></a> 规划中的功能</h3>
<ul>
<li>处理用户发送的图片消息</li>
<li>配置公众号关注消息</li>
<li>消息加解密</li>
<li>更多的管理接口</li>
<li>持久化消息存储</li>
<li>让用户配置模型参数</li>
</ul>
<h2 id="试用"><a class="markdownIt-Anchor" href="#试用"></a> 试用</h2>
<p>如果想直接体验，可以在以下公众号发起聊天（看不到图片的同学请微信搜索：Bright 技术 人生）：</p>
<img data-src="/attaches/2023/2023-03-26-wechatgpt/wechat-account.png" width="300">
<p><strong>注意</strong>：以上公众号系个人微信公众号，使用 OpenAI 的免费额度，每人每天只能对话 20 次。详见项目代码默认设置。后续可能限制更加严格。如果对本人公众号内容感兴趣，欢迎关注。否则，请试用后取关，以免受可能的消息打扰。</p>
]]></content>
      <categories>
        <category>machine-learning</category>
        <category>ChatGPT</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>机器学习</tag>
        <tag>ML</tag>
        <tag>ChatGPT</tag>
      </tags>
  </entry>
  <entry>
    <title>程序员眼中的ChatGPT</title>
    <url>/2023/04/12/chatgpt-from-programmer-point-of-view/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>作为一个一直对AI技术很感兴趣的软件开发工程师，早在深度学习开始火起来的15、16年，我也开始了相关技术的学习。当时还组织了公司内部同样有兴趣的同学一起研究，最终的成果汇集成几次社区中的分享以及几篇学习文章（见<a href="https://brightliao.com/tags/ai/">这里</a>）。</p>
<p>从去年OpenAI发布ChatGPT以来，AI的能力再次惊艳了世人。在这样的一个时间节点，重新去学习相关技术显得很有必要。</p>
<p>ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。</p>
<p>ChatGPT本身就具备很丰富的知识，所以ChatGPT自身实际上就是一个很好的学习渠道，我也将借助ChatGPT来学习ChatGPT。</p>
<p>这是此系列的第一篇，程序员眼中的ChatGPT。</p>
<span id="more"></span>
<h2 id="什么是chatgpt"><a class="markdownIt-Anchor" href="#什么是chatgpt"></a> 什么是ChatGPT</h2>
<p>网络上已经有铺天盖地的内容介绍ChatGPT是什么了。总结起来，有以下几个关于ChatGPT的认知：</p>
<ul>
<li>ChatGPT是由OpenAI开发的一个用于对话生成的AI模型</li>
<li>GPT是&quot;Generative Pre-trained Transformer&quot;的缩写，表示它是一个经过预训练的生成式Transformer模型</li>
<li>ChatGPT学习了大规模的文本内容，如互联网上的网页、书籍和对话等，能够准确理解输入的自然语言，并生成自然而连贯的回复</li>
<li>可用于构建智能聊天机器人、虚拟助手、虚拟客服等应用，可以帮助我们写文章、写剧本、做设计，甚至还能辅助编写和调试程序</li>
<li>ChatGPT的计算过程非常复杂，包含了超过千亿的参数，需要用大量的显卡并行计算</li>
</ul>
<p>这些内容，相信大家已经了解得足够多了，在这里我们就不详述了。</p>
<p>那么，对于开发人员而言，ChatGPT有哪些不一样的特征呢？如何与我们所熟悉的东西对比进行理解呢？下面主要从这个角度来分享一下我的观点。</p>
<h2 id="确定性与非确定性"><a class="markdownIt-Anchor" href="#确定性与非确定性"></a> 确定性与非确定性</h2>
<p>从普通开发人员的视角来看，ChatGPT与普通的程序会有什么不同呢？我觉得最大的不同在于确定性与非确定性。</p>
<p>我们编写的大部分可运行的软件程序以一种确定性的方式在工作。比如，这篇文章以Markdown格式编写，有一个程序，可以以一种确定的方式解析Markdown格式，并以一种确定的方式展示它。</p>
<p>ChatGPT模型就很不一样，它更多是以一种概率性的非确定的方式在工作。我们都知道自然语言本身就是充满不确定性的。比如，同样一句话“他这个人谁都看不上”，可能表示“他”很挑剔，看不上别人；也可能表示“他”能力比较差，大家都看不起他。到底表示什么意义？这就要根据不同的上下文、情境来确定。</p>
<p>ChatGPT模型可以较为准确的理解自然语言的含义，这说明它可以综合分析输入给它的文本，然后选择一个概率最高的理解。</p>
<p>同时，ChatGPT模型可以生成不同的回复，这也是由概率控制的。ChatGPT模型在工作时会根据给定的文本生成下一个词。如何选定下一个词？程序会根据配置随机的选择一个较高概率的词，由于这里的随机性，就产生了AI回复的多样性。如果我们在生成下一个词时始终选择概率最高的那个词，那ChatGPT模型就会变成一个确定性的程序。</p>
<h2 id="自动优化得来的一个复杂函数"><a class="markdownIt-Anchor" href="#自动优化得来的一个复杂函数"></a> 自动优化得来的一个复杂函数</h2>
<p>从开发人员的视角来看，ChatGPT其实也可以看做一个普通的函数，根据输入的文本，输出另一些文本。只不过，这个函数能实现的功能比较强大，并且是基于概率去实现的而已。</p>
<p>在这个函数的实现上，它与其他的主要通过开发人员编写代码去实现的方式也不一样。ChatGPT模型与其他的AI模型一样，它是通过训练来实现的。</p>
<p>简单来说，它的实现流程是这样。为了实现这个函数，我们随机初始化了一堆参数，然后准备好大量的我们认为这个函数应该具有的输入输出对（即训练数据集），用这些数据去训练它。训练的过程其实就是调整我们之前随机初始化的参数的过程。当这些参数经过长时间的大量的调整之后，我们发现这个函数大概率能针对我们提供的输入返回我们预期的输出了。此时，实际上这个函数就被以一种概率的方式实现了。</p>
<p>调整参数的过程，也可以类比高中数学中的方程组求解过程。比如，给一个包含两个未知数的方程<code>ax + by = c</code>，只要我们知道两组<code>a b c</code>的值，我们就可以求解出<code>x</code>和<code>y</code>。这里的训练就相当于找到了大量的这样的<code>a b c</code>值对，然后用这些值去求解<code>x</code>和<code>y</code>。不过，这里的求解过程实际上用到了一些基于向量的微积分的技术。</p>
<h2 id="难以理解的黑盒"><a class="markdownIt-Anchor" href="#难以理解的黑盒"></a> 难以理解的黑盒</h2>
<p>有了前面的理解，相信大家也不会觉得ChatGPT是什么神秘的技术了。它只是与我们平常的函数的实现机制稍微有些区别而已。</p>
<p>或许我们会觉得用这种参数优化的方式去实现复杂函数的机制很有趣，也很有启发意义。但其实这种实现方式也有其问题。</p>
<p>最大的问题或许在于，我们难以理解这个函数为什么可以工作。</p>
<p>这一方面是因为函数包含了大规模的参数，特别是ChatGPT这种大模型，比如ChatGPT3.5版本，就包含了1750亿个参数。这么多的参数显然无法依靠人为的去分析每一个参数的作用。</p>
<p>另一方面，我们也不知道这些参数是如何计算来的。因为参数的调整过程同样是经过了超长的时间，有超大规模的输入输出对给到它。我们只能从数学原理上说明，这些参数可以最终收敛到某一个靠近最优值的点。但是我们无法去分析每一次的优化具体产生了什么影响。</p>
<p>可以说，这样的AI模型，或者说智能函数，本身就是一个难以理解的黑盒。</p>
<p>既然难以理解，我们在使用上就需要小心，因为它很可能一直表现很好，但是某一个场景下就出现无法预料的很差的效果。这也是目前的人工智能技术让人觉得很炫酷，但在真正落地应用时，总是有这样那样的问题的一个重要原因。</p>
<p>实际上，如果我们问ChatGPT，ChatGPT模型在应用上有哪些挑战，它就会回复：</p>
<blockquote>
<p>ChatGPT具有令人振奋的潜力，但也面临着一些挑战和限制。例如，它可能会生成不准确或不符合预期的回复，以及对偏见和敏感话题的处理问题。</p>
</blockquote>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>有了上面的理解，大家再来看ChatGPT，我相信大家也不会觉得它很神秘了。</p>
<p>自ChatGPT发布以来，很多人认为这是一个人类走向通用人工智能的突破，也有一些人认为它其实没什么本质的改进。有很多人对自己的职业发展产生了很深的焦虑感，也有很多人感觉触碰到了科幻世界中的未来，还有很多人觉得又是一个可以好好捞一把的机会。</p>
<p>也许每个人都有必要去了解一下机器学习技术的原理，这样才能形成对它的理性的认知。</p>
<p>ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。</p>
<p>这是此系列的第一篇，程序员眼中的ChatGPT。</p>
]]></content>
      <categories>
        <category>machine-learning</category>
        <category>ChatGPT</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>机器学习</tag>
        <tag>ML</tag>
        <tag>ChatGPT</tag>
      </tags>
  </entry>
  <entry>
    <title>ChatGPT使用的技术概览</title>
    <url>/2023/04/25/chatgpt-a-technical-summary/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>作为一个一直对AI技术很感兴趣的软件开发工程师，早在深度学习开始火起来的15、16年，我也开始了相关技术的学习。当时还组织了公司内部同样有兴趣的同学一起研究，最终的成果汇集成几次社区中的分享以及几篇学习文章（见<a href="https://brightliao.com/tags/ai/">这里</a>）。</p>
<p>从去年OpenAI发布ChatGPT以来，AI的能力再次惊艳了世人。在这样的一个时间节点，重新去学习相关技术显得很有必要。</p>
<p>ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。</p>
<p>ChatGPT本身就具备很丰富的知识，所以ChatGPT自身实际上就是一个很好的学习渠道，我也将借助ChatGPT来学习ChatGPT。</p>
<p>这是此系列的第二篇，ChatGPT使用的技术概览。</p>
<span id="more"></span>
<p><a href="https://brightliao.com/2023/04/12/chatgpt-from-programmer-point-of-view/">上一篇</a>文章我们聊到了开发人员对于ChatGPT的认知。本文来聊一聊ChatGPT用到的机器学习技术。</p>
<h2 id="机器学习技术的发展"><a class="markdownIt-Anchor" href="#机器学习技术的发展"></a> 机器学习技术的发展</h2>
<p>要聊ChatGPT用到的机器学习技术，我们不得不回顾一下机器学习技术的发展。因为，ChatGPT用到的技术不是完全从零的发明，它也是站在巨人的肩膀上发展起来的。</p>
<h3 id="机器学习技术的分类"><a class="markdownIt-Anchor" href="#机器学习技术的分类"></a> 机器学习技术的分类</h3>
<p>实际上机器学习技术可以追溯到上个世纪三四十年代，一开始就与统计学分不开。早在1936年，著名的统计学家Fisher发明了线性判别分析方法（LDA）。LDA利用方差分析的思想，试图将高维数据分开。这后来演化为一类基础的机器学习技术任务，即分类问题。</p>
<p>在计算机出现之后，大量的基于计算机的机器学习算法出现，比如决策树、SVM、随机森林、朴素贝叶斯、逻辑回归等。它们也都可以用于解决分类问题。</p>
<p>分类问题是指我们事先知道要分为哪几类，这些类通常是人为定义的。比如人分为男性和女性，编程语言分为c/c++/java等。</p>
<p>还有一类问题是我们无法预先知道要分为几类的，比如给定一系列的新闻，按照主题进行分组，而我们可能无法事先人为的确定好有几个主题。此时可以利用机器学习算法自动去发现新闻中有几个类，然后再把不同的新闻放到不同的分类。这种问题是聚类问题。</p>
<p>有时，这个分类可能是连续的，比如，我们要用一个机器学习模型去预测某个人的身高，此时可以认为结果是在某一个范围内连续变化的值。这类问题，我们把它叫做回归问题。与分类的问题的区别仅仅在于我们希望输出一个连续的值。</p>
<p>除此之外，一些典型的机器学习问题还包括：降维、强化学习（通过智能体与环境的交互来学习最佳行动策略）等。</p>
<p>除了根据问题不同进行分类，还可以从机器学习技术使用数据的方式进行分类。从这个角度可以将机器学习技术分为有监督学习、无监督学习、半监督学习等。有监督学习要求我们为模型准备好标签值。无监督学习则无需我们准备标签值，只需数据即可开始训练。半监督学习是指需要一部分有标签值的数据。</p>
<p>从解决的问题上来看，ChatGPT可以认为是一个分类模型，它根据输入的文本预测下一个要输出的词是什么，而词的范围是确定的，即模型的输出是一个确定的分类。</p>
<p>从ChatGPT使用数据的方式来看，可以认为是使用了大量的无监督数据，加上少量的有监督的数据。所以，可以认为ChatGPT是一个半监督的机器学习技术。</p>
<h3 id="传统的机器学习算法与基于人工神经网络的机器学习算法"><a class="markdownIt-Anchor" href="#传统的机器学习算法与基于人工神经网络的机器学习算法"></a> 传统的机器学习算法与基于人工神经网络的机器学习算法</h3>
<p>上面提到的决策树、SVM、随机森林、朴素贝叶斯、逻辑回归等算法，多是基于可验证的可理解的统计学知识设计的算法。它们的局限性主要在于效果比较有限，即便使用海量数据也无法继续提升，这要归因于这些模型都是相对简单的模型。由于这些算法都是很早就被开发出来了，并且一直很稳定，没有什么更新，我们一般称这些算法为传统的机器学习算法。</p>
<p>另一类机器学习算法是基于人工神经网络的机器学习算法。这一类算法试图模拟人类的神经网络结构。其起源也很早，要追溯到1943年，W. S. McCulloch和W. Pitts提出的M-P模型。该模型根据生物神经元的结构和工作机理构造了一个简化的数学模型，如下图。</p>
<p><img data-src="/attaches/2023/2023-04-25-chatgpt-a-technical-summary/mp-model.jpeg" alt="M-P model" /></p>
<p>其中，xi代表神经元的第i个输入，权值wi为输入xi对神经元不同突触强度的表征，θ代表神经元的兴奋阀值，y表示神经元的输出，其值的正和负，分别代表神经元的兴奋和抑制。</p>
<p>该模型的数学公式可以表示为： 𝑦=∑𝑤𝑖*𝑥𝑖−𝜃 ，如果所有输入之和大于阀值θ则y值为正，神经元激活，否则神经元抑制。该模型作为人工神经网络研究的最简模型，一直沿用至今。</p>
<p>虽然这个模型看起来很简单，但是由于其可扩展可堆叠的特性，实际上可以用于构造一个非常复杂的网络。至于如何扩展和堆叠，其实就是人工神经网络数十年的发展要解决的问题。</p>
<p>这个模型如何优化呢？这里的优化其实就是修改wi的值，依靠一种名为反向传播的优化方式可以优化它。其计算过程，相当于对wi求偏导数，然后和学习率相乘再加回到原来的wi值上。</p>
<p>人工神经网络模型的算法思想非常简单，其效果只有在网络规模达到一定程度之后才会体现出来。但是一旦网络形成规模之后，对算力和数据的要求就非常高了。这也是为什么在21世纪之前这样的算法无法获得发展的原因。</p>
<p>从2000年开始，互联网进入了爆发式发展的阶段，大量的数据被累积起来，并且计算机算力也经历了数十个摩尔周期得到了长足的发展。于是基于人工神经网络的机器学习算法得到爆发式的发展。</p>
<p>各个研究领域都纷纷开始尝试利用人工神经网络来提升机器学习模型效果。</p>
<p>卷积神经网络（一种基于M-P模型的变种结构）在计算机视觉领域表现突出，逐渐演变为计算机视觉领域的基础结构。循环神经网络和长短期记忆网络（另一种基于M-P模型的变种结构）在自然语言处理领域表现突出，逐渐演变为自然语言处理领域的基础结构。</p>
<p>这两类网络结构曾经风靡一时，即便到现在也有很多问题是基于这两类结构的网络算法去解决的。它们在很大程度上促进了人工神经网络的机器学习算法的发展。</p>
<p>但是，研究人员从未停止对于网络结构的探索。在2017年的时候，Google的研究团队提出了一个名为Transformer的网络结构，强调了注意力机制在网络结构中的表示和应用。Transformer模型结构简单而一致，却表现出了非常好的效果。</p>
<p>ChatGPT的故事可以认为从这里开始了。在Transformer模型结构发布之后，后续有大量的研究基于Transformer开展起来，都取得了很好的效果，这里面就包括各类GPT模型。</p>
<p>最初的Transformer模型主要是应用在自然语言处理领域。近两年的研究发现，这一结构也可以被用到计算机视觉认为上，当前流行的Vision Transformer模型就是它在计算机视觉领域的应用成果。从这个趋势来看，Transformer有着要统一所有模型结构的势头。</p>
<h2 id="chatgpt技术概览"><a class="markdownIt-Anchor" href="#chatgpt技术概览"></a> ChatGPT技术概览</h2>
<p>有了前面的了解，终于轮到ChatGPT出场了。</p>
<p>ChatGPT用到了哪些技术呢？可以简要列举如下：</p>
<ul>
<li>基础模型结构：基于注意力机制的Transformer模型</li>
<li>超大规模的模型堆叠：GPT3堆叠了96层网络，参数数量高达1750亿</li>
<li>超大的训练数据：采用了45TB的原始数据进行训练</li>
<li>超大的计算资源：基于微软专门设计的包含数千块GPU的超级计算机完成训练</li>
<li>大规模并行训练：将模型分布到多个实例，多块GPU上并行计算完成训练</li>
<li>基于人类反馈数据进行调优：采用了大量的基于人类反馈的数据进行优化，使得对话更加自然、流畅而具有逻辑性</li>
</ul>
<p>由于OpenAI并未公布太多的ChatGPT的训练细节，所以，上述有一些模糊的估计数据。</p>
<p>值得注意的是，ChatGPT用到的核心技术其实并非原创，其核心模型结构Transformer来自于Google的研究成果。</p>
<p>这里只是列举了ChatGPT用到的技术，后面的内容我们将结合开源的代码示例，从原理上深入解构这些技术，敬请期待。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>自ChatGPT发布以来，很多人认为这是一个人类走向通用人工智能的突破，也有一些人认为它其实没什么本质的改进。有很多人对自己的职业发展产生了很深的焦虑感，也有很多人感觉触碰到了科幻世界中的未来，还有很多人觉得又是一个可以好好捞一把的机会。</p>
<p>也许每个人都有必要去了解一下机器学习技术的原理，这样才能形成对它的理性的认知。</p>
<p>ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。</p>
<p>这是此系列的第二篇，ChatGPT使用的技术概览。</p>
<h2 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h2>
<ul>
<li>wikipedia词条罗纳德·艾尔默·费希尔：<a href="https://zh.wikipedia.org/zh-sg/%E7%BE%85%E7%B4%8D%E5%BE%B7%C2%B7%E6%84%9B%E7%88%BE%E9%BB%98%C2%B7%E8%B2%BB%E9%9B%AA">https://zh.wikipedia.org/zh-sg/羅納德·愛爾默·費雪</a></li>
<li>人工智能与神经网络发展研究：<a href="https://image.hanspub.org/Html/2-1540922_23773.htm">https://image.hanspub.org/Html/2-1540922_23773.htm</a></li>
<li>OpenAI开发的ChatGPT资料（Training language models to follow instructions<br />
with human feedback）： <a href="https://arxiv.org/pdf/2203.02155.pdf">https://arxiv.org/pdf/2203.02155.pdf</a></li>
<li>OpenAI开放的GPT-3资料（Language Models are Few-Shot Learners）: <a href="https://arxiv.org/pdf/2005.14165.pdf">https://arxiv.org/pdf/2005.14165.pdf</a></li>
<li>OpenAI开放的GPT-2资料（Language Models are Unsupervised Multitask Learners）: <a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf">https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf</a></li>
<li>OpenAI开放的GPT资料（Improving Language Understanding by Generative Pre-Training): <a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf</a></li>
</ul>
<!-- 
简介：
ChatGPT用到的技术包括：基于注意力机制的Transformer模型；超大规模的模型堆叠；超大的训练数据；超大的计算资源；大规模并行训练；基于人类反馈数据进行调优。本文尝试简要介绍一下这些技术的来龙去脉。
-->
]]></content>
      <categories>
        <category>machine-learning</category>
        <category>ChatGPT</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>机器学习</tag>
        <tag>ML</tag>
        <tag>ChatGPT</tag>
      </tags>
  </entry>
  <entry>
    <title>ChatGPT的模型训练</title>
    <url>/2023/05/20/chatgpt-training/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>作为一个一直对AI技术很感兴趣的软件开发工程师，早在深度学习开始火起来的15、16年，我也开始了相关技术的学习。当时还组织了公司内部同样有兴趣的同学一起研究，最终的成果汇集成几次社区中的分享以及几篇学习文章（见<a href="https://brightliao.com/tags/ai/">这里</a>）。</p>
<p>从去年OpenAI发布ChatGPT以来，AI的能力再次惊艳了世人。在这样的一个时间节点，重新去学习相关技术显得很有必要。</p>
<p>ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。</p>
<p>ChatGPT本身就具备很丰富的知识，所以ChatGPT自身实际上就是一个很好的学习渠道，我也将借助ChatGPT来学习ChatGPT。</p>
<p>这是此系列的第四篇，ChatGPT的模型训练。</p>
<span id="more"></span>
<p><a href="https://brightliao.com/2023/05/18/2023-05-18-chatgpt-transformer/">上一篇</a>文章我们深入分析了ChatGPT使用到的Transformer模型。了解了其最核心的模型结构是Transformer结构，本文来聊一聊ChatGPT如何训练。</p>
<h2 id="介绍"><a class="markdownIt-Anchor" href="#介绍"></a> 介绍</h2>
<p>ChatGPT只在论文中有一些原理的解释，并没有公布代码。因此，为了弄清楚ChatGPT是如何训练的，我们只能从开源的类ChatGPT模型入手。目前，我们能看到ChatGPT的开源平替主要是来自斯坦福大学的<a href="https://github.com/tatsu-lab/stanford_alpaca">Alpaca</a>模型及伯克利大学的<a href="https://github.com/lm-sys/FastChat">Vicuna</a>模型。其中，当使用GPT-4来评估模型效果时，Vicuna模型的效果达到了ChatGPT的90%。这说明这些开源平替模型的正确性和有效性。</p>
<p>Alpaca模型及Vicuna模型都是基于Meta发布的LLaMA模型进行微调的。LLaMA的训练使用了大量的数据，并花费了大量的计算资源。</p>
<p>因此本文尝试帮助大家弄清楚这些开源模型的训练。当我们了解了这些开源模型的训练时，应该也能对ChatGPT的模型训练有了一个基本的了解了。</p>
<h2 id="训练过程"><a class="markdownIt-Anchor" href="#训练过程"></a> 训练过程</h2>
<p>从ChatGPT公布的论文内容来看，有三个训练阶段：1. 无监督预训练 2. 监督微调 3. 指令微调。</p>
<p><strong>无监督预训练</strong>是指直接使用大规模的文本数据作为输入来构建数据集，其输出就是当前文本中的下一个词。比如，文本“无监督训练”，可以拆分为如下几个训练样本：</p>
<ul>
<li>输入“无”，让模型预测“监督”</li>
<li>输入“无监督”让模型预测“训练”</li>
</ul>
<p>通过采集互联网上的大规模文本，可以构造一个超大规模的数据集用于无监督预训练。</p>
<p><strong>监督微调</strong>是指在输入文本中放入具体的任务信息，让模型尝试预测答案。比如，对于一个中文翻译为英文的任务可以构建训练样本如下（假定要翻译的文本为“无监督训练”）：</p>
<ul>
<li>输入“翻译文本为英文：无监督训练。译文：”，让模型输出“Non-supervised”</li>
<li>输入“翻译文本为英文：无监督训练。译文：Non-supervised”，让模型输出“training”</li>
</ul>
<p>监督微调阶段可以使用大量的当前NLP研究中的训练数据集。比如：</p>
<ul>
<li>常识推理数据集，如BoolQ、PIQA、SIQA、OpenBookQA等</li>
<li>闭卷问答数据集，如Natural Questions、TriviaQA等</li>
</ul>
<p>监督微调阶段使用了一些自然语言问答的模板，但是如果对话没有使用这样的模板，模型的效果就会大打折扣。于是为了训练一个ChatGPT这样的通用的模型，就需要更普适的问答模板。这就是<strong>指令微调</strong>阶段的作用。</p>
<p>从OpenAI开放的论文资料来看，指令微调采用了强化学习的方案。分成三个步骤完成：</p>
<p><img data-src="/attaches/2023/2023-05-20-chatgpt-training/instruct-gpt.png" alt="Instruct GPT" /></p>
<ul>
<li>第一步：从测试用户提交的问答中随机抽取数据，让专业的标注人员给出高质量的答案，并使用这些数据优化模型。</li>
<li>第二步：使用前面的模型生成N个不同的回答，让专业的标注人员对回答的质量进行排序，并使用这些数据训练一个奖励模型。</li>
<li>第三步：利用前面训练好的奖励模型，无需人工标注，通过强化学习的方式自动更新模型参数。</li>
</ul>
<p>这一阶段，通过让模型接受更广泛的自然语言回答任务，模型具备了回答通用问题的能力。</p>
<p>分析上述三个阶段，可以发现第三阶段用到的强化学习训练相对较为复杂，且需要大量人类的参与，目前开源替代并不多，由HPC-AI开源的<a href="https://github.com/hpcaitech/ColossalAI">ColossalChat</a>算是较为完善的一个。</p>
<p>上述提到的这些开源模型分别完成的阶段如下：</p>
<ul>
<li>LLaMA模型：利用开放的数据集完成了第一阶段和第二阶段</li>
<li>Alpaca、Vicuna模型：基于LLaMA，利用基于ChatGPT生成的指令数据，完成了第三阶段的第一步</li>
<li>ColossalChat：完成了完整的三个阶段</li>
</ul>
<h2 id="模型训练代码"><a class="markdownIt-Anchor" href="#模型训练代码"></a> 模型训练代码</h2>
<p>下面基于上述提到的三个模型分析一下模型的训练代码。</p>
<p>LLaMA的官方代码库中只有模型的结构及推理的代码，而没有包含训练的代码。虽然Meta的论文中提到了是如何训练的，但还是没有像可运行的代码这样包含所有细节。</p>
<p>Alpaca、Vicuna、ColossalChat模型作为开源可训练的模型，有完整的训练代码和脚本，我们主要基于它们来研究一下模型是如何训练的。</p>
<p>一般的机器学习模型训练主要包括三部分：定义模型结构、定义损失函数、准备训练数据。下面主要围绕这三部分来分析ChatGPT类模型是如何训练的。</p>
<h3 id="数据生成"><a class="markdownIt-Anchor" href="#数据生成"></a> 数据生成</h3>
<p>根据前文对训练过程的介绍，训练数据只需要组织成一系列的问答对即可。</p>
<p>从Alpaca的<a href="https://github.com/tatsu-lab/stanford_alpaca/tree/main">官方Github代码仓库</a>中的文档可以了解到，Alpaca用到了一种名为Self-Instruct的机制来生成数据。其原理是：</p>
<ol>
<li>定义一些种子任务</li>
<li>借助OpenAI发布的模型来生成具备多样性的指令任务</li>
<li>借助OpenAI的模型生成这些任务的回复</li>
</ol>
<p>以下是来自<a href="https://github.com/yizhongw/self-instruct">Self-Instruct的官方代码仓库</a>的数据生成流程图。其中Alpaca简化了分类任务和非分类任务，将其合成了同一类问答任务。</p>
<p><img data-src="/attaches/2023/2023-05-20-chatgpt-training/self-instruct.jpeg" alt="Self Instruct" /></p>
<p>下面是一些样例数据：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Give three tips for staying healthy.&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \n2. Exercise regularly to keep your body active and strong. \n3. Get enough sleep and maintain a consistent sleep schedule.&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;What are the three primary colors?&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;The three primary colors are red, blue, and yellow.&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    ...</span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>
<p>Vicuna的模型效果比Alpaca好不少，而且很好的支持了多语言。它的秘诀在于其训练数据与Alpaca通过Self-Instruct的机制生成的数据不一样，质量要高很多。Vicuna的数据来源于 <a href="http://ShareGPT.com">ShareGPT.com</a> 网站上大家分享的与ChatGPT聊天的数据。</p>
<p>ColossalChat模型的性能也可以与ChatGPT比肩（信息来自代码仓库中的<a href="https://medium.com/pytorch/colossalchat-an-open-source-solution-for-cloning-chatgpt-with-a-complete-rlhf-pipeline-5edf08fb538b">博客</a>），它的训练数据来源于<a href="https://github.com/XueFuzhao/InstructionWild">InstructionWild</a>，这个数据集基于从Twitter获取的700个基础任务，然后采用与Alpaca类似的机制从OpenAI获取更多样性的任务及回复。</p>
<h3 id="微调部分训练代码"><a class="markdownIt-Anchor" href="#微调部分训练代码"></a> 微调部分训练代码</h3>
<p>阅读Alpaca和Vicuna的训练代码，可以发现训练代码非常短，主要是调用了transformers库中的Trainer类来完成训练。</p>
<p>所以，要了解训练过程的代码，我们需要阅读一下transformers代码库中的相应代码。</p>
<p><a href="https://github.com/huggingface/transformers">Transformers</a> 是 Huggingface 打造的一个开源库。提供了数以千计的预训练模型，支持 100 多种语言的文本分类、信息抽取、问答、摘要、翻译、文本生成。其宗旨是为最先进的 NLP 技术提供易用性。 Transformers 提供了便于快速下载和使用的API，让你可以把预训练模型用在给定文本、在你的数据集上微调然后通过 model hub 与社区共享。同时，每个定义的 Python 模块均完全独立，方便修改和快速研究实验。（来自官方介绍）</p>
<p>由于Alpaca和Vicuna采用LLaMA作为基础模型，我们主要关注LLaMA相关的代码。源代码在<a href="https://github.com/huggingface/transformers/tree/main/src/transformers/models/llama">这个目录</a>下。</p>
<p>模型的核心代码在<a href="https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/modeling_llama.py">这里</a>，虽然Transformers库中的实现与Meta发布的源代码有所区别，但都是基于PyTorch库，并且模型结构是一致的，就不赘述了（想了解细节的请回顾<a href="%5B%E4%B8%8A%E4%B8%80%E7%AF%87%5D(https://brightliao.com/2023/05/18/2023-05-18-chatgpt-transformer/)">上一篇</a>）。 下面分析一下与模型训练相关的核心代码。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LlamaForCausalLM</span>(<span class="title class_ inherited__">LlamaPreTrainedModel</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, config</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(config)</span><br><span class="line">        <span class="comment"># 根据配置初始化LLaMA模型，此模型的结构与Meta发布的LLaMA一致，除了不包含最后一层</span></span><br><span class="line">        self.model = LlamaModel(config)</span><br><span class="line">        <span class="comment"># 定义最后一层全连接层</span></span><br><span class="line">        self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=<span class="literal">False</span>)</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">...</span>):</span><br><span class="line">        <span class="comment"># 从LLaMA的模型获取预测的结果，并取最后一个Transformer块的计算结果</span></span><br><span class="line">        outputs = self.model(...)</span><br><span class="line">        hidden_states = outputs[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算模型输出</span></span><br><span class="line">        logits = self.lm_head(hidden_states)</span><br><span class="line"></span><br><span class="line">        loss = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> labels <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 取预测结果的前N-1个，使预测的下一个词与标签词对应。</span></span><br><span class="line">            shift_logits = logits[..., :-<span class="number">1</span>, :].contiguous()</span><br><span class="line">            <span class="comment"># 取标签数据的后N-1个，使预测的下一个词与标签词对应。</span></span><br><span class="line">            shift_labels = labels[..., <span class="number">1</span>:].contiguous()</span><br><span class="line">            <span class="comment"># 创建交叉熵损失，用于计算模型预测结果与标签之间的差异。</span></span><br><span class="line">            loss_fct = CrossEntropyLoss()</span><br><span class="line">            <span class="comment"># 将预测结果和标签进行形状变换，展平为二维张量。第一个维度为样本的数量，第二个维度为词汇表的大小。</span></span><br><span class="line">            shift_logits = shift_logits.view(-<span class="number">1</span>, self.config.vocab_size)</span><br><span class="line">            shift_labels = shift_labels.view(-<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 计算损失</span></span><br><span class="line">            loss = loss_fct(shift_logits, shift_labels)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> CausalLMOutputWithPast(loss=loss, logits=logits, ...)</span><br></pre></td></tr></table></figure>
<p>上述对齐过程，可以举例解释如下：</p>
<ul>
<li>假设有一个句子作为输入文本序列：I love eating，模型将预测下一个词是什么。</li>
<li>在这个例子中，预测结果序列为<code>love eating</code>，标签序列<code>I love eating</code>也应该调整为与预测序列一致。</li>
<li>通过取预测结果的前N-1个及标签数据的后N-1个，就可以将logits与标签数据对齐。</li>
</ul>
<p>可以看到这里的训练代码其实非常简单，使用最常见的基于概率的交叉熵损失即可实现损失定义。至于反向传播过程，PyTorch已经为我们实现了，训练时程序可以自动计算梯度，我们无需实现反向传播的过程。</p>
<h3 id="强化学习部分训练代码"><a class="markdownIt-Anchor" href="#强化学习部分训练代码"></a> 强化学习部分训练代码</h3>
<p>下面来分析一下由ColossalAI实现的指令微调阶段的模型及代码。根据上面的分析，指令微调阶段分为三个步骤完成：1. 与第二阶段相同的监督微调； 2. 训练一个奖励模型；3. 训练一个强化学习模型。</p>
<h4 id="监督微调"><a class="markdownIt-Anchor" href="#监督微调"></a> 监督微调</h4>
<p>看起来第一步骤的代码与Alpaca和Vicuna的代码应该是一样的，不过ColossalAI为了支持在单卡上面做训练，采用了Lora的方式进行监督微调。</p>
<p>Lora是一种少量参数模型微调的方法，由微软于2021年提出。其基本的思想是：</p>
<ol>
<li>冻结所有原来的大模型参数</li>
<li>对某些层（一般是线性变换层）的参数，采用两个小矩阵合成一个与原参数大小一样的大矩阵（如采用一个10x2的矩阵A和一个2X10的矩阵B，两者的矩阵乘积就可以得到一个10x10的大矩阵C）</li>
<li>计算时（前向计算），参数的值采用原参数矩阵加上合成矩阵的值作为最终参数矩阵的值</li>
<li>微调时（反向传播），只更新上述小矩阵的参数</li>
</ol>
<p>具体代码在<a href="https://github.com/hpcaitech/ColossalAI/blob/main/applications/Chat/examples/train_sft.py">这里</a>，以下是核心逻辑。（ColossalAI由于支持了多个模型，其代码比较长，以下是单独看LLaMA模型的简化后的代码。）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">args</span>):</span><br><span class="line">    strategy = ColossalAIStrategy(stage=<span class="number">2</span>, placement_policy=<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">    <span class="keyword">with</span> strategy.model_init_context():</span><br><span class="line">        <span class="comment"># 将transformers库中的LlamaForCausalLM模型转化为Lora模型</span></span><br><span class="line">        model = convert_to_lora_module(LlamaForCausalLM.from_pretrained(args.pretrain), args.lora_rank)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 准备分词器</span></span><br><span class="line">    tokenizer = AutoTokenizer.from_pretrained(args.pretrain, padding_side=<span class="string">&quot;right&quot;</span>, ...)</span><br><span class="line">    tokenizer = prepare_llama_tokenizer_and_embedding(tokenizer, model)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 准备优化器</span></span><br><span class="line">    optim = HybridAdam(model.parameters(), lr=args.lr, clipping_norm=<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 准备数据集</span></span><br><span class="line">    train_dataset = SFTDataset(train_data, tokenizer, max_len)</span><br><span class="line">    eval_dataset = SFTDataset(eval_data, tokenizer, max_len)</span><br><span class="line">    train_dataloader = DataLoader(train_dataset, ...)</span><br><span class="line">    eval_dataloader = DataLoader(eval_dataset, ...)</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># 构造训练器并开始训练</span></span><br><span class="line">    (model, optim) = strategy.prepare((model, optim))</span><br><span class="line">    trainer = SFTTrainer(model=model, ...)</span><br><span class="line">    trainer.fit(...)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SFTTrainer</span>:</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, ...</span>):</span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(self.max_epochs):</span><br><span class="line">            <span class="comment"># 设置模型为训练模式</span></span><br><span class="line">            self.model.train()</span><br><span class="line">            <span class="comment"># 对数据集里面的每一个批次进行训练</span></span><br><span class="line">            <span class="keyword">for</span> batch_id, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.train_dataloader):</span><br><span class="line">                <span class="comment"># 执行模型前向计算</span></span><br><span class="line">                outputs = self.model(batch[<span class="string">&quot;input_ids&quot;</span>], batch[<span class="string">&quot;attention_mask&quot;</span>], batch[<span class="string">&quot;labels&quot;</span>])</span><br><span class="line">                <span class="comment"># 下面的代码采用了一种累计梯度的机制，可以让模型在批太小的场景下也能较为稳定的更新</span></span><br><span class="line">                <span class="comment"># 每次计算梯度时，将损失平均一下，再计算梯度</span></span><br><span class="line">                loss = outputs.loss</span><br><span class="line">                loss = loss / self.accumulation_steps</span><br><span class="line">                <span class="comment"># 计算梯度</span></span><br><span class="line">                self.strategy.backward(loss, self.model, self.optimizer)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 当达到定义的累计批次数时更新参数并将梯度置零</span></span><br><span class="line">                <span class="keyword">if</span> (batch_id + <span class="number">1</span>) % self.accumulation_steps == <span class="number">0</span>:</span><br><span class="line">                    self.strategy.optimizer_step(self.optimizer)  <span class="comment"># 更新参数</span></span><br><span class="line">                    self.optimizer.zero_grad()  <span class="comment"># 梯度置零</span></span><br><span class="line">                    self.scheduler.step()  <span class="comment"># 对学习率进行调整</span></span><br></pre></td></tr></table></figure>
<p>可以看到，上述代码中ColossalAI还贴心的采用了一种累计梯度的机制来支持小批微调。这是因为想要在少量的GPU资源上微调大模型，批大小不能设置太大，否则显存无法支持。关于累计梯度详细的解释，可以参考<a href="https://zhuanlan.zhihu.com/p/595716023">这里</a>。</p>
<h4 id="奖励模型"><a class="markdownIt-Anchor" href="#奖励模型"></a> 奖励模型</h4>
<p>第二个步骤是定义并训练一个奖励模型，此模型可以判断哪些回复更好。ColossalAI依然基于大语言模型，并采用Lora微调，来实现这个奖励模型。</p>
<p>具体代码在<a href="https://github.com/hpcaitech/ColossalAI/blob/main/applications/Chat/examples/train_reward_model.py">这里</a>，以下是核心逻辑。（ColossalAI由于支持了多个模型，其代码比较长，以下是单独看LLaMA模型的简化后的代码。）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">args</span>):</span><br><span class="line">    strategy = ColossalAIStrategy(stage=<span class="number">2</span>, placement_policy=<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">    <span class="keyword">with</span> strategy.model_init_context():</span><br><span class="line">        <span class="comment"># 定义基于LLaMA的奖励模型</span></span><br><span class="line">        model = LlamaRM(pretrained=args.pretrain, lora_rank=args.lora_rank)</span><br><span class="line">    <span class="comment"># 以下代码与监督微调部分类似</span></span><br><span class="line">    tokenizer = LlamaTokenizer.from_pretrained(args.pretrain)</span><br><span class="line">    tokenizer = prepare_llama_tokenizer_and_embedding(tokenizer, model)</span><br><span class="line">    optim = HybridAdam(model.parameters(), lr=<span class="number">5e-6</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义LogSig损失，LogSig损失是OpenAI在论文Training language models to follow instructions with human feedback中定义的损失函数</span></span><br><span class="line">    loss_fn = LogSigLoss()</span><br><span class="line"></span><br><span class="line">    data = load_dataset(args.dataset)</span><br><span class="line">    train_dataset = RmStaticDataset(data[<span class="string">&#x27;train&#x27;</span>], tokenizer, ...)</span><br><span class="line">    valid_dataset = RmStaticDataset(data[<span class="string">&#x27;test&#x27;</span>], tokenizer, ...)</span><br><span class="line">    train_dataloader = DataLoader(train_dataset, ...)</span><br><span class="line">    eval_dataloader = DataLoader(eval_dataset, ...)</span><br><span class="line"></span><br><span class="line">    (model, optim) = strategy.prepare((model, optim))</span><br><span class="line">    trainer = RewardModelTrainer(model=model, ...)</span><br><span class="line">    trainer.fit()</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LogSigLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, chosen_reward: torch.Tensor, reject_reward: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="comment"># 根据OpenAI在论文中的损失计算公式计算损失，见下文的分析</span></span><br><span class="line">        probs = torch.sigmoid(chosen_reward - reject_reward)</span><br><span class="line">        log_probs = torch.log(probs)</span><br><span class="line">        loss = -log_probs.mean()</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RewardModel</span>(<span class="title class_ inherited__">LoRAModule</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ...</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># 转换为Lora模型，以便支持少量参数微调</span></span><br><span class="line">        self.convert_to_lora()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, sequences: torch.LongTensor, attention_mask: <span class="type">Optional</span>[torch.Tensor] = <span class="literal">None</span></span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="comment"># 转换为Lora模型，以便支持少量参数微调</span></span><br><span class="line">        outputs = self.model(sequences, attention_mask=attention_mask)</span><br><span class="line">        last_hidden_states = outputs[<span class="string">&#x27;last_hidden_state&#x27;</span>]</span><br><span class="line">        values = self.value_head(last_hidden_states)[:, :-<span class="number">1</span>]</span><br><span class="line">        value = values.mean(dim=<span class="number">1</span>).squeeze(<span class="number">1</span>)    <span class="comment"># ensure shape is (B)</span></span><br><span class="line">        <span class="keyword">return</span> value</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LlamaRM</span>(<span class="title class_ inherited__">RewardModel</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ...</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># 从预训练模型文件中加载LLaMA的基础模型，使用transformers库的实现，无最后一个线性层</span></span><br><span class="line">        model = LlamaModel.from_pretrained(pretrained)</span><br><span class="line">        <span class="comment"># 定义线性最后层，输出维度为1，即一个数值型的奖励值</span></span><br><span class="line">        value_head = nn.Linear(model.config.hidden_size, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>参考Huggingface上面的数据集，可了解到训练奖励模型用到的数据示例为：</p>
<ul>
<li><strong>prompt (string)</strong>: Human: I am trying to write a fairy tale. What is the most popular plot? Assistant: The … Human: The … Assistant:</li>
<li><strong>response (string)</strong>: This sounds like a really interesting modern retelling of the story!</li>
<li><strong>chosen (string)</strong>: This sounds like a really interesting modern retelling of the story!</li>
<li><strong>rejected (string)</strong>: And the prince and the princess both decide that they are more powerful together than apart?</li>
</ul>
<p>通过上面的分析，可以知道，奖励模型可以为每一个回复生成一个奖励值。这个奖励值就可以用于训练强化学习模型了。</p>
<p>对于奖励模型的训练，OpenAI论文原文解释如下：</p>
<blockquote>
<p>RM是在一个包含两个模型输出之间比较的数据集上进行训练的。他们使用交叉熵损失，将比较结果作为标签，而奖励之间的差异表示了一个人类标注者更喜欢其中一个回答的对数几率。为了加快比较收集的速度，我们向标注者展示了K = 4至K = 9个回答供其进行排名。这为每个提示产生了K²个比较。由于每个标注任务中的比较非常相关，我们发现，如果我们简单地将比较混洗到一个数据集中，对数据集进行一次遍历就会导致奖励模型过拟合（如果将每个可能的K²个比较视为单独的数据点，那么每个完成将可能被用于K-1个独立的梯度更新。模型往往在一个epoch后出现过拟合，因此在一个epoch内重复数据也会导致它出现过拟合）。相反，我们将每个提示的所有K²个比较作为单个批次元素进行训练。这样做在计算上更加高效，因为每个完成（completion）只需要一次RM的前向传播（而不是K个完成需要K²次前向传播），并且由于不再过拟合，验证准确度和对数损失都有显著提升。</p>
</blockquote>
<p>损失计算公式为：</p>
<p><img data-src="/attaches/2023/2023-05-20-chatgpt-training/rm.png" alt="Loss of Reward Model" /></p>
<blockquote>
<p>其中，rθ(x, y)是奖励模型对于提示x和完成y的标量输出，具有参数θ；yw是在yw和yl这一对完成中更受青睐的完成；D是人类比较的数据集。<br />
最后，由于奖励模型的损失对于奖励的偏移是不变的，我们使用偏置对奖励模型进行归一化，以使标注者的演示在进行强化学习之前获得平均得分为0。</p>
</blockquote>
<h4 id="强化学习模型"><a class="markdownIt-Anchor" href="#强化学习模型"></a> 强化学习模型</h4>
<p>强化学习模型是最为复杂的部分，涉及很多新的知识点，限于篇幅，待下一篇继续分析。</p>
<p>不过，事实上基于前面的监督微调部分及奖励模型部分代码，我们似乎已经能窥探到强化学习部分的内容了。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>到这里，我们就分析完了ChatGPT类模型的训练和微调代码。在分析代码时，我们有意忽略了很多细节及模型并行处理的部分代码，这些对于我们理解模型帮助不大。</p>
<p>自ChatGPT发布以来，很多人认为这是一个人类走向通用人工智能的突破，也有一些人认为它其实没什么本质的改进。有很多人对自己的职业发展产生了很深的焦虑感，也有很多人感觉触碰到了科幻世界中的未来，还有很多人觉得又是一个可以好好捞一把的机会。</p>
<p>也许每个人都有必要去了解一下机器学习技术的原理，这样才能形成对它的理性的认知。</p>
<p>ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。</p>
<p>这是此系列的第四篇，ChatGPT的模型训练。</p>
<h2 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h2>
<ul>
<li>alpaca博客介绍：<a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">https://crfm.stanford.edu/2023/03/13/alpaca.html</a></li>
<li>LLAMA Paper：<a href="https://arxiv.org/abs/2302.13971v1">https://arxiv.org/abs/2302.13971v1</a></li>
<li>Self-Instruct: Aligning Language Model with Self Generated Instructions：<a href="https://arxiv.org/abs/2212.10560">https://arxiv.org/abs/2212.10560</a></li>
<li>Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality: <a href="https://lmsys.org/blog/2023-03-30-vicuna/">https://lmsys.org/blog/2023-03-30-vicuna/</a></li>
<li>OpenAI开发的ChatGPT资料（Training language models to follow instructions<br />
with human feedback）： <a href="https://arxiv.org/pdf/2203.02155.pdf">https://arxiv.org/pdf/2203.02155.pdf</a></li>
<li>OpenAI开放的GPT-3资料（Language Models are Few-Shot Learners）: <a href="https://arxiv.org/pdf/2005.14165.pdf">https://arxiv.org/pdf/2005.14165.pdf</a></li>
<li>OpenAI开放的GPT-2资料（Language Models are Unsupervised Multitask Learners）: <a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf">https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf</a></li>
<li>OpenAI开放的GPT资料（Improving Language Understanding by Generative Pre-Training): <a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf</a></li>
<li>梯度累加：<a href="https://zhuanlan.zhihu.com/p/595716023">https://zhuanlan.zhihu.com/p/595716023</a></li>
</ul>
]]></content>
      <categories>
        <category>machine-learning</category>
        <category>ChatGPT</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>机器学习</tag>
        <tag>ML</tag>
        <tag>ChatGPT</tag>
      </tags>
  </entry>
  <entry>
    <title>突破ChatGPT的知识限制</title>
    <url>/2023/06/02/chatgpt-long-context/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>作为一个一直对AI技术很感兴趣的软件开发工程师，早在深度学习开始火起来的15、16年，我也开始了相关技术的学习。当时还组织了公司内部同样有兴趣的同学一起研究，最终的成果汇集成几次社区中的分享以及几篇学习文章（见<a href="https://brightliao.com/tags/ai/">这里</a>）。</p>
<p>从去年OpenAI发布ChatGPT以来，AI的能力再次惊艳了世人。在这样的一个时间节点，重新去学习相关技术显得很有必要。</p>
<p>ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。</p>
<p>ChatGPT本身就具备很丰富的知识，所以ChatGPT自身实际上就是一个很好的学习渠道，我也将借助ChatGPT来学习ChatGPT。</p>
<p>这是此系列的第六篇，突破ChatGPT的知识限制。</p>
<p><img data-src="/attaches/2023/2023-06-02-chatgpt-long-context/content.png" alt="文章内容" /></p>
<span id="more"></span>
<h2 id="chatgpt的局限性"><a class="markdownIt-Anchor" href="#chatgpt的局限性"></a> ChatGPT的局限性</h2>
<p><a href="https://brightliao.com/2023/05/25/2023-05-25-chatgpt-rlhf/">上一篇</a>文章我们深入分析了ChatGPT如何结合奖励模型和强化学习算法进行自动优化。 OpenAI开放ChatGPT模型给大家使用，随着大家使用越多，产生的对话就越多，ChatGPT就能自动优化得更智能。</p>
<p>虽然ChatGPT能力很强，但是其局限性也很明显，对于没有纳入训练数据的知识它是不知道的，从而也没法给出我们期望的回复。但由于我们的日常工作往往要基于大量的ChatGPT不知道的背景知识进行判断和决策，所以很多场景我们也没法简单的通过向ChatGPT提问来得到想要的答案。</p>
<p>如何突破ChatGPT的知识限制，让ChatGPT具备更强大的能力，以便可以更好的辅助我们完成工作？这就是本文想要讨论的问题。</p>
<h2 id="扩充chatgpt的知识的方法"><a class="markdownIt-Anchor" href="#扩充chatgpt的知识的方法"></a> 扩充ChatGPT的知识的方法</h2>
<h3 id="基础模型优化"><a class="markdownIt-Anchor" href="#基础模型优化"></a> 基础模型优化</h3>
<p>如何让ChatGPT认知到这些复杂的背景知识？最简单的想法是把这些知识整理成文本，制作成数据集，然后让ChatGPT进行模型优化。</p>
<p>如何优化呢？前面ChatGPT模型训练内容我们分析了ChatGPT类模型的训练过程，分为三个阶段：基础语言模型训练、监督微调及指令微调。其中监督微调及指令微调阶段的数据量小，主要是解决模型的指令跟随问题。如果想在ChatGPT之上加入背景知识，看起来应该在基础语言模型训练阶段实施。</p>
<p>进行基础语言模型调优理论上是可行的，但是实践时会遇到很多问题。比如：</p>
<ul>
<li>如果新数据中存在错误、噪音或不准确的信息，将可能对模型的性能产生负面影响</li>
<li>使用这些新数据进行训练时，必须要非常小心的调整学习率，否则可能让ChatGPT遗忘之前学习到的通用知识，变得更笨</li>
<li>基础模型优化可能会影响第二和第三阶段的优化结果，使得ChatGPT没法很好的进行问答</li>
<li>模型本身太大，进行模型调优需要的计算资源更大，以目前的算力成本来看，很难负担得起</li>
</ul>
<p>目前来看，这一方法的可操作性不强。当然，在将来某一天，模型优化到一定程度，或者算力成本降低到一定程度时，也许这一方案也变得可行了。</p>
<h3 id="长上下文支持"><a class="markdownIt-Anchor" href="#长上下文支持"></a> 长上下文支持</h3>
<p>另一种扩充ChatGPT知识的方案是想办法增加模型的上下文支持能力。模型支持的上下文越长，表示我们可以输入给模型的内容越多，从而可以让ChatGPT基于更多的背景知识回答问题。</p>
<p>目前ChatGPT可以支持的上下文长度为4k或16k，而GPT-4支持的上下文长度为8k或32k（参考<a href="https://openai.com/pricing">这里</a>）。</p>
<p>从前面文章对于ChatGPT原理的分析来看，要想将上下文变长并不是一件容易的事。主要的挑战有：</p>
<ul>
<li><strong>显存消耗增长</strong>：由于计算自注意力结果时需要计算并保存所有上下文计算出来的中间结果，增加上下文长度会导致模型需要更多的显存来存储这些中间计算结果。</li>
<li><strong>计算复杂度增加</strong>：随着上下文长度的增加，每一个训练样本的计算复杂度都会增加，计算时间和计算资源的需求也会增加。</li>
<li><strong>长期依赖问题</strong>：更长的上下文导致信息在序列中的传播路径更长，这可能导致模型难以捕捉到远距离的依赖关系。</li>
</ul>
<p>然而，最重要的可能是并没有如此高质量的数据集供模型训练。特别是针对监督微调及指令微调阶段的数据集。</p>
<p>有很多分析和研究表明（参考<a href="https://juejin.cn/post/7249173717751087164">这里</a>），如果模型在4k上下文的数据集上面训练，是很难直接让它支持超过4k长度上下文的。具体表现就是模型性能严重下降。这就是所谓的<strong>模型的上下文长度外推能力</strong>。</p>
<p>目前有一些方法来增强模型的外推能力，如文章<a href="https://juejin.cn/post/7249173717751087164">《语言大模型100K上下文窗口的秘诀》</a>中提到的有：</p>
<ul>
<li><strong>ALiBi位置编码</strong>: 分两个阶段进行训练，首先在2K个词元的上下文长度上训练基本模型，然后在更长的上下文（例如65K）上进行微调。对于网络模型，则移除位置正弦嵌入，采用线性偏置注意力代替（通过附加一个与当前词元距离具有比例关系的惩罚来修正查询出来的注意力分数）。</li>
<li><strong>稀疏注意力机制</strong>：基于并非所有长上下文内容都是相互关联的这一假设，在计算注意力分数时仅考虑部分词元，具体实现有<a href="https://paperswithcode.com/method/sliding-window-attention">滑动窗口技术</a>、<a href="https://arxiv.org/abs/2007.14062">BigBird</a>等</li>
<li><strong>FlashAttention</strong>：在GPU的注意力层实现时，采用IO更高效的优化手段，以便可以支持快速训练与预测</li>
<li><strong>多查询注意力</strong>：优化模型中间结果缓存，在推理过程中能够显著加快增量注意力分数的计算</li>
</ul>
<p>最近的很多模型更新显示业界大家都在尝试实现更长的上下文支持。如：</p>
<ul>
<li>Anthropic在5.11日发布新的Cloude模型，表示支持100K上下文</li>
<li>OpenAI也在近期更新了GPT-3.5及GPT-4模型的上下文长度支持，分别从4K增加到16K和从8K增加到32K</li>
<li>国内清华系近期开源的ChatGLM2-6B模型的上下文长度从2K扩展到了32K</li>
</ul>
<p>显然，这已经是大模型开发厂商们正在努力的方向。</p>
<h3 id="基于文档搜索的知识扩充"><a class="markdownIt-Anchor" href="#基于文档搜索的知识扩充"></a> 基于文档搜索的知识扩充</h3>
<p>长上下文固然可以提高模型的背景知识，但在企业应用中，我们往往拥有海量的背景知识，全部依靠长上下文还是显得力不从心。</p>
<p>为了支持海量背景知识，可以对比参考我们人类解决问题的方法。一种常见的步骤是：</p>
<ol>
<li>查找相关文档，进行大量调研</li>
<li>汇总各类信息形成基本的解决方案</li>
<li>执行</li>
</ol>
<p>可以发现，即便人类所具有的背景知识也是有限的，人类也可以很好的解决问题。这是因为人可以主动的去查找相关信息，然后汇总形成方案。</p>
<p>这一思路就是基于搜索的思路，它是目前可操作性更强的方案。</p>
<p>在ChatGPT类的模型中应用搜索机制就变成：</p>
<ol>
<li>将所有知识文档搜集起来，然后拆分为小的文档，比如一篇文档2000字</li>
<li>对每一篇2000字的小文档进行向量化（采用大语言模型将其编码为向量，并使得这个向量与可能的问题具备较高的相关度），然后存储起来</li>
<li>在用户提出一个问题之后，将问题采用相同的方式编码为向量</li>
<li>将问题对应的向量与所有知识小文档向量计算相关度，选出相关度最大的几个文档</li>
<li>将这些选中的小文档提取出来，构造一个提示语传给大语言模型，让大语言模型根据这些上下文回答问题</li>
</ol>
<p><img data-src="/attaches/2023/2023-06-02-chatgpt-long-context/langchain-chatglm.png" alt="ChatGPT文档查询，图片来自：https://github.com/imClumsyPanda/langchain-ChatGLM" /></p>
<p>目前有很多开源库支持以这样的方式来扩充ChatGPT类模型的知识。比如<a href="https://gpt-index.readthedocs.io/en/latest/">LlamaIndex</a>、<a href="https://docs.langchain.com/docs/use-cases/qa-docs">LangChain</a>等。</p>
<p>它们的主要特点是：</p>
<ol>
<li>支持很多直接可用的经过验证文档向量化模型（如OpenAI的<a href="https://platform.openai.com/docs/guides/embeddings/embedding-models">Ada模型</a>、基于LLAMA的各类开源模型等）</li>
<li>提供多种方式实现上述第4步中的相关文档查找，比如基于向量存储库、基于树索引等</li>
<li>提供了一些常见的小文档使用模式及对应的上述第5步中的提示语，比如直接组合小文档的方式，基于每个小文档一步一步优化答案的方式，并行基于每个小文档生成回复然后一次性组合的方式等，详见<a href="https://python.langchain.com/docs/modules/chains/document/">这里</a></li>
</ol>
<p>一个简单的用LangChain实现的用例只需要几行代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.embeddings.openai <span class="keyword">import</span> OpenAIEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain.vectorstores <span class="keyword">import</span> Chroma</span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> CharacterTextSplitter</span><br><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> RetrievalQA</span><br><span class="line"><span class="keyword">from</span> langchain.document_loaders <span class="keyword">import</span> TextLoader</span><br><span class="line"></span><br><span class="line">loader = TextLoader(<span class="string">&quot;path/to/your/long-text-doc&quot;</span>)</span><br><span class="line">documents = loader.load()</span><br><span class="line">text_splitter = CharacterTextSplitter(chunk_size=<span class="number">1000</span>, chunk_overlap=<span class="number">0</span>)</span><br><span class="line">texts = text_splitter.split_documents(documents)</span><br><span class="line"></span><br><span class="line">openai_key = <span class="string">&#x27;...&#x27;</span></span><br><span class="line">embeddings = OpenAIEmbeddings(openai_api_key=openai_key)</span><br><span class="line">docsearch = Chroma.from_documents(texts, embeddings)</span><br><span class="line"></span><br><span class="line">docsearch.similarity_search_with_relevance_scores(<span class="string">&#x27;你的问题&#x27;</span>)</span><br><span class="line"></span><br><span class="line">qa = RetrievalQA.from_chain_type(llm=OpenAI(openai_api_key=openai_key), chain_type=<span class="string">&quot;refine&quot;</span>, retriever=docsearch.as_retriever())</span><br><span class="line"></span><br><span class="line">qa.run(<span class="string">&quot;你的问题&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>虽然看起来基于搜索的方案是目前给大语言模型注入知识的最佳方案，但实际效果却未也必能达到预期。</p>
<p>从实现原理来看，有很多因素可以导致效果下降，比如大文档切分时将关键的文本句子拆分为了不合理的小文档，文档搜索漏掉了某些关键的文档，搜索出来的相关但非关键的文档排名更靠前，组合得到的提示语过于简单等。</p>
<p>事实上，人类在决策时大量还是基于记忆而非搜索的知识的，这部分可能只能通过第一种方式（基础模型优化）才能更好的解决。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>本文分享了ChatGPT类大语言模型在当下应用时的局限性，并分析了改善的方法。虽然目前大语言模型还远未达到完美，但我们可以看到很多聪明的大脑正在为解决这个问题贡献极具创意的方案，相信不久的将来这些问题都会迎刃而解！</p>
<p>将来的大语言模型的应用会是怎样的？大胆的猜测一下，大概是每个人一个模型，每个团队一个模型，每个公司一个模型吧，这些大语言模型具备不同程度的背景知识，可以更精准更贴心的帮助我们更智慧的解决问题。</p>
<p>自ChatGPT发布以来，很多人认为这是一个人类走向通用人工智能的突破，也有一些人认为它其实没什么本质的改进。有很多人对自己的职业发展产生了很深的焦虑感，也有很多人感觉触碰到了科幻世界中的未来，还有很多人觉得又是一个可以好好捞一把的机会。</p>
<p>也许每个人都有必要去了解一下机器学习技术的原理，这样才能形成对它的理性的认知。</p>
<p>ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。</p>
<p>这是此系列的第六篇，突破ChatGPT的知识限制。</p>
<h2 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h2>
<ul>
<li>语言大模型100K上下文窗口的秘诀： <a href="https://juejin.cn/post/7249173717751087164">https://juejin.cn/post/7249173717751087164</a></li>
<li>Transformer升级之路：7、长度外推性与局部注意力：<a href="https://kexue.fm/archives/9431">https://kexue.fm/archives/9431</a></li>
<li>Transformer升级之路：8、长度外推性与位置鲁棒性: <a href="https://kexue.fm/archives/9444">https://kexue.fm/archives/9444</a></li>
<li>Transformer升级之路：9、一种全局长度外推的新思路: <a href="https://kexue.fm/archives/9603">https://kexue.fm/archives/9603</a></li>
<li>The Secret Sauce behind 100K context window in LLMs: <a href="https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c">https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c</a></li>
<li>What are Embeddings: <a href="https://platform.openai.com/docs/guides/embeddings/what-are-embeddings">https://platform.openai.com/docs/guides/embeddings/what-are-embeddings</a></li>
<li>FlashAttention: <a href="https://shreyansh26.github.io/post/2023-03-26_flash-attention/">https://shreyansh26.github.io/post/2023-03-26_flash-attention/</a></li>
<li>Fast Transformer Decoding: One Write-Head is All You Need: <a href="https://arxiv.org/abs/1911.02150">https://arxiv.org/abs/1911.02150</a></li>
<li>LangChain-Question answering over documents: <a href="https://python.langchain.com/docs/use_cases/question_answering.html">https://python.langchain.com/docs/use_cases/question_answering.html</a></li>
</ul>
<!--
from: https://markmap.js.org/repl
# 突破ChatGPT的知识限制
## ChatGPT的局限性
### 没有纳入训练数据的知识它是不知道
## 扩充ChatGPT的知识的方法
### 基础模型优化
- 实践时会遇到很多问题, 可操作性不强
### 长上下文支持
#### 示例
- Cloude: 100K
- GPT-3.5: 4K -> 16K
- GPT-4: 8K -> 32K
- ChatGLM2-6B: 2K -> 32K
#### 方法
- ALiBi位置编码
- 稀疏注意力机制
- FlashAttention
- 多查询注意力
### 基于文档搜索的知识扩充
- LlamaIndex
- LangChain
- SemanticKernel
-->
]]></content>
      <categories>
        <category>machine-learning</category>
        <category>ChatGPT</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>机器学习</tag>
        <tag>ML</tag>
        <tag>ChatGPT</tag>
      </tags>
  </entry>
  <entry>
    <title>ChatGPT使用的Transfomer模型</title>
    <url>/2023/05/18/chatgpt-transformer/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>作为一个一直对AI技术很感兴趣的软件开发工程师，早在深度学习开始火起来的15、16年，我也开始了相关技术的学习。当时还组织了公司内部同样有兴趣的同学一起研究，最终的成果汇集成几次社区中的分享以及几篇学习文章（见<a href="https://brightliao.com/tags/ai/">这里</a>）。</p>
<p>从去年OpenAI发布ChatGPT以来，AI的能力再次惊艳了世人。在这样的一个时间节点，重新去学习相关技术显得很有必要。</p>
<p>ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。</p>
<p>ChatGPT本身就具备很丰富的知识，所以ChatGPT自身实际上就是一个很好的学习渠道，我也将借助ChatGPT来学习ChatGPT。</p>
<p>这是此系列的第三篇，ChatGPT使用的Transfomer模型。</p>
<span id="more"></span>
<p><a href="https://brightliao.com/2023/04/25/chatgpt-a-technical-summary/">上一篇</a>文章我们聊到了ChatGPT使用的技术概览。了解了其最核心的模型结构是Transformer结构，本文来聊一聊Transformer模型。</p>
<h2 id="介绍"><a class="markdownIt-Anchor" href="#介绍"></a> 介绍</h2>
<p>Transformer的网络结构最早是Google在2017年的时候提出的，论文名称是《Attention Is All You Need》。从论文名称也能看出，Transformer结构强调了注意力机制在网络结构中的表示和应用。</p>
<p>当时这篇论文面世时，不少研究人员还认为标题有点夸大了注意力机制的作用。现在来看，似乎还真有注意力机制一统天下的势头。</p>
<p>下面我们将一起来揭开这个网络结构的面纱。</p>
<h2 id="原始的transfomer模型"><a class="markdownIt-Anchor" href="#原始的transfomer模型"></a> 原始的Transfomer模型</h2>
<p>原始的Transformer的整体结构比较复杂，以下是来自论文中的截图。</p>
<p><img data-src="/attaches/2023/2023-05-18-chatgpt-transformer/model-archi.png" alt="Model Architecture" /></p>
<p>可以看到，Transformer网络的主要由编码器和解码器组成。虽然看起来复杂，但实际上，编码器和解码器都是由多个相同的层堆叠而成，并且编码器和解码器结构也很相似。</p>
<p><strong>编码器（Encoder）每一层内结构为：</strong></p>
<ul>
<li>输入嵌入（Input Embedding）：将输入序列中的每个单词或符号转换为连续的向量表示。</li>
<li>位置编码（Positional Encoding）：为输入序列中的每个位置添加一个表示位置信息的向量。</li>
<li>多头自注意力（Multi-Head Self-Attention）：通过对输入序列中的每个位置进行自注意力计算，从全局上理解输入序列间的关系和重要性。</li>
<li>前馈神经网络（Feed-Forward Neural Network）：在每个位置上应用一个全连接前馈神经网络，以对自注意力输出进行进一步的非线性变换。</li>
<li>残差连接（Residual Connections）和层归一化（Layer Normalization）：在每个子层之间应用残差连接和层归一化，以帮助梯度流动和减少训练中的梯度消失问题。</li>
</ul>
<p><strong>解码器（Decoder）每一层内结构为：</strong></p>
<ul>
<li>编码器-解码器注意力（Encoder-Decoder Attention）：除了自注意力，解码器还对编码器的输出进行注意力计算，以利用编码器对输入序列的理解。</li>
<li>解码器自注意力（Decoder Self-Attention）：类似于编码器的自注意力，但在解码器中应用于当前位置以前的输出。</li>
<li>前馈神经网络：与编码器中的前馈神经网络相同。</li>
<li>残差连接和层归一化：与编码器中的残差连接和层归一化相同。</li>
</ul>
<p>通过堆叠多个编码器和解码器层，Transformer可以具备强大的能力。注意力机制还允许Transformer网络模型自动学习输入序列中的各个单词的依赖关系，并且可以通过并行计算来加速计算过程。</p>
<p><a href="https://zhuanlan.zhihu.com/p/338817680">这里</a>有一篇博客详细的介绍了每一个结构内部的实现机制。推荐大家阅读以了解细节。</p>
<p>如果希望阅读完整的代码，Transformer的完整代码在Google的TensorFlow框架和Meta的PyTorch框架中均有实现。TensorFlow的代码入库在<a href="https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py">这里</a>，不过其代码风格偏函数式风格，并不是很容易理解。PyTorch中的代码相对更容易理解，有兴趣阅读代码的可以看<a href="https://github.com/pytorch/pytorch/blob/main/torch/nn/modules/transformer.py">这里</a>，只需要阅读其<code>forward</code>函数即可了解到整个网络的结构。</p>
<h2 id="chatgpt中的transfomer模型"><a class="markdownIt-Anchor" href="#chatgpt中的transfomer模型"></a> ChatGPT中的Transfomer模型</h2>
<p>ChatGPT中的Transformer模型与原始的Transformer模型有一些差异。主要区别是将Transformer中的Encoder-Decoder双模块设计简化为只有一个Decoder模块。其实也可以认为是只有一个Encoder模块，因为Encoder和Decoder模块本来就很相似。这里之所为大家认为是Decoder，是因为Transformer和ChatGPT的Decoder是自循环的，因为Decoder会根据前一部分的文本生成下一个单词。</p>
<p>在这个单模块中，Self-Attention被替换为了Masked Self-Attention。</p>
<p>Masked Self-Attention在计算时，会将当前输入文本中不存在的部分给遮蔽掉，只对已知的文本信息进行计算。遮蔽其实只是在训练阶段有效，因为训练阶段的输入文本是已知的所有文本。遮蔽掉当前单词的后续单词就可以让模型在无法获取后面单词的信息，使得这一场景与预测阶段的一致。</p>
<p>作为一个程序员，如果不能从代码的粒度去理解，始终会觉得理解不够透彻。下面我们结合代码来详细了解一下Transformer的计算过程。</p>
<p>在这里，我将用来做LLAMA模型的代码实现作为参考，与大家一起结合代码进行分析。LLAMA模型是Meta的研究团队开发的一个与ChatGPT类似的模型，其核心模型结构与ChatGPT的模型是一致的。</p>
<p>LLAMA的实现代码非常短，很适合拿来作为学习材料。完整的代码在<a href="https://github.com/facebookresearch/llama/blob/main/llama/model.py">这里</a>。下面将结合代码与Transformer的原理进行分析。</p>
<h3 id="文本生成逻辑"><a class="markdownIt-Anchor" href="#文本生成逻辑"></a> 文本生成逻辑</h3>
<p>LLAMA生成文本的代码入口在<a href="https://github.com/facebookresearch/llama/blob/main/example.py">这里</a>，下面说明一下代码中关键的行为：</p>
<p>（为了说明代码主要的功能，以下代码仅截取了关键的代码行，并进行了注释，以便大家更容易阅读。）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 整个程序的入口函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="comment"># 调用下面的load函数，创建一个LLaMA对象，用于生成文本</span></span><br><span class="line">    generator = load(...)</span><br><span class="line">    <span class="comment"># 调用LLaMA对象，根据传入的文本，以及最大生成长度、温度、单词概率选择</span></span><br><span class="line">    results = generator.generate(prompts, max_gen_len=<span class="number">256</span>, temperature=temperature, top_p=top_p)</span><br><span class="line">    <span class="comment"># 打印结果</span></span><br><span class="line">    <span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">        <span class="built_in">print</span>(result)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n==================================\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load</span>(<span class="params">...</span>) -&gt; LLaMA:</span><br><span class="line">    <span class="comment"># 加载保存的模型参数</span></span><br><span class="line">    checkpoint = torch.load(ckpt_path, map_location=<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    model_args: ModelArgs = ModelArgs(...)</span><br><span class="line">    <span class="comment"># 初始化一个Tokenizer对象，此Tokenizer其实也是一个机器学习模型，用于将文本切分为单词，并将单词编码为整型数值</span></span><br><span class="line">    tokenizer = Tokenizer(model_path=tokenizer_path)</span><br><span class="line">    <span class="comment"># 初始化核心的Transformer模型</span></span><br><span class="line">    model = Transformer(model_args)</span><br><span class="line">    <span class="comment"># 构造LLaMA的文本生成器对象，并返回</span></span><br><span class="line">    generator = LLaMA(model, tokenizer)</span><br><span class="line">    <span class="keyword">return</span> generator</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LLaMA</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">generate</span>(<span class="params">...</span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span><br><span class="line">        <span class="comment"># 将输入的文本编码为数值</span></span><br><span class="line">        prompt_tokens = [self.tokenizer.encode(x, bos=<span class="literal">True</span>, eos=<span class="literal">False</span>) <span class="keyword">for</span> x <span class="keyword">in</span> prompts]</span><br><span class="line">        <span class="comment"># 用上面的文本数值编码创建一个适合模型输入的矩阵（不超过模型能支持的最大长度），长度太短的文本用pad_id填充</span></span><br><span class="line">        tokens = torch.full((bsz, total_len), self.tokenizer.pad_id).cuda().long()</span><br><span class="line">        <span class="keyword">for</span> k, t <span class="keyword">in</span> <span class="built_in">enumerate</span>(prompt_tokens):</span><br><span class="line">            tokens[k, : <span class="built_in">len</span>(t)] = torch.tensor(t).long()</span><br><span class="line">        <span class="comment"># 根据配置的文本生成长度，迭代生成文本，一次生成一个单词</span></span><br><span class="line">        <span class="keyword">for</span> cur_pos <span class="keyword">in</span> <span class="built_in">range</span>(start_pos, total_len):</span><br><span class="line">            <span class="comment"># 调用模型进行计算</span></span><br><span class="line">            logits = self.model.forward(tokens[:, prev_pos:cur_pos], prev_pos)</span><br><span class="line">            <span class="keyword">if</span> temperature &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># 如果有传入温度参数，将输出结果根据温度放大，并选择累计概率达到top-p概率的那些结果</span></span><br><span class="line">                <span class="comment"># 关于温度和top-p参数的详细解释见下文</span></span><br><span class="line">                probs = torch.softmax(logits / temperature, dim=-<span class="number">1</span>)</span><br><span class="line">                next_token = sample_top_p(probs, top_p)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 如果没有传入，则直接选择概率最大的那个单词</span></span><br><span class="line">                next_token = torch.argmax(logits, dim=-<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 将得到的单词加回原来的文本，继续生成下一个单词</span></span><br><span class="line">            tokens[:, cur_pos] = next_token</span><br><span class="line">        <span class="comment"># 通过单词编码器将生成的数值型文本反编码为可读的文本，并返回</span></span><br><span class="line">        decoded = []</span><br><span class="line">        <span class="keyword">for</span> i, t <span class="keyword">in</span> <span class="built_in">enumerate</span>(tokens.tolist()):</span><br><span class="line">            decoded.append(self.tokenizer.decode(t))</span><br><span class="line">        <span class="keyword">return</span> decoded</span><br></pre></td></tr></table></figure>
<p>这就是入口代码的主要逻辑。下面我们分析一下涉及到的几个核心子步骤。</p>
<h4 id="词嵌入"><a class="markdownIt-Anchor" href="#词嵌入"></a> 词嵌入</h4>
<p>词嵌入是将文本编码为数值的过程。LLaMA在进行词嵌入时，选择了<code>sentencepiece</code>库来实现。</p>
<p>SentencePiece 是一个开源的文本处理库，用于处理和生成分词模型。它的主要作用是将文本分割成子词（subwords）或标记（tokens），以便用于各种自然语言处理任务，例如机器翻译、文本分类、命名实体识别等。</p>
<p>SentencePiece 提供了基于不同分割算法的分词方法，包括未经训练的模型和基于训练数据的模型。它支持的分割算法包括 BPE（Byte-Pair Encoding）、Unigram 等。使用 SentencePiece，可以根据具体任务和需求创建自定义的分词模型。</p>
<p>通过使用 SentencePiece 库，可以实现以下功能：</p>
<ul>
<li>文本分词：将文本分割成子词或标记，提供更细粒度的语言处理单元。</li>
<li>词汇表生成：根据训练数据生成词汇表，用于构建词汇表索引或编码器-解码器模型。</li>
<li>子词编码：将文本转换为子词序列，以便在模型中进行处理和表示。</li>
<li>子词解码：将子词序列转换回原始文本，用于生成文本或进行后处理。</li>
</ul>
<p>SentencePiece 被广泛应用于各种自然语言处理任务和模型，特别是在跨语言和非常规语言处理方面具有很大的灵活性和适应性。它的灵活性使得可以根据不同语言、文本类型和任务的需求，定制化地构建分词模型，从而提高模型性能和效果。</p>
<p>下面是<code>Tokenizer</code>的核心代码分析：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Tokenizer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model_path: <span class="built_in">str</span></span>):</span><br><span class="line">        <span class="comment"># 根据模型文件创建SentencePieceProcessor对象</span></span><br><span class="line">        self.sp_model = SentencePieceProcessor(model_file=model_path)</span><br><span class="line">        <span class="comment"># 保存词汇表大小及一些关键的ID，如开始、结束符、填充符等</span></span><br><span class="line">        self.n_words: <span class="built_in">int</span> = self.sp_model.vocab_size()</span><br><span class="line">        self.bos_id: <span class="built_in">int</span> = self.sp_model.bos_id()</span><br><span class="line">        self.eos_id: <span class="built_in">int</span> = self.sp_model.eos_id()</span><br><span class="line">        self.pad_id: <span class="built_in">int</span> = self.sp_model.pad_id()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode</span>(<span class="params">self, s: <span class="built_in">str</span>, bos: <span class="built_in">bool</span>, eos: <span class="built_in">bool</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="comment"># 将文本编码为数值序列，并根据参数添加开始、结束符</span></span><br><span class="line">        t = self.sp_model.encode(s)</span><br><span class="line">        <span class="keyword">if</span> bos:</span><br><span class="line">            t = [self.bos_id] + t</span><br><span class="line">        <span class="keyword">if</span> eos:</span><br><span class="line">            t = t + [self.eos_id]</span><br><span class="line">        <span class="keyword">return</span> t</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">decode</span>(<span class="params">self, t: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="comment"># 将文本数值序列反编码为可读文本</span></span><br><span class="line">        <span class="keyword">return</span> self.sp_model.decode(t)</span><br></pre></td></tr></table></figure>
<h4 id="温度参数"><a class="markdownIt-Anchor" href="#温度参数"></a> 温度参数</h4>
<p>生成文本时，有两个重要的参数：温度（temperature）和top-p。它们是如何产生作用的呢？</p>
<p>温度参数（temperature）在生成文本过程中起到控制多样性的作用。较高的温度值会增加生成文本时的随机性，使得模型更加倾向于选择概率较小的标记，从而产生更多样化的输出。</p>
<p>具体来说，温度参数会影响 <code>softmax</code> 操作中的指数运算。在 <code>softmax</code> 函数中，通过将 <code>logits</code> 值进行指数运算并归一化，将其转换为概率分布。温度参数的作用是调整指数运算的敏感度。较高的温度值会使指数运算的结果更加平滑，减小了各个标记之间的概率差异，降低了概率较大的标记相对于概率较小的标记的优势。这样，在生成过程中，模型更有可能选择概率较小的标记，从而产生更多样化的输出。</p>
<p>举个例子，假设有一个具有三个候选标记的生成任务，对应的 <code>logits</code> 为 <code>[1.0, 2.0, 3.0]</code>。当温度参数为较低的值（例如1.0）时，通过 <code>softmax</code> 运算后，对应的概率分布为 <code>[0.09, 0.24, 0.67]</code>。可以看到，概率较大的标记 3 相对于其他标记有明显优势，模型更有可能选择标记 3。而当温度参数为较高的值（例如2.0）时，通过 <code>softmax</code> 运算后，对应的概率分布为 <code>[0.19, 0.31, 0.51]</code>。可以看到，概率差异缩小，标记 3 相对于其他标记的优势减小，模型更容易在标记之间进行随机选择。</p>
<p>因此，通过调整温度参数，可以在生成文本时控制多样性。较高的温度值可以增加生成文本的随机性，产生更多样化的输出；而较低的温度值可以增加生成文本的准确性，更倾向于选择概率较大的标记。根据具体的任务需求和应用场景，可以选择合适的温度值来平衡准确性和多样性之间的权衡。</p>
<h4 id="top-p参数"><a class="markdownIt-Anchor" href="#top-p参数"></a> top-p参数</h4>
<p><code>top-p</code>参数用于控制生成文本时的文本选择范围。</p>
<p>实现时，首先，计算 <code>softmax</code> 操作后的概率分布。然后，按照概率从高到低的顺序对概率进行排序。接下来，按照累积概率的方式逐个考虑排名靠前的标记，直到累积概率超过 <code>top-p</code> 的阈值。此时，只有排名靠前的文本才会被保留在选择范围内，其他排名较低的文本会被舍弃。</p>
<p>换句话说，<code>top-p</code> 参数通过动态地确定生成时所需的标记范围，使得生成的结果更加多样化且避免选择概率极低的标记。这种方式比传统的 <code>top-k</code> 采样更加灵活，因为 <code>top-p</code> 参数不依赖于固定的 <code>k</code> 值，而是根据概率分布动态地确定需要保留的标记数量。</p>
<p>下面函数是相关的实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sample_top_p</span>(<span class="params">probs, p</span>):</span><br><span class="line">    <span class="comment"># 对概率进行排序并记录排序后的索引</span></span><br><span class="line">    probs_sort, probs_idx = torch.sort(probs, dim=-<span class="number">1</span>, descending=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 计算累积概率</span></span><br><span class="line">    probs_sum = torch.cumsum(probs_sort, dim=-<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 创建一个布尔掩码，用于确定哪些概率需要保留</span></span><br><span class="line">    mask = probs_sum - probs_sort &gt; p</span><br><span class="line">    <span class="comment"># 将超过 top-p 阈值的概率置为 0</span></span><br><span class="line">    probs_sort[mask] = <span class="number">0.0</span></span><br><span class="line">    <span class="comment"># 将概率归一化，使其和为 1</span></span><br><span class="line">    probs_sort.div_(probs_sort.<span class="built_in">sum</span>(dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>))</span><br><span class="line">    <span class="comment"># 从归一化的概率分布中进行多项式分布采样，得到下一个标记</span></span><br><span class="line">    next_token = torch.multinomial(probs_sort, num_samples=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 使用排序后的索引获取对应的下一个标记</span></span><br><span class="line">    next_token = torch.gather(probs_idx, -<span class="number">1</span>, next_token)</span><br><span class="line">    <span class="keyword">return</span> next_token</span><br></pre></td></tr></table></figure>
<p>函数接受两个参数：<code>probs</code> 是经过 <code>softmax</code> 操作得到的概率分布，<code>p</code> 是 <code>top-p</code> 参数，用于确定保留的概率范围。</p>
<p>根据<code>top-p</code>进行结果选择的逻辑如下：</p>
<ul>
<li>对概率 <code>probs</code> 进行排序，并记录排序后的索引，使得概率从高到低排列。</li>
<li>计算概率的累积和。</li>
<li>创建一个布尔掩码，用于确定哪些概率需要保留。如果累积概率超过了 <code>top-p</code> 阈值，则对应的概率置为 0。</li>
<li>将概率归一化，使其和为 1，以便进行多项式分布采样。</li>
<li>使用多项式采样方法从归一化的概率分布中选取一个下一个标记。</li>
<li>使用排序后的索引 <code>probs_idx</code> 获取对应的下一个标记。</li>
<li>返回选取的下一个标记 <code>next_token</code>。</li>
<li>这段代码实现了根据 <code>top-p</code> 参数选择结果的逻辑，确保生成的结果在给定的概率范围内，并增加生成文本的多样性。</li>
</ul>
<h3 id="模型结构"><a class="markdownIt-Anchor" href="#模型结构"></a> 模型结构</h3>
<p>在生成文本的主流程中，构造了Transformer模型进行下一个单词的预测，下面分析一下Transformer模型的结构。</p>
<p>下面的代码需要有一些PyTorch构建神经网络模型的基础知识。对于不了解相关知识的同学，以下是一些要点：</p>
<ul>
<li>PyTorch抽象了一个Module类用于构建基本的模型构造块</li>
<li>在构建模型构造块时，需要继承Module类并实现其forward方法将输入变换为输出</li>
<li>在构建模型构造块时，需要在类的初始化方法<code>__init__</code>中初始化用到的子构造块</li>
<li>在构建模型构造块时，一般不需要关注参数更新的部分，PyTorch提供了自动计算梯度（参数的偏导数）的机制</li>
<li>PyTorch提供了很多内置的模块或函数，如<code>full</code> <code>triu</code> <code>matmul</code> <code>silu</code>等，帮助我们更快的复用标准构造块</li>
</ul>
<p>Transformer相关的完整代码在<a href="https://github.com/facebookresearch/llama/blob/main/llama/model.py">这里</a>，下面分析一下关键的实现。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Transformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, params: ModelArgs</span>):</span><br><span class="line">        ...</span><br><span class="line">        <span class="comment"># 构造文本嵌入，用于将文本转化为向量表示</span></span><br><span class="line">        self.tok_embeddings = ParallelEmbedding(params.vocab_size, params.dim, ...)</span><br><span class="line">        <span class="comment"># 根据模型参数指定的Transformer层数，创建核心网络结构</span></span><br><span class="line">        self.layers = torch.nn.ModuleList()</span><br><span class="line">        <span class="keyword">for</span> layer_id <span class="keyword">in</span> <span class="built_in">range</span>(params.n_layers):</span><br><span class="line">            self.layers.append(TransformerBlock(layer_id, params))</span><br><span class="line">        <span class="comment"># RMSNorm归一化算子，见下文解释</span></span><br><span class="line">        self.norm = RMSNorm(params.dim, eps=params.norm_eps)</span><br><span class="line">        <span class="comment"># 对输出的文本进行最终的线性变换的算子</span></span><br><span class="line">        self.output = ColumnParallelLinear(params.dim, params.vocab_size, bias=<span class="literal">False</span>, ...)</span><br><span class="line">        <span class="comment"># 预计算频率的复数表示，见下文旋转嵌入部分的分析</span></span><br><span class="line">        self.freqs_cis = precompute_freqs_cis(self.params.dim // self.params.n_heads, self.params.max_seq_len * <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, tokens: torch.Tensor, start_pos: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="comment"># 对传入的文本取嵌入向量</span></span><br><span class="line">        h = self.tok_embeddings(tokens)</span><br><span class="line">        <span class="comment"># 预计算旋转嵌入的旋转频率。可以减少在每个前向传播步骤中的重复计算，提高模型的运行效率。</span></span><br><span class="line">        <span class="comment"># 这里用到了一些复数计算技巧，详见下文注意力机制部分分析</span></span><br><span class="line">        self.freqs_cis = self.freqs_cis.to(h.device)</span><br><span class="line">        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]</span><br><span class="line">        <span class="comment"># 在传入的文本长度大于1时，构造一个上三角矩阵作为掩码，用于遮盖未生成的字词部分</span></span><br><span class="line">        mask = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> seqlen &gt; <span class="number">1</span>:</span><br><span class="line">            mask = torch.full((<span class="number">1</span>, <span class="number">1</span>, seqlen, seqlen), <span class="built_in">float</span>(<span class="string">&quot;-inf&quot;</span>), device=tokens.device)</span><br><span class="line">            mask = torch.triu(mask, diagonal=start_pos + <span class="number">1</span>).type_as(h)</span><br><span class="line">        <span class="comment"># 调用每一个Transfomer分层进行计算</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            h = layer(h, start_pos, freqs_cis, mask)</span><br><span class="line">        <span class="comment"># 归一化最后的结果</span></span><br><span class="line">        h = self.norm(h)</span><br><span class="line">        <span class="comment"># 取计算出来的最后一个词，并进行最后的线性变换后作为输出返回</span></span><br><span class="line">        output = self.output(h[:, -<span class="number">1</span>, :])  <span class="comment"># only compute last logits</span></span><br><span class="line">        <span class="keyword">return</span> output.<span class="built_in">float</span>()</span><br></pre></td></tr></table></figure>
<p>上述代码用到的核心结构<code>TransformerBlock</code>代码分析如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TransformerBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, layer_id: <span class="built_in">int</span>, args: ModelArgs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># 构造注意力部分结构，见下文注意力机制部分</span></span><br><span class="line">        self.attention = Attention(args)</span><br><span class="line">        <span class="comment"># 构造前馈神经网络部分结构，见下文前馈神经网络部分</span></span><br><span class="line">        self.feed_forward = FeedForward(dim=args.dim, hidden_dim=<span class="number">4</span> * args.dim, ...)</span><br><span class="line">        <span class="comment"># 注意力部分用到的RMSNorm归一化算子，见下文解释</span></span><br><span class="line">        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)</span><br><span class="line">        <span class="comment"># 前馈神经网络部分用到的RMSNorm归一化算子，见下文解释</span></span><br><span class="line">        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor, start_pos: <span class="built_in">int</span>, freqs_cis: torch.Tensor, mask: <span class="type">Optional</span>[torch.Tensor]</span>):</span><br><span class="line">        <span class="comment"># 将输入归一化，并计算注意力，然后加上x以形成残差结构</span></span><br><span class="line">        h = x + self.attention.forward(self.attention_norm(x), start_pos, freqs_cis, mask)</span><br><span class="line">        <span class="comment"># 将上述结果进行归一化，并计算前馈神经网络部分，然后加上h以形成残差结构</span></span><br><span class="line">        out = h + self.feed_forward.forward(self.ffn_norm(h))</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h3 id="注意力机制"><a class="markdownIt-Anchor" href="#注意力机制"></a> 注意力机制</h3>
<p>Transformer 中的注意力机制（Attention Mechanism）是核心组成部分之一，它在模型中用于捕捉输入序列中的相关信息，并为每个位置分配权重。</p>
<p>注意力的意思就是让模型关注在重要的地方，权重比较高的位置将得到更多的关注。如何实现？通过在每个位置上计算一个加权和就可以了！</p>
<p>Transformer 中使用的是自注意力机制（Self-Attention），即将输入序列中的每个位置视为查询（query）、键（key）和值（value）。通过计算查询与键的相似度得到权重分布，然后将权重与值进行加权求和得到每个位置的输出。</p>
<p>下面是 Transformer 中自注意力机制的主要步骤：</p>
<ul>
<li>对输入序列进行线性变换，分别得到查询（Q）、键（K）和值（V）。</li>
<li>计算查询与键的相似度分数，通常使用点积或其他函数（如缩放点积）计算相似度。</li>
<li>对相似度分数进行归一化处理，通过 softmax 函数将分数转换为注意力权重。</li>
<li>将权重与值进行加权求和，得到加权和作为该位置的输出。</li>
<li>将每个位置的输出进行线性变换，得到最终的自注意力输出。</li>
</ul>
<p>自注意力机制的优势在于它能够捕捉输入序列中的长距离依赖关系，并且能够对不同位置之间的相关性进行灵活的建模。通过自注意力机制，Transformer 可以同时考虑输入序列中所有位置的信息，而无需像循环神经网络那样依次处理序列。</p>
<p>在 Transformer 中，注意力机制通常通过多头注意力（Multi-Head Attention）来进行扩展，即使用多组不同的查询、键和值进行注意力计算，并将它们的输出进行拼接和线性变换，以增加模型的表达能力和学习能力。</p>
<p>总结起来，注意力机制是 Transformer 模型中重要的组成部分，它通过计算查询与键的相似度来为每个位置分配权重，并将权重与值进行加权求和得到输出。它能够捕捉输入序列中的相关信息，提升模型的表达能力和学习能力。</p>
<p><code>TransformerBlock</code>代码使用到的核心的<code>Attention</code>模块就是注意力机制的实现。这个模块的代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, args: ModelArgs</span>):</span><br><span class="line">        <span class="comment"># 构造注意力查询（Q）、键（K）和值（V）所需要的线性变换算子</span></span><br><span class="line">        <span class="comment"># 这里直接用一个变换算子支持了多头的场景，因为每个头实际上计算方式是完全一样的，只是参数不同</span></span><br><span class="line">        self.wq = ColumnParallelLinear(args.dim, args.n_heads * self.head_dim, ...)</span><br><span class="line">        self.wk = ColumnParallelLinear(args.dim, args.n_heads * self.head_dim, ...)</span><br><span class="line">        self.wv = ColumnParallelLinear(args.dim, args.n_heads * self.head_dim, ...)</span><br><span class="line">        <span class="comment"># 构造对最终输出进行线性变换的算子</span></span><br><span class="line">        self.wo = RowParallelLinear(args.n_heads * self.head_dim, args.dim, ...)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor, start_pos: <span class="built_in">int</span>, freqs_cis: torch.Tensor, mask: <span class="type">Optional</span>[torch.Tensor]</span>):</span><br><span class="line">        <span class="comment"># 对输入序列进行线性变换，分别得到查询（Q）、键（K）和值（V）。</span></span><br><span class="line">        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)</span><br><span class="line">        <span class="comment"># 对查询和键应用旋转嵌入（Rotary Embedding）操作</span></span><br><span class="line">        <span class="comment"># 旋转嵌入是一种在注意力机制中引入周期性信息的技术，有助于模型捕捉序列的顺序关系</span></span><br><span class="line">        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新缓存中的键（K）和值（V），将当前位置的键和值存储在缓存中以供后续的注意力计算使用。</span></span><br><span class="line">        self.cache_k[:bsz, start_pos : start_pos + seqlen] = xk</span><br><span class="line">        self.cache_v[:bsz, start_pos : start_pos + seqlen] = xv</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 从缓存中获取用于注意力计算的键（K）和值（V），包括当前位置之前的所有位置。</span></span><br><span class="line">        keys = self.cache_k[:bsz, : start_pos + seqlen]</span><br><span class="line">        values = self.cache_v[:bsz, : start_pos + seqlen]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对查询、键和值进行维度转置，以便进行矩阵乘法操作。</span></span><br><span class="line">        xq = xq.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        keys = keys.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        values = values.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 计算查询和键之间的相似度得分，通过矩阵乘法计算得到，同时除以头的维度的平方根来进行缩放，以控制相似度的范围。</span></span><br><span class="line">        scores = torch.matmul(xq, keys.transpose(<span class="number">2</span>, <span class="number">3</span>)) / math.sqrt(self.head_dim)</span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 如果存在掩码（mask），则将其加到相似度得分上，以屏蔽无效位置的影响。</span></span><br><span class="line">            scores = scores + mask  <span class="comment"># (bs, n_local_heads, slen, cache_len + slen)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对相似度得分进行 softmax 操作，将其转换为注意力权重，使得权重在每个位置的分布总和为 1。</span></span><br><span class="line">        scores = F.softmax(scores.<span class="built_in">float</span>(), dim=-<span class="number">1</span>).type_as(xq)</span><br><span class="line">        <span class="comment"># 根据注意力权重对值进行加权求和，得到最终的注意力输出。</span></span><br><span class="line">        output = torch.matmul(scores, values)  <span class="comment"># (bs, n_local_heads, slen, head_dim)</span></span><br><span class="line">        ...</span><br><span class="line">        <span class="comment"># 对注意力输出进行线性变换，得到最终的注意力机制的输出。</span></span><br><span class="line">        <span class="keyword">return</span> self.wo(output)</span><br></pre></td></tr></table></figure>
<p><strong>旋转嵌入</strong></p>
<p>旋转嵌入（Rotary Embedding）是一种在注意力机制中引入周期性信息的技术，用于增强模型对序列中的顺序关系的建模能力。它通过将输入的查询（Q）和键（K）进行旋转操作，以捕捉序列中位置之间的相对角度。</p>
<p>在注意力机制中，查询和键是通过点积运算来计算相似度得分的，而点积运算本质上是计算两个向量的内积。通过旋转嵌入，可以将原始的查询和键进行旋转操作，将它们的信息编码成一个复数的表示形式，从而引入角度信息。</p>
<p>旋转嵌入的具体操作如下：</p>
<ul>
<li>首先，将查询和键的维度分为实部和虚部两部分。</li>
<li>然后，使用三角函数（sin 和 cos）计算旋转角度的正弦和余弦值。</li>
<li>将原始的实部和虚部分别与正弦和余弦值相乘，得到旋转后的实部和虚部。</li>
<li>最后，将旋转后的实部和虚部重新组合成查询和键的表示。</li>
</ul>
<p>通过旋转嵌入，查询和键之间的点积运算相当于在复数域中进行了旋转操作，这样可以更好地处理序列中的相对位置关系。旋转嵌入的使用可以提升模型对序列中长距离依赖的建模能力，并有助于捕捉序列中的顺序信息。</p>
<p>需要注意的是，旋转嵌入只应用于查询和键，而值（V）保持不变。这是因为在注意力机制中，查询和键的作用是计算相似度得分，而值则用于根据得分对序列进行加权求和。旋转嵌入的引入主要是为了增强相似度计算的准确性，而对值的处理不需要引入旋转操作。</p>
<p>对应的代码为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">precompute_freqs_cis</span>(<span class="params">dim: <span class="built_in">int</span>, end: <span class="built_in">int</span>, theta: <span class="built_in">float</span> = <span class="number">10000.0</span></span>):</span><br><span class="line">    <span class="comment"># 预计算旋转嵌入的旋转频率。可以减少在每个前向传播步骤中的重复计算，提高模型的运行效率。</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算旋转嵌入的频率 freqs。</span></span><br><span class="line">    <span class="comment"># 1. 首先，生成一个从 0 到 dim 的整数序列，并取其中的偶数索引。</span></span><br><span class="line">    <span class="comment"># 2. 然后，将这些索引转换为浮点数，并将其除以 dim 后取倒数。</span></span><br><span class="line">    <span class="comment"># 这样可以生成一个频率递减的序列，用于控制旋转嵌入的旋转速度。</span></span><br><span class="line">    freqs = <span class="number">1.0</span> / (theta ** (torch.arange(<span class="number">0</span>, dim, <span class="number">2</span>)[: (dim // <span class="number">2</span>)].<span class="built_in">float</span>() / dim))</span><br><span class="line">    <span class="comment"># 创建一个长度为 end 的序列 t，其中的值从 0 到 end-1。</span></span><br><span class="line">    t = torch.arange(end, device=freqs.device)  <span class="comment"># type: ignore</span></span><br><span class="line">    <span class="comment"># 使用 torch.outer 函数计算旋转频率的复数形式。</span></span><br><span class="line">    <span class="comment"># 将 t 与 freqs 进行外积，得到一个形状为 [end, dim // 2] 的张量，其中每个元素是一个复数，表示旋转频率。</span></span><br><span class="line">    freqs = torch.outer(t, freqs).<span class="built_in">float</span>()  <span class="comment"># type: ignore</span></span><br><span class="line">    <span class="comment"># 使用 torch.polar 函数将复数频率转换为极坐标形式，得到一个复数张量 freqs_cis。</span></span><br><span class="line">    <span class="comment"># 该函数接受一个表示模长的张量（这里是全为1的张量）和一个表示相位的张量（这里是 freqs），并返回复数形式的张量。</span></span><br><span class="line">    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  <span class="comment"># complex64</span></span><br><span class="line">    <span class="keyword">return</span> freqs_cis</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">apply_rotary_emb</span>(<span class="params">xq: torch.Tensor, xk: torch.Tensor, freqs_cis: torch.Tensor</span>):</span><br><span class="line">    <span class="comment"># freqs_cis为旋转嵌入的旋转频率</span></span><br><span class="line">    <span class="comment"># 将输入的查询张量和键张量进行形状变换：</span></span><br><span class="line">    <span class="comment"># 1. 首先将其转换为浮点类型</span></span><br><span class="line">    <span class="comment"># 2. 然后将最后两个维度重塑为两倍大小的维度，以便处理复数形式的旋转嵌入。</span></span><br><span class="line">    <span class="comment"># 结果是一个形状为[batch_size, sequence_length, embedding_dim//2, 2]的复数张量。</span></span><br><span class="line">    xq_ = torch.view_as_complex(xq.<span class="built_in">float</span>().reshape(*xq.shape[:-<span class="number">1</span>], -<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">    xk_ = torch.view_as_complex(xk.<span class="built_in">float</span>().reshape(*xk.shape[:-<span class="number">1</span>], -<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">    <span class="comment"># 将旋转频率进行形状调整，使其与查询张量的形状相匹配。</span></span><br><span class="line">    <span class="comment"># 调整后的形状是根据查询张量形状的最后两个维度进行的，其他维度保持不变。</span></span><br><span class="line">    shape = [d <span class="keyword">if</span> i == <span class="number">1</span> <span class="keyword">or</span> i == ndim - <span class="number">1</span> <span class="keyword">else</span> <span class="number">1</span> <span class="keyword">for</span> i, d <span class="keyword">in</span> <span class="built_in">enumerate</span>(x.shape)]</span><br><span class="line">    freqs_cis = freqs_cis.view(*shape)</span><br><span class="line">    <span class="comment"># 将查询张量和键张量与旋转频率进行逐元素相乘。这相当于在复数域中将查询和键进行旋转操作。</span></span><br><span class="line">    <span class="comment"># 并将旋转后的张量重新转换为实数形式，通过取实部得到最终的旋转嵌入结果。</span></span><br><span class="line">    <span class="comment"># 将每个复数值展平为一个实数值。结果是形状为 [batch_size, sequence_length, embedding_dim] 的张量。</span></span><br><span class="line">    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(<span class="number">3</span>)</span><br><span class="line">    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> xq_out.type_as(xq), xk_out.type_as(xk)</span><br></pre></td></tr></table></figure>
<p>旋转嵌入部分代码略显复杂，并且用到了一些数学计算技巧。如果大家在此理解有困难，也可以忽略它，只需要明白旋转嵌入是为了计算注意力中的查询和键的相似度即可。</p>
<p>如果我们阅读<a href="https://github.com/openai/gpt-2/blob/master/src/model.py">GPT2的代码</a>，可以发现并没有使用旋转嵌入，只是简单的做了矩阵乘法。这是LLAMA引入的一个模型优化方式。</p>
<h3 id="前馈神经网络"><a class="markdownIt-Anchor" href="#前馈神经网络"></a> 前馈神经网络</h3>
<p>整个前馈神经网络的结构为：</p>
<ul>
<li>将输入进行线性变换并输入激活函数</li>
<li>将输入进行另一个线性变换并与上述结果相乘</li>
<li>将相乘后的结果再次经过线性变换得到最终的输出</li>
</ul>
<p>对应的代码为<code>TransformerBlock</code>代码使用的<code>FeedForward</code>模块代码，如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FeedForward</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim: <span class="built_in">int</span>, hidden_dim: <span class="built_in">int</span>, multiple_of: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="comment"># 首先根据隐藏层维度的要求进行调整。将隐藏层维度的值设置为输入维度的 2/3，并将其转换为整数。</span></span><br><span class="line">        <span class="comment"># 然后，使用 multiple_of 对隐藏层维度进行取整，确保隐藏层维度是 multiple_of 的倍数。</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        hidden_dim = <span class="built_in">int</span>(<span class="number">2</span> * hidden_dim / <span class="number">3</span>)</span><br><span class="line">        hidden_dim = multiple_of * ((hidden_dim + multiple_of - <span class="number">1</span>) // multiple_of)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义三个线性变换操作符 self.w1、self.w2 和 self.w3，分别用于前馈神经网络的第一层、第二层和第三层。</span></span><br><span class="line">        self.w1 = ColumnParallelLinear(dim, hidden_dim, ...)</span><br><span class="line">        self.w2 = RowParallelLinear(hidden_dim, dim, ...)</span><br><span class="line">        self.w3 = ColumnParallelLinear(dim, hidden_dim, ...)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 1. 将输入进行线性变换并输入激活函数</span></span><br><span class="line">        <span class="comment"># 2. 将输入进行另一个线性变换并与上述结果相乘</span></span><br><span class="line">        <span class="comment"># 3. 将相乘后的结果再次经过线性变换得到最终的输出</span></span><br><span class="line">        <span class="keyword">return</span> self.w2(F.silu(self.w1(x)) * self.w3(x))</span><br></pre></td></tr></table></figure>
<h3 id="rmsnorm"><a class="markdownIt-Anchor" href="#rmsnorm"></a> RMSNorm</h3>
<p>上述代码中多次用到了RMSNorm归一化，这是什么技术呢？</p>
<p>其实，RMSNorm（Root Mean Square Normalization）是一种归一化技术，用于在神经网络中对输入进行标准化处理。它旨在增强网络的鲁棒性和稳定性，并有助于减轻输入数据中的噪声和变化对模型的影响。</p>
<p>RMSNorm 的核心思想是基于输入的均方根（RMS）进行标准化。它通过计算输入张量沿指定维度的均方根，并将每个元素除以该均方根值来进行归一化。这种归一化方法相比于传统的均值和方差归一化（例如 Batch Normalization）更加简单和直观。</p>
<p>其代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RMSNorm</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim: <span class="built_in">int</span>, eps: <span class="built_in">float</span> = <span class="number">1e-6</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># eps 参数是一个小的常数，用于避免分母为零的情况，确保数值稳定性。</span></span><br><span class="line">        self.eps = eps</span><br><span class="line">        <span class="comment"># dim 参数表示输入张量的维度，即要在哪个维度上计算均方根并进行归一化。</span></span><br><span class="line">        <span class="comment"># weight 是一个可学习的权重参数，用于缩放标准化后的输入。</span></span><br><span class="line">        self.weight = nn.Parameter(torch.ones(dim))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_norm</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 计算输入张量的均方根，并将每个元素除以均方根值。</span></span><br><span class="line">        <span class="keyword">return</span> x * torch.rsqrt(x.<span class="built_in">pow</span>(<span class="number">2</span>).mean(-<span class="number">1</span>, keepdim=<span class="literal">True</span>) + self.eps)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 调用 _norm 方法对输入张量进行标准化处理，并将标准化后的结果与权重参数相乘，以进一步缩放和调整输出。</span></span><br><span class="line">        output = self._norm(x.<span class="built_in">float</span>()).type_as(x)</span><br><span class="line">        <span class="keyword">return</span> output * self.weight</span><br></pre></td></tr></table></figure>
<h3 id="掩码"><a class="markdownIt-Anchor" href="#掩码"></a> 掩码</h3>
<p>掩码部分也有一些技巧，下面来看看它是如何实现的。</p>
<p>在Transformer的前向计算时，会计算一个掩码矩阵。然后，在计算注意力时，使用此掩码来遮蔽掉无效位置。对应的代码片段如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Transformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, tokens: torch.Tensor, start_pos: <span class="built_in">int</span></span>):</span><br><span class="line">        ...</span><br><span class="line">        <span class="comment"># 在传入的文本长度大于1时，构造一个上三角矩阵作为掩码，用于遮盖未生成的字词部分</span></span><br><span class="line">        mask = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> seqlen &gt; <span class="number">1</span>:</span><br><span class="line">            mask = torch.full((<span class="number">1</span>, <span class="number">1</span>, seqlen, seqlen), <span class="built_in">float</span>(<span class="string">&quot;-inf&quot;</span>), device=tokens.device)</span><br><span class="line">            mask = torch.triu(mask, diagonal=start_pos + <span class="number">1</span>).type_as(h)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor, start_pos: <span class="built_in">int</span>, freqs_cis: torch.Tensor, mask: <span class="type">Optional</span>[torch.Tensor]</span>):</span><br><span class="line">        ...</span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 如果存在掩码（mask），则将其加到相似度得分上，以屏蔽无效位置的影响。</span></span><br><span class="line">            scores = scores + mask  <span class="comment"># (bs, n_local_heads, slen, cache_len + slen)</span></span><br></pre></td></tr></table></figure>
<p>在生成掩码时，上述代码生成了一个上三角掩码，以屏蔽未来位置的注意力。</p>
<p>在计算注意力分数时，通过将未来位置的分数设置为负无穷，可以使模型在自回归任务中只依赖于当前及之前的信息。这样可以确保模型在生成序列时不会看到未来位置的信息，保持了模型的自回归性质。</p>
<p>生成掩码的方式如下：</p>
<ul>
<li>首先，创建一个名为 mask 的变量，并将其初始化为 None。这意味着在开始时没有生成掩码。</li>
<li>如果 seqlen 大于 1，表示当前处理的序列长度大于 1，存在需要屏蔽的位置。</li>
<li>创建一个形状为 (1, 1, seqlen, seqlen) 的张量 mask，并将所有元素的值设为负无穷（float(&quot;-inf&quot;)）。这里使用 float(&quot;-inf&quot;) 是为了在计算注意力分数时将被掩盖的位置的注意力分数设为负无穷大，从而在softmax操作后将其值近似为0。</li>
<li>使用 torch.triu() 函数将 mask 张量的下三角部分（包括对角线）设为负无穷。这是通过设置 diagonal 参数为 start_pos + 1 来实现的，表示从对角线位置 start_pos + 1 开始屏蔽。这样，注意力机制在计算时将只关注当前位置及之前的位置，而忽略之后的位置。</li>
<li>最后，将 mask 张量的数据类型转换为输入张量 h 的数据类型，并将其赋值给 mask 变量。</li>
</ul>
<p>在代码中，scores 与 mask 相加，实际上是将 mask 中的非负数值添加到 scores 对应位置的元素上。通过这样的操作，可以将特定位置的注意力分数调整为一个较小的值，从而有效地屏蔽或降低模型对该位置的关注度。</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>到这里，我们就分析完了整个LLAMA模型的代码。需要注意的是，这里的代码只是LLAMA模型在生成文本时（即预测时）要执行的代码。LLAMA在训练阶段会有更多的技巧，也会涉及更多的代码。可惜Meta并没有公布相关的训练代码。</p>
<p>在分析代码时，我们有意忽略了模型并行处理的部分代码，这些是一些并行优化的机制，对于我们理解模型帮助不大。但如果我们希望将这个模型创建为一个服务，从而为大规模的用户服务时，并行处理部分就比较关键了。</p>
<p>在代码分析过程中，我借助了ChatGPT辅助进行理解，并引用了部分ChatGPT生成的内容，当然，也修正了ChatGPT回复中的一些明显的错误。在这个过程中，ChatGPT可以帮助提供足够多的详细的信息，我也深刻的体会到ChatGPT对于代码和我提出的问题的准确理解。可以说，ChatGPT很大程度上帮助我提升了代码分析的效率和学习的效率。</p>
<p>自ChatGPT发布以来，很多人认为这是一个人类走向通用人工智能的突破，也有一些人认为它其实没什么本质的改进。有很多人对自己的职业发展产生了很深的焦虑感，也有很多人感觉触碰到了科幻世界中的未来，还有很多人觉得又是一个可以好好捞一把的机会。</p>
<p>也许每个人都有必要去了解一下机器学习技术的原理，这样才能形成对它的理性的认知。</p>
<p>ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。</p>
<p>这是此系列的第三篇，ChatGPT使用的Transfomer模型。</p>
<h2 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h2>
<ul>
<li>Google的Transformer原始论文：<a href="https://arxiv.org/pdf/1706.03762.pdf">https://arxiv.org/pdf/1706.03762.pdf</a></li>
<li>Transformer模型详解（图解最完整版）：<a href="https://zhuanlan.zhihu.com/p/338817680">https://zhuanlan.zhihu.com/p/338817680</a></li>
<li>LLAMA Paper：<a href="https://arxiv.org/abs/2302.13971v1">https://arxiv.org/abs/2302.13971v1</a></li>
</ul>
]]></content>
      <categories>
        <category>machine-learning</category>
        <category>ChatGPT</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>机器学习</tag>
        <tag>ML</tag>
        <tag>ChatGPT</tag>
      </tags>
  </entry>
  <entry>
    <title>ChatGPT的自动优化</title>
    <url>/2023/05/25/chatgpt-rlhf/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>作为一个一直对AI技术很感兴趣的软件开发工程师，早在深度学习开始火起来的15、16年，我也开始了相关技术的学习。当时还组织了公司内部同样有兴趣的同学一起研究，最终的成果汇集成几次社区中的分享以及几篇学习文章（见<a href="https://brightliao.com/tags/ai/">这里</a>）。</p>
<p>从去年OpenAI发布ChatGPT以来，AI的能力再次惊艳了世人。在这样的一个时间节点，重新去学习相关技术显得很有必要。</p>
<p>ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。</p>
<p>ChatGPT本身就具备很丰富的知识，所以ChatGPT自身实际上就是一个很好的学习渠道，我也将借助ChatGPT来学习ChatGPT。</p>
<p>这是此系列的第五篇，ChatGPT的自动优化。</p>
<span id="more"></span>
<p><a href="https://brightliao.com/2023/05/20/2023-05-20-chatgpt-training/">上一篇</a>文章我们深入分析了ChatGPT是如何训练及优化的，了解了如何进行监督微调，及如何让模型可以支持更广泛领域的问答。但是，监督微调始终会限于训练集中的问题模板数量，无法支持更为一般的对话。这一步骤就需要引入强化学习的训练方式，让ChatGPT可以自动进行优化。</p>
<h2 id="介绍"><a class="markdownIt-Anchor" href="#介绍"></a> 介绍</h2>
<p>强化学习模型是最为复杂的部分，参考ColossalAI的文档，模型的工作原理如下：</p>
<p><img data-src="/attaches/2023/2023-05-25-chatgpt-rlhf/rlhf.jpeg" alt="RLHF" /></p>
<p>为了理解上图，需要先了解一下强化学习相关的背景知识。</p>
<h3 id="强化学习"><a class="markdownIt-Anchor" href="#强化学习"></a> 强化学习</h3>
<p>强化学习（Reinforcement Learning，简称RL）是一种机器学习方法，旨在使智能体（agent）通过与环境的交互来学习适应环境并制定实现特定目标的策略。在强化学习中，智能体通过观察环境的状态，执行动作，并接收环境的奖励或惩罚来不断调整自己的策略，以获得最大化累积奖励的能力。</p>
<p>强化学习的基本要素包括：</p>
<ul>
<li><strong>智能体（Agent）</strong>：智能体是进行学习和决策的主体，它通过观察环境的状态、选择合适的动作，并与环境进行交互。</li>
<li><strong>环境（Environment）</strong>：环境是智能体所处的外部世界，它可以是真实的物理环境，也可以是抽象的模拟环境。环境会根据智能体的动作进行状态转移，并根据智能体的表现给予奖励或惩罚。</li>
<li><strong>状态（State）</strong>：状态是描述环境的特征或信息，它可以是完全观察的，也可以是部分观察或隐含的。智能体的决策往往基于当前状态。</li>
<li><strong>动作（Action）</strong>：动作是智能体在某个状态下可以执行的操作或策略。智能体的目标是根据当前状态选择最优的动作。</li>
<li><strong>奖励（Reward）</strong>：奖励是环境根据智能体的动作和表现给予的反馈信号，用于指示动作的好坏。智能体的目标是通过最大化累积奖励来学习合适的策略。</li>
</ul>
<p>在ChatGPT这个场景中，ChatGPT模型即智能体，环境是一个对话系统，状态是当前对话的上下文及当前消息，动作是如何选择某一个回复，奖励是人类反馈的回复质量好或差。</p>
<p>强化学习的核心问题是通过智能体与环境的交互来学习一个最优的策略，以使智能体在长期累积奖励的过程中能够获得最大化的回报。强化学习算法通常基于价值函数或策略函数来进行决策和优化，其中价值函数用于评估状态或状态动作对的价值，策略函数用于指导智能体在特定状态下选择动作。</p>
<p>强化学习常常应用于机器人控制、游戏智能、自动驾驶等领域。</p>
<h3 id="强化学习算法"><a class="markdownIt-Anchor" href="#强化学习算法"></a> 强化学习算法</h3>
<p>如何学习最优策略呢？常见的学习算法包括Q-learning、SARSA、Deep Q-Network（DQN）、Policy Gradient、Proximal Policy Optimization（PPO）、Actor-Critic等。</p>
<p>以下简要介绍和RLHF相关的算法：</p>
<ul>
<li>Q-learning: 核心思想是学习一个状态-动作价值函数（Q函数），它衡量在给定状态下采取特定动作的长期累积回报。可根据贝尔曼公式 <code>Q(s,a) = Q(s,a) + α(r + γ * max(Q(s',a')) - Q(s,a))</code> 更新及优化Q函数，其中α是学习率，γ是折扣因子，r是奖励，s’是新的状态。</li>
<li>Policy Gradient（策略梯度）算法: 不需要建立值函数模型，而是直接优化策略（动作的选择）。其基本思想是通过采样经验轨迹（trajectory），通过最大化累积奖励来计算策略梯度，并利用梯度信息更新策略参数。</li>
<li>Proximal Policy Optimization（PPO）：一种基于策略梯度的强化学习算法，旨在通过有效地优化策略函数（通过引入一个重要性采样比率和一个剪切函数来限制策略更新的幅度，以保持策略的相对不变性）来提高强化学习的性能和稳定性。</li>
<li>Actor-Critic（演员-评论家）算法：结合了值函数和策略函数的强化学习算法。它通过同时学习一个策略函数（演员）和一个值函数（评论家），以提高强化学习的效率和性能。演员根据评论家的评估结果来更新策略，从而改进策略的质量。评论家则通过学习一个值函数来估计每个状态的值或动作值，以提供演员关于策略改进的反馈。</li>
</ul>
<p>RLHF算法结合了PPO和Actor-Critic算法的优势，所以可以高效而又稳定的优化ChatGPT的模型。</p>
<h2 id="代码分析"><a class="markdownIt-Anchor" href="#代码分析"></a> 代码分析</h2>
<p>有了前面的了解，下面咱们跟着代码一起来了解一下算法的细节。</p>
<h3 id="使用pytorch实现policy-gradient"><a class="markdownIt-Anchor" href="#使用pytorch实现policy-gradient"></a> 使用PyTorch实现Policy Gradient</h3>
<p>下面来看PyTorch的示例中提供的一个参考的策略梯度算法实现。</p>
<p>先介绍一下<code>gym</code>库，这个库提供了一个模拟环境，内置了很多小游戏，可以帮助我们开发强化学习算法。</p>
<p>比如下面这个平衡杆小游戏，我们要想办法控制平衡杆使其一直位于连接点的上方。有两个动作可以用来控制游戏中的连接点，即左和右。控制连接点向左时，可以避免平衡杆往左倾倒。控制连接点向右时，可以避免平衡杆往右倾倒。</p>
<p><img data-src="/attaches/2023/2023-05-25-chatgpt-rlhf/cartpole.png" alt="Cart Pole" /></p>
<p>下面来用策略梯度的方法训练一个强化学习算法让机器人自动玩游戏。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Policy</span>(nn.Module): <span class="comment"># 定义策略函数网络，输出每个动作对应的概率</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Policy, self).__init__()</span><br><span class="line">        <span class="comment"># 定义网络结构，包含了两层线性连接层，第二层输出的动作数量为2</span></span><br><span class="line">        self.affine1 = nn.Linear(<span class="number">4</span>, <span class="number">128</span>)</span><br><span class="line">        self.dropout = nn.Dropout(p=<span class="number">0.6</span>)</span><br><span class="line">        self.affine2 = nn.Linear(<span class="number">128</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.saved_log_probs = []</span><br><span class="line">        self.rewards = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(self.dropout(self.affine1(x)))</span><br><span class="line">        action_scores = self.affine2(x)</span><br><span class="line">        <span class="keyword">return</span> F.softmax(action_scores, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PolicyTrainer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 初始化游戏环境</span></span><br><span class="line">        self.env = gym.make(<span class="string">&quot;CartPole-v1&quot;</span>, render_mode=<span class="string">&quot;rgb_array&quot;</span>)</span><br><span class="line">        <span class="comment"># 初始化策略函数网络及优化器</span></span><br><span class="line">        self.policy = Policy()</span><br><span class="line">        self.optimizer = optim.Adam(self.policy.parameters(), lr=<span class="number">1e-2</span>)</span><br><span class="line">        self.eps = np.finfo(np.float32).eps.item()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">select_action</span>(<span class="params">self, state</span>):</span><br><span class="line">        <span class="comment"># 根据当前的状态，执行策略函数，并根据函数输出的概率选择一个动作</span></span><br><span class="line">        state = torch.from_numpy(state).<span class="built_in">float</span>().unsqueeze(<span class="number">0</span>)</span><br><span class="line">        probs = self.policy(state)</span><br><span class="line">        m = Categorical(probs)</span><br><span class="line">        action = m.sample()</span><br><span class="line">        <span class="comment"># 将动作保存起来，在一局游戏结束的时候，用于训练</span></span><br><span class="line">        self.policy.saved_log_probs.append(m.log_prob(action))</span><br><span class="line">        <span class="keyword">return</span> action.item()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">finish_episode</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 在一局游戏结束的时候，执行策略函数的训练</span></span><br><span class="line">        <span class="comment"># 根据执行动作时保存的奖励，来迭代计算每一个动作的奖励</span></span><br><span class="line">        <span class="comment"># 每一个动作的奖励 = 当前奖励 + 折扣率 * 整局游戏中将来的奖励</span></span><br><span class="line">        R = <span class="number">0</span></span><br><span class="line">        returns = deque()</span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> self.policy.rewards[::-<span class="number">1</span>]:</span><br><span class="line">            R = r + args.gamma * R</span><br><span class="line">            returns.appendleft(R)</span><br><span class="line">        returns = torch.tensor(returns)</span><br><span class="line">        <span class="comment"># 将奖励归一化</span></span><br><span class="line">        returns = (returns - returns.mean()) / (returns.std() + self.eps)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 采用梯度上升法最大化策略奖励，这里使用最小化策略奖励的负数来实现</span></span><br><span class="line">        policy_loss = []</span><br><span class="line">        <span class="keyword">for</span> log_prob, R <span class="keyword">in</span> <span class="built_in">zip</span>(self.policy.saved_log_probs, returns):</span><br><span class="line">            <span class="comment"># 计算每一个动作的策略损失，策略损失 = -动作概率 * 动作奖励</span></span><br><span class="line">            policy_loss.append(-log_prob * R)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 根据整局游戏的结果来计算梯度，并更新参数</span></span><br><span class="line">        self.optimizer.zero_grad()</span><br><span class="line">        policy_loss = torch.cat(policy_loss).<span class="built_in">sum</span>()</span><br><span class="line">        policy_loss.backward()</span><br><span class="line">        self.optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">del</span> self.policy.rewards[:]</span><br><span class="line">        <span class="keyword">del</span> self.policy.saved_log_probs[:]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self</span>):</span><br><span class="line">        running_reward = <span class="number">10</span></span><br><span class="line">        <span class="keyword">for</span> i_episode <span class="keyword">in</span> count(<span class="number">1</span>):</span><br><span class="line">            <span class="comment"># 新的一局游戏开始，初始化环境</span></span><br><span class="line">            state, _ = self.env.reset()</span><br><span class="line">            ep_reward = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10000</span>):  <span class="comment"># Don&#x27;t infinite loop while learning</span></span><br><span class="line">                <span class="comment"># 采用策略函数来生成下一步采用的动作，并执行</span></span><br><span class="line">                action = self.select_action(state)</span><br><span class="line">                state, reward, done, _, _ = self.env.step(action)</span><br><span class="line">                <span class="comment"># 记录奖励</span></span><br><span class="line">                self.policy.rewards.append(reward)</span><br><span class="line">                ep_reward += reward  <span class="comment"># 累计计算当前这一局游戏的奖励</span></span><br><span class="line">                <span class="keyword">if</span> done: <span class="comment"># 如果游戏结束，则退出循环</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 在一局游戏结束是，计算奖励的移动平均值</span></span><br><span class="line">            <span class="comment"># 这里将当前这一局游戏的奖励以5%的百分比给平衡掉，让我们更容易看出游戏当前能得到的奖励</span></span><br><span class="line">            running_reward = <span class="number">0.05</span> * ep_reward + (<span class="number">1</span> - <span class="number">0.05</span>) * running_reward</span><br><span class="line">            <span class="comment"># 触发策略网络更新</span></span><br><span class="line">            self.finish_episode()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 周期性打印日志</span></span><br><span class="line">            <span class="keyword">if</span> i_episode % args.log_interval == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Episode &#123;&#125;\tLast reward: &#123;:.2f&#125;\tAverage reward: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(i_episode, ep_reward, running_reward))</span><br><span class="line">            <span class="keyword">if</span> running_reward &gt; self.env.spec.reward_threshold:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Solved! Running reward is now &#123;&#125; and &quot;</span> <span class="string">&quot;the last episode runs to &#123;&#125; time steps!&quot;</span>.<span class="built_in">format</span>(running_reward, t))</span><br><span class="line">                <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>完整代码见<a href="https://github.com/pytorch/examples/blob/main/reinforcement_learning/reinforce.py">这里</a>。运行以上算法可以看到以下日志：</p>
<blockquote>
<p>Episode 10      Last reward: 21.00      Average reward: 16.30<br />
Episode 20      Last reward: 41.00      Average reward: 24.02<br />
Episode 30      Last reward: 33.00      Average reward: 33.05<br />
Episode 40      Last reward: 64.00      Average reward: 50.71<br />
Episode 50      Last reward: 73.00      Average reward: 59.70<br />
Episode 60      Last reward: 41.00      Average reward: 63.28<br />
Episode 70      Last reward: 59.00      Average reward: 63.88<br />
Episode 80      Last reward: 86.00      Average reward: 80.87<br />
Episode 90      Last reward: 125.00     Average reward: 91.54<br />
Episode 100     Last reward: 224.00     Average reward: 136.09<br />
Episode 110     Last reward: 95.00      Average reward: 182.31<br />
Episode 120     Last reward: 200.00     Average reward: 170.03<br />
Episode 130     Last reward: 80.00      Average reward: 149.48<br />
Episode 140     Last reward: 102.00     Average reward: 148.63<br />
Episode 150     Last reward: 644.00     Average reward: 349.26<br />
Solved! Running reward is now 550.1608406568259 and the last episode runs to 2888 time steps!</p>
</blockquote>
<p>可以看到，在算法玩了150多次游戏的时候，已经可以玩得非常好了。但是我们也能注意到算法有一些波动，特别是在100局到110局时，曾经达到一个不错的水平，但是后来突然又有一些下降。</p>
<h3 id="使用pytorch实现actor-critic"><a class="markdownIt-Anchor" href="#使用pytorch实现actor-critic"></a> 使用PyTorch实现Actor-Critic</h3>
<p>Actor-Critic算法与Policy Gradient算法是类似的。下面看一下代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">SavedAction = namedtuple(<span class="string">&quot;SavedAction&quot;</span>, [<span class="string">&quot;log_prob&quot;</span>, <span class="string">&quot;value&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Policy</span>(nn.Module): <span class="comment"># 定义演员函数和评论家函数网络</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Policy, self).__init__()</span><br><span class="line">        self.affine1 = nn.Linear(<span class="number">4</span>, <span class="number">128</span>)</span><br><span class="line">        self.action_head = nn.Linear(<span class="number">128</span>, <span class="number">2</span>) <span class="comment"># 演员函数输出每个动作对应的概率</span></span><br><span class="line">        self.value_head = nn.Linear(<span class="number">128</span>, <span class="number">1</span>) <span class="comment"># 评论家函数输出每个动作对应的奖励</span></span><br><span class="line">        <span class="comment"># action &amp; reward buffer</span></span><br><span class="line">        self.saved_actions = []</span><br><span class="line">        self.rewards = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(self.affine1(x))</span><br><span class="line">        action_prob = F.softmax(self.action_head(x), dim=-<span class="number">1</span>)</span><br><span class="line">        state_values = self.value_head(x)</span><br><span class="line">        <span class="keyword">return</span> action_prob, state_values</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PolicyTrainer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.env = gym.make(<span class="string">&quot;CartPole-v1&quot;</span>)</span><br><span class="line">        self.model = Policy()</span><br><span class="line">        self.optimizer = optim.Adam(self.model.parameters(), lr=<span class="number">3e-2</span>)</span><br><span class="line">        self.eps = np.finfo(np.float32).eps.item()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">select_action</span>(<span class="params">self, state</span>):</span><br><span class="line">        state = torch.from_numpy(state).<span class="built_in">float</span>()</span><br><span class="line">        probs, state_value = self.model(state)</span><br><span class="line">        m = Categorical(probs)</span><br><span class="line">        action = m.sample()</span><br><span class="line">        self.model.saved_actions.append(SavedAction(m.log_prob(action), state_value))</span><br><span class="line">        <span class="keyword">return</span> action.item()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">finish_episode</span>(<span class="params">self</span>):</span><br><span class="line">        R = <span class="number">0</span></span><br><span class="line">        saved_actions = self.model.saved_actions</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算每一个步骤的奖励</span></span><br><span class="line">        returns = []</span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> self.model.rewards[::-<span class="number">1</span>]:</span><br><span class="line">            R = r + args.gamma * R</span><br><span class="line">            returns.insert(<span class="number">0</span>, R)</span><br><span class="line"></span><br><span class="line">        returns = torch.tensor(returns)</span><br><span class="line">        returns = (returns - returns.mean()) / (returns.std() + self.eps)</span><br><span class="line"></span><br><span class="line">        policy_losses = []</span><br><span class="line">        value_losses = []</span><br><span class="line">        <span class="keyword">for</span> (log_prob, value), R <span class="keyword">in</span> <span class="built_in">zip</span>(saved_actions, returns):</span><br><span class="line">            <span class="comment"># 计算真实奖励与评论家函数估计的奖励之差，并将其用于计算演员函数的损失</span></span><br><span class="line">            advantage = R - value.item()</span><br><span class="line">            policy_losses.append(-log_prob * advantage)</span><br><span class="line">            <span class="comment"># 评论家函数的损失使用平滑L1损失函数（与均方差损失类似，但更稳定）</span></span><br><span class="line">            value_losses.append(F.smooth_l1_loss(value, torch.tensor([R])))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算梯度并更新网络</span></span><br><span class="line">        self.optimizer.zero_grad()</span><br><span class="line">        loss = torch.stack(policy_losses).<span class="built_in">sum</span>() + torch.stack(value_losses).<span class="built_in">sum</span>()</span><br><span class="line">        loss.backward()</span><br><span class="line">        self.optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 清理数据</span></span><br><span class="line">        <span class="keyword">del</span> self.model.rewards[:]</span><br><span class="line">        <span class="keyword">del</span> self.model.saved_actions[:]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 训练过程与策略梯度方法类似</span></span><br><span class="line">        running_reward = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i_episode <span class="keyword">in</span> count(<span class="number">1</span>):</span><br><span class="line">            state, _ = self.env.reset()</span><br><span class="line">            ep_reward = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10000</span>):</span><br><span class="line">                action = self.select_action(state)</span><br><span class="line">                state, reward, done, _, _ = self.env.step(action)</span><br><span class="line">                self.model.rewards.append(reward)</span><br><span class="line">                ep_reward += reward</span><br><span class="line">                <span class="keyword">if</span> done:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            running_reward = <span class="number">0.05</span> * ep_reward + (<span class="number">1</span> - <span class="number">0.05</span>) * running_reward</span><br><span class="line"></span><br><span class="line">            self.finish_episode()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># log results</span></span><br><span class="line">            <span class="keyword">if</span> i_episode % args.log_interval == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Episode &#123;&#125;\tLast reward: &#123;:.2f&#125;\tAverage reward: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(i_episode, ep_reward, running_reward))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># check if we have &quot;solved&quot; the cart pole problem</span></span><br><span class="line">            <span class="keyword">if</span> running_reward &gt; self.env.spec.reward_threshold:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Solved! Running reward is now &#123;&#125; and &quot;</span> <span class="string">&quot;the last episode runs to &#123;&#125; time steps!&quot;</span>.<span class="built_in">format</span>(running_reward, t))</span><br><span class="line">                <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>完整代码见<a href="https://github.com/pytorch/examples/blob/main/reinforcement_learning/actor_critic.py">这里</a>。运行以上算法可以看到以下日志：</p>
<blockquote>
<p>Episode 10      Last reward: 32.00      Average reward: 14.11<br />
Episode 20      Last reward: 89.00      Average reward: 32.64<br />
Episode 30      Last reward: 20.00      Average reward: 45.73<br />
Episode 40      Last reward: 32.00      Average reward: 47.44<br />
Episode 50      Last reward: 332.00     Average reward: 142.78<br />
Episode 60      Last reward: 410.00     Average reward: 428.13<br />
Solved! Running reward is now 476.8880228063767 and the last episode runs to 1334 time steps!</p>
</blockquote>
<p>可以看到算法在经历60多次的迭代之后就有一个很好的效果了。</p>
<h2 id="chatgpt的rlhf算法"><a class="markdownIt-Anchor" href="#chatgpt的rlhf算法"></a> ChatGPT的RLHF算法</h2>
<p>ColossalAI中使用的强化学习算法与上述算法基本一致，完整代码的入口在<a href="https://github.com/hpcaitech/ColossalAI/blob/main/applications/Chat/examples/train_prompts.py">这里</a>， 代码比较长，以下是简化后的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">args</span>):</span><br><span class="line">    strategy = ColossalAIStrategy(stage=<span class="number">2</span>, placement_policy=<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">    <span class="keyword">with</span> strategy.model_init_context():</span><br><span class="line">        initial_model = LlamaActor(pretrained=args.pretrain)</span><br><span class="line">        reward_model = LlamaRM(pretrained=args.rm_pretrain)</span><br><span class="line">        actor = LlamaActor(pretrained=args.pretrain, lora_rank=args.lora_rank)</span><br><span class="line">        critic = LlamaCritic(pretrained=args.rm_pretrain, lora_rank=args.lora_rank, use_action_mask=<span class="literal">True</span>)</span><br><span class="line">    actor_optim = HybridAdam(actor.parameters(), lr=<span class="number">1e-7</span>)</span><br><span class="line">    critic_optim = HybridAdam(critic.parameters(), lr=<span class="number">1e-7</span>)</span><br><span class="line">    tokenizer = LlamaTokenizer.from_pretrained(args.pretrain)</span><br><span class="line">    tokenizer = prepare_llama_tokenizer_and_embedding(tokenizer, actor)</span><br><span class="line"></span><br><span class="line">    prompt_dataset = PromptDataset(tokenizer=tokenizer, data_path=args.prompt_dataset, max_datasets_size=<span class="number">16384</span>)</span><br><span class="line">    prompt_dataloader = DataLoader(prompt_dataset, ...)</span><br><span class="line">    pretrain_dataset = SupervisedDataset(tokenizer=tokenizer, ...)</span><br><span class="line">    pretrain_dataloader = DataLoader(pretrain_dataset, ...)</span><br><span class="line"></span><br><span class="line">    (actor, actor_optim), (critic, critic_optim) = strategy.prepare((actor, actor_optim), (critic, critic_optim))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># configure trainer</span></span><br><span class="line">    trainer = PPOTrainer(strategy, actor, critic, reward_model, initial_model, ...)</span><br><span class="line">    trainer.fit(prompt_dataloader, pretrain_dataloader, args.num_episodes, ...)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Critic</span>(<span class="title class_ inherited__">LoRAModule</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ...</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        ...</span><br><span class="line">        self.convert_to_lora()  <span class="comment"># 将Critic模型转换为LoRA模型</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, sequences: torch.LongTensor, action_mask, attention_mask</span>) -&gt; torch.Tensor:</span><br><span class="line">        outputs = self.model(sequences, attention_mask=attention_mask)  <span class="comment"># 模型前向传播</span></span><br><span class="line">        <span class="comment"># 获取最后一层隐藏状态，并通过value_head线性层得到值函数估计值</span></span><br><span class="line">        last_hidden_states = outputs[<span class="string">&#x27;last_hidden_state&#x27;</span>]</span><br><span class="line">        values = self.value_head(last_hidden_states).squeeze(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> action_mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> self.use_action_mask:</span><br><span class="line">            num_actions = action_mask.size(<span class="number">1</span>)</span><br><span class="line">            prompt_mask = attention_mask[:, :-num_actions]</span><br><span class="line">            values = values[:, :-num_actions]</span><br><span class="line">            value = masked_mean(values, prompt_mask, dim=<span class="number">1</span>) <span class="comment"># 根据动作掩码计算平均值</span></span><br><span class="line">            <span class="keyword">return</span> value</span><br><span class="line"></span><br><span class="line">        values = values[:, :-<span class="number">1</span>]</span><br><span class="line">        value = values.mean(dim=<span class="number">1</span>)  <span class="comment"># 计算平均值作为最终的评论家函数估计值</span></span><br><span class="line">        <span class="keyword">return</span> value</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LlamaCritic</span>(<span class="title class_ inherited__">Critic</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ...</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        model = LlamaModel.from_pretrained(pretrained)  <span class="comment"># 使用预训练的LlamaModel初始化模型</span></span><br><span class="line">        value_head = nn.Linear(model.config.hidden_size, <span class="number">1</span>)  <span class="comment"># 使用线性层作为评论家函数头部</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Actor</span>(<span class="title class_ inherited__">LoRAModule</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model: nn.Module, ...</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.convert_to_lora()  <span class="comment"># 将Actor模型转换为LoRA模型</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @torch.no_grad()</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">generate</span>(<span class="params">self, input_ids: torch.Tensor, return_action_mask: <span class="built_in">bool</span> = <span class="literal">True</span>, **kwargs</span>):</span><br><span class="line">        sequences = generate(self.model, input_ids, **kwargs)  <span class="comment"># 生成序列</span></span><br><span class="line">        attention_mask = <span class="literal">None</span></span><br><span class="line">        attention_mask = sequences.not_equal(pad_token_id)  <span class="comment"># 生成注意力掩码</span></span><br><span class="line">        <span class="comment"># left padding may be applied, only mask action</span></span><br><span class="line">        action_mask = (sequences[:, input_len:] == eos_token_id).cumsum(dim=-<span class="number">1</span>) == <span class="number">0</span>  <span class="comment"># 生成动作掩码</span></span><br><span class="line">        action_mask = F.pad(action_mask, (<span class="number">1</span> + input_len, -<span class="number">1</span>), value=<span class="literal">True</span>)    <span class="comment"># include eos token and input</span></span><br><span class="line">        action_mask[:, :input_len] = <span class="literal">False</span></span><br><span class="line">        action_mask = action_mask[:, <span class="number">1</span>:]</span><br><span class="line">        <span class="comment"># 返回生成的序列、注意力掩码和动作掩码</span></span><br><span class="line">        <span class="keyword">return</span> sequences, attention_mask, action_mask[:, -(sequences.size(<span class="number">1</span>) - input_len):]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, sequences: torch.LongTensor, num_actions: <span class="built_in">int</span>, attention_mask</span>):</span><br><span class="line">        output = self.model(sequences, attention_mask=attention_mask)  <span class="comment"># 模型前向传播</span></span><br><span class="line">        <span class="comment"># 从logits计算动作的对数概率</span></span><br><span class="line">        log_probs = log_probs_from_logits(output[<span class="string">&#x27;logits&#x27;</span>][:, :-<span class="number">1</span>, :], sequences[:, <span class="number">1</span>:])</span><br><span class="line">        <span class="keyword">return</span> log_probs[:, -num_actions:]  <span class="comment"># 返回动作的对数概率</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LlamaActor</span>(<span class="title class_ inherited__">Actor</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ...</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        model = LlamaForCausalLM.from_pretrained(pretrained)  <span class="comment"># 使用预训练的LlamaForCausalLM初始化模型</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PPOTrainer</span>(<span class="title class_ inherited__">Trainer</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ...</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># 初始化PPO训练器的各个组件和参数</span></span><br><span class="line">        self.experience_maker = NaiveExperienceMaker(actor, critic, reward_model, initial_model, kl_coef)</span><br><span class="line">        self.replay_buffer = NaiveReplayBuffer(train_batch_size, buffer_limit, buffer_cpu_offload)</span><br><span class="line"></span><br><span class="line">        self.actor = actor</span><br><span class="line">        self.critic = critic</span><br><span class="line"></span><br><span class="line">        self.actor_loss_fn = PolicyLoss(eps_clip)  <span class="comment"># 演员损失函数</span></span><br><span class="line">        self.critic_loss_fn = ValueLoss(value_clip)  <span class="comment"># 评论家损失函数</span></span><br><span class="line">        self.vf_coef = vf_coef</span><br><span class="line">        self.ptx_loss_fn = GPTLMLoss()  <span class="comment"># 预训练损失函数</span></span><br><span class="line">        self.ptx_coef = ptx_coef</span><br><span class="line">        self.actor_optim = actor_optim   <span class="comment"># 演员网络的优化器</span></span><br><span class="line">        self.critic_optim = critic_optim  <span class="comment"># 评论家网络的优化器</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_learn</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 根据是否使用重放缓冲区选择不同的训练方式</span></span><br><span class="line">        <span class="keyword">if</span> self.sample_replay_buffer:</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self.max_epochs):</span><br><span class="line">                experience = self.replay_buffer.sample()  <span class="comment"># 从重放缓冲区中采样经验</span></span><br><span class="line">                metrics = self.training_step(experience)  <span class="comment"># 执行训练步骤</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(self.max_epochs):</span><br><span class="line">                <span class="keyword">for</span> experience <span class="keyword">in</span> dataloader:  <span class="comment"># 从数据集中获取经验</span></span><br><span class="line">                    metrics = self.training_step(experience)  <span class="comment"># 执行训练步骤</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, prompt_dataloader, pretrain_dataloader</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        time = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> episode <span class="keyword">in</span> <span class="built_in">range</span>(num_episodes):</span><br><span class="line">            <span class="keyword">for</span> timestep <span class="keyword">in</span> <span class="built_in">range</span>(max_timesteps):</span><br><span class="line">                time += <span class="number">1</span></span><br><span class="line">                prompts = <span class="built_in">next</span>(<span class="built_in">iter</span>(self.prompt_dataloader))  <span class="comment"># 获取输入提示数据</span></span><br><span class="line">                <span class="comment"># 生成经验，这里可以支持在线和人进行对话</span></span><br><span class="line">                experience = self.experience_maker.make_experience(prompts, **self.generate_kwargs)</span><br><span class="line">                self.replay_buffer.append(experience)  <span class="comment"># 将经验添加到重放缓冲区</span></span><br><span class="line">                <span class="keyword">if</span> time % update_timesteps == <span class="number">0</span>:</span><br><span class="line">                    self._learn()  <span class="comment"># 执行模型更新</span></span><br><span class="line">                    self.replay_buffer.clear()  <span class="comment"># 清空重放缓冲区</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">training_step</span>(<span class="params">self, experience: Experience</span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">float</span>]:</span><br><span class="line">        self.actor.train()  <span class="comment"># 设置演员网络为训练模式</span></span><br><span class="line">        self.critic.train()  <span class="comment"># 设置评论家网络为训练模式</span></span><br><span class="line">        <span class="comment"># 计算演员网络的动作对数概率</span></span><br><span class="line">        num_actions = experience.action_mask.size(<span class="number">1</span>)</span><br><span class="line">        action_log_probs = self.actor(experience.sequences, num_actions, attention_mask=experience.attention_mask)</span><br><span class="line">        <span class="comment"># 计算演员损失函数</span></span><br><span class="line">        actor_loss = self.actor_loss_fn(</span><br><span class="line">            action_log_probs, experience.action_log_probs, experience.advantages, experience.action_mask)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算预训练损失函数</span></span><br><span class="line">        <span class="keyword">if</span> self.ptx_coef != <span class="number">0</span>:</span><br><span class="line">            batch = <span class="built_in">next</span>(<span class="built_in">iter</span>(self.pretrain_dataloader))</span><br><span class="line">            ptx_log_probs = self.actor.get_base_model()(batch[<span class="string">&#x27;input_ids&#x27;</span>],</span><br><span class="line">                                                        attention_mask=batch[<span class="string">&#x27;attention_mask&#x27;</span>])[<span class="string">&#x27;logits&#x27;</span>]</span><br><span class="line">            ptx_loss = self.ptx_loss_fn(ptx_log_probs, batch[<span class="string">&#x27;labels&#x27;</span>])</span><br><span class="line">            actor_loss = ptx_loss * self.ptx_coef + actor_loss * (<span class="number">1</span> - self.ptx_coef)</span><br><span class="line"></span><br><span class="line">        self.strategy.backward(actor_loss, self.actor, self.actor_optim)  <span class="comment"># 演员网络的反向传播</span></span><br><span class="line">        self.strategy.optimizer_step(self.actor_optim)  <span class="comment"># 演员网络的优化器步骤</span></span><br><span class="line">        self.actor_optim.zero_grad()  <span class="comment"># 清空演员网络的梯度</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算评论家损失函数</span></span><br><span class="line">        values = self.critic(experience.sequences, experience.action_mask, experience.attention_mask)</span><br><span class="line">        critic_loss = self.critic_loss_fn(values, experience.values, experience.reward, experience.action_mask)</span><br><span class="line">        critic_loss = critic_loss * self.vf_coef</span><br><span class="line">        self.strategy.backward(critic_loss, self.critic, self.critic_optim)  <span class="comment"># 评论家网络的反向传播</span></span><br><span class="line">        self.strategy.optimizer_step(self.critic_optim)  <span class="comment"># 评论家网络的优化器步骤</span></span><br><span class="line">        self.critic_optim.zero_grad()  <span class="comment"># 清空评论家网络的梯度</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GPTLMLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.loss = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, logits: torch.Tensor, labels: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="comment"># 将logits向左移动一位，去掉最后一个时间步的预测</span></span><br><span class="line">        shift_logits = logits[..., :-<span class="number">1</span>, :].contiguous()</span><br><span class="line">        <span class="comment"># 将标签向右移动一位，去掉第一个时间步的标签</span></span><br><span class="line">        shift_labels = labels[..., <span class="number">1</span>:].contiguous()</span><br><span class="line">        <span class="comment"># 计算交叉熵损失</span></span><br><span class="line">        <span class="keyword">return</span> self.loss(shift_logits.view(-<span class="number">1</span>, shift_logits.size(-<span class="number">1</span>)), shift_labels.view(-<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PolicyLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, clip_eps: <span class="built_in">float</span> = <span class="number">0.2</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.clip_eps = clip_eps</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, log_probs, old_log_probs, advantages, action_mask</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="comment"># 计算当前动作对数概率和旧动作对数概率的比例</span></span><br><span class="line">        ratio = (log_probs - old_log_probs).exp()</span><br><span class="line">        surr1 = ratio * advantages  <span class="comment"># 第一项损失计算</span></span><br><span class="line">        surr2 = ratio.clamp(<span class="number">1</span> - self.clip_eps, <span class="number">1</span> + self.clip_eps) * advantages <span class="comment"># 第二项损失计算</span></span><br><span class="line">        loss = -torch.<span class="built_in">min</span>(surr1, surr2)  <span class="comment"># 选取较小的损失</span></span><br><span class="line">        <span class="keyword">if</span> action_mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            loss = masked_mean(loss, action_mask)  <span class="comment"># 根据动作掩码计算平均损失</span></span><br><span class="line">        loss = loss.mean()  <span class="comment"># 计算平均损失</span></span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ValueLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, clip_eps: <span class="built_in">float</span> = <span class="number">0.4</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.clip_eps = clip_eps</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, values, old_values, reward, action_mask</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="comment"># 对奖励进行裁剪</span></span><br><span class="line">        values_clipped = old_values + (values - old_values).clamp(-self.clip_eps, self.clip_eps)</span><br><span class="line">        surr1 = (values_clipped - reward)**<span class="number">2</span>  <span class="comment"># 第一项损失计算</span></span><br><span class="line">        surr2 = (values - reward)**<span class="number">2</span> <span class="comment"># 第二项损失计算</span></span><br><span class="line">        loss = torch.<span class="built_in">max</span>(surr1, surr2)  <span class="comment"># 选取较大的损失</span></span><br><span class="line">        loss = loss.mean()  <span class="comment"># 计算平均损失</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.5</span> * loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NaiveExperienceMaker</span>(<span class="title class_ inherited__">ExperienceMaker</span>):</span><br><span class="line"><span class="meta">    @torch.no_grad()</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">make_experience</span>(<span class="params">self, input_ids: torch.Tensor, **generate_kwargs</span>) -&gt; Experience:</span><br><span class="line">        <span class="comment"># 基于演员函数生成回复及掩码</span></span><br><span class="line">        sequences, attention_mask, action_mask = self.actor.generate(input_ids, ...)</span><br><span class="line">        num_actions = action_mask.size(<span class="number">1</span>)  <span class="comment"># 获取动作的数量</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算动作的对数概率</span></span><br><span class="line">        action_log_probs = self.actor(sequences, num_actions, attention_mask)</span><br><span class="line">        <span class="comment"># 使用初始模型计算动作的对数概率</span></span><br><span class="line">        base_action_log_probs = self.initial_model(sequences, num_actions, attention_mask)</span><br><span class="line">        <span class="comment"># 计算价值</span></span><br><span class="line">        value = self.critic(sequences, action_mask, attention_mask)</span><br><span class="line">        <span class="comment"># 计算基础奖励值</span></span><br><span class="line">        r = self.reward_model(sequences, attention_mask)</span><br><span class="line">        <span class="comment"># 基于动作概率调整奖励值</span></span><br><span class="line">        reward = compute_reward(r, self.kl_coef, action_log_probs, base_action_log_probs, action_mask=action_mask)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算优势函数</span></span><br><span class="line">        advantage = reward - value</span><br><span class="line">        <span class="keyword">return</span> Experience(...)  <span class="comment"># 返回经验</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_reward</span>(<span class="params">r, kl_coef, log_probs, log_probs_base, action_mask</span>) -&gt; torch.Tensor:</span><br><span class="line">    kl = compute_approx_kl(log_probs, log_probs_base, action_mask=action_mask)  <span class="comment"># 计算KL散度</span></span><br><span class="line">    reward = r - kl_coef * kl  <span class="comment"># 计算奖励</span></span><br><span class="line">    <span class="keyword">return</span> reward</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_approx_kl</span>(<span class="params">log_probs, log_probs_base, action_mask</span>) -&gt; torch.Tensor:</span><br><span class="line">    log_ratio = log_probs - log_probs_base  <span class="comment"># 计算对数概率之间的差异</span></span><br><span class="line">    approx_kl = (log_ratio.exp() - <span class="number">1</span>) - log_ratio  <span class="comment"># 计算近似KL散度</span></span><br><span class="line">    <span class="keyword">if</span> action_mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        approx_kl = masked_mean(approx_kl, action_mask, dim=<span class="number">1</span>)  <span class="comment"># 根据动作掩码计算平均KL散度</span></span><br><span class="line">        <span class="keyword">return</span> approx_kl</span><br><span class="line">    approx_kl = approx_kl.mean(dim=<span class="number">1</span>)  <span class="comment"># 计算平均KL散度</span></span><br><span class="line">    <span class="keyword">return</span> approx_kl</span><br></pre></td></tr></table></figure>
<p>上述代码中用到了KL散度。KL散度（Kullback-Leibler divergence）是一种用于衡量两个概率分布之间差异的指标。在信息论和统计学中广泛应用。</p>
<p>给定两个离散概率分布P和Q，它们的KL散度定义为：<code>KL(P || Q) = Σ P(i) * log(P(i) / Q(i))</code> 其中，P(i)和Q(i)分别表示P和Q在第i个事件上的概率。</p>
<p>KL散度不具备对称性，即KL(P || Q) ≠ KL(Q || P)。它度量的是从P到Q的信息损失或差异。KL散度的值为非负数，当且仅当P和Q相等时，KL散度等于0。当P和Q之间的差异增大时，KL散度的值也会增大。</p>
<p>在深度学习中，KL散度常用于衡量生成模型生成的样本分布与真实数据分布之间的差异。通过最小化KL散度，可以使生成模型逼近真实数据分布，从而提高生成样本的质量。在上述代码中，KL散度被用于计算奖励信号。通过比较动作对数概率与基准动作对数概率之间的差异，可以衡量动作选择与基准模型之间的差异程度，进而调整奖励的大小。</p>
<h3 id="rlhf算法总结"><a class="markdownIt-Anchor" href="#rlhf算法总结"></a> RLHF算法总结</h3>
<p>回顾RLHF算法的过程，可以看到，由于我们之前训练了一个奖励函数，RLHF算法在执行过程中，可以没有人类的参与而自动进行。奖励函数代替人给出了对于模型生成的回复的质量的反馈。</p>
<p>到这里，大家可以理解为什么ChatGPT可以如此智能的回复大家的任意的自然语言问题了吧？OpenAI开放ChatGPT模型给大家使用，随着大家使用越多，OpenAI就可以根据RLHF的算法让模型接触到更多的对话，从而基于这些对话自动的优化ChatGPT！</p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>到这里，我们就分析完了所有的ChatGPT类模型的训练和微调、RLHF微调的代码。在分析代码时，我们有意忽略了很多细节及模型并行处理的部分代码，这些对于我们理解模型帮助不大。</p>
<p>到这里大家应该对ChatGPT类模型的训练有一个较为深入的认识了。</p>
<p>自ChatGPT发布以来，很多人认为这是一个人类走向通用人工智能的突破，也有一些人认为它其实没什么本质的改进。有很多人对自己的职业发展产生了很深的焦虑感，也有很多人感觉触碰到了科幻世界中的未来，还有很多人觉得又是一个可以好好捞一把的机会。</p>
<p>也许每个人都有必要去了解一下机器学习技术的原理，这样才能形成对它的理性的认知。</p>
<p>ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。</p>
<p>这是此系列的第五篇，ChatGPT的自动优化。</p>
<h2 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h2>
<ul>
<li>alpaca博客介绍：<a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">https://crfm.stanford.edu/2023/03/13/alpaca.html</a></li>
<li>LLAMA Paper：<a href="https://arxiv.org/abs/2302.13971v1">https://arxiv.org/abs/2302.13971v1</a></li>
<li>Self-Instruct: Aligning Language Model with Self Generated Instructions：<a href="https://arxiv.org/abs/2212.10560">https://arxiv.org/abs/2212.10560</a></li>
<li>Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality: <a href="https://lmsys.org/blog/2023-03-30-vicuna/">https://lmsys.org/blog/2023-03-30-vicuna/</a></li>
<li>OpenAI开发的ChatGPT资料（Training language models to follow instructions<br />
with human feedback）： <a href="https://arxiv.org/pdf/2203.02155.pdf">https://arxiv.org/pdf/2203.02155.pdf</a></li>
<li>OpenAI开放的GPT-3资料（Language Models are Few-Shot Learners）: <a href="https://arxiv.org/pdf/2005.14165.pdf">https://arxiv.org/pdf/2005.14165.pdf</a></li>
<li>OpenAI开放的GPT-2资料（Language Models are Unsupervised Multitask Learners）: <a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf">https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf</a></li>
<li>OpenAI开放的GPT资料（Improving Language Understanding by Generative Pre-Training): <a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf</a></li>
</ul>
]]></content>
      <categories>
        <category>machine-learning</category>
        <category>ChatGPT</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>机器学习</tag>
        <tag>强化学习</tag>
        <tag>ML</tag>
        <tag>ChatGPT</tag>
      </tags>
  </entry>
</search>
