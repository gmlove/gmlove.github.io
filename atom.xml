<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Bright LGM&#39;s Blog</title>
  
  <subtitle>Code speaks.</subtitle>
  <link href="http://brightliao.com/atom.xml" rel="self"/>
  
  <link href="http://brightliao.com/"/>
  <updated>2023-06-16T09:54:15.242Z</updated>
  <id>http://brightliao.com/</id>
  
  <author>
    <name>Bright LGM</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ChatGPT的自动优化</title>
    <link href="http://brightliao.com/2023/05/25/chatgpt-rlhf/"/>
    <id>http://brightliao.com/2023/05/25/chatgpt-rlhf/</id>
    <published>2023-05-25T12:00:00.000Z</published>
    <updated>2023-06-16T09:54:15.242Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>作为一个一直对AI技术很感兴趣的软件开发工程师，早在深度学习开始火起来的15、16年，我也开始了相关技术的学习。当时还组织了公司内部同样有兴趣的同学一起研究，最终的成果汇集成几次社区中的分享以及几篇学习文章（见<a href="https://brightliao.com/tags/ai/">这里</a>）。</p><p>从去年OpenAI发布ChatGPT以来，AI的能力再次惊艳了世人。在这样的一个时间节点，重新去学习相关技术显得很有必要。</p><p>ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。</p><p>ChatGPT本身就具备很丰富的知识，所以ChatGPT自身实际上就是一个很好的学习渠道，我也将借助ChatGPT来学习ChatGPT。</p><p>这是此系列的第五篇，ChatGPT的自动优化。</p><span id="more"></span><p><a href="https://brightliao.com/2023/05/18/2023-05-18-chatgpt-transformer/">上一篇</a>文章我们深入分析了ChatGPT是如何训练及优化的，了解了如何进行监督微调，及如何让模型可以支持更广泛领域的问答。但是，监督微调始终会限于训练集中的问题模板数量，无法支持更为一般的对话。这一步骤就需要引入强化学习的训练方式，让ChatGPT可以自动进行优化。</p><h2 id="介绍"><a class="markdownIt-Anchor" href="#介绍"></a> 介绍</h2><p>强化学习模型是最为复杂的部分，参考ColossalAI的文档，模型的工作原理如下：</p><p><img data-src="/attaches/2023/2023-05-25-chatgpt-rlhf/rlhf.jpeg" alt="RLHF" /></p><p>为了理解上图，需要先了解一下强化学习相关的背景知识。</p><h3 id="强化学习"><a class="markdownIt-Anchor" href="#强化学习"></a> 强化学习</h3><p>强化学习（Reinforcement Learning，简称RL）是一种机器学习方法，旨在使智能体（agent）通过与环境的交互来学习适应环境并制定实现特定目标的策略。在强化学习中，智能体通过观察环境的状态，执行动作，并接收环境的奖励或惩罚来不断调整自己的策略，以获得最大化累积奖励的能力。</p><p>强化学习的基本要素包括：</p><ul><li><strong>智能体（Agent）</strong>：智能体是进行学习和决策的主体，它通过观察环境的状态、选择合适的动作，并与环境进行交互。</li><li><strong>环境（Environment）</strong>：环境是智能体所处的外部世界，它可以是真实的物理环境，也可以是抽象的模拟环境。环境会根据智能体的动作进行状态转移，并根据智能体的表现给予奖励或惩罚。</li><li><strong>状态（State）</strong>：状态是描述环境的特征或信息，它可以是完全观察的，也可以是部分观察或隐含的。智能体的决策往往基于当前状态。</li><li><strong>动作（Action）</strong>：动作是智能体在某个状态下可以执行的操作或策略。智能体的目标是根据当前状态选择最优的动作。</li><li><strong>奖励（Reward）</strong>：奖励是环境根据智能体的动作和表现给予的反馈信号，用于指示动作的好坏。智能体的目标是通过最大化累积奖励来学习合适的策略。</li></ul><p>在ChatGPT这个场景中，ChatGPT模型即智能体，环境是一个对话系统，状态是当前对话的上下文及当前消息，动作是如何选择某一个回复，奖励是人类反馈的回复质量好或差。</p><p>强化学习的核心问题是通过智能体与环境的交互来学习一个最优的策略，以使智能体在长期累积奖励的过程中能够获得最大化的回报。强化学习算法通常基于价值函数或策略函数来进行决策和优化，其中价值函数用于评估状态或状态动作对的价值，策略函数用于指导智能体在特定状态下选择动作。</p><p>强化学习常常应用于机器人控制、游戏智能、自动驾驶等领域。</p><h3 id="强化学习算法"><a class="markdownIt-Anchor" href="#强化学习算法"></a> 强化学习算法</h3><p>如何学习最优策略呢？常见的学习算法包括Q-learning、SARSA、Deep Q-Network（DQN）、Policy Gradient、Proximal Policy Optimization（PPO）、Actor-Critic等。</p><p>以下简要介绍和RLHF相关的算法：</p><ul><li>Q-learning: 核心思想是学习一个状态-动作价值函数（Q函数），它衡量在给定状态下采取特定动作的长期累积回报。可根据贝尔曼公式 <code>Q(s,a) = Q(s,a) + α(r + γ * max(Q(s',a')) - Q(s,a))</code> 更新及优化Q函数，其中α是学习率，γ是折扣因子，r是奖励，s’是新的状态。</li><li>Policy Gradient（策略梯度）算法: 不需要建立值函数模型，而是直接优化策略（动作的选择）。其基本思想是通过采样经验轨迹（trajectory），通过最大化累积奖励来计算策略梯度，并利用梯度信息更新策略参数。</li><li>Proximal Policy Optimization（PPO）：一种基于策略梯度的强化学习算法，旨在通过有效地优化策略函数（通过引入一个重要性采样比率和一个剪切函数来限制策略更新的幅度，以保持策略的相对不变性）来提高强化学习的性能和稳定性。</li><li>Actor-Critic（演员-评论家）算法：结合了值函数和策略函数的强化学习算法。它通过同时学习一个策略函数（演员）和一个值函数（评论家），以提高强化学习的效率和性能。演员根据评论家的评估结果来更新策略，从而改进策略的质量。评论家则通过学习一个值函数来估计每个状态的值或动作值，以提供演员关于策略改进的反馈。</li></ul><p>RLHF算法结合了PPO和Actor-Critic算法的优势，所以可以高效而又稳定的优化ChatGPT的模型。</p><h2 id="代码分析"><a class="markdownIt-Anchor" href="#代码分析"></a> 代码分析</h2><p>有了前面的了解，下面咱们跟着代码一起来了解一下算法的细节。</p><h3 id="使用pytorch实现policy-gradient"><a class="markdownIt-Anchor" href="#使用pytorch实现policy-gradient"></a> 使用PyTorch实现Policy Gradient</h3><p>下面来看PyTorch的示例中提供的一个参考的策略梯度算法实现。</p><p>先介绍一下<code>gym</code>库，这个库提供了一个模拟环境，内置了很多小游戏，可以帮助我们开发强化学习算法。</p><p>比如下面这个平衡杆小游戏，我们要想办法控制平衡杆使其一直位于连接点的上方。有两个动作可以用来控制游戏中的连接点，即左和右。控制连接点向左时，可以避免平衡杆往左倾倒。控制连接点向右时，可以避免平衡杆往右倾倒。</p><p><img data-src="/attaches/2023/2023-05-25-chatgpt-rlhf/cartpole.png" alt="Cart Pole" /></p><p>下面来用策略梯度的方法训练一个强化学习算法让机器人自动玩游戏。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Policy</span>(nn.Module): <span class="comment"># 定义策略函数网络，输出每个动作对应的概率</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Policy, self).__init__()</span><br><span class="line">        <span class="comment"># 定义网络结构，包含了两层线性连接层，第二层输出的动作数量为2</span></span><br><span class="line">        self.affine1 = nn.Linear(<span class="number">4</span>, <span class="number">128</span>)</span><br><span class="line">        self.dropout = nn.Dropout(p=<span class="number">0.6</span>)</span><br><span class="line">        self.affine2 = nn.Linear(<span class="number">128</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.saved_log_probs = []</span><br><span class="line">        self.rewards = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(self.dropout(self.affine1(x)))</span><br><span class="line">        action_scores = self.affine2(x)</span><br><span class="line">        <span class="keyword">return</span> F.softmax(action_scores, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PolicyTrainer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 初始化游戏环境</span></span><br><span class="line">        self.env = gym.make(<span class="string">&quot;CartPole-v1&quot;</span>, render_mode=<span class="string">&quot;rgb_array&quot;</span>)</span><br><span class="line">        <span class="comment"># 初始化策略函数网络及优化器</span></span><br><span class="line">        self.policy = Policy()</span><br><span class="line">        self.optimizer = optim.Adam(self.policy.parameters(), lr=<span class="number">1e-2</span>)</span><br><span class="line">        self.eps = np.finfo(np.float32).eps.item()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">select_action</span>(<span class="params">self, state</span>):</span><br><span class="line">        <span class="comment"># 根据当前的状态，执行策略函数，并根据函数输出的概率选择一个动作</span></span><br><span class="line">        state = torch.from_numpy(state).<span class="built_in">float</span>().unsqueeze(<span class="number">0</span>)</span><br><span class="line">        probs = self.policy(state)</span><br><span class="line">        m = Categorical(probs)</span><br><span class="line">        action = m.sample()</span><br><span class="line">        <span class="comment"># 将动作保存起来，在一局游戏结束的时候，用于训练</span></span><br><span class="line">        self.policy.saved_log_probs.append(m.log_prob(action))</span><br><span class="line">        <span class="keyword">return</span> action.item()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">finish_episode</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 在一局游戏结束的时候，执行策略函数的训练</span></span><br><span class="line">        <span class="comment"># 根据执行动作时保存的奖励，来迭代计算每一个动作的奖励</span></span><br><span class="line">        <span class="comment"># 每一个动作的奖励 = 当前奖励 + 折扣率 * 整局游戏中将来的奖励</span></span><br><span class="line">        R = <span class="number">0</span></span><br><span class="line">        returns = deque()</span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> self.policy.rewards[::-<span class="number">1</span>]:</span><br><span class="line">            R = r + args.gamma * R</span><br><span class="line">            returns.appendleft(R)</span><br><span class="line">        returns = torch.tensor(returns)</span><br><span class="line">        <span class="comment"># 将奖励归一化</span></span><br><span class="line">        returns = (returns - returns.mean()) / (returns.std() + self.eps)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 采用梯度上升法最大化策略奖励，这里使用最小化策略奖励的负数来实现</span></span><br><span class="line">        policy_loss = []</span><br><span class="line">        <span class="keyword">for</span> log_prob, R <span class="keyword">in</span> <span class="built_in">zip</span>(self.policy.saved_log_probs, returns):</span><br><span class="line">            <span class="comment"># 计算每一个动作的策略损失，策略损失 = -动作概率 * 动作奖励</span></span><br><span class="line">            policy_loss.append(-log_prob * R)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 根据整局游戏的结果来计算梯度，并更新参数</span></span><br><span class="line">        self.optimizer.zero_grad()</span><br><span class="line">        policy_loss = torch.cat(policy_loss).<span class="built_in">sum</span>()</span><br><span class="line">        policy_loss.backward()</span><br><span class="line">        self.optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">del</span> self.policy.rewards[:]</span><br><span class="line">        <span class="keyword">del</span> self.policy.saved_log_probs[:]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self</span>):</span><br><span class="line">        running_reward = <span class="number">10</span></span><br><span class="line">        <span class="keyword">for</span> i_episode <span class="keyword">in</span> count(<span class="number">1</span>):</span><br><span class="line">            <span class="comment"># 新的一局游戏开始，初始化环境</span></span><br><span class="line">            state, _ = self.env.reset()</span><br><span class="line">            ep_reward = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10000</span>):  <span class="comment"># Don&#x27;t infinite loop while learning</span></span><br><span class="line">                <span class="comment"># 采用策略函数来生成下一步采用的动作，并执行</span></span><br><span class="line">                action = self.select_action(state)</span><br><span class="line">                state, reward, done, _, _ = self.env.step(action)</span><br><span class="line">                <span class="comment"># 记录奖励</span></span><br><span class="line">                self.policy.rewards.append(reward)</span><br><span class="line">                ep_reward += reward  <span class="comment"># 累计计算当前这一局游戏的奖励</span></span><br><span class="line">                <span class="keyword">if</span> done: <span class="comment"># 如果游戏结束，则退出循环</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 在一局游戏结束是，计算奖励的移动平均值</span></span><br><span class="line">            <span class="comment"># 这里将当前这一局游戏的奖励以5%的百分比给平衡掉，让我们更容易看出游戏当前能得到的奖励</span></span><br><span class="line">            running_reward = <span class="number">0.05</span> * ep_reward + (<span class="number">1</span> - <span class="number">0.05</span>) * running_reward</span><br><span class="line">            <span class="comment"># 触发策略网络更新</span></span><br><span class="line">            self.finish_episode()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 周期性打印日志</span></span><br><span class="line">            <span class="keyword">if</span> i_episode % args.log_interval == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Episode &#123;&#125;\tLast reward: &#123;:.2f&#125;\tAverage reward: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(i_episode, ep_reward, running_reward))</span><br><span class="line">            <span class="keyword">if</span> running_reward &gt; self.env.spec.reward_threshold:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Solved! Running reward is now &#123;&#125; and &quot;</span> <span class="string">&quot;the last episode runs to &#123;&#125; time steps!&quot;</span>.<span class="built_in">format</span>(running_reward, t))</span><br><span class="line">                <span class="keyword">break</span></span><br></pre></td></tr></table></figure><p>完整代码见<a href="https://github.com/pytorch/examples/blob/main/reinforcement_learning/reinforce.py">这里</a>。运行以上算法可以看到以下日志：</p><blockquote><p>Episode 10      Last reward: 21.00      Average reward: 16.30<br />Episode 20      Last reward: 41.00      Average reward: 24.02<br />Episode 30      Last reward: 33.00      Average reward: 33.05<br />Episode 40      Last reward: 64.00      Average reward: 50.71<br />Episode 50      Last reward: 73.00      Average reward: 59.70<br />Episode 60      Last reward: 41.00      Average reward: 63.28<br />Episode 70      Last reward: 59.00      Average reward: 63.88<br />Episode 80      Last reward: 86.00      Average reward: 80.87<br />Episode 90      Last reward: 125.00     Average reward: 91.54<br />Episode 100     Last reward: 224.00     Average reward: 136.09<br />Episode 110     Last reward: 95.00      Average reward: 182.31<br />Episode 120     Last reward: 200.00     Average reward: 170.03<br />Episode 130     Last reward: 80.00      Average reward: 149.48<br />Episode 140     Last reward: 102.00     Average reward: 148.63<br />Episode 150     Last reward: 644.00     Average reward: 349.26<br />Solved! Running reward is now 550.1608406568259 and the last episode runs to 2888 time steps!</p></blockquote><p>可以看到，在算法玩了150多次游戏的时候，已经可以玩得非常好了。但是我们也能注意到算法有一些波动，特别是在100局到110局时，曾经达到一个不错的水平，但是后来突然又有一些下降。</p><h3 id="使用pytorch实现actor-critic"><a class="markdownIt-Anchor" href="#使用pytorch实现actor-critic"></a> 使用PyTorch实现Actor-Critic</h3><p>Actor-Critic算法与Policy Gradient算法是类似的。下面看一下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line">SavedAction = namedtuple(<span class="string">&quot;SavedAction&quot;</span>, [<span class="string">&quot;log_prob&quot;</span>, <span class="string">&quot;value&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Policy</span>(nn.Module): <span class="comment"># 定义演员函数和评论家函数网络</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Policy, self).__init__()</span><br><span class="line">        self.affine1 = nn.Linear(<span class="number">4</span>, <span class="number">128</span>)</span><br><span class="line">        self.action_head = nn.Linear(<span class="number">128</span>, <span class="number">2</span>) <span class="comment"># 演员函数输出每个动作对应的概率</span></span><br><span class="line">        self.value_head = nn.Linear(<span class="number">128</span>, <span class="number">1</span>) <span class="comment"># 评论家函数输出每个动作对应的奖励</span></span><br><span class="line">        <span class="comment"># action &amp; reward buffer</span></span><br><span class="line">        self.saved_actions = []</span><br><span class="line">        self.rewards = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(self.affine1(x))</span><br><span class="line">        action_prob = F.softmax(self.action_head(x), dim=-<span class="number">1</span>)</span><br><span class="line">        state_values = self.value_head(x)</span><br><span class="line">        <span class="keyword">return</span> action_prob, state_values</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PolicyTrainer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.env = gym.make(<span class="string">&quot;CartPole-v1&quot;</span>)</span><br><span class="line">        self.model = Policy()</span><br><span class="line">        self.optimizer = optim.Adam(self.model.parameters(), lr=<span class="number">3e-2</span>)</span><br><span class="line">        self.eps = np.finfo(np.float32).eps.item()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">select_action</span>(<span class="params">self, state</span>):</span><br><span class="line">        state = torch.from_numpy(state).<span class="built_in">float</span>()</span><br><span class="line">        probs, state_value = self.model(state)</span><br><span class="line">        m = Categorical(probs)</span><br><span class="line">        action = m.sample()</span><br><span class="line">        self.model.saved_actions.append(SavedAction(m.log_prob(action), state_value))</span><br><span class="line">        <span class="keyword">return</span> action.item()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">finish_episode</span>(<span class="params">self</span>):</span><br><span class="line">        R = <span class="number">0</span></span><br><span class="line">        saved_actions = self.model.saved_actions</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算每一个步骤的奖励</span></span><br><span class="line">        returns = []</span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> self.model.rewards[::-<span class="number">1</span>]:</span><br><span class="line">            R = r + args.gamma * R</span><br><span class="line">            returns.insert(<span class="number">0</span>, R)</span><br><span class="line"></span><br><span class="line">        returns = torch.tensor(returns)</span><br><span class="line">        returns = (returns - returns.mean()) / (returns.std() + self.eps)</span><br><span class="line"></span><br><span class="line">        policy_losses = []</span><br><span class="line">        value_losses = []</span><br><span class="line">        <span class="keyword">for</span> (log_prob, value), R <span class="keyword">in</span> <span class="built_in">zip</span>(saved_actions, returns):</span><br><span class="line">            <span class="comment"># 计算真实奖励与评论家函数估计的奖励之差，并将其用于计算演员函数的损失</span></span><br><span class="line">            advantage = R - value.item()</span><br><span class="line">            policy_losses.append(-log_prob * advantage)</span><br><span class="line">            <span class="comment"># 评论家函数的损失使用平滑L1损失函数（与均方差损失类似，但更稳定）</span></span><br><span class="line">            value_losses.append(F.smooth_l1_loss(value, torch.tensor([R])))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算梯度并更新网络</span></span><br><span class="line">        self.optimizer.zero_grad()</span><br><span class="line">        loss = torch.stack(policy_losses).<span class="built_in">sum</span>() + torch.stack(value_losses).<span class="built_in">sum</span>()</span><br><span class="line">        loss.backward()</span><br><span class="line">        self.optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 清理数据</span></span><br><span class="line">        <span class="keyword">del</span> self.model.rewards[:]</span><br><span class="line">        <span class="keyword">del</span> self.model.saved_actions[:]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 训练过程与策略梯度方法类似</span></span><br><span class="line">        running_reward = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i_episode <span class="keyword">in</span> count(<span class="number">1</span>):</span><br><span class="line">            state, _ = self.env.reset()</span><br><span class="line">            ep_reward = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10000</span>):</span><br><span class="line">                action = self.select_action(state)</span><br><span class="line">                state, reward, done, _, _ = self.env.step(action)</span><br><span class="line">                self.model.rewards.append(reward)</span><br><span class="line">                ep_reward += reward</span><br><span class="line">                <span class="keyword">if</span> done:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            running_reward = <span class="number">0.05</span> * ep_reward + (<span class="number">1</span> - <span class="number">0.05</span>) * running_reward</span><br><span class="line"></span><br><span class="line">            self.finish_episode()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># log results</span></span><br><span class="line">            <span class="keyword">if</span> i_episode % args.log_interval == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Episode &#123;&#125;\tLast reward: &#123;:.2f&#125;\tAverage reward: &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(i_episode, ep_reward, running_reward))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># check if we have &quot;solved&quot; the cart pole problem</span></span><br><span class="line">            <span class="keyword">if</span> running_reward &gt; self.env.spec.reward_threshold:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Solved! Running reward is now &#123;&#125; and &quot;</span> <span class="string">&quot;the last episode runs to &#123;&#125; time steps!&quot;</span>.<span class="built_in">format</span>(running_reward, t))</span><br><span class="line">                <span class="keyword">break</span></span><br></pre></td></tr></table></figure><p>完整代码见<a href="https://github.com/pytorch/examples/blob/main/reinforcement_learning/actor_critic.py">这里</a>。运行以上算法可以看到以下日志：</p><blockquote><p>Episode 10      Last reward: 32.00      Average reward: 14.11<br />Episode 20      Last reward: 89.00      Average reward: 32.64<br />Episode 30      Last reward: 20.00      Average reward: 45.73<br />Episode 40      Last reward: 32.00      Average reward: 47.44<br />Episode 50      Last reward: 332.00     Average reward: 142.78<br />Episode 60      Last reward: 410.00     Average reward: 428.13<br />Solved! Running reward is now 476.8880228063767 and the last episode runs to 1334 time steps!</p></blockquote><p>可以看到算法在经历60多次的迭代之后就有一个很好的效果了。</p><h2 id="chatgpt的rlhf算法"><a class="markdownIt-Anchor" href="#chatgpt的rlhf算法"></a> ChatGPT的RLHF算法</h2><p>ColossalAI中使用的强化学习算法与上述算法基本一致，完整代码的入口在<a href="https://github.com/hpcaitech/ColossalAI/blob/main/applications/Chat/examples/train_prompts.py">这里</a>， 代码比较长，以下是简化后的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">args</span>):</span><br><span class="line">    strategy = ColossalAIStrategy(stage=<span class="number">2</span>, placement_policy=<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">    <span class="keyword">with</span> strategy.model_init_context():</span><br><span class="line">        initial_model = LlamaActor(pretrained=args.pretrain)</span><br><span class="line">        reward_model = LlamaRM(pretrained=args.rm_pretrain)</span><br><span class="line">        actor = LlamaActor(pretrained=args.pretrain, lora_rank=args.lora_rank)</span><br><span class="line">        critic = LlamaCritic(pretrained=args.rm_pretrain, lora_rank=args.lora_rank, use_action_mask=<span class="literal">True</span>)</span><br><span class="line">    actor_optim = HybridAdam(actor.parameters(), lr=<span class="number">1e-7</span>)</span><br><span class="line">    critic_optim = HybridAdam(critic.parameters(), lr=<span class="number">1e-7</span>)</span><br><span class="line">    tokenizer = LlamaTokenizer.from_pretrained(args.pretrain)</span><br><span class="line">    tokenizer = prepare_llama_tokenizer_and_embedding(tokenizer, actor)</span><br><span class="line"></span><br><span class="line">    prompt_dataset = PromptDataset(tokenizer=tokenizer, data_path=args.prompt_dataset, max_datasets_size=<span class="number">16384</span>)</span><br><span class="line">    prompt_dataloader = DataLoader(prompt_dataset, ...)</span><br><span class="line">    pretrain_dataset = SupervisedDataset(tokenizer=tokenizer, ...)</span><br><span class="line">    pretrain_dataloader = DataLoader(pretrain_dataset, ...)</span><br><span class="line"></span><br><span class="line">    (actor, actor_optim), (critic, critic_optim) = strategy.prepare((actor, actor_optim), (critic, critic_optim))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># configure trainer</span></span><br><span class="line">    trainer = PPOTrainer(strategy, actor, critic, reward_model, initial_model, ...)</span><br><span class="line">    trainer.fit(prompt_dataloader, pretrain_dataloader, args.num_episodes, ...)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Critic</span>(<span class="title class_ inherited__">LoRAModule</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ...</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        ...</span><br><span class="line">        self.convert_to_lora()  <span class="comment"># 将Critic模型转换为LoRA模型</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, sequences: torch.LongTensor, action_mask, attention_mask</span>) -&gt; torch.Tensor:</span><br><span class="line">        outputs = self.model(sequences, attention_mask=attention_mask)  <span class="comment"># 模型前向传播</span></span><br><span class="line">        <span class="comment"># 获取最后一层隐藏状态，并通过value_head线性层得到值函数估计值</span></span><br><span class="line">        last_hidden_states = outputs[<span class="string">&#x27;last_hidden_state&#x27;</span>]</span><br><span class="line">        values = self.value_head(last_hidden_states).squeeze(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> action_mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> self.use_action_mask:</span><br><span class="line">            num_actions = action_mask.size(<span class="number">1</span>)</span><br><span class="line">            prompt_mask = attention_mask[:, :-num_actions]</span><br><span class="line">            values = values[:, :-num_actions]</span><br><span class="line">            value = masked_mean(values, prompt_mask, dim=<span class="number">1</span>) <span class="comment"># 根据动作掩码计算平均值</span></span><br><span class="line">            <span class="keyword">return</span> value</span><br><span class="line"></span><br><span class="line">        values = values[:, :-<span class="number">1</span>]</span><br><span class="line">        value = values.mean(dim=<span class="number">1</span>)  <span class="comment"># 计算平均值作为最终的评论家函数估计值</span></span><br><span class="line">        <span class="keyword">return</span> value</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LlamaCritic</span>(<span class="title class_ inherited__">Critic</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ...</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        model = LlamaModel.from_pretrained(pretrained)  <span class="comment"># 使用预训练的LlamaModel初始化模型</span></span><br><span class="line">        value_head = nn.Linear(model.config.hidden_size, <span class="number">1</span>)  <span class="comment"># 使用线性层作为评论家函数头部</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Actor</span>(<span class="title class_ inherited__">LoRAModule</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model: nn.Module, ...</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.convert_to_lora()  <span class="comment"># 将Actor模型转换为LoRA模型</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @torch.no_grad()</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">generate</span>(<span class="params">self, input_ids: torch.Tensor, return_action_mask: <span class="built_in">bool</span> = <span class="literal">True</span>, **kwargs</span>):</span><br><span class="line">        sequences = generate(self.model, input_ids, **kwargs)  <span class="comment"># 生成序列</span></span><br><span class="line">        attention_mask = <span class="literal">None</span></span><br><span class="line">        attention_mask = sequences.not_equal(pad_token_id)  <span class="comment"># 生成注意力掩码</span></span><br><span class="line">        <span class="comment"># left padding may be applied, only mask action</span></span><br><span class="line">        action_mask = (sequences[:, input_len:] == eos_token_id).cumsum(dim=-<span class="number">1</span>) == <span class="number">0</span>  <span class="comment"># 生成动作掩码</span></span><br><span class="line">        action_mask = F.pad(action_mask, (<span class="number">1</span> + input_len, -<span class="number">1</span>), value=<span class="literal">True</span>)    <span class="comment"># include eos token and input</span></span><br><span class="line">        action_mask[:, :input_len] = <span class="literal">False</span></span><br><span class="line">        action_mask = action_mask[:, <span class="number">1</span>:]</span><br><span class="line">        <span class="comment"># 返回生成的序列、注意力掩码和动作掩码</span></span><br><span class="line">        <span class="keyword">return</span> sequences, attention_mask, action_mask[:, -(sequences.size(<span class="number">1</span>) - input_len):]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, sequences: torch.LongTensor, num_actions: <span class="built_in">int</span>, attention_mask</span>):</span><br><span class="line">        output = self.model(sequences, attention_mask=attention_mask)  <span class="comment"># 模型前向传播</span></span><br><span class="line">        <span class="comment"># 从logits计算动作的对数概率</span></span><br><span class="line">        log_probs = log_probs_from_logits(output[<span class="string">&#x27;logits&#x27;</span>][:, :-<span class="number">1</span>, :], sequences[:, <span class="number">1</span>:])</span><br><span class="line">        <span class="keyword">return</span> log_probs[:, -num_actions:]  <span class="comment"># 返回动作的对数概率</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LlamaActor</span>(<span class="title class_ inherited__">Actor</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ...</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        model = LlamaForCausalLM.from_pretrained(pretrained)  <span class="comment"># 使用预训练的LlamaForCausalLM初始化模型</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PPOTrainer</span>(<span class="title class_ inherited__">Trainer</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ...</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># 初始化PPO训练器的各个组件和参数</span></span><br><span class="line">        self.experience_maker = NaiveExperienceMaker(actor, critic, reward_model, initial_model, kl_coef)</span><br><span class="line">        self.replay_buffer = NaiveReplayBuffer(train_batch_size, buffer_limit, buffer_cpu_offload)</span><br><span class="line"></span><br><span class="line">        self.actor = actor</span><br><span class="line">        self.critic = critic</span><br><span class="line"></span><br><span class="line">        self.actor_loss_fn = PolicyLoss(eps_clip)  <span class="comment"># 演员损失函数</span></span><br><span class="line">        self.critic_loss_fn = ValueLoss(value_clip)  <span class="comment"># 评论家损失函数</span></span><br><span class="line">        self.vf_coef = vf_coef</span><br><span class="line">        self.ptx_loss_fn = GPTLMLoss()  <span class="comment"># 预训练损失函数</span></span><br><span class="line">        self.ptx_coef = ptx_coef</span><br><span class="line">        self.actor_optim = actor_optim   <span class="comment"># 演员网络的优化器</span></span><br><span class="line">        self.critic_optim = critic_optim  <span class="comment"># 评论家网络的优化器</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_learn</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 根据是否使用重放缓冲区选择不同的训练方式</span></span><br><span class="line">        <span class="keyword">if</span> self.sample_replay_buffer:</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(self.max_epochs):</span><br><span class="line">                experience = self.replay_buffer.sample()  <span class="comment"># 从重放缓冲区中采样经验</span></span><br><span class="line">                metrics = self.training_step(experience)  <span class="comment"># 执行训练步骤</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(self.max_epochs):</span><br><span class="line">                <span class="keyword">for</span> experience <span class="keyword">in</span> dataloader:  <span class="comment"># 从数据集中获取经验</span></span><br><span class="line">                    metrics = self.training_step(experience)  <span class="comment"># 执行训练步骤</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, prompt_dataloader, pretrain_dataloader</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        time = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> episode <span class="keyword">in</span> <span class="built_in">range</span>(num_episodes):</span><br><span class="line">            <span class="keyword">for</span> timestep <span class="keyword">in</span> <span class="built_in">range</span>(max_timesteps):</span><br><span class="line">                time += <span class="number">1</span></span><br><span class="line">                prompts = <span class="built_in">next</span>(<span class="built_in">iter</span>(self.prompt_dataloader))  <span class="comment"># 获取输入提示数据</span></span><br><span class="line">                <span class="comment"># 生成经验，这里可以支持在线和人进行对话</span></span><br><span class="line">                experience = self.experience_maker.make_experience(prompts, **self.generate_kwargs)</span><br><span class="line">                self.replay_buffer.append(experience)  <span class="comment"># 将经验添加到重放缓冲区</span></span><br><span class="line">                <span class="keyword">if</span> time % update_timesteps == <span class="number">0</span>:</span><br><span class="line">                    self._learn()  <span class="comment"># 执行模型更新</span></span><br><span class="line">                    self.replay_buffer.clear()  <span class="comment"># 清空重放缓冲区</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">training_step</span>(<span class="params">self, experience: Experience</span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">float</span>]:</span><br><span class="line">        self.actor.train()  <span class="comment"># 设置演员网络为训练模式</span></span><br><span class="line">        self.critic.train()  <span class="comment"># 设置评论家网络为训练模式</span></span><br><span class="line">        <span class="comment"># 计算演员网络的动作对数概率</span></span><br><span class="line">        num_actions = experience.action_mask.size(<span class="number">1</span>)</span><br><span class="line">        action_log_probs = self.actor(experience.sequences, num_actions, attention_mask=experience.attention_mask)</span><br><span class="line">        <span class="comment"># 计算演员损失函数</span></span><br><span class="line">        actor_loss = self.actor_loss_fn(</span><br><span class="line">            action_log_probs, experience.action_log_probs, experience.advantages, experience.action_mask)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算预训练损失函数</span></span><br><span class="line">        <span class="keyword">if</span> self.ptx_coef != <span class="number">0</span>:</span><br><span class="line">            batch = <span class="built_in">next</span>(<span class="built_in">iter</span>(self.pretrain_dataloader))</span><br><span class="line">            ptx_log_probs = self.actor.get_base_model()(batch[<span class="string">&#x27;input_ids&#x27;</span>],</span><br><span class="line">                                                        attention_mask=batch[<span class="string">&#x27;attention_mask&#x27;</span>])[<span class="string">&#x27;logits&#x27;</span>]</span><br><span class="line">            ptx_loss = self.ptx_loss_fn(ptx_log_probs, batch[<span class="string">&#x27;labels&#x27;</span>])</span><br><span class="line">            actor_loss = ptx_loss * self.ptx_coef + actor_loss * (<span class="number">1</span> - self.ptx_coef)</span><br><span class="line"></span><br><span class="line">        self.strategy.backward(actor_loss, self.actor, self.actor_optim)  <span class="comment"># 演员网络的反向传播</span></span><br><span class="line">        self.strategy.optimizer_step(self.actor_optim)  <span class="comment"># 演员网络的优化器步骤</span></span><br><span class="line">        self.actor_optim.zero_grad()  <span class="comment"># 清空演员网络的梯度</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算评论家损失函数</span></span><br><span class="line">        values = self.critic(experience.sequences, experience.action_mask, experience.attention_mask)</span><br><span class="line">        critic_loss = self.critic_loss_fn(values, experience.values, experience.reward, experience.action_mask)</span><br><span class="line">        critic_loss = critic_loss * self.vf_coef</span><br><span class="line">        self.strategy.backward(critic_loss, self.critic, self.critic_optim)  <span class="comment"># 评论家网络的反向传播</span></span><br><span class="line">        self.strategy.optimizer_step(self.critic_optim)  <span class="comment"># 评论家网络的优化器步骤</span></span><br><span class="line">        self.critic_optim.zero_grad()  <span class="comment"># 清空评论家网络的梯度</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GPTLMLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.loss = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, logits: torch.Tensor, labels: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="comment"># 将logits向左移动一位，去掉最后一个时间步的预测</span></span><br><span class="line">        shift_logits = logits[..., :-<span class="number">1</span>, :].contiguous()</span><br><span class="line">        <span class="comment"># 将标签向右移动一位，去掉第一个时间步的标签</span></span><br><span class="line">        shift_labels = labels[..., <span class="number">1</span>:].contiguous()</span><br><span class="line">        <span class="comment"># 计算交叉熵损失</span></span><br><span class="line">        <span class="keyword">return</span> self.loss(shift_logits.view(-<span class="number">1</span>, shift_logits.size(-<span class="number">1</span>)), shift_labels.view(-<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PolicyLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, clip_eps: <span class="built_in">float</span> = <span class="number">0.2</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.clip_eps = clip_eps</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, log_probs, old_log_probs, advantages, action_mask</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="comment"># 计算当前动作对数概率和旧动作对数概率的比例</span></span><br><span class="line">        ratio = (log_probs - old_log_probs).exp()</span><br><span class="line">        surr1 = ratio * advantages  <span class="comment"># 第一项损失计算</span></span><br><span class="line">        surr2 = ratio.clamp(<span class="number">1</span> - self.clip_eps, <span class="number">1</span> + self.clip_eps) * advantages <span class="comment"># 第二项损失计算</span></span><br><span class="line">        loss = -torch.<span class="built_in">min</span>(surr1, surr2)  <span class="comment"># 选取较小的损失</span></span><br><span class="line">        <span class="keyword">if</span> action_mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            loss = masked_mean(loss, action_mask)  <span class="comment"># 根据动作掩码计算平均损失</span></span><br><span class="line">        loss = loss.mean()  <span class="comment"># 计算平均损失</span></span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ValueLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, clip_eps: <span class="built_in">float</span> = <span class="number">0.4</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.clip_eps = clip_eps</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, values, old_values, reward, action_mask</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="comment"># 对奖励进行裁剪</span></span><br><span class="line">        values_clipped = old_values + (values - old_values).clamp(-self.clip_eps, self.clip_eps)</span><br><span class="line">        surr1 = (values_clipped - reward)**<span class="number">2</span>  <span class="comment"># 第一项损失计算</span></span><br><span class="line">        surr2 = (values - reward)**<span class="number">2</span> <span class="comment"># 第二项损失计算</span></span><br><span class="line">        loss = torch.<span class="built_in">max</span>(surr1, surr2)  <span class="comment"># 选取较大的损失</span></span><br><span class="line">        loss = loss.mean()  <span class="comment"># 计算平均损失</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.5</span> * loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NaiveExperienceMaker</span>(<span class="title class_ inherited__">ExperienceMaker</span>):</span><br><span class="line"><span class="meta">    @torch.no_grad()</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">make_experience</span>(<span class="params">self, input_ids: torch.Tensor, **generate_kwargs</span>) -&gt; Experience:</span><br><span class="line">        <span class="comment"># 基于演员函数生成回复及掩码</span></span><br><span class="line">        sequences, attention_mask, action_mask = self.actor.generate(input_ids, ...)</span><br><span class="line">        num_actions = action_mask.size(<span class="number">1</span>)  <span class="comment"># 获取动作的数量</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算动作的对数概率</span></span><br><span class="line">        action_log_probs = self.actor(sequences, num_actions, attention_mask)</span><br><span class="line">        <span class="comment"># 使用初始模型计算动作的对数概率</span></span><br><span class="line">        base_action_log_probs = self.initial_model(sequences, num_actions, attention_mask)</span><br><span class="line">        <span class="comment"># 计算价值</span></span><br><span class="line">        value = self.critic(sequences, action_mask, attention_mask)</span><br><span class="line">        <span class="comment"># 计算基础奖励值</span></span><br><span class="line">        r = self.reward_model(sequences, attention_mask)</span><br><span class="line">        <span class="comment"># 基于动作概率调整奖励值</span></span><br><span class="line">        reward = compute_reward(r, self.kl_coef, action_log_probs, base_action_log_probs, action_mask=action_mask)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算优势函数</span></span><br><span class="line">        advantage = reward - value</span><br><span class="line">        <span class="keyword">return</span> Experience(...)  <span class="comment"># 返回经验</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_reward</span>(<span class="params">r, kl_coef, log_probs, log_probs_base, action_mask</span>) -&gt; torch.Tensor:</span><br><span class="line">    kl = compute_approx_kl(log_probs, log_probs_base, action_mask=action_mask)  <span class="comment"># 计算KL散度</span></span><br><span class="line">    reward = r - kl_coef * kl  <span class="comment"># 计算奖励</span></span><br><span class="line">    <span class="keyword">return</span> reward</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_approx_kl</span>(<span class="params">log_probs, log_probs_base, action_mask</span>) -&gt; torch.Tensor:</span><br><span class="line">    log_ratio = log_probs - log_probs_base  <span class="comment"># 计算对数概率之间的差异</span></span><br><span class="line">    approx_kl = (log_ratio.exp() - <span class="number">1</span>) - log_ratio  <span class="comment"># 计算近似KL散度</span></span><br><span class="line">    <span class="keyword">if</span> action_mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        approx_kl = masked_mean(approx_kl, action_mask, dim=<span class="number">1</span>)  <span class="comment"># 根据动作掩码计算平均KL散度</span></span><br><span class="line">        <span class="keyword">return</span> approx_kl</span><br><span class="line">    approx_kl = approx_kl.mean(dim=<span class="number">1</span>)  <span class="comment"># 计算平均KL散度</span></span><br><span class="line">    <span class="keyword">return</span> approx_kl</span><br></pre></td></tr></table></figure><p>上述代码中用到了KL散度。KL散度（Kullback-Leibler divergence）是一种用于衡量两个概率分布之间差异的指标。在信息论和统计学中广泛应用。</p><p>给定两个离散概率分布P和Q，它们的KL散度定义为：<code>KL(P || Q) = Σ P(i) * log(P(i) / Q(i))</code> 其中，P(i)和Q(i)分别表示P和Q在第i个事件上的概率。</p><p>KL散度不具备对称性，即KL(P || Q) ≠ KL(Q || P)。它度量的是从P到Q的信息损失或差异。KL散度的值为非负数，当且仅当P和Q相等时，KL散度等于0。当P和Q之间的差异增大时，KL散度的值也会增大。</p><p>在深度学习中，KL散度常用于衡量生成模型生成的样本分布与真实数据分布之间的差异。通过最小化KL散度，可以使生成模型逼近真实数据分布，从而提高生成样本的质量。在上述代码中，KL散度被用于计算奖励信号。通过比较动作对数概率与基准动作对数概率之间的差异，可以衡量动作选择与基准模型之间的差异程度，进而调整奖励的大小。</p><h3 id="rlhf算法总结"><a class="markdownIt-Anchor" href="#rlhf算法总结"></a> RLHF算法总结</h3><p>回顾RLHF算法的过程，可以看到，由于我们之前训练了一个奖励函数，RLHF算法在执行过程中，可以没有人类的参与而自动进行。奖励函数代替人给出了对于模型生成的回复的质量的反馈。</p><p>到这里，大家可以理解为什么ChatGPT可以如此智能的回复大家的任意的自然语言问题了吧？OpenAI开放ChatGPT模型给大家使用，随着大家使用越多，OpenAI就可以根据RLHF的算法让模型接触到更多的对话，从而基于这些对话自动的优化ChatGPT！</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>到这里，我们就分析完了所有的ChatGPT类模型的训练和微调、RLHF微调的代码。在分析代码时，我们有意忽略了很多细节及模型并行处理的部分代码，这些对于我们理解模型帮助不大。</p><p>到这里大家应该对ChatGPT类模型的训练有一个较为深入的认识了。</p><p>自ChatGPT发布以来，很多人认为这是一个人类走向通用人工智能的突破，也有一些人认为它其实没什么本质的改进。有很多人对自己的职业发展产生了很深的焦虑感，也有很多人感觉触碰到了科幻世界中的未来，还有很多人觉得又是一个可以好好捞一把的机会。</p><p>也许每个人都有必要去了解一下机器学习技术的原理，这样才能形成对它的理性的认知。</p><p>ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。</p><p>这是此系列的第五篇，ChatGPT的自动优化。</p><h2 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h2><ul><li>alpaca博客介绍：<a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">https://crfm.stanford.edu/2023/03/13/alpaca.html</a></li><li>LLAMA Paper：<a href="https://arxiv.org/abs/2302.13971v1">https://arxiv.org/abs/2302.13971v1</a></li><li>Self-Instruct: Aligning Language Model with Self Generated Instructions：<a href="https://arxiv.org/abs/2212.10560">https://arxiv.org/abs/2212.10560</a></li><li>Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality: <a href="https://lmsys.org/blog/2023-03-30-vicuna/">https://lmsys.org/blog/2023-03-30-vicuna/</a></li><li>OpenAI开发的ChatGPT资料（Training language models to follow instructions<br />with human feedback）： <a href="https://arxiv.org/pdf/2203.02155.pdf">https://arxiv.org/pdf/2203.02155.pdf</a></li><li>OpenAI开放的GPT-3资料（Language Models are Few-Shot Learners）: <a href="https://arxiv.org/pdf/2005.14165.pdf">https://arxiv.org/pdf/2005.14165.pdf</a></li><li>OpenAI开放的GPT-2资料（Language Models are Unsupervised Multitask Learners）: <a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf">https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf</a></li><li>OpenAI开放的GPT资料（Improving Language Understanding by Generative Pre-Training): <a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;作为一个一直对AI技术很感兴趣的软件开发工程师，早在深度学习开始火起来的15、16年，我也开始了相关技术的学习。当时还组织了公司内部同样有兴趣的同学一起研究，最终的成果汇集成几次社区中的分享以及几篇学习文章（见&lt;a href=&quot;https://brightliao.com/tags/ai/&quot;&gt;这里&lt;/a&gt;）。&lt;/p&gt;
&lt;p&gt;从去年OpenAI发布ChatGPT以来，AI的能力再次惊艳了世人。在这样的一个时间节点，重新去学习相关技术显得很有必要。&lt;/p&gt;
&lt;p&gt;ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。&lt;/p&gt;
&lt;p&gt;ChatGPT本身就具备很丰富的知识，所以ChatGPT自身实际上就是一个很好的学习渠道，我也将借助ChatGPT来学习ChatGPT。&lt;/p&gt;
&lt;p&gt;这是此系列的第五篇，ChatGPT的自动优化。&lt;/p&gt;</summary>
    
    
    
    <category term="machine-learning" scheme="http://brightliao.com/categories/machine-learning/"/>
    
    <category term="ChatGPT" scheme="http://brightliao.com/categories/machine-learning/chatgpt/"/>
    
    
    <category term="AI" scheme="http://brightliao.com/tags/ai/"/>
    
    <category term="ML" scheme="http://brightliao.com/tags/ml/"/>
    
    <category term="机器学习" scheme="http://brightliao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="ChatGPT" scheme="http://brightliao.com/tags/chatgpt/"/>
    
    <category term="强化学习" scheme="http://brightliao.com/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>ChatGPT的模型训练</title>
    <link href="http://brightliao.com/2023/05/20/chatgpt-training/"/>
    <id>http://brightliao.com/2023/05/20/chatgpt-training/</id>
    <published>2023-05-20T12:00:00.000Z</published>
    <updated>2023-06-16T09:54:11.637Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>作为一个一直对AI技术很感兴趣的软件开发工程师，早在深度学习开始火起来的15、16年，我也开始了相关技术的学习。当时还组织了公司内部同样有兴趣的同学一起研究，最终的成果汇集成几次社区中的分享以及几篇学习文章（见<a href="https://brightliao.com/tags/ai/">这里</a>）。</p><p>从去年OpenAI发布ChatGPT以来，AI的能力再次惊艳了世人。在这样的一个时间节点，重新去学习相关技术显得很有必要。</p><p>ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。</p><p>ChatGPT本身就具备很丰富的知识，所以ChatGPT自身实际上就是一个很好的学习渠道，我也将借助ChatGPT来学习ChatGPT。</p><p>这是此系列的第四篇，ChatGPT的模型训练。</p><span id="more"></span><p><a href="https://brightliao.com/2023/05/18/2023-05-18-chatgpt-transformer/">上一篇</a>文章我们深入分析了ChatGPT使用到的Transformer模型。了解了其最核心的模型结构是Transformer结构，本文来聊一聊ChatGPT如何训练。</p><h2 id="介绍"><a class="markdownIt-Anchor" href="#介绍"></a> 介绍</h2><p>ChatGPT只在论文中有一些原理的解释，并没有公布代码。因此，为了弄清楚ChatGPT是如何训练的，我们只能从开源的类ChatGPT模型入手。目前，我们能看到ChatGPT的开源平替主要是来自斯坦福大学的<a href="https://github.com/tatsu-lab/stanford_alpaca">Alpaca</a>模型及伯克利大学的<a href="https://github.com/lm-sys/FastChat">Vicuna</a>模型。其中，当使用GPT-4来评估模型效果时，Vicuna模型的效果达到了ChatGPT的90%。这说明这些开源平替模型的正确性和有效性。</p><p>Alpaca模型及Vicuna模型都是基于Meta发布的LLaMA模型进行微调的。LLaMA的训练使用了大量的数据，并花费了大量的计算资源。</p><p>因此本文尝试帮助大家弄清楚这些开源模型的训练。当我们了解了这些开源模型的训练时，应该也能对ChatGPT的模型训练有了一个基本的了解了。</p><h2 id="训练过程"><a class="markdownIt-Anchor" href="#训练过程"></a> 训练过程</h2><p>从ChatGPT公布的论文内容来看，有三个训练阶段：1. 无监督预训练 2. 监督微调 3. 指令微调。</p><p><strong>无监督预训练</strong>是指直接使用大规模的文本数据作为输入来构建数据集，其输出就是当前文本中的下一个词。比如，文本“无监督训练”，可以拆分为如下几个训练样本：</p><ul><li>输入“无”，让模型预测“监督”</li><li>输入“无监督”让模型预测“训练”</li></ul><p>通过采集互联网上的大规模文本，可以构造一个超大规模的数据集用于无监督预训练。</p><p><strong>监督微调</strong>是指在输入文本中放入具体的任务信息，让模型尝试预测答案。比如，对于一个中文翻译为英文的任务可以构建训练样本如下（假定要翻译的文本为“无监督训练”）：</p><ul><li>输入“翻译文本为英文：无监督训练。译文：”，让模型输出“Non-supervised”</li><li>输入“翻译文本为英文：无监督训练。译文：Non-supervised”，让模型输出“training”</li></ul><p>监督微调阶段可以使用大量的当前NLP研究中的训练数据集。比如：</p><ul><li>常识推理数据集，如BoolQ、PIQA、SIQA、OpenBookQA等</li><li>闭卷问答数据集，如Natural Questions、TriviaQA等</li></ul><p>监督微调阶段使用了一些自然语言问答的模板，但是如果对话没有使用这样的模板，模型的效果就会大打折扣。于是为了训练一个ChatGPT这样的通用的模型，就需要更普适的问答模板。这就是<strong>指令微调</strong>阶段的作用。</p><p>从OpenAI开放的论文资料来看，指令微调采用了强化学习的方案。分成三个步骤完成：</p><p><img data-src="/attaches/2023/2023-05-20-chatgpt-training/instruct-gpt.png" alt="Instruct GPT" /></p><ul><li>第一步：从测试用户提交的问答中随机抽取数据，让专业的标注人员给出高质量的答案，并使用这些数据优化模型。</li><li>第二步：使用前面的模型生成N个不同的回答，让专业的标注人员对回答的质量进行排序，并使用这些数据训练一个奖励模型。</li><li>第三步：利用前面训练好的奖励模型，无需人工标注，通过强化学习的方式自动更新模型参数。</li></ul><p>这一阶段，通过让模型接受更广泛的自然语言回答任务，模型具备了回答通用问题的能力。</p><p>分析上述三个阶段，可以发现第三阶段用到的强化学习训练相对较为复杂，且需要大量人类的参与，目前开源替代并不多，由HPC-AI开源的<a href="https://github.com/hpcaitech/ColossalAI">ColossalChat</a>算是较为完善的一个。</p><p>上述提到的这些开源模型分别完成的阶段如下：</p><ul><li>LLaMA模型：利用开放的数据集完成了第一阶段和第二阶段</li><li>Alpaca、Vicuna模型：基于LLaMA，利用基于ChatGPT生成的指令数据，完成了第三阶段的第一步</li><li>ColossalChat：完成了完整的三个阶段</li></ul><h2 id="模型训练代码"><a class="markdownIt-Anchor" href="#模型训练代码"></a> 模型训练代码</h2><p>下面基于上述提到的三个模型分析一下模型的训练代码。</p><p>LLaMA的官方代码库中只有模型的结构及推理的代码，而没有包含训练的代码。虽然Meta的论文中提到了是如何训练的，但还是没有像可运行的代码这样包含所有细节。</p><p>Alpaca、Vicuna、ColossalChat模型作为开源可训练的模型，有完整的训练代码和脚本，我们主要基于它们来研究一下模型是如何训练的。</p><p>一般的机器学习模型训练主要包括三部分：定义模型结构、定义损失函数、准备训练数据。下面主要围绕这三部分来分析ChatGPT类模型是如何训练的。</p><h3 id="数据生成"><a class="markdownIt-Anchor" href="#数据生成"></a> 数据生成</h3><p>根据前文对训练过程的介绍，训练数据只需要组织成一系列的问答对即可。</p><p>从Alpaca的<a href="https://github.com/tatsu-lab/stanford_alpaca/tree/main">官方Github代码仓库</a>中的文档可以了解到，Alpaca用到了一种名为Self-Instruct的机制来生成数据。其原理是：</p><ol><li>定义一些种子任务</li><li>借助OpenAI发布的模型来生成具备多样性的指令任务</li><li>借助OpenAI的模型生成这些任务的回复</li></ol><p>以下是来自<a href="https://github.com/yizhongw/self-instruct">Self-Instruct的官方代码仓库</a>的数据生成流程图。其中Alpaca简化了分类任务和非分类任务，将其合成了同一类问答任务。</p><p><img data-src="/attaches/2023/2023-05-20-chatgpt-training/self-instruct.jpeg" alt="Self Instruct" /></p><p>下面是一些样例数据：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Give three tips for staying healthy.&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \n2. Exercise regularly to keep your body active and strong. \n3. Get enough sleep and maintain a consistent sleep schedule.&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;What are the three primary colors?&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;The three primary colors are red, blue, and yellow.&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    ...</span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure><p>Vicuna的模型效果比Alpaca好不少，而且很好的支持了多语言。它的秘诀在于其训练数据与Alpaca通过Self-Instruct的机制生成的数据不一样，质量要高很多。Vicuna的数据来源于 <a href="http://ShareGPT.com">ShareGPT.com</a> 网站上大家分享的与ChatGPT聊天的数据。</p><p>ColossalChat模型的性能也可以与ChatGPT比肩（信息来自代码仓库中的<a href="https://medium.com/pytorch/colossalchat-an-open-source-solution-for-cloning-chatgpt-with-a-complete-rlhf-pipeline-5edf08fb538b">博客</a>），它的训练数据来源于<a href="https://github.com/XueFuzhao/InstructionWild">InstructionWild</a>，这个数据集基于从Twitter获取的700个基础任务，然后采用与Alpaca类似的机制从OpenAI获取更多样性的任务及回复。</p><h3 id="微调部分训练代码"><a class="markdownIt-Anchor" href="#微调部分训练代码"></a> 微调部分训练代码</h3><p>阅读Alpaca和Vicuna的训练代码，可以发现训练代码非常短，主要是调用了transformers库中的Trainer类来完成训练。</p><p>所以，要了解训练过程的代码，我们需要阅读一下transformers代码库中的相应代码。</p><p><a href="https://github.com/huggingface/transformers">Transformers</a> 是 Huggingface 打造的一个开源库。提供了数以千计的预训练模型，支持 100 多种语言的文本分类、信息抽取、问答、摘要、翻译、文本生成。其宗旨是为最先进的 NLP 技术提供易用性。 Transformers 提供了便于快速下载和使用的API，让你可以把预训练模型用在给定文本、在你的数据集上微调然后通过 model hub 与社区共享。同时，每个定义的 Python 模块均完全独立，方便修改和快速研究实验。（来自官方介绍）</p><p>由于Alpaca和Vicuna采用LLaMA作为基础模型，我们主要关注LLaMA相关的代码。源代码在<a href="https://github.com/huggingface/transformers/tree/main/src/transformers/models/llama">这个目录</a>下。</p><p>模型的核心代码在<a href="https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/modeling_llama.py">这里</a>，虽然Transformers库中的实现与Meta发布的源代码有所区别，但都是基于PyTorch库，并且模型结构是一致的，就不赘述了（想了解细节的请回顾<a href="%5B%E4%B8%8A%E4%B8%80%E7%AF%87%5D(https://brightliao.com/2023/05/18/2023-05-18-chatgpt-transformer/)">上一篇</a>）。 下面分析一下与模型训练相关的核心代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LlamaForCausalLM</span>(<span class="title class_ inherited__">LlamaPreTrainedModel</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, config</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(config)</span><br><span class="line">        <span class="comment"># 根据配置初始化LLaMA模型，此模型的结构与Meta发布的LLaMA一致，除了不包含最后一层</span></span><br><span class="line">        self.model = LlamaModel(config)</span><br><span class="line">        <span class="comment"># 定义最后一层全连接层</span></span><br><span class="line">        self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=<span class="literal">False</span>)</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">...</span>):</span><br><span class="line">        <span class="comment"># 从LLaMA的模型获取预测的结果，并取最后一个Transformer块的计算结果</span></span><br><span class="line">        outputs = self.model(...)</span><br><span class="line">        hidden_states = outputs[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算模型输出</span></span><br><span class="line">        logits = self.lm_head(hidden_states)</span><br><span class="line"></span><br><span class="line">        loss = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> labels <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 取预测结果的前N-1个，使预测的下一个词与标签词对应。</span></span><br><span class="line">            shift_logits = logits[..., :-<span class="number">1</span>, :].contiguous()</span><br><span class="line">            <span class="comment"># 取标签数据的后N-1个，使预测的下一个词与标签词对应。</span></span><br><span class="line">            shift_labels = labels[..., <span class="number">1</span>:].contiguous()</span><br><span class="line">            <span class="comment"># 创建交叉熵损失，用于计算模型预测结果与标签之间的差异。</span></span><br><span class="line">            loss_fct = CrossEntropyLoss()</span><br><span class="line">            <span class="comment"># 将预测结果和标签进行形状变换，展平为二维张量。第一个维度为样本的数量，第二个维度为词汇表的大小。</span></span><br><span class="line">            shift_logits = shift_logits.view(-<span class="number">1</span>, self.config.vocab_size)</span><br><span class="line">            shift_labels = shift_labels.view(-<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 计算损失</span></span><br><span class="line">            loss = loss_fct(shift_logits, shift_labels)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> CausalLMOutputWithPast(loss=loss, logits=logits, ...)</span><br></pre></td></tr></table></figure><p>上述对齐过程，可以举例解释如下：</p><ul><li>假设有一个句子作为输入文本序列：I love eating，模型将预测下一个词是什么。</li><li>在这个例子中，预测结果序列为<code>love eating</code>，标签序列<code>I love eating</code>也应该调整为与预测序列一致。</li><li>通过取预测结果的前N-1个及标签数据的后N-1个，就可以将logits与标签数据对齐。</li></ul><p>可以看到这里的训练代码其实非常简单，使用最常见的基于概率的交叉熵损失即可实现损失定义。至于反向传播过程，PyTorch已经为我们实现了，训练时程序可以自动计算梯度，我们无需实现反向传播的过程。</p><h3 id="强化学习部分训练代码"><a class="markdownIt-Anchor" href="#强化学习部分训练代码"></a> 强化学习部分训练代码</h3><p>下面来分析一下由ColossalAI实现的指令微调阶段的模型及代码。根据上面的分析，指令微调阶段分为三个步骤完成：1. 与第二阶段相同的监督微调； 2. 训练一个奖励模型；3. 训练一个强化学习模型。</p><h4 id="监督微调"><a class="markdownIt-Anchor" href="#监督微调"></a> 监督微调</h4><p>看起来第一步骤的代码与Alpaca和Vicuna的代码应该是一样的，不过ColossalAI为了支持在单卡上面做训练，采用了Lora的方式进行监督微调。</p><p>Lora是一种少量参数模型微调的方法，由微软于2021年提出。其基本的思想是：</p><ol><li>冻结所有原来的大模型参数</li><li>对某些层（一般是线性变换层）的参数，采用两个小矩阵合成一个与原参数大小一样的大矩阵（如采用一个10x2的矩阵A和一个2X10的矩阵B，两者的矩阵乘积就可以得到一个10x10的大矩阵C）</li><li>计算时（前向计算），参数的值采用原参数矩阵加上合成矩阵的值作为最终参数矩阵的值</li><li>微调时（反向传播），只更新上述小矩阵的参数</li></ol><p>具体代码在<a href="https://github.com/hpcaitech/ColossalAI/blob/main/applications/Chat/examples/train_sft.py">这里</a>，以下是核心逻辑。（ColossalAI由于支持了多个模型，其代码比较长，以下是单独看LLaMA模型的简化后的代码。）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">args</span>):</span><br><span class="line">    strategy = ColossalAIStrategy(stage=<span class="number">2</span>, placement_policy=<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">    <span class="keyword">with</span> strategy.model_init_context():</span><br><span class="line">        <span class="comment"># 将transformers库中的LlamaForCausalLM模型转化为Lora模型</span></span><br><span class="line">        model = convert_to_lora_module(LlamaForCausalLM.from_pretrained(args.pretrain), args.lora_rank)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 准备分词器</span></span><br><span class="line">    tokenizer = AutoTokenizer.from_pretrained(args.pretrain, padding_side=<span class="string">&quot;right&quot;</span>, ...)</span><br><span class="line">    tokenizer = prepare_llama_tokenizer_and_embedding(tokenizer, model)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 准备优化器</span></span><br><span class="line">    optim = HybridAdam(model.parameters(), lr=args.lr, clipping_norm=<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 准备数据集</span></span><br><span class="line">    train_dataset = SFTDataset(train_data, tokenizer, max_len)</span><br><span class="line">    eval_dataset = SFTDataset(eval_data, tokenizer, max_len)</span><br><span class="line">    train_dataloader = DataLoader(train_dataset, ...)</span><br><span class="line">    eval_dataloader = DataLoader(eval_dataset, ...)</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># 构造训练器并开始训练</span></span><br><span class="line">    (model, optim) = strategy.prepare((model, optim))</span><br><span class="line">    trainer = SFTTrainer(model=model, ...)</span><br><span class="line">    trainer.fit(...)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SFTTrainer</span>:</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, ...</span>):</span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(self.max_epochs):</span><br><span class="line">            <span class="comment"># 设置模型为训练模式</span></span><br><span class="line">            self.model.train()</span><br><span class="line">            <span class="comment"># 对数据集里面的每一个批次进行训练</span></span><br><span class="line">            <span class="keyword">for</span> batch_id, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.train_dataloader):</span><br><span class="line">                <span class="comment"># 执行模型前向计算</span></span><br><span class="line">                outputs = self.model(batch[<span class="string">&quot;input_ids&quot;</span>], batch[<span class="string">&quot;attention_mask&quot;</span>], batch[<span class="string">&quot;labels&quot;</span>])</span><br><span class="line">                <span class="comment"># 下面的代码采用了一种累计梯度的机制，可以让模型在批太小的场景下也能较为稳定的更新</span></span><br><span class="line">                <span class="comment"># 每次计算梯度时，将损失平均一下，再计算梯度</span></span><br><span class="line">                loss = outputs.loss</span><br><span class="line">                loss = loss / self.accumulation_steps</span><br><span class="line">                <span class="comment"># 计算梯度</span></span><br><span class="line">                self.strategy.backward(loss, self.model, self.optimizer)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 当达到定义的累计批次数时更新参数并将梯度置零</span></span><br><span class="line">                <span class="keyword">if</span> (batch_id + <span class="number">1</span>) % self.accumulation_steps == <span class="number">0</span>:</span><br><span class="line">                    self.strategy.optimizer_step(self.optimizer)  <span class="comment"># 更新参数</span></span><br><span class="line">                    self.optimizer.zero_grad()  <span class="comment"># 梯度置零</span></span><br><span class="line">                    self.scheduler.step()  <span class="comment"># 对学习率进行调整</span></span><br></pre></td></tr></table></figure><p>可以看到，上述代码中ColossalAI还贴心的采用了一种累计梯度的机制来支持小批微调。这是因为想要在少量的GPU资源上微调大模型，批大小不能设置太大，否则显存无法支持。关于累计梯度详细的解释，可以参考<a href="https://zhuanlan.zhihu.com/p/595716023">这里</a>。</p><h4 id="奖励模型"><a class="markdownIt-Anchor" href="#奖励模型"></a> 奖励模型</h4><p>第二个步骤是定义并训练一个奖励模型，此模型可以判断哪些回复更好。ColossalAI依然基于大语言模型，并采用Lora微调，来实现这个奖励模型。</p><p>具体代码在<a href="https://github.com/hpcaitech/ColossalAI/blob/main/applications/Chat/examples/train_reward_model.py">这里</a>，以下是核心逻辑。（ColossalAI由于支持了多个模型，其代码比较长，以下是单独看LLaMA模型的简化后的代码。）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">args</span>):</span><br><span class="line">    strategy = ColossalAIStrategy(stage=<span class="number">2</span>, placement_policy=<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">    <span class="keyword">with</span> strategy.model_init_context():</span><br><span class="line">        <span class="comment"># 定义基于LLaMA的奖励模型</span></span><br><span class="line">        model = LlamaRM(pretrained=args.pretrain, lora_rank=args.lora_rank)</span><br><span class="line">    <span class="comment"># 以下代码与监督微调部分类似</span></span><br><span class="line">    tokenizer = LlamaTokenizer.from_pretrained(args.pretrain)</span><br><span class="line">    tokenizer = prepare_llama_tokenizer_and_embedding(tokenizer, model)</span><br><span class="line">    optim = HybridAdam(model.parameters(), lr=<span class="number">5e-6</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义LogSig损失，LogSig损失是OpenAI在论文Training language models to follow instructions with human feedback中定义的损失函数</span></span><br><span class="line">    loss_fn = LogSigLoss()</span><br><span class="line"></span><br><span class="line">    data = load_dataset(args.dataset)</span><br><span class="line">    train_dataset = RmStaticDataset(data[<span class="string">&#x27;train&#x27;</span>], tokenizer, ...)</span><br><span class="line">    valid_dataset = RmStaticDataset(data[<span class="string">&#x27;test&#x27;</span>], tokenizer, ...)</span><br><span class="line">    train_dataloader = DataLoader(train_dataset, ...)</span><br><span class="line">    eval_dataloader = DataLoader(eval_dataset, ...)</span><br><span class="line"></span><br><span class="line">    (model, optim) = strategy.prepare((model, optim))</span><br><span class="line">    trainer = RewardModelTrainer(model=model, ...)</span><br><span class="line">    trainer.fit()</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LogSigLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, chosen_reward: torch.Tensor, reject_reward: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="comment"># 根据OpenAI在论文中的损失计算公式计算损失，见下文的分析</span></span><br><span class="line">        probs = torch.sigmoid(chosen_reward - reject_reward)</span><br><span class="line">        log_probs = torch.log(probs)</span><br><span class="line">        loss = -log_probs.mean()</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RewardModel</span>(<span class="title class_ inherited__">LoRAModule</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ...</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># 转换为Lora模型，以便支持少量参数微调</span></span><br><span class="line">        self.convert_to_lora()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, sequences: torch.LongTensor, attention_mask: <span class="type">Optional</span>[torch.Tensor] = <span class="literal">None</span></span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="comment"># 转换为Lora模型，以便支持少量参数微调</span></span><br><span class="line">        outputs = self.model(sequences, attention_mask=attention_mask)</span><br><span class="line">        last_hidden_states = outputs[<span class="string">&#x27;last_hidden_state&#x27;</span>]</span><br><span class="line">        values = self.value_head(last_hidden_states)[:, :-<span class="number">1</span>]</span><br><span class="line">        value = values.mean(dim=<span class="number">1</span>).squeeze(<span class="number">1</span>)    <span class="comment"># ensure shape is (B)</span></span><br><span class="line">        <span class="keyword">return</span> value</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LlamaRM</span>(<span class="title class_ inherited__">RewardModel</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ...</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># 从预训练模型文件中加载LLaMA的基础模型，使用transformers库的实现，无最后一个线性层</span></span><br><span class="line">        model = LlamaModel.from_pretrained(pretrained)</span><br><span class="line">        <span class="comment"># 定义线性最后层，输出维度为1，即一个数值型的奖励值</span></span><br><span class="line">        value_head = nn.Linear(model.config.hidden_size, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>参考Huggingface上面的数据集，可了解到训练奖励模型用到的数据示例为：</p><ul><li><strong>prompt (string)</strong>: Human: I am trying to write a fairy tale. What is the most popular plot? Assistant: The … Human: The … Assistant:</li><li><strong>response (string)</strong>: This sounds like a really interesting modern retelling of the story!</li><li><strong>chosen (string)</strong>: This sounds like a really interesting modern retelling of the story!</li><li><strong>rejected (string)</strong>: And the prince and the princess both decide that they are more powerful together than apart?</li></ul><p>通过上面的分析，可以知道，奖励模型可以为每一个回复生成一个奖励值。这个奖励值就可以用于训练强化学习模型了。</p><p>对于奖励模型的训练，OpenAI论文原文解释如下：</p><blockquote><p>RM是在一个包含两个模型输出之间比较的数据集上进行训练的。他们使用交叉熵损失，将比较结果作为标签，而奖励之间的差异表示了一个人类标注者更喜欢其中一个回答的对数几率。为了加快比较收集的速度，我们向标注者展示了K = 4至K = 9个回答供其进行排名。这为每个提示产生了K²个比较。由于每个标注任务中的比较非常相关，我们发现，如果我们简单地将比较混洗到一个数据集中，对数据集进行一次遍历就会导致奖励模型过拟合（如果将每个可能的K²个比较视为单独的数据点，那么每个完成将可能被用于K-1个独立的梯度更新。模型往往在一个epoch后出现过拟合，因此在一个epoch内重复数据也会导致它出现过拟合）。相反，我们将每个提示的所有K²个比较作为单个批次元素进行训练。这样做在计算上更加高效，因为每个完成（completion）只需要一次RM的前向传播（而不是K个完成需要K²次前向传播），并且由于不再过拟合，验证准确度和对数损失都有显著提升。</p></blockquote><p>损失计算公式为：</p><p><img data-src="/attaches/2023/2023-05-20-chatgpt-training/rm.png" alt="Loss of Reward Model" /></p><blockquote><p>其中，rθ(x, y)是奖励模型对于提示x和完成y的标量输出，具有参数θ；yw是在yw和yl这一对完成中更受青睐的完成；D是人类比较的数据集。<br />最后，由于奖励模型的损失对于奖励的偏移是不变的，我们使用偏置对奖励模型进行归一化，以使标注者的演示在进行强化学习之前获得平均得分为0。</p></blockquote><h4 id="强化学习模型"><a class="markdownIt-Anchor" href="#强化学习模型"></a> 强化学习模型</h4><p>强化学习模型是最为复杂的部分，涉及很多新的知识点，限于篇幅，待下一篇继续分析。</p><p>不过，事实上基于前面的监督微调部分及奖励模型部分代码，我们似乎已经能窥探到强化学习部分的内容了。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>到这里，我们就分析完了ChatGPT类模型的训练和微调代码。在分析代码时，我们有意忽略了很多细节及模型并行处理的部分代码，这些对于我们理解模型帮助不大。</p><p>自ChatGPT发布以来，很多人认为这是一个人类走向通用人工智能的突破，也有一些人认为它其实没什么本质的改进。有很多人对自己的职业发展产生了很深的焦虑感，也有很多人感觉触碰到了科幻世界中的未来，还有很多人觉得又是一个可以好好捞一把的机会。</p><p>也许每个人都有必要去了解一下机器学习技术的原理，这样才能形成对它的理性的认知。</p><p>ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。</p><p>这是此系列的第四篇，ChatGPT的模型训练。</p><h2 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h2><ul><li>alpaca博客介绍：<a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">https://crfm.stanford.edu/2023/03/13/alpaca.html</a></li><li>LLAMA Paper：<a href="https://arxiv.org/abs/2302.13971v1">https://arxiv.org/abs/2302.13971v1</a></li><li>Self-Instruct: Aligning Language Model with Self Generated Instructions：<a href="https://arxiv.org/abs/2212.10560">https://arxiv.org/abs/2212.10560</a></li><li>Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality: <a href="https://lmsys.org/blog/2023-03-30-vicuna/">https://lmsys.org/blog/2023-03-30-vicuna/</a></li><li>OpenAI开发的ChatGPT资料（Training language models to follow instructions<br />with human feedback）： <a href="https://arxiv.org/pdf/2203.02155.pdf">https://arxiv.org/pdf/2203.02155.pdf</a></li><li>OpenAI开放的GPT-3资料（Language Models are Few-Shot Learners）: <a href="https://arxiv.org/pdf/2005.14165.pdf">https://arxiv.org/pdf/2005.14165.pdf</a></li><li>OpenAI开放的GPT-2资料（Language Models are Unsupervised Multitask Learners）: <a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf">https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf</a></li><li>OpenAI开放的GPT资料（Improving Language Understanding by Generative Pre-Training): <a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf</a></li><li>梯度累加：<a href="https://zhuanlan.zhihu.com/p/595716023">https://zhuanlan.zhihu.com/p/595716023</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;作为一个一直对AI技术很感兴趣的软件开发工程师，早在深度学习开始火起来的15、16年，我也开始了相关技术的学习。当时还组织了公司内部同样有兴趣的同学一起研究，最终的成果汇集成几次社区中的分享以及几篇学习文章（见&lt;a href=&quot;https://brightliao.com/tags/ai/&quot;&gt;这里&lt;/a&gt;）。&lt;/p&gt;
&lt;p&gt;从去年OpenAI发布ChatGPT以来，AI的能力再次惊艳了世人。在这样的一个时间节点，重新去学习相关技术显得很有必要。&lt;/p&gt;
&lt;p&gt;ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。&lt;/p&gt;
&lt;p&gt;ChatGPT本身就具备很丰富的知识，所以ChatGPT自身实际上就是一个很好的学习渠道，我也将借助ChatGPT来学习ChatGPT。&lt;/p&gt;
&lt;p&gt;这是此系列的第四篇，ChatGPT的模型训练。&lt;/p&gt;</summary>
    
    
    
    <category term="machine-learning" scheme="http://brightliao.com/categories/machine-learning/"/>
    
    <category term="ChatGPT" scheme="http://brightliao.com/categories/machine-learning/chatgpt/"/>
    
    
    <category term="AI" scheme="http://brightliao.com/tags/ai/"/>
    
    <category term="ML" scheme="http://brightliao.com/tags/ml/"/>
    
    <category term="机器学习" scheme="http://brightliao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="ChatGPT" scheme="http://brightliao.com/tags/chatgpt/"/>
    
  </entry>
  
  <entry>
    <title>ChatGPT使用的Transfomer模型</title>
    <link href="http://brightliao.com/2023/05/18/chatgpt-transformer/"/>
    <id>http://brightliao.com/2023/05/18/chatgpt-transformer/</id>
    <published>2023-05-18T12:00:00.000Z</published>
    <updated>2023-06-19T16:02:52.603Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>作为一个一直对AI技术很感兴趣的软件开发工程师，早在深度学习开始火起来的15、16年，我也开始了相关技术的学习。当时还组织了公司内部同样有兴趣的同学一起研究，最终的成果汇集成几次社区中的分享以及几篇学习文章（见<a href="https://brightliao.com/tags/ai/">这里</a>）。</p><p>从去年OpenAI发布ChatGPT以来，AI的能力再次惊艳了世人。在这样的一个时间节点，重新去学习相关技术显得很有必要。</p><p>ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。</p><p>ChatGPT本身就具备很丰富的知识，所以ChatGPT自身实际上就是一个很好的学习渠道，我也将借助ChatGPT来学习ChatGPT。</p><p>这是此系列的第三篇，ChatGPT使用的Transfomer模型。</p><span id="more"></span><p><a href="https://brightliao.com/2023/04/25/chatgpt-a-technical-summary/">上一篇</a>文章我们聊到了ChatGPT使用的技术概览。了解了其最核心的模型结构是Transformer结构，本文来聊一聊Transformer模型。</p><h2 id="介绍"><a class="markdownIt-Anchor" href="#介绍"></a> 介绍</h2><p>Transformer的网络结构最早是Google在2017年的时候提出的，论文名称是《Attention Is All You Need》。从论文名称也能看出，Transformer结构强调了注意力机制在网络结构中的表示和应用。</p><p>当时这篇论文面世时，不少研究人员还认为标题有点夸大了注意力机制的作用。现在来看，似乎还真有注意力机制一统天下的势头。</p><p>下面我们将一起来揭开这个网络结构的面纱。</p><h2 id="原始的transfomer模型"><a class="markdownIt-Anchor" href="#原始的transfomer模型"></a> 原始的Transfomer模型</h2><p>原始的Transformer的整体结构比较复杂，以下是来自论文中的截图。</p><p><img data-src="/attaches/2023/2023-05-18-chatgpt-transformer/model-archi.png" alt="Model Architecture" /></p><p>可以看到，Transformer网络的主要由编码器和解码器组成。虽然看起来复杂，但实际上，编码器和解码器都是由多个相同的层堆叠而成，并且编码器和解码器结构也很相似。</p><p><strong>编码器（Encoder）每一层内结构为：</strong></p><ul><li>输入嵌入（Input Embedding）：将输入序列中的每个单词或符号转换为连续的向量表示。</li><li>位置编码（Positional Encoding）：为输入序列中的每个位置添加一个表示位置信息的向量。</li><li>多头自注意力（Multi-Head Self-Attention）：通过对输入序列中的每个位置进行自注意力计算，从全局上理解输入序列间的关系和重要性。</li><li>前馈神经网络（Feed-Forward Neural Network）：在每个位置上应用一个全连接前馈神经网络，以对自注意力输出进行进一步的非线性变换。</li><li>残差连接（Residual Connections）和层归一化（Layer Normalization）：在每个子层之间应用残差连接和层归一化，以帮助梯度流动和减少训练中的梯度消失问题。</li></ul><p><strong>解码器（Decoder）每一层内结构为：</strong></p><ul><li>编码器-解码器注意力（Encoder-Decoder Attention）：除了自注意力，解码器还对编码器的输出进行注意力计算，以利用编码器对输入序列的理解。</li><li>解码器自注意力（Decoder Self-Attention）：类似于编码器的自注意力，但在解码器中应用于当前位置以前的输出。</li><li>前馈神经网络：与编码器中的前馈神经网络相同。</li><li>残差连接和层归一化：与编码器中的残差连接和层归一化相同。</li></ul><p>通过堆叠多个编码器和解码器层，Transformer可以具备强大的能力。注意力机制还允许Transformer网络模型自动学习输入序列中的各个单词的依赖关系，并且可以通过并行计算来加速计算过程。</p><p><a href="https://zhuanlan.zhihu.com/p/338817680">这里</a>有一篇博客详细的介绍了每一个结构内部的实现机制。推荐大家阅读以了解细节。</p><p>如果希望阅读完整的代码，Transformer的完整代码在Google的TensorFlow框架和Meta的PyTorch框架中均有实现。TensorFlow的代码入库在<a href="https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py">这里</a>，不过其代码风格偏函数式风格，并不是很容易理解。PyTorch中的代码相对更容易理解，有兴趣阅读代码的可以看<a href="https://github.com/pytorch/pytorch/blob/main/torch/nn/modules/transformer.py">这里</a>，只需要阅读其<code>forward</code>函数即可了解到整个网络的结构。</p><h2 id="chatgpt中的transfomer模型"><a class="markdownIt-Anchor" href="#chatgpt中的transfomer模型"></a> ChatGPT中的Transfomer模型</h2><p>ChatGPT中的Transformer模型与原始的Transformer模型有一些差异。主要区别是将Transformer中的Encoder-Decoder双模块设计简化为只有一个Decoder模块。其实也可以认为是只有一个Encoder模块，因为Encoder和Decoder模块本来就很相似。这里之所为大家认为是Decoder，是因为Transformer和ChatGPT的Decoder是自循环的，因为Decoder会根据前一部分的文本生成下一个单词。</p><p>在这个单模块中，Self-Attention被替换为了Masked Self-Attention。</p><p>Masked Self-Attention在计算时，会将当前输入文本中不存在的部分给遮蔽掉，只对已知的文本信息进行计算。遮蔽其实只是在训练阶段有效，因为训练阶段的输入文本是已知的所有文本。遮蔽掉当前单词的后续单词就可以让模型在无法获取后面单词的信息，使得这一场景与预测阶段的一致。</p><p>作为一个程序员，如果不能从代码的粒度去理解，始终会觉得理解不够透彻。下面我们结合代码来详细了解一下Transformer的计算过程。</p><p>在这里，我将用来做LLAMA模型的代码实现作为参考，与大家一起结合代码进行分析。LLAMA模型是Meta的研究团队开发的一个与ChatGPT类似的模型，其核心模型结构与ChatGPT的模型是一致的。</p><p>LLAMA的实现代码非常短，很适合拿来作为学习材料。完整的代码在<a href="https://github.com/facebookresearch/llama/blob/main/llama/model.py">这里</a>。下面将结合代码与Transformer的原理进行分析。</p><h3 id="文本生成逻辑"><a class="markdownIt-Anchor" href="#文本生成逻辑"></a> 文本生成逻辑</h3><p>LLAMA生成文本的代码入口在<a href="https://github.com/facebookresearch/llama/blob/main/example.py">这里</a>，下面说明一下代码中关键的行为：</p><p>（为了说明代码主要的功能，以下代码仅截取了关键的代码行，并进行了注释，以便大家更容易阅读。）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 整个程序的入口函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="comment"># 调用下面的load函数，创建一个LLaMA对象，用于生成文本</span></span><br><span class="line">    generator = load(...)</span><br><span class="line">    <span class="comment"># 调用LLaMA对象，根据传入的文本，以及最大生成长度、温度、单词概率选择</span></span><br><span class="line">    results = generator.generate(prompts, max_gen_len=<span class="number">256</span>, temperature=temperature, top_p=top_p)</span><br><span class="line">    <span class="comment"># 打印结果</span></span><br><span class="line">    <span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">        <span class="built_in">print</span>(result)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n==================================\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load</span>(<span class="params">...</span>) -&gt; LLaMA:</span><br><span class="line">    <span class="comment"># 加载保存的模型参数</span></span><br><span class="line">    checkpoint = torch.load(ckpt_path, map_location=<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    model_args: ModelArgs = ModelArgs(...)</span><br><span class="line">    <span class="comment"># 初始化一个Tokenizer对象，此Tokenizer其实也是一个机器学习模型，用于将文本切分为单词，并将单词编码为整型数值</span></span><br><span class="line">    tokenizer = Tokenizer(model_path=tokenizer_path)</span><br><span class="line">    <span class="comment"># 初始化核心的Transformer模型</span></span><br><span class="line">    model = Transformer(model_args)</span><br><span class="line">    <span class="comment"># 构造LLaMA的文本生成器对象，并返回</span></span><br><span class="line">    generator = LLaMA(model, tokenizer)</span><br><span class="line">    <span class="keyword">return</span> generator</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LLaMA</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">generate</span>(<span class="params">...</span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span><br><span class="line">        <span class="comment"># 将输入的文本编码为数值</span></span><br><span class="line">        prompt_tokens = [self.tokenizer.encode(x, bos=<span class="literal">True</span>, eos=<span class="literal">False</span>) <span class="keyword">for</span> x <span class="keyword">in</span> prompts]</span><br><span class="line">        <span class="comment"># 用上面的文本数值编码创建一个适合模型输入的矩阵（不超过模型能支持的最大长度），长度太短的文本用pad_id填充</span></span><br><span class="line">        tokens = torch.full((bsz, total_len), self.tokenizer.pad_id).cuda().long()</span><br><span class="line">        <span class="keyword">for</span> k, t <span class="keyword">in</span> <span class="built_in">enumerate</span>(prompt_tokens):</span><br><span class="line">            tokens[k, : <span class="built_in">len</span>(t)] = torch.tensor(t).long()</span><br><span class="line">        <span class="comment"># 根据配置的文本生成长度，迭代生成文本，一次生成一个单词</span></span><br><span class="line">        <span class="keyword">for</span> cur_pos <span class="keyword">in</span> <span class="built_in">range</span>(start_pos, total_len):</span><br><span class="line">            <span class="comment"># 调用模型进行计算</span></span><br><span class="line">            logits = self.model.forward(tokens[:, prev_pos:cur_pos], prev_pos)</span><br><span class="line">            <span class="keyword">if</span> temperature &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># 如果有传入温度参数，将输出结果根据温度放大，并选择累计概率达到top-p概率的那些结果</span></span><br><span class="line">                <span class="comment"># 关于温度和top-p参数的详细解释见下文</span></span><br><span class="line">                probs = torch.softmax(logits / temperature, dim=-<span class="number">1</span>)</span><br><span class="line">                next_token = sample_top_p(probs, top_p)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 如果没有传入，则直接选择概率最大的那个单词</span></span><br><span class="line">                next_token = torch.argmax(logits, dim=-<span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 将得到的单词加回原来的文本，继续生成下一个单词</span></span><br><span class="line">            tokens[:, cur_pos] = next_token</span><br><span class="line">        <span class="comment"># 通过单词编码器将生成的数值型文本反编码为可读的文本，并返回</span></span><br><span class="line">        decoded = []</span><br><span class="line">        <span class="keyword">for</span> i, t <span class="keyword">in</span> <span class="built_in">enumerate</span>(tokens.tolist()):</span><br><span class="line">            decoded.append(self.tokenizer.decode(t))</span><br><span class="line">        <span class="keyword">return</span> decoded</span><br></pre></td></tr></table></figure><p>这就是入口代码的主要逻辑。下面我们分析一下涉及到的几个核心子步骤。</p><h4 id="词嵌入"><a class="markdownIt-Anchor" href="#词嵌入"></a> 词嵌入</h4><p>词嵌入是将文本编码为数值的过程。LLaMA在进行词嵌入时，选择了<code>sentencepiece</code>库来实现。</p><p>SentencePiece 是一个开源的文本处理库，用于处理和生成分词模型。它的主要作用是将文本分割成子词（subwords）或标记（tokens），以便用于各种自然语言处理任务，例如机器翻译、文本分类、命名实体识别等。</p><p>SentencePiece 提供了基于不同分割算法的分词方法，包括未经训练的模型和基于训练数据的模型。它支持的分割算法包括 BPE（Byte-Pair Encoding）、Unigram 等。使用 SentencePiece，可以根据具体任务和需求创建自定义的分词模型。</p><p>通过使用 SentencePiece 库，可以实现以下功能：</p><ul><li>文本分词：将文本分割成子词或标记，提供更细粒度的语言处理单元。</li><li>词汇表生成：根据训练数据生成词汇表，用于构建词汇表索引或编码器-解码器模型。</li><li>子词编码：将文本转换为子词序列，以便在模型中进行处理和表示。</li><li>子词解码：将子词序列转换回原始文本，用于生成文本或进行后处理。</li></ul><p>SentencePiece 被广泛应用于各种自然语言处理任务和模型，特别是在跨语言和非常规语言处理方面具有很大的灵活性和适应性。它的灵活性使得可以根据不同语言、文本类型和任务的需求，定制化地构建分词模型，从而提高模型性能和效果。</p><p>下面是<code>Tokenizer</code>的核心代码分析：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Tokenizer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model_path: <span class="built_in">str</span></span>):</span><br><span class="line">        <span class="comment"># 根据模型文件创建SentencePieceProcessor对象</span></span><br><span class="line">        self.sp_model = SentencePieceProcessor(model_file=model_path)</span><br><span class="line">        <span class="comment"># 保存词汇表大小及一些关键的ID，如开始、结束符、填充符等</span></span><br><span class="line">        self.n_words: <span class="built_in">int</span> = self.sp_model.vocab_size()</span><br><span class="line">        self.bos_id: <span class="built_in">int</span> = self.sp_model.bos_id()</span><br><span class="line">        self.eos_id: <span class="built_in">int</span> = self.sp_model.eos_id()</span><br><span class="line">        self.pad_id: <span class="built_in">int</span> = self.sp_model.pad_id()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode</span>(<span class="params">self, s: <span class="built_in">str</span>, bos: <span class="built_in">bool</span>, eos: <span class="built_in">bool</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="comment"># 将文本编码为数值序列，并根据参数添加开始、结束符</span></span><br><span class="line">        t = self.sp_model.encode(s)</span><br><span class="line">        <span class="keyword">if</span> bos:</span><br><span class="line">            t = [self.bos_id] + t</span><br><span class="line">        <span class="keyword">if</span> eos:</span><br><span class="line">            t = t + [self.eos_id]</span><br><span class="line">        <span class="keyword">return</span> t</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">decode</span>(<span class="params">self, t: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="comment"># 将文本数值序列反编码为可读文本</span></span><br><span class="line">        <span class="keyword">return</span> self.sp_model.decode(t)</span><br></pre></td></tr></table></figure><h4 id="温度参数"><a class="markdownIt-Anchor" href="#温度参数"></a> 温度参数</h4><p>生成文本时，有两个重要的参数：温度（temperature）和top-p。它们是如何产生作用的呢？</p><p>温度参数（temperature）在生成文本过程中起到控制多样性的作用。较高的温度值会增加生成文本时的随机性，使得模型更加倾向于选择概率较小的标记，从而产生更多样化的输出。</p><p>具体来说，温度参数会影响 <code>softmax</code> 操作中的指数运算。在 <code>softmax</code> 函数中，通过将 <code>logits</code> 值进行指数运算并归一化，将其转换为概率分布。温度参数的作用是调整指数运算的敏感度。较高的温度值会使指数运算的结果更加平滑，增加了各个标记之间的概率差异，降低了概率较大的标记相对于概率较小的标记的优势。这样，在生成过程中，模型更有可能选择概率较小的标记，从而产生更多样化的输出。</p><p>举个例子，假设有一个具有三个候选标记的生成任务，对应的 <code>logits</code> 为 <code>[1.0, 2.0, 3.0]</code>。当温度参数为较低的值（例如1.0）时，通过 <code>softmax</code> 运算后，对应的概率分布为 <code>[0.09, 0.24, 0.67]</code>。可以看到，概率较大的标记 3 相对于其他标记有明显优势，模型更有可能选择标记 3。而当温度参数为较高的值（例如2.0）时，通过 <code>softmax</code> 运算后，对应的概率分布为 <code>[0.02, 0.11, 0.87]</code>。可以看到，概率差异缩小，标记 3 相对于其他标记的优势减小，模型更容易在标记之间进行随机选择。</p><p>因此，通过调整温度参数，可以在生成文本时控制多样性。较高的温度值可以增加生成文本的随机性，产生更多样化的输出；而较低的温度值可以增加生成文本的准确性，更倾向于选择概率较大的标记。根据具体的任务需求和应用场景，可以选择合适的温度值来平衡准确性和多样性之间的权衡。</p><h4 id="top-p参数"><a class="markdownIt-Anchor" href="#top-p参数"></a> top-p参数</h4><p><code>top-p</code>参数用于控制生成文本时的文本选择范围。</p><p>实现时，首先，计算 <code>softmax</code> 操作后的概率分布。然后，按照概率从高到低的顺序对概率进行排序。接下来，按照累积概率的方式逐个考虑排名靠前的标记，直到累积概率超过 <code>top-p</code> 的阈值。此时，只有排名靠前的文本才会被保留在选择范围内，其他排名较低的文本会被舍弃。</p><p>换句话说，<code>top-p</code> 参数通过动态地确定生成时所需的标记范围，使得生成的结果更加多样化且避免选择概率极低的标记。这种方式比传统的 <code>top-k</code> 采样更加灵活，因为 <code>top-p</code> 参数不依赖于固定的 <code>k</code> 值，而是根据概率分布动态地确定需要保留的标记数量。</p><p>下面函数是相关的实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sample_top_p</span>(<span class="params">probs, p</span>):</span><br><span class="line">    <span class="comment"># 对概率进行排序并记录排序后的索引</span></span><br><span class="line">    probs_sort, probs_idx = torch.sort(probs, dim=-<span class="number">1</span>, descending=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 计算累积概率</span></span><br><span class="line">    probs_sum = torch.cumsum(probs_sort, dim=-<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 创建一个布尔掩码，用于确定哪些概率需要保留</span></span><br><span class="line">    mask = probs_sum - probs_sort &gt; p</span><br><span class="line">    <span class="comment"># 将超过 top-p 阈值的概率置为 0</span></span><br><span class="line">    probs_sort[mask] = <span class="number">0.0</span></span><br><span class="line">    <span class="comment"># 将概率归一化，使其和为 1</span></span><br><span class="line">    probs_sort.div_(probs_sort.<span class="built_in">sum</span>(dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>))</span><br><span class="line">    <span class="comment"># 从归一化的概率分布中进行多项式采样，得到下一个标记</span></span><br><span class="line">    next_token = torch.multinomial(probs_sort, num_samples=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 使用排序后的索引获取对应的下一个标记</span></span><br><span class="line">    next_token = torch.gather(probs_idx, -<span class="number">1</span>, next_token)</span><br><span class="line">    <span class="keyword">return</span> next_token</span><br></pre></td></tr></table></figure><p>函数接受两个参数：<code>probs</code> 是经过 <code>softmax</code> 操作得到的概率分布，<code>p</code> 是 <code>top-p</code> 参数，用于确定保留的概率范围。</p><p>根据<code>top-p</code>进行结果选择的逻辑如下：</p><ul><li>对概率 <code>probs</code> 进行排序，并记录排序后的索引，使得概率从高到低排列。</li><li>计算概率的累积和。</li><li>创建一个布尔掩码，用于确定哪些概率需要保留。如果累积概率超过了 <code>top-p</code> 阈值，则对应的概率置为 0。</li><li>将概率归一化，使其和为 1，以便进行多项式采样。</li><li>使用多项式采样方法从归一化的概率分布中选取一个下一个标记。</li><li>使用排序后的索引 <code>probs_idx</code> 获取对应的下一个标记。</li><li>返回选取的下一个标记 <code>next_token</code>。</li><li>这段代码实现了根据 <code>top-p</code> 参数选择结果的逻辑，确保生成的结果在给定的概率范围内，并增加生成文本的多样性。</li></ul><h3 id="模型结构"><a class="markdownIt-Anchor" href="#模型结构"></a> 模型结构</h3><p>在生成文本的主流程中，构造了Transformer模型进行下一个单词的预测，下面分析一下Transformer模型的结构。</p><p>下面的代码需要有一些PyTorch构建神经网络模型的基础知识。对于不了解相关知识的同学，以下是一些要点：</p><ul><li>PyTorch抽象了一个Module类用于构建基本的模型构造块</li><li>在构建模型构造块时，需要继承Module类并实现其forward方法将输入变换为输出</li><li>在构建模型构造块时，需要在类的初始化方法<code>__init__</code>中初始化用到的子构造块</li><li>在构建模型构造块时，一般不需要关注参数更新的部分，PyTorch提供了自动计算梯度（参数的偏导数）的机制</li><li>PyTorch提供了很多内置的模块或函数，如<code>full</code> <code>triu</code> <code>matmul</code> <code>silu</code>等，帮助我们更快的复用标准构造块</li></ul><p>Transformer相关的完整代码在<a href="https://github.com/facebookresearch/llama/blob/main/llama/model.py">这里</a>，下面分析一下关键的实现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Transformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, params: ModelArgs</span>):</span><br><span class="line">        ...</span><br><span class="line">        <span class="comment"># 构造文本嵌入，用于将文本转化为向量表示</span></span><br><span class="line">        self.tok_embeddings = ParallelEmbedding(params.vocab_size, params.dim, ...)</span><br><span class="line">        <span class="comment"># 根据模型参数指定的Transformer层数，创建核心网络结构</span></span><br><span class="line">        self.layers = torch.nn.ModuleList()</span><br><span class="line">        <span class="keyword">for</span> layer_id <span class="keyword">in</span> <span class="built_in">range</span>(params.n_layers):</span><br><span class="line">            self.layers.append(TransformerBlock(layer_id, params))</span><br><span class="line">        <span class="comment"># RMSNorm归一化算子，见下文解释</span></span><br><span class="line">        self.norm = RMSNorm(params.dim, eps=params.norm_eps)</span><br><span class="line">        <span class="comment"># 对输出的文本进行最终的线性变换的算子</span></span><br><span class="line">        self.output = ColumnParallelLinear(params.dim, params.vocab_size, bias=<span class="literal">False</span>, ...)</span><br><span class="line">        <span class="comment"># 预计算频率的复数表示，见下文旋转嵌入部分的分析</span></span><br><span class="line">        self.freqs_cis = precompute_freqs_cis(self.params.dim // self.params.n_heads, self.params.max_seq_len * <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, tokens: torch.Tensor, start_pos: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="comment"># 对传入的文本取嵌入向量</span></span><br><span class="line">        h = self.tok_embeddings(tokens)</span><br><span class="line">        <span class="comment"># 预计算旋转嵌入的旋转频率。可以减少在每个前向传播步骤中的重复计算，提高模型的运行效率。</span></span><br><span class="line">        <span class="comment"># 这里用到了一些复数计算技巧，详见下文注意力机制部分分析</span></span><br><span class="line">        self.freqs_cis = self.freqs_cis.to(h.device)</span><br><span class="line">        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]</span><br><span class="line">        <span class="comment"># 在传入的文本长度大于1时，构造一个上三角矩阵作为掩码，用于遮盖未生成的字词部分</span></span><br><span class="line">        mask = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> seqlen &gt; <span class="number">1</span>:</span><br><span class="line">            mask = torch.full((<span class="number">1</span>, <span class="number">1</span>, seqlen, seqlen), <span class="built_in">float</span>(<span class="string">&quot;-inf&quot;</span>), device=tokens.device)</span><br><span class="line">            mask = torch.triu(mask, diagonal=start_pos + <span class="number">1</span>).type_as(h)</span><br><span class="line">        <span class="comment"># 调用每一个Transfomer分层进行计算</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            h = layer(h, start_pos, freqs_cis, mask)</span><br><span class="line">        <span class="comment"># 归一化最后的结果</span></span><br><span class="line">        h = self.norm(h)</span><br><span class="line">        <span class="comment"># 取计算出来的最后一个词，并进行最后的线性变换后作为输出返回</span></span><br><span class="line">        output = self.output(h[:, -<span class="number">1</span>, :])  <span class="comment"># only compute last logits</span></span><br><span class="line">        <span class="keyword">return</span> output.<span class="built_in">float</span>()</span><br></pre></td></tr></table></figure><p>上述代码用到的核心结构<code>TransformerBlock</code>代码分析如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TransformerBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, layer_id: <span class="built_in">int</span>, args: ModelArgs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># 构造注意力部分结构，见下文注意力机制部分</span></span><br><span class="line">        self.attention = Attention(args)</span><br><span class="line">        <span class="comment"># 构造前馈神经网络部分结构，见下文前馈神经网络部分</span></span><br><span class="line">        self.feed_forward = FeedForward(dim=args.dim, hidden_dim=<span class="number">4</span> * args.dim, ...)</span><br><span class="line">        <span class="comment"># 注意力部分用到的RMSNorm归一化算子，见下文解释</span></span><br><span class="line">        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)</span><br><span class="line">        <span class="comment"># 前馈神经网络部分用到的RMSNorm归一化算子，见下文解释</span></span><br><span class="line">        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor, start_pos: <span class="built_in">int</span>, freqs_cis: torch.Tensor, mask: <span class="type">Optional</span>[torch.Tensor]</span>):</span><br><span class="line">        <span class="comment"># 将输入归一化，并计算注意力，然后加上x以形成残差结构</span></span><br><span class="line">        h = x + self.attention.forward(self.attention_norm(x), start_pos, freqs_cis, mask)</span><br><span class="line">        <span class="comment"># 将上述结果进行归一化，并计算前馈神经网络部分，然后加上h以形成残差结构</span></span><br><span class="line">        out = h + self.feed_forward.forward(self.ffn_norm(h))</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><h3 id="注意力机制"><a class="markdownIt-Anchor" href="#注意力机制"></a> 注意力机制</h3><p>Transformer 中的注意力机制（Attention Mechanism）是核心组成部分之一，它在模型中用于捕捉输入序列中的相关信息，并为每个位置分配权重。</p><p>注意力的意思就是让模型关注在重要的地方，权重比较高的位置将得到更多的关注。如何实现？通过在每个位置上计算一个加权和就可以了！</p><p>Transformer 中使用的是自注意力机制（Self-Attention），即将输入序列中的每个位置视为查询（query）、键（key）和值（value）。通过计算查询与键的相似度得到权重分布，然后将权重与值进行加权求和得到每个位置的输出。</p><p>下面是 Transformer 中自注意力机制的主要步骤：</p><ul><li>对输入序列进行线性变换，分别得到查询（Q）、键（K）和值（V）。</li><li>计算查询与键的相似度分数，通常使用点积或其他函数（如缩放点积）计算相似度。</li><li>对相似度分数进行归一化处理，通过 softmax 函数将分数转换为注意力权重。</li><li>将权重与值进行加权求和，得到加权和作为该位置的输出。</li><li>将每个位置的输出进行线性变换，得到最终的自注意力输出。</li></ul><p>自注意力机制的优势在于它能够捕捉输入序列中的长距离依赖关系，并且能够对不同位置之间的相关性进行灵活的建模。通过自注意力机制，Transformer 可以同时考虑输入序列中所有位置的信息，而无需像循环神经网络那样依次处理序列。</p><p>在 Transformer 中，注意力机制通常通过多头注意力（Multi-Head Attention）来进行扩展，即使用多组不同的查询、键和值进行注意力计算，并将它们的输出进行拼接和线性变换，以增加模型的表达能力和学习能力。</p><p>总结起来，注意力机制是 Transformer 模型中重要的组成部分，它通过计算查询与键的相似度来为每个位置分配权重，并将权重与值进行加权求和得到输出。它能够捕捉输入序列中的相关信息，提升模型的表达能力和学习能力。</p><p><code>TransformerBlock</code>代码使用到的核心的<code>Attention</code>模块就是注意力机制的实现。这个模块的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, args: ModelArgs</span>):</span><br><span class="line">        <span class="comment"># 构造注意力查询（Q）、键（K）和值（V）所需要的线性变换算子</span></span><br><span class="line">        <span class="comment"># 这里直接用一个变换算子支持了多头的场景，因为每个头实际上计算方式是完全一样的，只是参数不同</span></span><br><span class="line">        self.wq = ColumnParallelLinear(args.dim, args.n_heads * self.head_dim, ...)</span><br><span class="line">        self.wk = ColumnParallelLinear(args.dim, args.n_heads * self.head_dim, ...)</span><br><span class="line">        self.wv = ColumnParallelLinear(args.dim, args.n_heads * self.head_dim, ...)</span><br><span class="line">        <span class="comment"># 构造对最终输出进行线性变换的算子</span></span><br><span class="line">        self.wo = RowParallelLinear(args.n_heads * self.head_dim, args.dim, ...)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor, start_pos: <span class="built_in">int</span>, freqs_cis: torch.Tensor, mask: <span class="type">Optional</span>[torch.Tensor]</span>):</span><br><span class="line">        <span class="comment"># 对输入序列进行线性变换，分别得到查询（Q）、键（K）和值（V）。</span></span><br><span class="line">        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)</span><br><span class="line">        <span class="comment"># 对查询和键应用旋转嵌入（Rotary Embedding）操作</span></span><br><span class="line">        <span class="comment"># 旋转嵌入是一种在注意力机制中引入周期性信息的技术，有助于模型捕捉序列的顺序关系</span></span><br><span class="line">        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新缓存中的键（K）和值（V），将当前位置的键和值存储在缓存中以供后续的注意力计算使用。</span></span><br><span class="line">        self.cache_k[:bsz, start_pos : start_pos + seqlen] = xk</span><br><span class="line">        self.cache_v[:bsz, start_pos : start_pos + seqlen] = xv</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 从缓存中获取用于注意力计算的键（K）和值（V），包括当前位置之前的所有位置。</span></span><br><span class="line">        keys = self.cache_k[:bsz, : start_pos + seqlen]</span><br><span class="line">        values = self.cache_v[:bsz, : start_pos + seqlen]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对查询、键和值进行维度转置，以便进行矩阵乘法操作。</span></span><br><span class="line">        xq = xq.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        keys = keys.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        values = values.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 计算查询和键之间的相似度得分，通过矩阵乘法计算得到，同时除以头的维度的平方根来进行缩放，以控制相似度的范围。</span></span><br><span class="line">        scores = torch.matmul(xq, keys.transpose(<span class="number">2</span>, <span class="number">3</span>)) / math.sqrt(self.head_dim)</span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 如果存在掩码（mask），则将其加到相似度得分上，以屏蔽无效位置的影响。</span></span><br><span class="line">            scores = scores + mask  <span class="comment"># (bs, n_local_heads, slen, cache_len + slen)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对相似度得分进行 softmax 操作，将其转换为注意力权重，使得权重在每个位置的分布总和为 1。</span></span><br><span class="line">        scores = F.softmax(scores.<span class="built_in">float</span>(), dim=-<span class="number">1</span>).type_as(xq)</span><br><span class="line">        <span class="comment"># 根据注意力权重对值进行加权求和，得到最终的注意力输出。</span></span><br><span class="line">        output = torch.matmul(scores, values)  <span class="comment"># (bs, n_local_heads, slen, head_dim)</span></span><br><span class="line">        ...</span><br><span class="line">        <span class="comment"># 对注意力输出进行线性变换，得到最终的注意力机制的输出。</span></span><br><span class="line">        <span class="keyword">return</span> self.wo(output)</span><br></pre></td></tr></table></figure><p><strong>旋转嵌入</strong></p><p>旋转嵌入（Rotary Embedding）是一种在注意力机制中引入周期性信息的技术，用于增强模型对序列中的顺序关系的建模能力。它通过将输入的查询（Q）和键（K）进行旋转操作，以捕捉序列中位置之间的相对角度。</p><p>在注意力机制中，查询和键是通过点积运算来计算相似度得分的，而点积运算本质上是计算两个向量的内积。通过旋转嵌入，可以将原始的查询和键进行旋转操作，将它们的信息编码成一个复数的表示形式，从而引入角度信息。</p><p>旋转嵌入的具体操作如下：</p><ul><li>首先，将查询和键的维度分为实部和虚部两部分。</li><li>然后，使用三角函数（sin 和 cos）计算旋转角度的正弦和余弦值。</li><li>将原始的实部和虚部分别与正弦和余弦值相乘，得到旋转后的实部和虚部。</li><li>最后，将旋转后的实部和虚部重新组合成查询和键的表示。</li></ul><p>通过旋转嵌入，查询和键之间的点积运算相当于在复数域中进行了旋转操作，这样可以更好地处理序列中的相对位置关系。旋转嵌入的使用可以提升模型对序列中长距离依赖的建模能力，并有助于捕捉序列中的顺序信息。</p><p>需要注意的是，旋转嵌入只应用于查询和键，而值（V）保持不变。这是因为在注意力机制中，查询和键的作用是计算相似度得分，而值则用于根据得分对序列进行加权求和。旋转嵌入的引入主要是为了增强相似度计算的准确性，而对值的处理不需要引入旋转操作。</p><p>对应的代码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">precompute_freqs_cis</span>(<span class="params">dim: <span class="built_in">int</span>, end: <span class="built_in">int</span>, theta: <span class="built_in">float</span> = <span class="number">10000.0</span></span>):</span><br><span class="line">    <span class="comment"># 预计算旋转嵌入的旋转频率。可以减少在每个前向传播步骤中的重复计算，提高模型的运行效率。</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算旋转嵌入的频率 freqs。</span></span><br><span class="line">    <span class="comment"># 1. 首先，生成一个从 0 到 dim 的整数序列，并取其中的偶数索引。</span></span><br><span class="line">    <span class="comment"># 2. 然后，将这些索引转换为浮点数，并将其除以 dim 后取倒数。</span></span><br><span class="line">    <span class="comment"># 这样可以生成一个频率递减的序列，用于控制旋转嵌入的旋转速度。</span></span><br><span class="line">    freqs = <span class="number">1.0</span> / (theta ** (torch.arange(<span class="number">0</span>, dim, <span class="number">2</span>)[: (dim // <span class="number">2</span>)].<span class="built_in">float</span>() / dim))</span><br><span class="line">    <span class="comment"># 创建一个长度为 end 的序列 t，其中的值从 0 到 end-1。</span></span><br><span class="line">    t = torch.arange(end, device=freqs.device)  <span class="comment"># type: ignore</span></span><br><span class="line">    <span class="comment"># 使用 torch.outer 函数计算旋转频率的复数形式。</span></span><br><span class="line">    <span class="comment"># 将 t 与 freqs 进行外积，得到一个形状为 [end, dim // 2] 的张量，其中每个元素是一个复数，表示旋转频率。</span></span><br><span class="line">    freqs = torch.outer(t, freqs).<span class="built_in">float</span>()  <span class="comment"># type: ignore</span></span><br><span class="line">    <span class="comment"># 使用 torch.polar 函数将复数频率转换为极坐标形式，得到一个复数张量 freqs_cis。</span></span><br><span class="line">    <span class="comment"># 该函数接受一个表示模长的张量（这里是全为1的张量）和一个表示相位的张量（这里是 freqs），并返回复数形式的张量。</span></span><br><span class="line">    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  <span class="comment"># complex64</span></span><br><span class="line">    <span class="keyword">return</span> freqs_cis</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">apply_rotary_emb</span>(<span class="params">xq: torch.Tensor, xk: torch.Tensor, freqs_cis: torch.Tensor</span>):</span><br><span class="line">    <span class="comment"># freqs_cis为旋转嵌入的旋转频率</span></span><br><span class="line">    <span class="comment"># 将输入的查询张量和键张量进行形状变换：</span></span><br><span class="line">    <span class="comment"># 1. 首先将其转换为浮点类型</span></span><br><span class="line">    <span class="comment"># 2. 然后将最后两个维度重塑为两倍大小的维度，以便处理复数形式的旋转嵌入。</span></span><br><span class="line">    <span class="comment"># 结果是一个形状为[batch_size, sequence_length, embedding_dim//2, 2]的复数张量。</span></span><br><span class="line">    xq_ = torch.view_as_complex(xq.<span class="built_in">float</span>().reshape(*xq.shape[:-<span class="number">1</span>], -<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">    xk_ = torch.view_as_complex(xk.<span class="built_in">float</span>().reshape(*xk.shape[:-<span class="number">1</span>], -<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">    <span class="comment"># 将旋转频率进行形状调整，使其与查询张量的形状相匹配。</span></span><br><span class="line">    <span class="comment"># 调整后的形状是根据查询张量形状的最后两个维度进行的，其他维度保持不变。</span></span><br><span class="line">    shape = [d <span class="keyword">if</span> i == <span class="number">1</span> <span class="keyword">or</span> i == ndim - <span class="number">1</span> <span class="keyword">else</span> <span class="number">1</span> <span class="keyword">for</span> i, d <span class="keyword">in</span> <span class="built_in">enumerate</span>(x.shape)]</span><br><span class="line">    freqs_cis = freqs_cis.view(*shape)</span><br><span class="line">    <span class="comment"># 将查询张量和键张量与旋转频率进行逐元素相乘。这相当于在复数域中将查询和键进行旋转操作。</span></span><br><span class="line">    <span class="comment"># 并将旋转后的张量重新转换为实数形式，通过取实部得到最终的旋转嵌入结果。</span></span><br><span class="line">    <span class="comment"># 将每个复数值展平为一个实数值。结果是形状为 [batch_size, sequence_length, embedding_dim] 的张量。</span></span><br><span class="line">    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(<span class="number">3</span>)</span><br><span class="line">    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> xq_out.type_as(xq), xk_out.type_as(xk)</span><br></pre></td></tr></table></figure><p>旋转嵌入部分代码略显复杂，并且用到了一些数学计算技巧。如果大家在此理解有困难，也可以忽略它，只需要明白旋转嵌入是为了计算注意力中的查询和键的相似度即可。</p><p>如果我们阅读<a href="https://github.com/openai/gpt-2/blob/master/src/model.py">GPT2的代码</a>，可以发现并没有使用旋转嵌入，只是简单的做了矩阵乘法。这是LLAMA引入的一个模型优化方式。</p><h3 id="前馈神经网络"><a class="markdownIt-Anchor" href="#前馈神经网络"></a> 前馈神经网络</h3><p>整个前馈神经网络的结构为：</p><ul><li>将输入进行线性变换并输入激活函数</li><li>将输入进行另一个线性变换并与上述结果相乘</li><li>将相乘后的结果再次经过线性变换得到最终的输出</li></ul><p>对应的代码为<code>TransformerBlock</code>代码使用的<code>FeedForward</code>模块代码，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FeedForward</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim: <span class="built_in">int</span>, hidden_dim: <span class="built_in">int</span>, multiple_of: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="comment"># 首先根据隐藏层维度的要求进行调整。将隐藏层维度的值设置为输入维度的 2/3，并将其转换为整数。</span></span><br><span class="line">        <span class="comment"># 然后，使用 multiple_of 对隐藏层维度进行取整，确保隐藏层维度是 multiple_of 的倍数。</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        hidden_dim = <span class="built_in">int</span>(<span class="number">2</span> * hidden_dim / <span class="number">3</span>)</span><br><span class="line">        hidden_dim = multiple_of * ((hidden_dim + multiple_of - <span class="number">1</span>) // multiple_of)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义三个线性变换操作符 self.w1、self.w2 和 self.w3，分别用于前馈神经网络的第一层、第二层和第三层。</span></span><br><span class="line">        self.w1 = ColumnParallelLinear(dim, hidden_dim, ...)</span><br><span class="line">        self.w2 = RowParallelLinear(hidden_dim, dim, ...)</span><br><span class="line">        self.w3 = ColumnParallelLinear(dim, hidden_dim, ...)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 1. 将输入进行线性变换并输入激活函数</span></span><br><span class="line">        <span class="comment"># 2. 将输入进行另一个线性变换并与上述结果相乘</span></span><br><span class="line">        <span class="comment"># 3. 将相乘后的结果再次经过线性变换得到最终的输出</span></span><br><span class="line">        <span class="keyword">return</span> self.w2(F.silu(self.w1(x)) * self.w3(x))</span><br></pre></td></tr></table></figure><h3 id="rmsnorm"><a class="markdownIt-Anchor" href="#rmsnorm"></a> RMSNorm</h3><p>上述代码中多次用到了RMSNorm归一化，这是什么技术呢？</p><p>其实，RMSNorm（Root Mean Square Normalization）是一种归一化技术，用于在神经网络中对输入进行标准化处理。它旨在增强网络的鲁棒性和稳定性，并有助于减轻输入数据中的噪声和变化对模型的影响。</p><p>RMSNorm 的核心思想是基于输入的均方根（RMS）进行标准化。它通过计算输入张量沿指定维度的均方根，并将每个元素除以该均方根值来进行归一化。这种归一化方法相比于传统的均值和方差归一化（例如 Batch Normalization）更加简单和直观。</p><p>其代码实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RMSNorm</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim: <span class="built_in">int</span>, eps: <span class="built_in">float</span> = <span class="number">1e-6</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># eps 参数是一个小的常数，用于避免分母为零的情况，确保数值稳定性。</span></span><br><span class="line">        self.eps = eps</span><br><span class="line">        <span class="comment"># dim 参数表示输入张量的维度，即要在哪个维度上计算均方根并进行归一化。</span></span><br><span class="line">        <span class="comment"># weight 是一个可学习的权重参数，用于缩放标准化后的输入。</span></span><br><span class="line">        self.weight = nn.Parameter(torch.ones(dim))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_norm</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 计算输入张量的均方根，并将每个元素除以均方根值。</span></span><br><span class="line">        <span class="keyword">return</span> x * torch.rsqrt(x.<span class="built_in">pow</span>(<span class="number">2</span>).mean(-<span class="number">1</span>, keepdim=<span class="literal">True</span>) + self.eps)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 调用 _norm 方法对输入张量进行标准化处理，并将标准化后的结果与权重参数相乘，以进一步缩放和调整输出。</span></span><br><span class="line">        output = self._norm(x.<span class="built_in">float</span>()).type_as(x)</span><br><span class="line">        <span class="keyword">return</span> output * self.weight</span><br></pre></td></tr></table></figure><h3 id="掩码"><a class="markdownIt-Anchor" href="#掩码"></a> 掩码</h3><p>掩码部分也有一些技巧，下面来看看它是如何实现的。</p><p>在Transformer的前向计算时，会计算一个掩码矩阵。然后，在计算注意力时，使用此掩码来遮蔽掉无效位置。对应的代码片段如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Transformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, tokens: torch.Tensor, start_pos: <span class="built_in">int</span></span>):</span><br><span class="line">        ...</span><br><span class="line">        <span class="comment"># 在传入的文本长度大于1时，构造一个上三角矩阵作为掩码，用于遮盖未生成的字词部分</span></span><br><span class="line">        mask = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> seqlen &gt; <span class="number">1</span>:</span><br><span class="line">            mask = torch.full((<span class="number">1</span>, <span class="number">1</span>, seqlen, seqlen), <span class="built_in">float</span>(<span class="string">&quot;-inf&quot;</span>), device=tokens.device)</span><br><span class="line">            mask = torch.triu(mask, diagonal=start_pos + <span class="number">1</span>).type_as(h)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor, start_pos: <span class="built_in">int</span>, freqs_cis: torch.Tensor, mask: <span class="type">Optional</span>[torch.Tensor]</span>):</span><br><span class="line">        ...</span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 如果存在掩码（mask），则将其加到相似度得分上，以屏蔽无效位置的影响。</span></span><br><span class="line">            scores = scores + mask  <span class="comment"># (bs, n_local_heads, slen, cache_len + slen)</span></span><br></pre></td></tr></table></figure><p>在生成掩码时，上述代码生成了一个上三角掩码，以屏蔽未来位置的注意力。</p><p>在计算注意力分数时，通过将未来位置的分数设置为负无穷，可以使模型在自回归任务中只依赖于当前及之前的信息。这样可以确保模型在生成序列时不会看到未来位置的信息，保持了模型的自回归性质。</p><p>生成掩码的方式如下：</p><ul><li>首先，创建一个名为 mask 的变量，并将其初始化为 None。这意味着在开始时没有生成掩码。</li><li>如果 seqlen 大于 1，表示当前处理的序列长度大于 1，存在需要屏蔽的位置。</li><li>创建一个形状为 (1, 1, seqlen, seqlen) 的张量 mask，并将所有元素的值设为负无穷（float(&quot;-inf&quot;)）。这里使用 float(&quot;-inf&quot;) 是为了在计算注意力分数时将被掩盖的位置的注意力分数设为负无穷大，从而在softmax操作后将其值近似为0。</li><li>使用 torch.triu() 函数将 mask 张量的下三角部分（包括对角线）设为负无穷。这是通过设置 diagonal 参数为 start_pos + 1 来实现的，表示从对角线位置 start_pos + 1 开始屏蔽。这样，注意力机制在计算时将只关注当前位置及之前的位置，而忽略之后的位置。</li><li>最后，将 mask 张量的数据类型转换为输入张量 h 的数据类型，并将其赋值给 mask 变量。</li></ul><p>在代码中，scores 与 mask 相加，实际上是将 mask 中的非负数值添加到 scores 对应位置的元素上。通过这样的操作，可以将特定位置的注意力分数调整为一个较小的值，从而有效地屏蔽或降低模型对该位置的关注度。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>到这里，我们就分析完了整个LLAMA模型的代码。需要注意的是，这里的代码只是LLAMA模型在生成文本时（即预测时）要执行的代码。LLAMA在训练阶段会有更多的技巧，也会涉及更多的代码。可惜Meta并没有公布相关的训练代码。</p><p>在分析代码时，我们有意忽略了模型并行处理的部分代码，这些是一些并行优化的机制，对于我们理解模型帮助不大。但如果我们希望将这个模型创建为一个服务，从而为大规模的用户服务时，并行处理部分就比较关键了。</p><p>在代码分析过程中，我借助了ChatGPT辅助进行理解，并引用了部分ChatGPT生成的内容，当然，也修正了ChatGPT回复中的一些明显的错误。在这个过程中，ChatGPT可以帮助提供足够多的详细的信息，我也深刻的体会到ChatGPT对于代码和我提出的问题的准确理解。可以说，ChatGPT很大程度上帮助我提升了代码分析的效率和学习的效率。</p><p>自ChatGPT发布以来，很多人认为这是一个人类走向通用人工智能的突破，也有一些人认为它其实没什么本质的改进。有很多人对自己的职业发展产生了很深的焦虑感，也有很多人感觉触碰到了科幻世界中的未来，还有很多人觉得又是一个可以好好捞一把的机会。</p><p>也许每个人都有必要去了解一下机器学习技术的原理，这样才能形成对它的理性的认知。</p><p>ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。</p><p>这是此系列的第三篇，ChatGPT使用的Transfomer模型。</p><h2 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h2><ul><li>Google的Transformer原始论文：<a href="https://arxiv.org/pdf/1706.03762.pdf">https://arxiv.org/pdf/1706.03762.pdf</a></li><li>Transformer模型详解（图解最完整版）：<a href="https://zhuanlan.zhihu.com/p/338817680">https://zhuanlan.zhihu.com/p/338817680</a></li><li>LLAMA Paper：<a href="https://arxiv.org/abs/2302.13971v1">https://arxiv.org/abs/2302.13971v1</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;作为一个一直对AI技术很感兴趣的软件开发工程师，早在深度学习开始火起来的15、16年，我也开始了相关技术的学习。当时还组织了公司内部同样有兴趣的同学一起研究，最终的成果汇集成几次社区中的分享以及几篇学习文章（见&lt;a href=&quot;https://brightliao.com/tags/ai/&quot;&gt;这里&lt;/a&gt;）。&lt;/p&gt;
&lt;p&gt;从去年OpenAI发布ChatGPT以来，AI的能力再次惊艳了世人。在这样的一个时间节点，重新去学习相关技术显得很有必要。&lt;/p&gt;
&lt;p&gt;ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。&lt;/p&gt;
&lt;p&gt;ChatGPT本身就具备很丰富的知识，所以ChatGPT自身实际上就是一个很好的学习渠道，我也将借助ChatGPT来学习ChatGPT。&lt;/p&gt;
&lt;p&gt;这是此系列的第三篇，ChatGPT使用的Transfomer模型。&lt;/p&gt;</summary>
    
    
    
    <category term="machine-learning" scheme="http://brightliao.com/categories/machine-learning/"/>
    
    <category term="ChatGPT" scheme="http://brightliao.com/categories/machine-learning/chatgpt/"/>
    
    
    <category term="AI" scheme="http://brightliao.com/tags/ai/"/>
    
    <category term="ML" scheme="http://brightliao.com/tags/ml/"/>
    
    <category term="机器学习" scheme="http://brightliao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="ChatGPT" scheme="http://brightliao.com/tags/chatgpt/"/>
    
  </entry>
  
  <entry>
    <title>ChatGPT使用的技术概览</title>
    <link href="http://brightliao.com/2023/04/25/chatgpt-a-technical-summary/"/>
    <id>http://brightliao.com/2023/04/25/chatgpt-a-technical-summary/</id>
    <published>2023-04-25T12:00:00.000Z</published>
    <updated>2023-06-19T16:02:52.592Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>作为一个一直对AI技术很感兴趣的软件开发工程师，早在深度学习开始火起来的15、16年，我也开始了相关技术的学习。当时还组织了公司内部同样有兴趣的同学一起研究，最终的成果汇集成几次社区中的分享以及几篇学习文章（见<a href="https://brightliao.com/tags/ai/">这里</a>）。</p><p>从去年OpenAI发布ChatGPT以来，AI的能力再次惊艳了世人。在这样的一个时间节点，重新去学习相关技术显得很有必要。</p><p>ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。</p><p>ChatGPT本身就具备很丰富的知识，所以ChatGPT自身实际上就是一个很好的学习渠道，我也将借助ChatGPT来学习ChatGPT。</p><p>这是此系列的第二篇，ChatGPT使用的技术概览。</p><span id="more"></span><p><a href="https://brightliao.com/2023/04/12/chatgpt-from-programmer-point-of-view/">上一篇</a>文章我们聊到了开发人员对于ChatGPT的认知。本文来聊一聊ChatGPT用到的机器学习技术。</p><h2 id="机器学习技术的发展"><a class="markdownIt-Anchor" href="#机器学习技术的发展"></a> 机器学习技术的发展</h2><p>要聊ChatGPT用到的机器学习技术，我们不得不回顾一下机器学习技术的发展。因为，ChatGPT用到的技术不是完全从零的发明，它也是站在巨人的肩膀上发展起来的。</p><h3 id="机器学习技术的分类"><a class="markdownIt-Anchor" href="#机器学习技术的分类"></a> 机器学习技术的分类</h3><p>实际上机器学习技术可以追溯到上个世纪三四十年代，一开始就与统计学分不开。早在1936年，著名的统计学家Fisher发明了线性判别分析方法（LDA）。LDA利用方差分析的思想，试图将高维数据分开。这后来演化为一类基础的机器学习技术任务，即分类问题。</p><p>在计算机出现之后，大量的基于计算机的机器学习算法出现，比如决策树、SVM、随机森林、朴素贝叶斯、逻辑回归等。它们也都可以用于解决分类问题。</p><p>分类问题是指我们事先知道要分为哪几类，这些类通常是人为定义的。比如人分为男性和女性，编程语言分为c/c++/java等。</p><p>还有一类问题是我们无法预先知道要分为几类的，比如给定一系列的新闻，按照主题进行分组，而我们可能无法事先人为的确定好有几个主题。此时可以利用机器学习算法自动去发现新闻中有几个类，然后再把不同的新闻放到不同的分类。这种问题是聚类问题。</p><p>有时，这个分类可能是连续的，比如，我们要用一个机器学习模型去预测某个人的身高，此时可以认为结果是在某一个范围内连续变化的值。这类问题，我们把它叫做回归问题。与分类的问题的区别仅仅在于我们希望输出一个连续的值。</p><p>除此之外，一些典型的机器学习问题还包括：降维、强化学习（通过智能体与环境的交互来学习最佳行动策略）等。</p><p>除了根据问题不同进行分类，还可以从机器学习技术使用数据的方式进行分类。从这个角度可以将机器学习技术分为有监督学习、无监督学习、半监督学习等。有监督学习要求我们为模型准备好标签值。无监督学习则无需我们准备标签值，只需数据即可开始训练。半监督学习是指需要一部分有标签值的数据。</p><p>从解决的问题上来看，ChatGPT可以认为是一个分类模型，它根据输入的文本预测下一个要输出的词是什么，而词的范围是确定的，即模型的输出是一个确定的分类。</p><p>从ChatGPT使用数据的方式来看，可以认为是使用了大量的无监督数据，加上少量的有监督的数据。所以，可以认为ChatGPT是一个半监督的机器学习技术。</p><h3 id="传统的机器学习算法与基于人工神经网络的机器学习算法"><a class="markdownIt-Anchor" href="#传统的机器学习算法与基于人工神经网络的机器学习算法"></a> 传统的机器学习算法与基于人工神经网络的机器学习算法</h3><p>上面提到的决策树、SVM、随机森林、朴素贝叶斯、逻辑回归等算法，多是基于可验证的可理解的统计学知识设计的算法。它们的局限性主要在于效果比较有限，即便使用海量数据也无法继续提升，这要归因于这些模型都是相对简单的模型。由于这些算法都是很早就被开发出来了，并且一直很稳定，没有什么更新，我们一般称这些算法为传统的机器学习算法。</p><p>另一类机器学习算法是基于人工神经网络的机器学习算法。这一类算法试图模拟人类的神经网络结构。其起源也很早，要追溯到1943年，W. S. McCulloch和W. Pitts提出的M-P模型。该模型根据生物神经元的结构和工作机理构造了一个简化的数学模型，如下图。</p><p><img data-src="/attaches/2023/2023-04-25-chatgpt-a-technical-summary/mp-model.jpeg" alt="M-P model" /></p><p>其中，xi代表神经元的第i个输入，权值wi为输入xi对神经元不同突触强度的表征，θ代表神经元的兴奋阀值，y表示神经元的输出，其值的正和负，分别代表神经元的兴奋和抑制。</p><p>该模型的数学公式可以表示为： 𝑦=∑𝑤𝑖*𝑥𝑖−𝜃 ，如果所有输入之和大于阀值θ则y值为正，神经元激活，否则神经元抑制。该模型作为人工神经网络研究的最简模型，一直沿用至今。</p><p>虽然这个模型看起来很简单，但是由于其可扩展可堆叠的特性，实际上可以用于构造一个非常复杂的网络。至于如何扩展和堆叠，其实就是人工神经网络数十年的发展要解决的问题。</p><p>这个模型如何优化呢？这里的优化其实就是修改wi的值，依靠一种名为反向传播的优化方式可以优化它。其计算过程，相当于对wi求偏导数，然后和学习率相乘再加回到原来的wi值上。</p><p>人工神经网络模型的算法思想非常简单，其效果只有在网络规模达到一定程度之后才会体现出来。但是一旦网络形成规模之后，对算力和数据的要求就非常高了。这也是为什么在21世纪之前这样的算法无法获得发展的原因。</p><p>从2000年开始，互联网进入了爆发式发展的阶段，大量的数据被累积起来，并且计算机算力也经历了数十个摩尔周期得到了长足的发展。于是基于人工神经网络的机器学习算法得到爆发式的发展。</p><p>各个研究领域都纷纷开始尝试利用人工神经网络来提升机器学习模型效果。</p><p>卷积神经网络（一种基于M-P模型的变种结构）在计算机视觉领域表现突出，逐渐演变为计算机视觉领域的基础结构。循环神经网络和长短期记忆网络（另一种基于M-P模型的变种结构）在自然语言处理领域表现突出，逐渐演变为自然语言处理领域的基础结构。</p><p>这两类网络结构曾经风靡一时，即便到现在也有很多问题是基于这两类结构的网络算法去解决的。它们在很大程度上促进了人工神经网络的机器学习算法的发展。</p><p>但是，研究人员从未停止对于网络结构的探索。在2017年的时候，Google的研究团队提出了一个名为Transformer的网络结构，强调了注意力机制在网络结构中的表示和应用。Transformer模型结构简单而一致，却表现出了非常好的效果。</p><p>ChatGPT的故事可以认为从这里开始了。在Transformer模型结构发布之后，后续有大量的研究基于Transformer开展起来，都取得了很好的效果，这里面就包括各类GPT模型。</p><p>最初的Transformer模型主要是应用在自然语言处理领域。近两年的研究发现，这一结构也可以被用到计算机视觉认为上，当前流行的Vision Transformer模型就是它在计算机视觉领域的应用成果。从这个趋势来看，Transformer有着要统一所有模型结构的势头。</p><h2 id="chatgpt技术概览"><a class="markdownIt-Anchor" href="#chatgpt技术概览"></a> ChatGPT技术概览</h2><p>有了前面的了解，终于轮到ChatGPT出场了。</p><p>ChatGPT用到了哪些技术呢？可以简要列举如下：</p><ul><li>基础模型结构：基于注意力机制的Transformer模型</li><li>超大规模的模型堆叠：GPT3堆叠了96层网络，参数数量高达1750亿</li><li>超大的训练数据：采用了45TB的原始数据进行训练</li><li>超大的计算资源：基于微软专门设计的包含数千块GPU的超级计算机完成训练</li><li>大规模并行训练：将模型分布到多个实例，多块GPU上并行计算完成训练</li><li>基于人类反馈数据进行调优：采用了大量的基于人类反馈的数据进行优化，使得对话更加自然、流畅而具有逻辑性</li></ul><p>由于OpenAI并未公布太多的ChatGPT的训练细节，所以，上述有一些模糊的估计数据。</p><p>值得注意的是，ChatGPT用到的核心技术其实并非原创，其核心模型结构Transformer来自于Google的研究成果。</p><p>这里只是列举了ChatGPT用到的技术，后面的内容我们将结合开源的代码示例，从原理上深入解构这些技术，敬请期待。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>自ChatGPT发布以来，很多人认为这是一个人类走向通用人工智能的突破，也有一些人认为它其实没什么本质的改进。有很多人对自己的职业发展产生了很深的焦虑感，也有很多人感觉触碰到了科幻世界中的未来，还有很多人觉得又是一个可以好好捞一把的机会。</p><p>也许每个人都有必要去了解一下机器学习技术的原理，这样才能形成对它的理性的认知。</p><p>ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。</p><p>这是此系列的第二篇，ChatGPT使用的技术概览。</p><h2 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h2><ul><li>wikipedia词条罗纳德·艾尔默·费希尔：<a href="https://zh.wikipedia.org/zh-sg/%E7%BE%85%E7%B4%8D%E5%BE%B7%C2%B7%E6%84%9B%E7%88%BE%E9%BB%98%C2%B7%E8%B2%BB%E9%9B%AA">https://zh.wikipedia.org/zh-sg/羅納德·愛爾默·費雪</a></li><li>人工智能与神经网络发展研究：<a href="https://image.hanspub.org/Html/2-1540922_23773.htm">https://image.hanspub.org/Html/2-1540922_23773.htm</a></li><li>OpenAI开发的ChatGPT资料（Training language models to follow instructions<br />with human feedback）： <a href="https://arxiv.org/pdf/2203.02155.pdf">https://arxiv.org/pdf/2203.02155.pdf</a></li><li>OpenAI开放的GPT-3资料（Language Models are Few-Shot Learners）: <a href="https://arxiv.org/pdf/2005.14165.pdf">https://arxiv.org/pdf/2005.14165.pdf</a></li><li>OpenAI开放的GPT-2资料（Language Models are Unsupervised Multitask Learners）: <a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf">https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf</a></li><li>OpenAI开放的GPT资料（Improving Language Understanding by Generative Pre-Training): <a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;作为一个一直对AI技术很感兴趣的软件开发工程师，早在深度学习开始火起来的15、16年，我也开始了相关技术的学习。当时还组织了公司内部同样有兴趣的同学一起研究，最终的成果汇集成几次社区中的分享以及几篇学习文章（见&lt;a href=&quot;https://brightliao.com/tags/ai/&quot;&gt;这里&lt;/a&gt;）。&lt;/p&gt;
&lt;p&gt;从去年OpenAI发布ChatGPT以来，AI的能力再次惊艳了世人。在这样的一个时间节点，重新去学习相关技术显得很有必要。&lt;/p&gt;
&lt;p&gt;ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。&lt;/p&gt;
&lt;p&gt;ChatGPT本身就具备很丰富的知识，所以ChatGPT自身实际上就是一个很好的学习渠道，我也将借助ChatGPT来学习ChatGPT。&lt;/p&gt;
&lt;p&gt;这是此系列的第二篇，ChatGPT使用的技术概览。&lt;/p&gt;</summary>
    
    
    
    <category term="machine-learning" scheme="http://brightliao.com/categories/machine-learning/"/>
    
    <category term="ChatGPT" scheme="http://brightliao.com/categories/machine-learning/chatgpt/"/>
    
    
    <category term="AI" scheme="http://brightliao.com/tags/ai/"/>
    
    <category term="ML" scheme="http://brightliao.com/tags/ml/"/>
    
    <category term="机器学习" scheme="http://brightliao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="ChatGPT" scheme="http://brightliao.com/tags/chatgpt/"/>
    
  </entry>
  
  <entry>
    <title>程序员眼中的ChatGPT</title>
    <link href="http://brightliao.com/2023/04/12/chatgpt-from-programmer-point-of-view/"/>
    <id>http://brightliao.com/2023/04/12/chatgpt-from-programmer-point-of-view/</id>
    <published>2023-04-12T12:00:00.000Z</published>
    <updated>2023-06-25T04:18:49.220Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>作为一个一直对AI技术很感兴趣的软件开发工程师，早在深度学习开始火起来的15、16年，我也开始了相关技术的学习。当时还组织了公司内部同样有兴趣的同学一起研究，最终的成果汇集成几次社区中的分享以及几篇学习文章（见<a href="https://brightliao.com/tags/ai/">这里</a>）。</p><p>从去年OpenAI发布ChatGPT以来，AI的能力再次惊艳了世人。在这样的一个时间节点，重新去学习相关技术显得很有必要。</p><p>ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。</p><p>ChatGPT本身就具备很丰富的知识，所以ChatGPT自身实际上就是一个很好的学习渠道，我也将借助ChatGPT来学习ChatGPT。</p><p>这是此系列的第一篇，程序员眼中的ChatGPT。</p><span id="more"></span><h2 id="什么是chatgpt"><a class="markdownIt-Anchor" href="#什么是chatgpt"></a> 什么是ChatGPT</h2><p>网络上已经有铺天盖地的内容介绍ChatGPT是什么了。总结起来，有以下几个关于ChatGPT的认知：</p><ul><li>ChatGPT是由OpenAI开发的一个用于对话生成的AI模型</li><li>GPT是&quot;Generative Pre-trained Transformer&quot;的缩写，表示它是一个经过预训练的生成式Transformer模型</li><li>ChatGPT学习了大规模的文本内容，如互联网上的网页、书籍和对话等，能够准确理解输入的自然语言，并生成自然而连贯的回复</li><li>可用于构建智能聊天机器人、虚拟助手、虚拟客服等应用，可以帮助我们写文章、写剧本、做设计，甚至还能辅助编写和调试程序</li><li>ChatGPT的计算过程非常复杂，包含了超过千亿的参数，需要用大量的显卡并行计算</li></ul><p>这些内容，相信大家已经了解得足够多了，在这里我们就不详述了。</p><p>那么，对于开发人员而言，ChatGPT有哪些不一样的特征呢？如何与我们所熟悉的东西对比进行理解呢？下面主要从这个角度来分享一下我的观点。</p><h2 id="确定性与非确定性"><a class="markdownIt-Anchor" href="#确定性与非确定性"></a> 确定性与非确定性</h2><p>从普通开发人员的视角来看，ChatGPT与普通的程序会有什么不同呢？我觉得最大的不同在于确定性与非确定性。</p><p>我们编写的大部分可运行的软件程序以一种确定性的方式在工作。比如，这篇文章以Markdown格式编写，有一个程序，可以以一种确定的方式解析Markdown格式，并以一种确定的方式展示它。</p><p>ChatGPT模型就很不一样，它更多是以一种概率性的非确定的方式在工作。我们都知道自然语言本身就是充满不确定性的。比如，同样一句话“他这个人谁都看不上”，可能表示“他”很挑剔，看不上别人；也可能表示“他”能力比较差，大家都看不起他。到底表示什么意义？这就要根据不同的上下文、情境来确定。</p><p>ChatGPT模型可以较为准确的理解自然语言的含义，这说明它可以综合分析输入给它的文本，然后选择一个概率最高的理解。</p><p>同时，ChatGPT模型可以生成不同的回复，这也是由概率控制的。ChatGPT模型在工作时会根据给定的文本生成下一个词。如何选定下一个词？程序会根据配置随机的选择一个较高概率的词，由于这里的随机性，就产生了AI回复的多样性。如果我们在生成下一个词时始终选择概率最高的那个词，那ChatGPT模型就会变成一个确定性的程序。</p><h2 id="自动优化得来的一个复杂函数"><a class="markdownIt-Anchor" href="#自动优化得来的一个复杂函数"></a> 自动优化得来的一个复杂函数</h2><p>从开发人员的视角来看，ChatGPT其实也可以看做一个普通的函数，根据输入的文本，输出另一些文本。只不过，这个函数能实现的功能比较强大，并且是基于概率去实现的而已。</p><p>在这个函数的实现上，它与其他的主要通过开发人员编写代码去实现的方式也不一样。ChatGPT模型与其他的AI模型一样，它是通过训练来实现的。</p><p>简单来说，它的实现流程是这样。为了实现这个函数，我们随机初始化了一堆参数，然后准备好大量的我们认为这个函数应该具有的输入输出对（即训练数据集），用这些数据去训练它。训练的过程其实就是调整我们之前随机初始化的参数的过程。当这些参数经过长时间的大量的调整之后，我们发现这个函数大概率能针对我们提供的输入返回我们预期的输出了。此时，实际上这个函数就被以一种概率的方式实现了。</p><p>调整参数的过程，也可以类比高中数学中的方程组求解过程。比如，给一个包含两个未知数的方程<code>ax + by = c</code>，只要我们知道两组<code>a b c</code>的值，我们就可以求解出<code>x</code>和<code>y</code>。这里的训练就相当于找到了大量的这样的<code>a b c</code>值对，然后用这些值去求解<code>x</code>和<code>y</code>。不过，这里的求解过程实际上用到了一些基于向量的微积分的技术。</p><h2 id="难以理解的黑盒"><a class="markdownIt-Anchor" href="#难以理解的黑盒"></a> 难以理解的黑盒</h2><p>有了前面的理解，相信大家也不会觉得ChatGPT是什么神秘的技术了。它只是与我们平常的函数的实现机制稍微有些区别而已。</p><p>或许我们会觉得用这种参数优化的方式去实现复杂函数的机制很有趣，也很有启发意义。但其实这种实现方式也有其问题。</p><p>最大的问题或许在于，我们难以理解这个函数为什么可以工作。</p><p>这一方面是因为函数包含了大规模的参数，特别是ChatGPT这种大模型，比如ChatGPT3.5版本，就包含了1750亿个参数。这么多的参数显然无法依靠人为的去分析每一个参数的作用。</p><p>另一方面，我们也不知道这些参数是如何计算来的。因为参数的调整过程同样是经过了超长的时间，有超大规模的输入输出对给到它。我们只能从数学原理上说明，这些参数可以最终收敛到某一个靠近最优值的点。但是我们无法去分析每一次的优化具体产生了什么影响。</p><p>可以说，这样的AI模型，或者说智能函数，本身就是一个难以理解的黑盒。</p><p>既然难以理解，我们在使用上就需要小心，因为它很可能一直表现很好，但是某一个场景下就出现无法预料的很差的效果。这也是目前的人工智能技术让人觉得很炫酷，但在真正落地应用时，总是有这样那样的问题的一个重要原因。</p><p>实际上，如果我们问ChatGPT，ChatGPT模型在应用上有哪些挑战，它就会回复：</p><blockquote><p>ChatGPT具有令人振奋的潜力，但也面临着一些挑战和限制。例如，它可能会生成不准确或不符合预期的回复，以及对偏见和敏感话题的处理问题。</p></blockquote><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>有了上面的理解，大家再来看ChatGPT，我相信大家也不会觉得它很神秘了。</p><p>自ChatGPT发布以来，很多人认为这是一个人类走向通用人工智能的突破，也有一些人认为它其实没什么本质的改进。有很多人对自己的职业发展产生了很深的焦虑感，也有很多人感觉触碰到了科幻世界中的未来，还有很多人觉得又是一个可以好好捞一把的机会。</p><p>也许每个人都有必要去了解一下机器学习技术的原理，这样才能形成对它的理性的认知。</p><p>ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。</p><p>这是此系列的第一篇，程序员眼中的ChatGPT。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;作为一个一直对AI技术很感兴趣的软件开发工程师，早在深度学习开始火起来的15、16年，我也开始了相关技术的学习。当时还组织了公司内部同样有兴趣的同学一起研究，最终的成果汇集成几次社区中的分享以及几篇学习文章（见&lt;a href=&quot;https://brightliao.com/tags/ai/&quot;&gt;这里&lt;/a&gt;）。&lt;/p&gt;
&lt;p&gt;从去年OpenAI发布ChatGPT以来，AI的能力再次惊艳了世人。在这样的一个时间节点，重新去学习相关技术显得很有必要。&lt;/p&gt;
&lt;p&gt;ChatGPT的内容很多，我计划采用一个系列，多篇文章来分享学习我自己学习过程中的一些理解。本系列文章，我将站在一个普通开发人员的角度展开，希望对想了解ChatGPT技术原理的普通开发者们有帮助。&lt;/p&gt;
&lt;p&gt;ChatGPT本身就具备很丰富的知识，所以ChatGPT自身实际上就是一个很好的学习渠道，我也将借助ChatGPT来学习ChatGPT。&lt;/p&gt;
&lt;p&gt;这是此系列的第一篇，程序员眼中的ChatGPT。&lt;/p&gt;</summary>
    
    
    
    <category term="machine-learning" scheme="http://brightliao.com/categories/machine-learning/"/>
    
    <category term="ChatGPT" scheme="http://brightliao.com/categories/machine-learning/chatgpt/"/>
    
    
    <category term="AI" scheme="http://brightliao.com/tags/ai/"/>
    
    <category term="ML" scheme="http://brightliao.com/tags/ml/"/>
    
    <category term="机器学习" scheme="http://brightliao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="ChatGPT" scheme="http://brightliao.com/tags/chatgpt/"/>
    
  </entry>
  
  <entry>
    <title>微信中的智能助手--WeChatGPT</title>
    <link href="http://brightliao.com/2023/03/26/wechatgpt/"/>
    <id>http://brightliao.com/2023/03/26/wechatgpt/</id>
    <published>2023-03-26T12:00:00.000Z</published>
    <updated>2023-06-16T09:54:26.729Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>ChatGPT刚刚开放API，价格低到没朋友。抛开背后的商业运作，这本身对人类的进步是很大的贡献。</p><p>可惜ChatGPT国内的网络环境让大家没法很容易的体验到最新的人工智能成果。</p><p>本人利用业余时间，搭建了一个简单的开源项目，可以帮助大家快速的基于微信公众号搭建自己的ChatGPT智能助理。</p><p>先上几个聊天截图，大家先睹为快。</p><span id="more"></span><p><img data-src="/attaches/2023/2023-03-26-wechatgpt/1.png" alt="Chat 1" /><br /><img data-src="/attaches/2023/2023-03-26-wechatgpt/2.png" alt="Chat 2" /></p><h2 id="为什么需要本项目"><a class="markdownIt-Anchor" href="#为什么需要本项目"></a> 为什么需要本项目</h2><p>为什么 OpenAI 开放了网页版本的聊天功能之后，还需要一个基于微信公众号的版本？主要原因是：</p><ul><li>国内网络无法直接访问</li><li>网页版本体验较差，无法在任意时刻任意地点有手机就能用</li></ul><p>微信作为一个广泛使用的专业的聊天软件，是智能助手的理想载体。</p><h2 id="项目的初衷和目的"><a class="markdownIt-Anchor" href="#项目的初衷和目的"></a> 项目的初衷和目的</h2><p>项目的目标是提供一套可用的代码及尽可能简单完善的步骤，帮助一般开发人员通过几步操作就能搭建自己的微信智能助理。</p><p>本项目不会致力于让代码具备高性能和支持高并发，因为出于个人用途（或者小的团体，比如家庭），这些特性是没必要的，只能白白的增加复杂度。</p><p>（如果希望基于此项目，搭建并发布自己的对外公共服务，出现的一切问题，请自行负责。）</p><h2 id="使用教程"><a class="markdownIt-Anchor" href="#使用教程"></a> 使用教程</h2><p>借助云服务的能力及微信的免费开放服务，可以零成本搭建一个智能助手。</p><p>主要需要完成以下几步：</p><ul><li>注册 aws 云服务账号，并启动虚拟机</li><li>注册 OpenAI 开发者账号，获取 token</li><li>注册微信公众号</li><li>配置微信公众号自动回复</li><li>部署此服务</li></ul><p>完成上述步骤需要具备一定的技术基础，熟练的同学应该可以很快搞定。具体操作就不详述了，请大家移步<a href="https://github.com/gmlove/wechatgpt">GitHub</a>参考。</p><h2 id="功能说明"><a class="markdownIt-Anchor" href="#功能说明"></a> 功能说明</h2><h3 id="基本功能"><a class="markdownIt-Anchor" href="#基本功能"></a> 基本功能</h3><ul><li>微信消息签名验证及接口集成</li><li>调用 OpenAI 的 API 发起聊天</li><li>聊天会话管理</li><li>多人同时独立对话互不影响</li><li>处理微信公众号 API 返回时间限制</li><li>在对话太长时，提示会开启新的对话</li><li>定期清理聊天会话</li><li>记录基本聊天统计信息</li><li>获取微信 ID：发送消息&quot;My ID&quot;或者&quot;我的微信 ID&quot;可获取微信 ID（用于辅助管理此服务）</li></ul><h3 id="管理功能"><a class="markdownIt-Anchor" href="#管理功能"></a> 管理功能</h3><p>项目支持管理员用户通过微信公众号消息管理服务。目前支持的管理功能包括：对话权限管理、对话次数限制、获取对话统计等。</p><p>当前一共定义了以下几类管理命令：</p><ul><li><code>add_white_list</code>: 添加白名单用户。参数为用户的微信 OpenID，可从日志中或通过基本功能中的“获取微信 ID”功能获取。</li><li><code>remove_white_list</code>: 移除白名单用户。参数为用户的微信 OpenID，可从日志中或通过基本功能中的“获取微信 ID”功能获取。</li><li><code>set_limit</code>: 设置用户对话次数限制。参数为用户的微信 OpenID 及每日对话次数限制，以逗号分隔，如 <code>user_a,100</code>表示限制 OpenID 为<code>user_a</code>的用户的每天对话次数为 100 次。</li><li><code>set_token</code>: 设置管理员 <code>token</code>。参数为新的 <code>token</code> 值。</li><li><code>get_config</code>: 获取配置。无参数，可将参数行设置为 1。</li><li><code>get_stat</code>: 获取对话统计。无参数，可将参数行设置为 1。<br />调用命令的方式是通过微信公众号发特定格式的消息。</li></ul><p>消息格式如下（消息必须包含三行）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">admin-command:&#123;YOUR_ADMIN_TOKEN&#125;</span><br><span class="line">&#123;COMAND_NAME&#125;</span><br><span class="line">&#123;COMMAND_ARGS&#125;</span><br></pre></td></tr></table></figure><h3 id="规划中的功能"><a class="markdownIt-Anchor" href="#规划中的功能"></a> 规划中的功能</h3><ul><li>处理用户发送的图片消息</li><li>配置公众号关注消息</li><li>消息加解密</li><li>更多的管理接口</li><li>持久化消息存储</li><li>让用户配置模型参数</li></ul><h2 id="试用"><a class="markdownIt-Anchor" href="#试用"></a> 试用</h2><p>如果想直接体验，可以在以下公众号发起聊天（看不到图片的同学请微信搜索：Bright 技术 人生）：</p><img data-src="/attaches/2023/2023-03-26-wechatgpt/wechat-account.png" width="300"><p><strong>注意</strong>：以上公众号系个人微信公众号，使用 OpenAI 的免费额度，每人每天只能对话 20 次。详见项目代码默认设置。后续可能限制更加严格。如果对本人公众号内容感兴趣，欢迎关注。否则，请试用后取关，以免受可能的消息打扰。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;ChatGPT刚刚开放API，价格低到没朋友。抛开背后的商业运作，这本身对人类的进步是很大的贡献。&lt;/p&gt;
&lt;p&gt;可惜ChatGPT国内的网络环境让大家没法很容易的体验到最新的人工智能成果。&lt;/p&gt;
&lt;p&gt;本人利用业余时间，搭建了一个简单的开源项目，可以帮助大家快速的基于微信公众号搭建自己的ChatGPT智能助理。&lt;/p&gt;
&lt;p&gt;先上几个聊天截图，大家先睹为快。&lt;/p&gt;</summary>
    
    
    
    <category term="machine-learning" scheme="http://brightliao.com/categories/machine-learning/"/>
    
    <category term="ChatGPT" scheme="http://brightliao.com/categories/machine-learning/chatgpt/"/>
    
    
    <category term="AI" scheme="http://brightliao.com/tags/ai/"/>
    
    <category term="ML" scheme="http://brightliao.com/tags/ml/"/>
    
    <category term="机器学习" scheme="http://brightliao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="ChatGPT" scheme="http://brightliao.com/tags/chatgpt/"/>
    
  </entry>
  
  <entry>
    <title>敏捷数据工程实践--以ETL为单位的CI和CD</title>
    <link href="http://brightliao.com/2023/01/10/ade-ci-cd-per-etl/"/>
    <id>http://brightliao.com/2023/01/10/ade-ci-cd-per-etl/</id>
    <published>2023-01-10T12:00:00.000Z</published>
    <updated>2023-05-16T09:22:34.832Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>前几天，我在跟一位做进口贸易的朋友聊天，发现一个很有意思的事情。</p><p>他们做的是国内的高端仪器进口的进口贸易业务。主要帮助销售国外产品的公司完成竞标、合同签订、物流、海关、进口贸易政策符合、维保等等事务。</p><p>我很疑惑，为什么会有这样的业务形态存在？为什么这些产品销售公司不自己处理这些事务，反而代理出去让其他公司赚钱呢？</p><span id="more"></span><p>我带着这个疑问，向他请教，获得了很多启发。</p><p>众所周知，国内的工业起步较晚，虽然这些年突飞猛进成为了世界工厂，但是核心的生产设备很多还是依赖进口。比如在生产芯片时少不了光刻机，在环境、食品、农业等实验室进行的样本成分分析也少不了可以分析各元素浓度的原子光谱仪。这个市场是一个万亿级的大市场。</p><p>这个业务有什么特点呢？</p><p>一是产品销售数量少。高端仪器一般售价都比较高，普遍在几十万到数百万。所以，一个年营业额在十亿的仪器产品公司其实也只是销售了数百台仪器而已。</p><p>二是销售流程特别复杂。由于是物理设备进口，将涉及很多现实的问题，除了产品推广和销售，还有一系列的事务，比如竞标、合同签订、物流、海关、进口贸易政策符合、维保等等，非常复杂。</p><p>作为一个在国内销售进口设备的企业，要如何组织其业务呢？</p><p>推广和销售是自不必说，否则市场根本不了解产品，就更别谈卖出去了。</p><p>但是，销售之外的其他事务要不要自己来做？这个就值得思考了。因为产品销售数量不会太大，但是销售之外的事务却特别复杂而繁多。如果培养一个专业的团队做这件事，由于产品销量不大，团队工作势必不会饱和。如果减少团队人员数量，这些事务又难以做得专业，容易出纰漏。</p><p>在经过大量的市场尝试和调整之后，专门做对进口贸易易的企业就诞生了。他们负责产品销售之外的大部分事务，涉及竞标、合同签订、物流、海关、进口贸易政策符合、税收、维保方式设计等。他们常常是一个非常专业的团队，可负责各个领域不同产品的进口贸易业务。在某些品类销售淡季时，其他品类可能又到销售旺季了。所以，他们的业务通常也能保持稳定和饱和。</p><p>于是，海外产品研发公司+国内产品销售公司+国内进口贸易公司的模式就在市场上慢慢形成并稳定下来了。总结起来，可以用下图简单地描述这三个企业如何愉快地合作完成整个产品进口销售的过程。</p><p><img data-src="/attaches/2023/2023-01-10-ade-ci-cd-per-etl/import-trade.png" alt="Import trade" /></p><p>进口贸易企业业务的兴起对整个行业效率和质量的提升都起到了正面的效果，这也是进口贸易企业得以存在的理由。</p><p>和这位朋友的交流完之后，我发现进口贸易企业业务的形成给了我不少启发。</p><p>从进口贸易企业的兴起中可以看到业务的重构和演变，即，通过合理的<strong>抽取</strong>和<strong>拆分</strong>提升了整体的效率。</p><h2 id="以etl为单位的持续集成"><a class="markdownIt-Anchor" href="#以etl为单位的持续集成"></a> 以ETL为单位的持续集成</h2><p>我联想到了近几天一直在思考的数据应用开发中的持续集成流水线设计。</p><p>在应用软件开发中，我们常常仅设计一条持续集成流水线，在流水线中运行所有的测试，接着将所有代码打包成一个大的产品包，然后部署到测试或产品环境中。</p><p>在数据应用中，是不是也需要这样做呢？这样做的好处是可以将产品环境的制品与代码仓库中的版本对应。其劣势其实也很多，比如，修改一个局部的代码，就不得不运行所有的测试，然后运行流水线中所有耗时的步骤，可能还需要进入手工测试的环节，最后才能发布到线上。效率非常低下。</p><p>这一问题在数据应用中更是被放大了。因为数据应用通常涉及数百个指标计算ETL，这些ETL的自动化测试只能用缓慢的集成测试来覆盖，这就导致流水线中的测试步骤耗时很长。在我们的项目中，常常需要跑半小时到一小时才能跑完。</p><p>这就如同做进口高端仪器销售的公司，如果自己来做进口贸易相关业务，不仅耗时特别长，而且出纰漏的可能性大（业务质量低）。</p><p>有没有更好的做法？既然只修改了某一个ETL，为什么不能就只部署和测试这个ETL？联想到前面进口贸易业务的抽取和拆分，是不是可以对流水线进行抽取和拆分呢？即，做<strong>以ETL为单位的持续集成流水线</strong>。</p><p>在数据应用开发场景中，这也是具备可行性的。原因在于，相比应用软件代码中的一个一个类或代码文件，ETL间几乎没有依赖。不同的ETL代码通常有不同的入口，存在于一个独立的文件。可以认为一个ETL就是一个独立的数据应用。</p><p>事实上，如果以ETL为单位进行持续集成和部署，还不用担心自己的部署会影响到其他的线上指标计算ETL，这也在一定程度上增强了安全性。</p><p>看起来，在数据应用开发领域，以ETL为单位的持续集是顺理成章的事。</p><p>对比一下微服务实践，还可以发现，这一实践与微服务中推荐的为每一个服务搭建一条持续集成流水线的实践几乎是等同的。</p><h2 id="如何实现"><a class="markdownIt-Anchor" href="#如何实现"></a> 如何实现</h2><p>如何实现以ETL为单位的持续集成呢？</p><p>如果基于Jenkins，可以在流水线上面加一个参数，如“ETL文件路径”，在运行流水线时，可以指定这个参数，让流水线仅针对指定的ETL运行测试与部署。</p><p>如果觉得在Jenkins上面实施以ETL为单位的持续集成较为麻烦，也可以团队自主开发一个专用的数据持续集成流水线。如果仅实现基本的功能，其实也并不复杂。</p><p>需要注意的是，一旦以ETL为单位进行持续集成了，就需要有一种方式记录每一个ETL对应的代码仓库里面的版本号，方便版本追溯。实现方式有多种，比如，可以在部署ETL的时候，在生产环境写入一个该ETL对应的版本文件。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>如果采用应用软件持续流水线的大包发布方式构建数据应用的持续集成流水线，将降低部署频率，且容易引起安全问题。借鉴进口贸易业务的抽取和拆分模式，在数据应用开发中，将持续集成流水线拆分为以ETL为单位的流水线可以有效解决上述问题。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;前几天，我在跟一位做进口贸易的朋友聊天，发现一个很有意思的事情。&lt;/p&gt;
&lt;p&gt;他们做的是国内的高端仪器进口的进口贸易业务。主要帮助销售国外产品的公司完成竞标、合同签订、物流、海关、进口贸易政策符合、维保等等事务。&lt;/p&gt;
&lt;p&gt;我很疑惑，为什么会有这样的业务形态存在？为什么这些产品销售公司不自己处理这些事务，反而代理出去让其他公司赚钱呢？&lt;/p&gt;</summary>
    
    
    
    <category term="敏捷" scheme="http://brightliao.com/categories/%E6%95%8F%E6%8D%B7/"/>
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%8F%E6%8D%B7/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="敏捷" scheme="http://brightliao.com/tags/%E6%95%8F%E6%8D%B7/"/>
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据工程" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="软件工程" scheme="http://brightliao.com/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="数据开发" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>DDD建模案例分享</title>
    <link href="http://brightliao.com/2022/07/28/modelling-examples/"/>
    <id>http://brightliao.com/2022/07/28/modelling-examples/</id>
    <published>2022-07-28T12:00:00.000Z</published>
    <updated>2023-06-19T14:41:07.181Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>前面的文章<a href="/2022/07/27/smart-domain-and-ddd/">《我理解的Smart Domain与DDD》</a>中，我们分析了 Smart Domain 的设计，尝试回答了为什么 Smart Domain 可以用于实现 DDD，并对Smart Domain和DDD进行了一些扩展性的讨论。</p><p>虽然 Smart Domain 作为一种设计范式，可以辅助我们实现 DDD。但是具体到真实项目中，建模这个过程还得结合实际的领域问题，深入思考，大量尝试，大声建模，才能得到好的模型。有哪些值得参考的案例呢？下面分享几个个人在项目中觉得还不错的建模实践。</p><span id="more"></span><h2 id="继承的应用"><a class="markdownIt-Anchor" href="#继承的应用"></a> 继承的应用</h2><p>作为面向对象编程范式三大关键特性之一的“继承”，如果使用得当，在实践中可以帮助我们更好的建模概念间的关系并有效避免重复代码。</p><h3 id="algorithm模型抽象"><a class="markdownIt-Anchor" href="#algorithm模型抽象"></a> Algorithm模型抽象</h3><p>我曾经经历过一个<strong>机器学习平台</strong>的项目，代码中有一个算法的概念。在没有有效建模之前，代码库中只有一个名为Algorithm的类，所有算法相关的信息均保存在这个类的属性上。项目中涉及到了几十个算法，都以数据的形式存储到了数据库。</p><p>表面上看，这一设计可以让我们更容易的添加算法（只需要增加数据即可）。但是，这带来的后果是大量的算法类型判断出现在代码库中。这是因为我们常常要对不同的算法进行不同的处理，比如在运行算法时需要为基于Tensorflow的深度学习算法和基于Spark的分布式学习选择不同的计算框架。</p><p>这一场景可以通过设计良好的一组有继承关系的类来表达（Algorithm基类，SparkAlgorithm/TensorflowAlgorithm抽象类，各个算法实现类），利用多态特性可以轻松避免这些条件判断代码。这一设计的另一大作用是将不太会变化的属性放入了代码而只将需要变化的属性放入数据库，从而很大程度上简化代码（大部分操作无需查询数据库）。关于此项目的更多内容请参考<a href="/2020/05/24/architecture-designing-practise-for-ml-platform-oop/">《机器学习平台架构实践 – 面向对象设计》</a>。</p><h3 id="backend模型抽象"><a class="markdownIt-Anchor" href="#backend模型抽象"></a> Backend模型抽象</h3><p>另一个项目是我们近期开源的名为<a href="https://github.com/easysql/easy_sql"><strong>Easy SQL</strong></a>的ETL开发语言项目。</p><p>为了同时支持不同的后端计算引擎，我们设计了一个抽象的<code>Backend</code>类型，针对<code>Spark</code>和<code>MaxCompute</code>分别提供了实现。</p><p>同时由于需要支持不同类型的常规的关系型数据库作为后端计算引擎，我们实现了一个<code>Rdb</code>的<code>Backend</code>，在<code>Rdb</code>的实现中，为了支持不同的方言，定义了一个名为<code>Dialect</code>的抽象接口，然后针对此接口提供了<code>PostgreSQL</code> <code>Clickhouse</code> <code>BigQuery</code>的实现。详情请参考这里的<a href="https://github.com/easysql/easy_sql/blob/main/easy_sql/sql_processor/backend/base.py">代码</a>。</p><h3 id="apply模型抽象"><a class="markdownIt-Anchor" href="#apply模型抽象"></a> Apply模型抽象</h3><p>还有一个<strong>为分布式服务创建中心化的权限管理</strong>应用。</p><p>在这个应用中有一个权限申请的概念。申请分为两种类型，一是对团队空间的权限申请，二是对发布数据的权限申请。这两种类型的申请存在相似性，比如审批流程相似，都有审批人等。但同时也存在诸多不同，比如，权限类型不同，团队空间可以有写权限，而发布的数据只有读权限。</p><p>遗憾的是，团队在进行模型设计时，只用了一个<code>Apply</code>类来表达申请的概念，并因此引入了多处对申请的资源的类型的判断。现在回想起来，如果可以用两个子类来表达不同的申请，结果可能会好不少。</p><h2 id="工厂模式的应用"><a class="markdownIt-Anchor" href="#工厂模式的应用"></a> 工厂模式的应用</h2><p>工厂模式是继承的好朋友。试想，有了继承树，如何创建对应的类呢？一般而言，还需要一个工厂方法来根据不同类型创建不同对象。在我经历过的很多建模实践中，很多情况下都会将“继承”和“工厂模式”搭配起来使用。</p><h3 id="算法工厂"><a class="markdownIt-Anchor" href="#算法工厂"></a> 算法工厂</h3><p>比如，在上面的机器学习平台中，由于有多种不同的算法构成的继承树，在通过用户的选择进行对象构建时，就可以使用工厂模式。不同的算法往往需要不同的参数及配置，这一做法可以有效的将参数选择逻辑集中起来管理。</p><h3 id="步骤工厂"><a class="markdownIt-Anchor" href="#步骤工厂"></a> 步骤工厂</h3><p>除了配合“继承”使用，如果某些对象的构造本身比较复杂，也可以考虑用工厂来进行抽象。比如，在<a href="https://github.com/easysql/easy_sql">Easy SQL</a>中，一个ETL被抽象为多个主要由SQL组成的步骤，在通过SQL文件来创建一组步骤的时候，就可以考虑用工厂模式实现。具体代码可以参考<a href="https://github.com/easysql/easy_sql/blob/main/easy_sql/sql_processor/step.py">这里</a>。</p><h2 id="有限状态机的应用"><a class="markdownIt-Anchor" href="#有限状态机的应用"></a> 有限状态机的应用</h2><p>在<strong>机器学习平台</strong>项目中，为了管理复杂的批处理任务的状态及其迁移路径，我们用到了有限状态机模式来进行抽象。</p><p>状态机定期获取任务的状态，在状态变化时进行记录，并根据启动时设置的任务状态转换处理器进行处理。</p><p>没有有限状态机抽象时，程序很多地方需要判断任务状态，并进行一定的逻辑处理。代码分散，很难理解。有了有限状态机的抽象之后，任务状态及状态迁移的处理器都被集中起来管理，从而变得直观、清晰且可控。</p><p>关于这个例子的更多内容可以参考之前的博客<a href="/2020/05/24/architecture-designing-practise-for-ml-platform-oop/">《机器学习平台架构实践 – 面向对象设计》</a>。</p><h2 id="其他设计模式的应用"><a class="markdownIt-Anchor" href="#其他设计模式的应用"></a> 其他设计模式的应用</h2><p>设计模式是针对某一类问题的通用解决方案。如果能在建模的时候有效使用设计模式，可以以一种大家都熟悉的方式解决问题并提升设计的质量。</p><p>其他很多设计模式都可以在建模阶段灵活选用。我们可以从很多架构设计或常用库的实现里面看到他们的影子。</p><p>Clean架构中的<code>Adapter</code>层，其实是用了适配器模式。</p><p>前端开发中，我们会添加很多交互事件处理器，这其实是观察者模式的应用。</p><p>后端开发中的<code>Filter</code>是职责链模式的应用。</p><p>Java标准库中的各类包装类型，如<code>Integer</code>, <code>Long</code>等在实现时使用了Flyweight享元模式。</p><p>在我们自己进行建模时，可以参考选用这些设计模式使用。不过在使用设计模式时，需要注意不要为了用设计模式而用设计模式，否则很容易过度设计。</p><h2 id="面向接口编程的应用"><a class="markdownIt-Anchor" href="#面向接口编程的应用"></a> 面向接口编程的应用</h2><p>面向接口编程是一种拥有强大抽象能力的编程范式。在Smart Domain示例中，关联对象以接口的形式定义在模型中，用于辅助实现依赖倒置。</p><h3 id="验证器"><a class="markdownIt-Anchor" href="#验证器"></a> 验证器</h3><p>另一个例子是验证器的实现。</p><p>在Web后端开发中，常常要对传入的参数进行严格的校验。很多校验需要跨属性进行。此时可以用自定义JSR的验证器来实现。</p><p>用面向接口编程的思想来实现这样的验证器，可以这样做：</p><p>1.定义一个验证器类<code>V</code>，其验证的注解为<code>VA</code>，验证目标对象为<code>VO</code><br />2.在验证器类中定义内部注解接口<code>VA</code><br />3.在验证器类中定义内部目标对象接口<code>VO</code><br />4.在要验证的类<code>B</code>上加上<code>VA</code>注解，并实现<code>VO</code>接口</p><p>代码结构参考：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">V</span> <span class="keyword">implements</span> <span class="title class_">ConstraintValidator</span>&lt;V.VA, V.VO&gt; &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="meta">@interface</span> VA &#123; ... &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">VO</span> &#123; ... &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@V</span>.VA</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">B</span> <span class="keyword">implements</span> <span class="title class_">V</span>.VO &#123; ... &#125;</span><br></pre></td></tr></table></figure><p>一个具体的实例可以参考这里的<a href="https://github.com/gmlove/experiments/blob/master/java_validator/ValidatorTest.java">代码</a>。</p><p>这样做的好处是，<code>V</code>这个类变成了DDD原书中提到的Standalone Class，除了Java标准库依赖之外，没有任何其他依赖。这使得这个验证器非常容易被复用，因为它可被用于验证任何实现了<code>VO</code>接口的对象。</p><p>结合Spring这样的依赖注入框架使用，还可以通过构造器给验证器注入任意的其他组件，以便实现更复杂的验证功能。</p><p>从这个例子里，我们可以看到面向接口编程带来的强大抽象能力。</p><h3 id="tdd的应用"><a class="markdownIt-Anchor" href="#tdd的应用"></a> TDD的应用</h3><p>TDD对于改善设计有很大的帮助。</p><p>Eric在书中建议团队“大声”的建模，这实际上就是在强调我们人类的语言天赋。不同背景的人在讨论问题时，会很容易形成一种双方都可以理解的“混杂”语言。这是人类的天赋。通过交流和讨论，很多情况下，我们可以自然的找到一种合适的模型。</p><p>这跟TDD实践是一致的。在进行TDD时，我们会站在使用代码的角度进行解决方案的描述。在描述的过程中，可以充分发挥语言能力，让我们自然的得到一个良好的模型。</p><p>关于如何使用TDD来改善模型设计，我之前有几篇文章分享。列举如下，给大家参考：</p><ul><li><a href="/2019/07/20/tdd-for-improving-design/">《从改善设计的角度理解 TDD》</a></li><li><a href="/2019/08/18/tdd-for-improving-design-2/">《从改善设计的角度理解 TDD (2)》</a></li><li><a href="/2022/07/05/tdd-to-develop-a-long-running-task-system">《用TDD开发基于数据库的长时任务系统》</a></li><li><a href="/2022/05/24/5-properties-of-good-code-cupid/">《好代码的五个特质-CUPID》</a></li></ul><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>本文分享了一些建模的例子，从这些例子中可以看到，其实每个项目中都可以有很多可挖掘的内容，关键在于我们不能轻易满足提取“名词”，而是要深入思考直至深刻理解问题，大胆创新直至找到最恰当的抽象。</p><p>对于长期从事某一个特定领域的开发，如只做前端或只做后端的同学，我们可能需要去尝试练习一下端到端的应用设计和开发，以便于认识软件构建的全貌。这可能对于我们从软件整体去思考和建模有更大的帮助。可以按照软件技术发展脉络来设计自己的练习。一个推荐的路径是：简单命令行程序-&gt;客户端应用-&gt;前后端分离的Web应用-&gt;微服务。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;前面的文章&lt;a href=&quot;/2022/07/27/smart-domain-and-ddd/&quot;&gt;《我理解的Smart Domain与DDD》&lt;/a&gt;中，我们分析了 Smart Domain 的设计，尝试回答了为什么 Smart Domain 可以用于实现 DDD，并对Smart Domain和DDD进行了一些扩展性的讨论。&lt;/p&gt;
&lt;p&gt;虽然 Smart Domain 作为一种设计范式，可以辅助我们实现 DDD。但是具体到真实项目中，建模这个过程还得结合实际的领域问题，深入思考，大量尝试，大声建模，才能得到好的模型。有哪些值得参考的案例呢？下面分享几个个人在项目中觉得还不错的建模实践。&lt;/p&gt;</summary>
    
    
    
    <category term="敏捷" scheme="http://brightliao.com/categories/%E6%95%8F%E6%8D%B7/"/>
    
    <category term="架构" scheme="http://brightliao.com/categories/%E6%95%8F%E6%8D%B7/%E6%9E%B6%E6%9E%84/"/>
    
    <category term="DDD" scheme="http://brightliao.com/categories/%E6%95%8F%E6%8D%B7/%E6%9E%B6%E6%9E%84/ddd/"/>
    
    
    <category term="架构" scheme="http://brightliao.com/tags/%E6%9E%B6%E6%9E%84/"/>
    
    <category term="DDD" scheme="http://brightliao.com/tags/ddd/"/>
    
    <category term="领域" scheme="http://brightliao.com/tags/%E9%A2%86%E5%9F%9F/"/>
    
  </entry>
  
  <entry>
    <title>我理解的Smart Domain与DDD</title>
    <link href="http://brightliao.com/2022/07/27/smart-domain-and-ddd/"/>
    <id>http://brightliao.com/2022/07/27/smart-domain-and-ddd/</id>
    <published>2022-07-27T12:00:00.000Z</published>
    <updated>2023-06-19T14:40:58.666Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>前段时间，咱们CTO八叉在极客时间做了一次关于用Smart Domain实现DDD的分享（点击<a href="https://www.bilibili.com/video/BV1QT411J7jh">这里</a>回看）。一个新词Smart Domain进入大家的视野。</p><h2 id="smart-domain解析"><a class="markdownIt-Anchor" href="#smart-domain解析"></a> Smart Domain解析</h2><p>Smart Domain是啥？为什么可以用Smart Domain实现DDD？本文尝试结合以往对DDD的学习和实践的经验，跟大家分享一下个人的理解。</p><p>八叉在分享中提到Smart Domain这个名字来源于Smart UI。我们都知道Smart UI是DDD中提到的一种反模式，只能用于解决简单问题。这里的命名略带反讽戏谑的意味。</p><span id="more"></span><p>下面咱们结合示例看看Smart Domain究竟是什么。</p><p>打开Smart Domain的示例工程：<a href="https://github.com/Re-engineering-Domain-Driven-Design/Accounting">https://github.com/Re-engineering-Domain-Driven-Design/Accounting</a>。可以看到，项目在结构上分为了四个子模块：</p><ul><li><code>main</code>: Web应用入口，负责配置即启动应用</li><li><code>api</code>: 定义Restful API</li><li><code>domain</code>: 核心领域层</li><li><code>persistent</code>: 数据持久化</li></ul><h3 id="模块划分与依赖关系"><a class="markdownIt-Anchor" href="#模块划分与依赖关系"></a> 模块划分与依赖关系</h3><p>深究起来，这四个模块和现在的分层架构有一些相似之处，但却并<strong>没有显示的严格的进行分层</strong>。同时，八叉在分享中明确提到了分层架构对领域建模是有伤害的，容易导致抽象不足。</p><p>值得注意的是，<strong><code>domain</code>模块没有任何依赖</strong>，其他模块则依赖<code>spring</code>及相应的包。通过在<code>domain</code>层定义抽象的接口（但不提供实现，由其他模块提供实现）的方式，将<code>domain</code>层的核心逻辑隔离起来，使得<code>domain</code>层可以非常容易根据领域需要进行灵活的设计及独立的测试。大家如果熟悉依赖倒置的设计原则，应该可以很容易领会这一做法的好处。（<code>domain</code>层本应该依赖数据持久化进行数据的查询与保存，这里通过抽象的接口设计让持久化层反过来依赖<code>domain</code>层的接口。）</p><h3 id="关联对象"><a class="markdownIt-Anchor" href="#关联对象"></a> 关联对象</h3><p>Smart Domain的一个关键设计在于在模型之间<strong>引入了一个中间关联对象</strong>。关联对象由一系列接口来定义（见代码中的<code>HasMany</code> <code>HasOne</code> <code>Many</code>接口），各类跨模型的操作均通过关联对象实现。这一设计避免了直接进行模型引用的诸多问题，比如引用的模型数量太多无法直接放入内存、引用的模型的查询修改通过<code>Repository</code>实现进而引入抽象能力很弱的<code>Service</code>去协调等。</p><p>示例项目中通过关联对象建模出的结果如下：</p><p><img data-src="/attaches/2022/2022-07-27-smart-domain-and-ddd/smart-domain-models.jpeg" alt="Smart Domain Models" /></p><p>无关联对象的实现方式的本质问题在于希望完全用内存模型来抽象数据库访问，而内存模型事实上无法直接建模数据库的复杂性，因而引起了一系列连锁反应。通过引入关联对象，<strong>将数据库访问显示的建模出来</strong>，这些连锁反应就不复存在了，领域层也将更清晰、纯粹和丰满。</p><p>关联对象和传统DDD中的<code>Repository</code>的抽象有一定的相似点，在我看来其最重要的区别在于关联对象接口定义在了引用方代码中。这一做法的隐含建议是<strong>从使用的角度来定义接口</strong>，从而使得接口定义不多不少，刚好满足系统需求。</p><h3 id="其他"><a class="markdownIt-Anchor" href="#其他"></a> 其他</h3><p>由于在Smart Domain的设计里面，<strong>对象图以统一的关联的形式被创建</strong>出来，所以可以提供一个统一的访问关联对象的方法。这一点很好的符合了Restful API的设计思想，API模块利用这个特点，以很少的代码完成了Restful API的导出。</p><p>纵观Smart Domain的设计，可以发现结构上非常简洁，没有引入传统DDD实践中常用却很难用好的<code>Repository</code> <code>Service</code> <code>Aggregate</code>等模式。然而这恰恰是让开发人员可以<strong>集中精力在对领域的挖掘和思考</strong>上。</p><h3 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h3><p>总结起来，Smart Domain主要的创新及价值有以下几点：</p><ul><li>打破了大家习惯用的分层架构，这些分层架构大都是从技术角度进行的抽象，而非领域角度</li><li>摒弃了职责模糊不清的service模式，使得原来service层的逻辑下沉到领域模型中，从而期望得到更丰满的领域模型</li><li>弱化了DDD中引入的聚合、限界上下文等容易引起争议的模式</li><li>尽可能的摒弃了在代码中使用过于技术化的术语，如Controller、DTO等，从而使得我们更专注于领域设计，通过引入更多的抽象来解决问题</li><li>将数据库查询显示的建模出来（通过关联对象），而不是直接在模型中引用关联模型的实例，有利于避免查询性能问题</li></ul><h2 id="为什么说smart-domain实现了ddd"><a class="markdownIt-Anchor" href="#为什么说smart-domain实现了ddd"></a> 为什么说Smart Domain实现了DDD？</h2><p>经过上面对Smart Domain的分析之后，可能有人会问：这跟DDD有啥关系？为什么DDD中的很多设计模式都没用却说实现了DDD？</p><p>要回答这个问题，需要搞清楚什么是DDD，即DDD的定义是什么。</p><h3 id="什么是ddd"><a class="markdownIt-Anchor" href="#什么是ddd"></a> 什么是DDD？</h3><p>要追寻DDD的定义，可以回到这本早期的也是业界公认最权威的Eric的书《领域驱动设计-软件核心复杂性应对之道》中。</p><p>Eric并未直接在书中对DDD进行定义，但是在第一章中，结合示例，总结了有效建模的几个要素：</p><ul><li>模型和实现的绑定</li><li>获得了一种基于模型的语言</li><li>开发一个蕴含丰富知识的模型</li><li>持续进行模型提炼</li><li>头脑风暴进行创新，进行大量实验</li></ul><p>在知识消化章节提到：</p><ul><li>分析员和程序员将自己的知识输入到了模型中，因此模型的组织更严密，抽象也更为整洁</li><li>模型反映业务的深层次知识，模型真正是对业务原理的抽象反映</li></ul><p>在统一语言章节提到：</p><ul><li>如果不把“讲话”与各种沟通方式配合起来使用，那么将是巨大的浪费，因为人类本身就有 讲话的天赋。遗憾的是，当人们讲话时，一般并不使用领域模型的语言。</li><li>当人们谈话时，自然会发现词语解释和意义上的差别，而且自然而然会解决这些差别。他们会发现这种语言中的晦涩之处并消除它们，从而使语言变得顺畅。</li><li>使用模型的元素以及模型中各元素之间的交互来大声描述场景，并且按照模型允许的方式将各种概念结合到一起。找到更简单的表达方式来讲出你要讲的话，然后将这些新的思想应用到图和代码中。</li></ul><p>从这些描述可以看出DDD的指导思想是：<strong>深入研究领域，消化知识，充分沟通，然后用软件模型对问题进行深刻的抽象，最终得到一个富含知识的领域模型。</strong></p><h3 id="smart-domain实现ddd"><a class="markdownIt-Anchor" href="#smart-domain实现ddd"></a> Smart Domain实现DDD</h3><p>从上面的分析来看，DDD的实现不在于用何种方法，而是看最后是否得到了良好的深刻的领域模型。Smart Domain可以促进我们把关注点从研究技术转向研究领域，从而推动开发人员去深入分析理解问题，创新的大胆的进行抽象和建模，最终得到好的领域模型。所以，可以说Smart Domain提供了一种很好的方式来实现DDD，这显然是合理的。</p><h2 id="smart-domain的扩展思考"><a class="markdownIt-Anchor" href="#smart-domain的扩展思考"></a> Smart Domain的扩展思考</h2><p>Smart Domain给我们提供了一个新的DDD实现思路。我们对它有没有什么疑问呢？</p><h3 id="领域层抽象"><a class="markdownIt-Anchor" href="#领域层抽象"></a> 领域层抽象</h3><p>习惯分层架构的同学，看到Smart Domain的思想，可能在直觉上会感觉事情不太对：以往可能有的项目上的代码超过10w行，但领域模型却只有10多个，难道要把这些代码都放入这10多个类？</p><p>事实上，这正好是抽象不足的表现，也正是Smart Domain或者DDD希望解决的问题。正是由于我们不能把太多代码放入同一个类（过大的类是一种明显的反模式）这个原因，才<strong>促使我们想办法通过引入更多的抽象来解决问题</strong>。</p><p>如何引入新的抽象？一个典型的示例是DDD原书中提到的关于策略模式抽象的例子。</p><p>在航运领域建模的过程中，在处理货物超订时，如果没有抽象，可以直接在代码中加入一些条件判断代码来实现。这样的处理方式的结果就是某个模型或类中的代码越来越多，直至难以维护。</p><p>而仔细思考领域之后，可以发现：</p><blockquote><p>超订规则是一个策略。策略其实是一种设计模式，也就是我们所说的STRATEGY模式。</p></blockquote><p>可以看到，用策略模式来抽象可以很好的解决这个问题。这就是深入思考的结果。</p><p>除了可以用策略模式进行抽象，DDD书中提到的大多数常见模式都是可以使用的，比如<code>Factory</code>、<code>Repository</code>等。这些模式还包括设计模式中的组合模式、门面模式、解释器模式、观察者模式等等。</p><p>或许是大家在学习或者讲解DDD时过于关注了DDD引入的几个新的模式（如实体、值对象、聚合等），很多人都忽略了DDD中指出的要深入理解领域这个重点中的重点。</p><p>下面是Eric在书中语重心长的想要提醒大家的文字：</p><blockquote><p>通过像PCB示例这样的模型获得的知识远远不只是“发现名词”，业务活动和规则如同所涉 及的实体一样，都是领域的中心…当我们的建模不再局限于寻找实体和值对象时我们才能充分吸取知识…领域专家往往不会意识到他们的思考过程有多么复杂，协作消化知识的过程使得规则得以澄清和充实，并消除规则矛盾以及删除无用规则。</p></blockquote><h3 id="弱化分层强化领域划分"><a class="markdownIt-Anchor" href="#弱化分层强化领域划分"></a> 弱化分层，强化领域划分</h3><p>有人可能会问，上面例子中的策略模式相关的代码应该放在什么地方？当然是领域层！事实上Smart Domain的设计思想是根本不区分这些分层。这样一来，所有代码都是可以看作领域层代码（尽管有一些代码看作基础设施层可能更为合理），从而把尽量多的代码放在领域层，尽最大可能丰富领域层。</p><p>分层被弱化了，领域中的代码变多了，这正是DDD和Smart Domain所希望的结果。然而，随之而来的问题是如何管理这些代码。</p><p>很容易想到的答案是进行模块划分。事实上，DDD中有单独提到“模块”这一模式。<strong>进行模块划分时，应参考高内聚低耦合的原则</strong>，使得模块内是高内聚，模块间是低耦合的。</p><p>常见的不符合高内聚低耦合模块划分原则的一个反例是按照技术名称进行模块划分。比如，可以回顾一下我们维护过的代码库，是不是还记得里面有一些模块的名称是<code>controller</code> <code>requests</code> <code>responses</code> <code>dtos</code> <code>services</code>等等？当我们打开这些模块时，会发现里面的类其实没什么关系，而模块间的相互引用却非常多。</p><p>事实上，DDD中讲到了更多的关于广义的模块划分的内容。从整个源代码库的角度来看，源代码可以按照从小到大不同粒度划分为函数、类、模块、领域、服务等级别。DDD中讲到了如何在这些不同的层级进行划分。</p><p>在<strong>类级别</strong>，DDD原书中提到了<strong>Standalone Class</strong>模式。Standalone Class即独立的与其他类无关的类。这一模式其实是在说类级别的高内聚低耦合。</p><p>在类级别之上，DDD中提到了<strong>Aggregate</strong>模式。Aggretate即<strong>一组强相关的类</strong>形成的聚合。这一模式其实是在说一组类的高内聚低耦合。</p><p>在<strong>领域级别</strong>，DDD提到了<strong>领域划分</strong>。可以按照领域的职责，将领域划分为核心域、通用域、支撑域等领域。这一模式是在说领域的高内聚低耦合。</p><p>事实上，从完整的代码库的角度来看，可以很容易建立以下认知：</p><p>代码块构成一个范围，函数体构成一个范围，类构成一个范围，类所在的包构成了一个范围，包所在的库构成了一个范围。将范围当做领域来理解，可以认为这些领域按照不同的细节程度和抽象程度构成了一个类似森林的结构。而森林的每一层都应当是高内聚低耦合的。</p><p>关于以上内容的更多描述，欢迎参考我的另一篇博客<a href="/2019/08/08/domain-concept-in-your-code/">《代码中的领域》</a>。</p><h3 id="与传统的聚合相结合"><a class="markdownIt-Anchor" href="#与传统的聚合相结合"></a> 与传统的聚合相结合</h3><p>在Smart Domain的示例代码中，基于内存的抽象也通过关联实现，略显麻烦。比如：</p><ul><li>客户端需要调用好几个api才能把一个页面需要的数据拿到，不太方便</li><li>基于内存访问数据比基于关联对象访问更方便</li></ul><p>传统的DDD实现通过聚合（聚合根直接引用其他实体）来解决此问题。如果可以确定聚合中关联的其他实体数量不多，则也许还是可以考虑通过聚合的方式来实现。此时，直接通过一个Restful API一次性返回此聚合中的所有模型即可。</p><p>对于聚合根之间的引用，则仍然可以采用Smart Domain中的关联对象实现方式。</p><p>如此一来，可以结合两者的优势。这可能是实践过程中值得考虑的选择。</p><p>不过，混合两种模式对架构师可能不太友好。与其引入更多的选择，他们可能更希望推进项目中的架构一致性。实际项目中，可能要结合团队成员的能力来综合考虑如何选择。</p><h2 id="总结-2"><a class="markdownIt-Anchor" href="#总结-2"></a> 总结</h2><p>本文分析了Smart Domain的设计，尝试回答了为什么Smart Domain可以用于实现DDD。结合以往对DDD的学习和实践经验，分享了一些扩展的问题。希望对大家了解DDD和Smart Domain有一定帮助。</p><p>虽然Smart Domain作为一种设计范式，可以辅助我们实现DDD。但是具体到真实项目中，建模这个过程还得结合实际的领域问题。有哪些值得参考的案例呢？下一篇文章将做一些分享。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;前段时间，咱们CTO八叉在极客时间做了一次关于用Smart Domain实现DDD的分享（点击&lt;a href=&quot;https://www.bilibili.com/video/BV1QT411J7jh&quot;&gt;这里&lt;/a&gt;回看）。一个新词Smart Domain进入大家的视野。&lt;/p&gt;
&lt;h2 id=&quot;smart-domain解析&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#smart-domain解析&quot;&gt;&lt;/a&gt; Smart Domain解析&lt;/h2&gt;
&lt;p&gt;Smart Domain是啥？为什么可以用Smart Domain实现DDD？本文尝试结合以往对DDD的学习和实践的经验，跟大家分享一下个人的理解。&lt;/p&gt;
&lt;p&gt;八叉在分享中提到Smart Domain这个名字来源于Smart UI。我们都知道Smart UI是DDD中提到的一种反模式，只能用于解决简单问题。这里的命名略带反讽戏谑的意味。&lt;/p&gt;</summary>
    
    
    
    <category term="敏捷" scheme="http://brightliao.com/categories/%E6%95%8F%E6%8D%B7/"/>
    
    <category term="架构" scheme="http://brightliao.com/categories/%E6%95%8F%E6%8D%B7/%E6%9E%B6%E6%9E%84/"/>
    
    <category term="DDD" scheme="http://brightliao.com/categories/%E6%95%8F%E6%8D%B7/%E6%9E%B6%E6%9E%84/ddd/"/>
    
    
    <category term="架构" scheme="http://brightliao.com/tags/%E6%9E%B6%E6%9E%84/"/>
    
    <category term="DDD" scheme="http://brightliao.com/tags/ddd/"/>
    
    <category term="领域" scheme="http://brightliao.com/tags/%E9%A2%86%E5%9F%9F/"/>
    
  </entry>
  
  <entry>
    <title>用TDD开发基于数据库的长时任务系统</title>
    <link href="http://brightliao.com/2022/07/05/tdd-to-develop-a-long-running-task-system/"/>
    <id>http://brightliao.com/2022/07/05/tdd-to-develop-a-long-running-task-system/</id>
    <published>2022-07-05T12:00:00.000Z</published>
    <updated>2022-07-06T06:27:30.614Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h2 id="背景"><a class="markdownIt-Anchor" href="#背景"></a> 背景</h2><p>在最近的一个项目上，我们再次碰到了需要处理长时任务的场景。事实上，随着要处理的业务问题越来越复杂，要集成的系统越来越多，在<code>Web</code>服务器端开发中，长时任务处理已经成为了一个普遍的问题。</p><p>以下场景均可看作长时任务场景：</p><ul><li>在<code>GitHub</code>提交了一个<code>PR</code>，要分别向上百个相关用户单独发送邮件</li><li>用户上传了一个文件，需要扫描这个文件是不是带病毒</li><li>用户想以<code>pdf</code>格式下载某一个文档，需要先将文档转换为<code>pdf</code>格式</li></ul><span id="more"></span><p>这些问题的一个共同特征是执行时间比较长，不能简单的用<strong>单线程的Web服务请求-响应模型</strong>来实现。</p><h2 id="分析问题识别难点"><a class="markdownIt-Anchor" href="#分析问题识别难点"></a> 分析问题，识别难点</h2><p>在应对这些需求场景时，一个关键的设计是需要用异步API模型进行建模。如下图所示：</p><p><img data-src="/attaches/2022/2022-07-05-tdd-to-develop-a-long-running-task-system/long-running-task-basic-model.png" alt="Event model for long-running task" /></p><p>通常的做法如下：</p><ul><li>采用事件模型（<code>Event Model</code>），将长时任务包装为一个事件，放入事件队列</li><li>将待处理事件从事件队列中推送给事件消费者（或者消费者主动拉取新的事件）</li><li>事件消费者处理事件，并保存事件处理结果</li><li>关注事件结果的客户端查询事件处理状态，并提取事件处理结果</li></ul><p>这看上去并不太难，但是，如果仔细思考一下事件的处理过程，会发现情况不对，这里面还存在以下一系列问题：</p><ul><li>如何尽量避免多个事件消费者同时处理此事件，以便节省计算资源？</li><li>如果恰好同时有多个事件消费者在处理事件，会发生什么问题？</li><li>如果有多个相关事件正在被同时处理，如何处理资源竞争问题？</li><li>如何避免长时任务可能导致的长时数据库事务问题？</li></ul><p><img data-src="/attaches/2022/2022-07-05-tdd-to-develop-a-long-running-task-system/long-running-task-problems.png" alt="Problems related to event model" /></p><p>以下方案可用于应对上述问题：</p><ul><li>在事件分派时，通过并发控制或者资源锁定机制，确保只将事件分派给某一个事件消费者</li><li>保证事件处理器的实现是幂等的，即：即便多次同时执行，其最终结果也是一致的</li><li>将任务处理过程拆分为多个短数据库事务过程，避免长期持有数据库锁引起性能问题</li></ul><p>经过以上分析可以发现，异步任务模型是相对比较复杂的模型，程序实现及上线之后的问题分析、调试成本都比较高。在进行系统设计时，如果发现系统可以接受一定的延迟，并且并发也不高，就应尽量避免引入异步任务模型。</p><p>近年来，<code>CQRS</code>（命令查询分离）+<code>Event Sourcing</code>（事件溯源）设计模式越来越受到大家的关注。这一模式中，所有的写操作均采用异步事件的方式进行处理。准备采用这一模式时，一定要评估是否值得，因为异步任务将带来与上述类似的非预期复杂度。同时，如果事件使用不当还容易导致更复杂的情况。比如，如果在事件处理过程中生成了其他的事件，就可能产生一个由任务序列组成的有向图，甚至图中带环，从而使得处理过程的分析变得异常复杂。</p><h2 id="tdd方法简介"><a class="markdownIt-Anchor" href="#tdd方法简介"></a> TDD方法简介</h2><p><code>TDD</code>可以用于辅助我们进行复杂软件设计。是不是可以用<code>TDD</code>帮助我们实现这一复杂的异步任务处理系统呢？下面来做一下尝试。</p><p>在回答这个问题之前，我们先了解一下<code>TDD</code>的基本思想及其实施过程。</p><p>从驱动设计的角度来看，<code>TDD</code>的基本思想是，在还没有代码的时候，先站在使用代码的<strong>用户的角度</strong>来定义测试（编写测试就是在使用代码，所以可以自然的站在用户角度），由于使用了<strong>用户视角</strong>来定义系统组件及其接口，就可以使得到的组件和接口易于使用。</p><p>很多人无法在没有代码的时候编写测试，或者会由于IDE给出的一系列红色警告（由于组件还未定义）而感到不自然。</p><h3 id="写不出测试"><a class="markdownIt-Anchor" href="#写不出测试"></a> 写不出测试</h3><p>写不出测试一般是由于没有理解问题或不了解现有架构。可以采用<code>Tasking</code>（任务拆解）的方式来验证自己是否理解问题并了解架构。其基本思想是，对于一个问题，如果可以列出解决它所需的一系列清晰而合理的步骤，那就说明对问题和架构都较为清楚了。所以，在实施<code>TDD</code>时，一般需要先进行<code>Tasking</code>任务拆解。</p><h3 id="红色警告让人感到不自然"><a class="markdownIt-Anchor" href="#红色警告让人感到不自然"></a> 红色警告让人感到不自然</h3><p>对IDE给出的红色警告感到不自然的问题一般来自习惯。在编写测试代码时，需要调整视角，以完成设计和验证结果为重心。事实上，先写测试还会带来一个额外的好处，那就是在写完测试之后，可以让IDE帮助我们生成绝大多数代码，从而更快的完成代码编写。</p><h2 id="用tdd辅助开发基于数据库的队列服务"><a class="markdownIt-Anchor" href="#用tdd辅助开发基于数据库的队列服务"></a> 用TDD辅助开发基于数据库的队列服务</h2><p>下面看看如何用<code>TDD</code>来设计一个满足上述需求的异步任务处理系统。</p><p>经过前文的分析，我们大致了解了解决长时任务的关键方案。方案里面有一个核心的组件，那就是队列服务。</p><p>可以找到很多开源软件用来做队列服务，比如<code>RabbitMQ</code>，<code>Apache ActiveMQ</code>，<code>Apache RocketMQ</code>，<code>Kafka</code>，<code>Redis</code>等。甚至很多云端的SaaS服务也可以用来解决这个问题，比如<code>AWS SQS</code>，<code>Azure Service Bus queues</code>, <code>GCP Pubsub</code>等。</p><p>在很多项目的上下文中，可以预期并不会有太多的长时任务。此时，为了保持系统简单，避免引入其他的依赖，可以考虑基于数据库来实现这样的一个队列服务。下面分享一下如何用<code>TDD</code>指导我们开发一个基于数据库的长时任务系统。</p><h3 id="第一个测试"><a class="markdownIt-Anchor" href="#第一个测试"></a> 第一个测试</h3><p>采用<code>TDD</code>的思想，首先我们站在（长时任务）系统的用户（将来使用长时任务API的开发者）的角度思考如何使用长时任务的API完成程序功能。</p><pre><code>假设有一个长时任务，它应该可以被添加到队列中。队列应该启动一个后台线程，即消费者线程，从队列中取出任务开始执行。由于任务在消费者线程中执行，消费者线程应该需要知道任务所对应的可执行代码是什么。所以，在消费者线程开始运行之前，需要注册好任务对应的可执行代码。</code></pre><p>基于上面的分析，使用Java进行编码，可写出对应的测试如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TaskQueueTest</span> &#123;</span><br><span class="line">...</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">should_run_task_from_queue</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">var</span> <span class="variable">queue</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskQueue</span>();</span><br><span class="line">        <span class="type">var</span> <span class="variable">consumer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskQueueConsumer</span>(queue);</span><br><span class="line">        </span><br><span class="line">        <span class="type">var</span> <span class="variable">task1Runnable</span> <span class="operator">=</span> mock(TaskRunnable.class);</span><br><span class="line">        <span class="type">var</span> <span class="variable">task2Runnable</span> <span class="operator">=</span> mock(TaskRunnable.class);</span><br><span class="line">        consumer.registerTask(<span class="string">&quot;task_type_1&quot;</span>, task1Runnable);</span><br><span class="line">        consumer.registerTask(<span class="string">&quot;task_type_2&quot;</span>, task2Runnable);</span><br><span class="line">        consumer.start();</span><br><span class="line"></span><br><span class="line">        <span class="type">var</span> <span class="variable">task1Arg</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskType1Arg</span>(“some arg”);</span><br><span class="line">        queue.addTask(“task_type_1”, task1Arg);</span><br><span class="line"></span><br><span class="line">        Thread.sleep(<span class="number">100</span>);</span><br><span class="line">        </span><br><span class="line">        verify(task1Runnable, times(<span class="number">1</span>)).run(eq(task1Arg));</span><br><span class="line"></span><br><span class="line">        <span class="type">var</span> <span class="variable">task2Arg</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskType2Arg</span>(“some arg”);</span><br><span class="line">        queue.addTask(“task_type_2”, task2Arg);</span><br><span class="line"></span><br><span class="line">        Thread.sleep(<span class="number">100</span>);</span><br><span class="line">        </span><br><span class="line">        verify(task2Runnable, times(<span class="number">1</span>)).run(eq(task2Arg));</span><br><span class="line">    &#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>到这里，一个基本的测试用例就定义好了。上述代码用到了<code>JUnit</code>及<code>Mockito</code>测试库的一些<code>API</code>。在编写测试的过程中，我们完成了基本的组件拆分及功能设计。值得注意的是，这里用到的类的名字、方法的名字、方法的参数等均是从用户的角度进行设计的。</p><p>因为我们直接写出了这样的测试代码，此时，IDE会显示很多红色警告，因为测试中用到的类和方法都还未被创建。如果使用<code>Idea</code>进行开发的话，可以将光标移动到红色警告处，按下<code>Alt+Enter</code>，<code>Idea</code>将提示创建类或变量，跟随IDE的指引，就可以很容易的完成这些代码的编写。</p><p><img data-src="/attaches/2022/2022-07-05-tdd-to-develop-a-long-running-task-system/leverage-ide-to-coding.png" alt="Leverage IDE to help coding" /></p><p>到这里我们就完成了第一个测试，并生成了对应的代码框架。整个系统设计的第一步已经初步完成。</p><h3 id="引入新的设计改进测试"><a class="markdownIt-Anchor" href="#引入新的设计改进测试"></a> 引入新的设计，改进测试</h3><p>由于我们希望基于数据库来实现任务队列，而数据库访问一般用<code>Repository</code>进行抽象。对应这里的设计，任务队列应该需要把数据读写的职责拆分出去。</p><p>考虑如何在测试中使用<code>Repository</code>，可以在之前的测试基础上增加<code>Repository</code>相关接口设计。有几处需要修改的地方：</p><ul><li>测试开始时，应该构造一个模拟的<code>Repository</code>对象。</li><li>当新任务加入队列时，任务队列应当调用<code>Repository</code>的接口保存新任务。</li><li>当任务队列消费者开始运行时，它应当从任务队列取出新任务，而任务队列使用<code>Repository</code>查询新的任务。</li><li>当任务被取出，将要运行时，其状态应当被修改为开始执行，并保存到数据库中，此时应当采用批量保存的方式。</li><li>在任务执行期间，其状态将有一系列变化：待运行、开始执行、执行中、执行成功/失败。在任务状态变化时，将调用<code>Repository</code>更新数据库的状态。</li><li>在保存任务的时候，任务的参数需要以一种方式序列化为字符串才能在数据库中保存。可以使用常用的json序列化方式。</li></ul><p>修改测试如下（完整代码见<a href="https://github.com/gmlove/taskqueue-demo/blob/d261bb18d8/src/test/java/com/brightliao/taskqueue/TaskQueueTest.java">这里</a>）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TaskQueueTest</span> &#123;</span><br><span class="line">...</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">should_run_task_from_queue</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">var</span> <span class="variable">taskRepository</span> <span class="operator">=</span> mock(TaskRepository.class);</span><br><span class="line">        <span class="keyword">final</span> <span class="type">ObjectMapper</span> <span class="variable">objectMapper</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ObjectMapper</span>();</span><br><span class="line">        <span class="type">var</span> <span class="variable">queue</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskQueue</span>(taskRepository, tt, objectMapper);</span><br><span class="line">        <span class="type">var</span> <span class="variable">consumer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskQueueConsumer</span>(queue, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">var</span> <span class="variable">task1Runnable</span> <span class="operator">=</span> mock(TaskRunnable.class);</span><br><span class="line">        <span class="type">var</span> <span class="variable">task2Runnable</span> <span class="operator">=</span> mock(TaskRunnable.class);</span><br><span class="line">        consumer.registerTask(<span class="string">&quot;task_type_1&quot;</span>, task1Runnable);</span><br><span class="line">        consumer.registerTask(<span class="string">&quot;task_type_2&quot;</span>, task2Runnable);</span><br><span class="line">        consumer.start();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// run task1 successfully</span></span><br><span class="line">        <span class="type">var</span> <span class="variable">task1Arg</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskType1Arg</span>(<span class="string">&quot;some arg&quot;</span>);</span><br><span class="line">        <span class="keyword">final</span> <span class="type">Task</span> <span class="variable">task1</span> <span class="operator">=</span> someTask(<span class="number">1L</span>, <span class="string">&quot;task_type_1&quot;</span>, <span class="string">&quot;&#123;\&quot;arg\&quot;:\&quot;some arg\&quot;&#125;&quot;</span>);</span><br><span class="line">        when(taskRepository.findNewTasks(eq(<span class="number">1</span>))).thenReturn(List.of(task1)).thenReturn(List.of());</span><br><span class="line">        when(taskRepository.saveAll(anyList())).thenAnswer(answer -&gt; answer.getArgument(<span class="number">0</span>));</span><br><span class="line">        when(taskRepository.save(any())).thenAnswer(answer -&gt; answer.getArgument(<span class="number">0</span>));</span><br><span class="line"></span><br><span class="line">        queue.addTask(<span class="string">&quot;task_type_1&quot;</span>, task1Arg);</span><br><span class="line"></span><br><span class="line">        Thread.sleep(<span class="number">500</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// add -&gt; running -&gt; succeeded</span></span><br><span class="line">        verify(taskRepository, times(<span class="number">3</span>)).save(any(Task.class));</span><br><span class="line">        <span class="comment">// started</span></span><br><span class="line">        verify(taskRepository, times(<span class="number">1</span>)).saveAll(anyList());</span><br><span class="line">        verify(task1Runnable, times(<span class="number">1</span>)).run(eq(<span class="string">&quot;&#123;\&quot;arg\&quot;:\&quot;some arg\&quot;&#125;&quot;</span>));</span><br><span class="line">        assertThat(task1.isSucceeded()).isEqualTo(<span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">        ......</span><br><span class="line">    &#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述测试中，我们模拟了<code>TaskRepository</code>对象，并基于这个模拟对象进行测试。通过模拟这个对象的接口，我们可以完成整个<code>TaskRepository</code>的<code>API</code>设计。</p><p>同样的，可以利用IDE辅助我们生成大量的模板代码，在实现时，只需要在不同的地方填入代码即可。</p><h3 id="加入数据库事务支持进一步改进测试"><a class="markdownIt-Anchor" href="#加入数据库事务支持进一步改进测试"></a> 加入数据库事务支持，进一步改进测试</h3><p>由于程序需要访问数据库进行数据存取，数据库事务控制是一个需要注意的问题。从性能上考虑，数据库事务应当较短，不适合将长时任务运行过程放入事务过程中。</p><p>数据库事务实现可以基于<code>Spring</code>框架提供的事务抽象，即<code>TransactionTemplate</code>接口。可以对以下可快速完成的过程进行事务控制：</p><ul><li>取出新任务后，将任务标记为开始执行。使用排它锁进行事务控制，防止其他任务消费者取到同一个任务</li><li>任务开始执行时，将任务标记为正在执行状态，使用基于版本的乐观锁进行事务控制</li><li>任务执行完成之后，更新任务状态，使用基于版本的乐观锁进行事务控制</li></ul><p>修改测试如下（完整代码见<a href="https://github.com/gmlove/taskqueue-demo/blob/47c332f5c9/src/test/java/com/brightliao/taskqueue/TaskQueueTest.java">这里</a>）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TaskQueueTest</span> &#123;</span><br><span class="line">...</span><br><span class="line">    <span class="keyword">private</span> TransactionTemplate <span class="title function_">mockTransactionTemplate</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">var</span> <span class="variable">tt</span> <span class="operator">=</span> mock(TransactionTemplate.class);</span><br><span class="line">        when(tt.execute(any())).thenAnswer(answer -&gt; &#123;</span><br><span class="line">            <span class="keyword">final</span> TransactionCallback&lt;?&gt; arg = (TransactionCallback&lt;?&gt;) answer.getArgument(<span class="number">0</span>);</span><br><span class="line">            log.info(<span class="string">&quot;execute in transaction: &#123;&#125;&quot;</span>, arg);</span><br><span class="line">            <span class="keyword">return</span> arg.doInTransaction(<span class="keyword">new</span> <span class="title class_">SimpleTransactionStatus</span>());</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        doAnswer(answer -&gt; &#123;</span><br><span class="line">            ((Consumer&lt;TransactionStatus&gt;) answer.getArgument(<span class="number">0</span>)).accept(<span class="keyword">new</span> <span class="title class_">SimpleTransactionStatus</span>());</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">        &#125;).when(tt).executeWithoutResult(any());</span><br><span class="line">        <span class="keyword">return</span> tt;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">should_run_task_from_queue</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">TransactionTemplate</span> <span class="variable">tt</span> <span class="operator">=</span> mockTransactionTemplate();</span><br><span class="line"></span><br><span class="line">        <span class="type">var</span> <span class="variable">taskRepository</span> <span class="operator">=</span> mock(TaskRepository.class);</span><br><span class="line">        <span class="keyword">final</span> <span class="type">ObjectMapper</span> <span class="variable">objectMapper</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ObjectMapper</span>();</span><br><span class="line">        <span class="type">var</span> <span class="variable">queue</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskQueue</span>(taskRepository, tt, objectMapper);</span><br><span class="line">        <span class="type">var</span> <span class="variable">consumer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskQueueConsumer</span>(queue, <span class="number">1</span>);</span><br><span class="line">        ......</span><br><span class="line">    &#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="实现现有的接口"><a class="markdownIt-Anchor" href="#实现现有的接口"></a> 实现现有的接口</h3><p>由于目前只是通过IDE生成了一些代码框架，尚未提供实现，上述测试会失败。接下来的一步就是为现在的设计提供一个实现。</p><p>有了前面的分析，及测试的保障，实现起来应该不是什么难事。有兴趣的同学可以自己试着写一写代码。</p><p>一个参考实现见<a href="https://github.com/gmlove/taskqueue-demo/commit/47c332f5c9652e7484e054d48e03cfb45c5215a8">这里</a>。</p><h3 id="其他的考虑"><a class="markdownIt-Anchor" href="#其他的考虑"></a> 其他的考虑</h3><p>为保证我们的长时任务实现具有较好的易用性，还可以考虑增加以下特性：</p><ul><li>任务消费者异常退出时，任务应该被回收，以便新的任务消费者可以重新处理该任务。</li><li>任务消费者应当被周期性的唤醒，以便可以定时的从队列中取出新任务进行处理。</li><li>当有新任务加入时，任务消费者应该快速被唤醒，以便新任务可以及时得到处理。</li><li>如果执行任务时，任务处理器未被注册，则应该抛出异常，并将任务标记为失败。</li><li>如果任务执行失败，可以进行一定次数的重试。</li><li>可以实现<code>Restful API</code>来完成添加任务、获取任务状态、查询任务列表、重启任务等功能。</li></ul><p>这些特性都可以通过<code>TDD</code>的方式进行实现。</p><p>部分上述特性的详细实现过程及代码可以参考<a href="https://github.com/gmlove/taskqueue-demo/commits/main">这里</a>的提交记录。</p><p>值得注意的是，除了按照前文进行基本的<code>TDD</code>开发。在设计测试时，还需要考虑整体的测试策略。一般而言，测试应该可以按照集成度的从小到大构成一个金字塔的结构。即，大量集成度小的单元测试，中等数量集成度中等的测试，少量的集成度高的测试。在进行<code>TDD</code>时，需要考虑用哪种集成度的测试更好。</p><p>一般的策略是：</p><ul><li>先写一个简单的高集成度测试，通过这个测试驱动编写面向用户的接口，同时也作为面向用户的功能验收。</li><li>再编写少量中等集成度的测试，通过这些测试驱动完成各个组件及其交互接口的设计，同时验证这些组件确实按照设计工作。</li><li>然后再以类级别或函数级别的测试为主，为类或函数的实现提供正确性保障。</li></ul><p>在<code>TDD</code>的过程中，通常还会结合重构来进行局部代码优化。在上述实现中，也有一些可以参考的地方。比如，任务处理器最初命名为<code>TaskRunnable</code>，后来改为<code>TaskHandler</code>，以便更符合语义。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>编写有效的自动化测试是专业的开发人员的一项基本技能。然而，很多团队一味追求快速写完代码，忽略了锻炼开发人员的自动化测试技能，这对于开发人员的能力提升是不利的。</p><p>很多开发人员或者执着于追求底层技术，或者执着于为实现高并发高性能而引入的技巧，或者执着于某个复杂的算法，或者执着于理解某一框架的实现细节。他们认为这些才是自己技术能力的体现。这些确实可以体现一部分开发人员的能力，但是，别忘了，这些始终只是别人创造的成果。</p><p>真实的日常工作常常只是将一个个特定场景下的需求变成可工作的软件，并应对复杂的业务及将来的变更。针对这些特定的问题给出相对简单的合理的设计的能力，编写优雅且高质量的代码的能力，才是开发人员最重要的能力。自动化测试和<code>TDD</code>在这方面可以给开发人员很大的助力。</p><p>事实上，自动化测试和<code>TDD</code>不仅可以帮助完成高质量软件的开发，对前面提到的技术提升也很有帮助。因为，为了编写有效的测试，需要我们对所使用的框架或库有足够的了解，这就促使我们去了解它们的实现细节，同时，可运行的测试还可以用于确认我们的理解。</p><p>本文展示了在一个相对复杂的场景下，如何用<code>TDD</code>帮助我们开发拥有良好设计的代码。可以发现，<code>TDD</code>不仅为我们提供了测试护航，而且，面向用户的接口设计，领域语言的运用，都可以在<code>TDD</code>的加持下自然的落地。</p><p>最后，只看不练并不能带来能力的提升，要想熟练的掌握<code>TDD</code>还需要在日常工作中抓住每一个机会刻意练习。</p><p><strong>相关文章：</strong></p><ul><li><a href="/2019/07/20/tdd-for-improving-design/">从改善设计的角度理解TDD</a></li><li><a href="/2019/08/18/tdd-for-improving-design-2/">从改善设计的角度理解TDD (2)</a></li><li><a href="/2022/05/24/5-properties-of-good-code-cupid/">好代码的五个特质-CUPID</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;背景&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#背景&quot;&gt;&lt;/a&gt; 背景&lt;/h2&gt;
&lt;p&gt;在最近的一个项目上，我们再次碰到了需要处理长时任务的场景。事实上，随着要处理的业务问题越来越复杂，要集成的系统越来越多，在&lt;code&gt;Web&lt;/code&gt;服务器端开发中，长时任务处理已经成为了一个普遍的问题。&lt;/p&gt;
&lt;p&gt;以下场景均可看作长时任务场景：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在&lt;code&gt;GitHub&lt;/code&gt;提交了一个&lt;code&gt;PR&lt;/code&gt;，要分别向上百个相关用户单独发送邮件&lt;/li&gt;
&lt;li&gt;用户上传了一个文件，需要扫描这个文件是不是带病毒&lt;/li&gt;
&lt;li&gt;用户想以&lt;code&gt;pdf&lt;/code&gt;格式下载某一个文档，需要先将文档转换为&lt;code&gt;pdf&lt;/code&gt;格式&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="tdd" scheme="http://brightliao.com/categories/tdd/"/>
    
    <category term="敏捷" scheme="http://brightliao.com/categories/tdd/%E6%95%8F%E6%8D%B7/"/>
    
    
    <category term="agile" scheme="http://brightliao.com/tags/agile/"/>
    
    <category term="敏捷" scheme="http://brightliao.com/tags/%E6%95%8F%E6%8D%B7/"/>
    
    <category term="tdd" scheme="http://brightliao.com/tags/tdd/"/>
    
    <category term="测试" scheme="http://brightliao.com/tags/%E6%B5%8B%E8%AF%95/"/>
    
    <category term="质量" scheme="http://brightliao.com/tags/%E8%B4%A8%E9%87%8F/"/>
    
  </entry>
  
  <entry>
    <title>Efficient ETL Testing</title>
    <link href="http://brightliao.com/2022/06/08/efficient-etl-testing/"/>
    <id>http://brightliao.com/2022/06/08/efficient-etl-testing/</id>
    <published>2022-06-08T12:00:00.000Z</published>
    <updated>2022-07-06T06:23:09.231Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2022/2022-06-08-efficient-etl-testing/efficiency.jpeg" alt="Efficiency. Image from https://unsplash.com/photos/gZB-i-dA6ns" /></p><p><strong>Previous posts about Easy SQL</strong></p><ul><li><a href="/2022/05/04/a-new-etl-language-easy-sql/">A new ETL language – Easy SQL</a></li><li><a href="/2022/05/16/a-guide-to-write-elegant-etl/">A guide to write elegant ETL</a></li><li><a href="/2022/05/25/neat-syntax-design-of-an-etl-language/">Neat syntax design of an ETL language (part 1)</a></li><li><a href="/2022/05/30/neat-syntax-design-of-an-etl-language-part-2/">Neat syntax design of an ETL language (part 2)</a></li></ul><p>It’s always been a pain point to do ETL testing. But it more and more becomes a must after data being so widely used these days.</p><p>An ETL with more than 100 lines of code is common. The filter conditions, data transformation rules, join conditions and other logic there could be very complicated.</p><span id="more"></span><p>In these cases, we should do testing early to avoid possible production issues. Testing gives us confidence about what we coded and helps team with quality assurance.</p><p>But there are a lot of challenges about ETL testing there, and we see a lot of teams struggling.</p><h1 id="etl-testing-challenges"><a class="markdownIt-Anchor" href="#etl-testing-challenges"></a> ETL testing challenges</h1><p>A common way to do ETL testing requires the steps below:</p><ul><li>Create a production-like environment.</li><li>Copy the database definition and table schema to the environment.</li><li>For tables used in the ETL, we prepare testing data and insert data to tables.</li><li>We run the ETL and it generates a new table with data as a result.</li><li>We compare the generated data and the expected data to find if there are any issues.</li></ul><p>There is no easy thing for the above steps.</p><p>For step 1, a production-like environment not only costs, but also requires heavy ops work. Cloud services may ease the ops work but you may be tightly bounded to some cloud.</p><p>For step 2, we may need to write scripts to sync database and table schema. We also need to develop a strategy to store the existing data in test environment. The drawback of it is that it breaks the network separation from test to production environment.</p><p>For step 3, it’s always been hard work to prepare testing data since some tables the ETL used may contain hundreds of columns and we have to pay attention to columns that are not used in the ETL. We also need to be careful about the column types and how the data is generated. And we need a script to insert data as well.</p><p>For step 4, we may need to maintain a separate configuration for test environment.</p><p>For step 5, comparing data manually is tedious work and it’s easy to make mistakes.</p><p>Some team relies on the statistics of the output table to identify issues of ETLs. It is good practice. But when the logic becomes more and more complicated, it’s not enough to just rely on statistics, since there might be cases that are not covered even by the real data.</p><h1 id="testing-etl-in-easy-sql"><a class="markdownIt-Anchor" href="#testing-etl-in-easy-sql"></a> Testing ETL in Easy SQL</h1><p>Easy SQL provides a very light-weight way to do ETL testing. It removes most of the blockers mentioned above.</p><p>To prepare a test in Easy SQL is easy. The first thing to do is to create a spreadsheet from the provided template.</p><p>The template looks like below:</p><p><img data-src="/attaches/2022/2022-06-08-efficient-etl-testing/test_case.png" alt="Test case template" /></p><p>There are two concepts which are popular in testing domain. Easy SQL also adopted them:</p><ul><li>Test case: A single test used to test your code in some specific scenario.</li><li>Test suit: A bundle of a few unit test cases. Could be used to run them together.</li></ul><h2 id="test-suit"><a class="markdownIt-Anchor" href="#test-suit"></a> Test suit</h2><p>In the screenshot above, we see two test suits, named ‘Suit 1’ and ‘Suit 2’. They are put in different sheets. In Easy SQL, if there is any sheet with a name starting with word ‘Suit’, the sheet is considered to be a test suit.</p><h2 id="test-case"><a class="markdownIt-Anchor" href="#test-case"></a> Test case</h2><p>In test suit ‘Suit 1’, we can see two test cases. One case is ‘A test for ETL abc.sql’, and the other is ‘Another test for ETL abc.sql’.</p><p>Test case is recognized by an uppercase keyword <code>CASE</code> in column ‘A’. There should be a name of the test case in column ‘B’, and be next to the <code>CASE</code> keyword.</p><p>To describe a test case, we usually specify the variables that should be used to run the ETL, the data of all input tables, the data of the output tables. They are recognized by keywords <code>VARS</code> <code>INPUT</code> <code>OUTPUT</code> in column ‘A’ and values followed starting from column ‘B’.</p><p>The data of output tables is used to test if output of the ETL after execution is exactly the same as the data specified in the test case.</p><p><strong>Test case element format</strong></p><p>The values of the mentioned elements in a test should be of formats below.</p><ul><li><code>VARS</code>: A table with header and exactly one row of data.</li><li><code>INPUT</code>: A name of the input table specified at column ‘B’; A table with header and number of rows of data starting from column ‘C’ of the same row; Mandatory descriptions of each row of data at column ‘B’ starting from the next row.</li><li><code>OUTPUT</code>: The same format with ‘INPUT’, except that the descriptions of each row of data is optional.</li></ul><p>You may ask why the descriptions of each row of data in ‘INPUT’ table is mandatory. This is a design on purpose. It is designed to improve test readability. The test case designer could record how the data is generated to explain the business rules behind the data and what is the scenario that the data is designed to cover.</p><p>For input tables and output tables, we may need to specify the type of each column. If so, we need to add type to the column names in format ‘{COLUMN_NAME}:{TYPE}’. If there is any column of a table with type specified, the type of other columns should be specified as well. If the type of any other column is not specified, it will be default to ‘string’ type.</p><p><strong>Column types</strong></p><p>The type of column varies for different backends.</p><p>For Spark, it should be <code>int</code> <code>bigint</code> <code>boolean</code> <code>string</code> and so on. The full list of types with built-in support are: <code>int</code> <code>tinyint</code> <code>bigint</code> <code>double</code> <code>float</code> <code>string</code> <code>decimal</code> <code>boolean</code> <code>date</code> <code>timestamp</code> <code>array&lt;string&gt;</code> <code>array&lt;int&gt;</code> <code>array&lt;tinyint&gt;</code> <code>array&lt;bigint&gt;</code> <code>array&lt;double&gt;</code> <code>array&lt;float&gt;</code> <code>array&lt;boolean&gt;</code> <code>array&lt;date&gt;</code> <code>array&lt;timestamp&gt;</code>.</p><p>For Postgres, it should be <code>int</code> <code>bigint</code> <code>boolean</code> <code>text</code> and so on. The full list of types could be found <a href="https://www.postgresql.org/docs/current/datatype.html">here</a>. The default type is <code>text</code>.</p><p>For Clickhouse, it should be <code>Int8</code> <code>Boolean</code> <code>String</code> and so on. The full list of types could be found <a href="https://clickhouse.com/docs/en/sql-reference/data-types/">here</a>.</p><p>For the other backends, please refer to the database data types related document of it.</p><p><strong>Mock includes</strong></p><p>If we have used <strong>include</strong> command in our ETL and we’d like to mock the body of the included file. We can add a <code>INCLUDES</code> section in the test case.</p><p>Then provide the mocked body of the ETL follow the rules below:</p><ol><li>Column ‘B’ at the same row of the <code>INCLUDES</code> keyword should be filled with the file path of the include command in ETL.</li><li>Column ‘C’ at the same row of the <code>INCLUDES</code> keyword should be filled with the mocked body of the included file.</li><li>Add another row to specify a second <code>INCLUDE</code> to mock, with column ‘B’ and ‘C’ filled with file path and the mocked file body.</li></ol><p>Usually, the included ETL file returns some temporary table. In this case, we can mock the content of the included file as below:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=temp.THE_RETURNED_TEMP_TABLE</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> some_mocked_data</span><br></pre></td></tr></table></figure><p>After this, we need to add an input table and provide the mocked data. The way to achieve this is the same as to define a normal input table above.</p><p><strong>Test file name</strong></p><p>We recommend creating one test file for one ETL. It means all the test cases in one spreadsheet file should be testing the same ETL.</p><p>In this case, the file name of the test file and the testing ETL could follow some convention so that we can find the ETL file given the test file.</p><p>Easy SQL provides a way to find ETL file from the test file automatically, which follows a simple convention that the base name of the ETL file and that of the test file should be the same.</p><p>E.g. when the ETL file is named <code>some_etl.sql</code>, then the test file should be named <code>some_etl.xlsx</code>.</p><p>We also recommend there is only one <code>OUTPUT</code> table in one ETL. In this case, the name of the ETL could be the full table name of the output table.</p><p>E.g. when an ETL output a table named <code>some_db.some_table</code>, the file name of the ETL should be <code>some_db.some_table.sql</code> and the test file name of the ETL should be <code>some_db.some_table.xlsx</code>.</p><p><strong>Add test files to version control system</strong></p><p>The test file mentioned above is a spreadsheet file. It is in binary format and not so easy to be added to version control system.</p><p>Easy SQL provides a way to dump a test in spreadsheet format to JSON format. After this, we can add the JSON file to version control system. In this way, we can easily compare the changes of each version of this case.</p><p>The JSON file is also optimized to let us compare data changes easily.</p><p>To convert a test file in spreadsheet format to JSON format. Run the command below:</p><p>(Before you run the command below, you will need to install two additional packages by <code>pip3 install click==6.7 pymongo==3.10.1 xlrd==1.2.0</code>)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m easy_sql.sql_test convert-json -f &#123;YOUR_XLSX_FILE_PATH&#125;</span><br></pre></td></tr></table></figure><p>After the command finishes, there will be a JSON file with the same name but a <code>.json</code> suffix of the spreadsheet file generated. The directory of the JSON file is the same as the spreadsheet file.</p><h1 id="run-test"><a class="markdownIt-Anchor" href="#run-test"></a> Run test</h1><p>Easy SQL provides a command line module to help to run ETL tests.</p><p>To run the ETL test, execute the command below:</p><p>(Before you run the command below, you will need to install two additional packages by <code>pip3 install click==6.7 pymongo==3.10.1 xlrd==1.2.0</code>)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m easy_sql.sql_test run-test -f &#123;YOUR_XLSX_FILE_PATH&#125; -b &#123;BACKEND&#125;</span><br></pre></td></tr></table></figure><p>The test file could be a JSON test file as well. And the backend could be one of the supported backend.</p><p>For details of the command line usage, please run <code>python3 -m easy_sql.sql_test --help</code>.</p><h2 id="run-test-programmatically"><a class="markdownIt-Anchor" href="#run-test-programmatically"></a> Run test programmatically</h2><p>Easy SQL also provides an interface to run ETL programmatically. This way, you can easily integrate tests in Easy SQL with your favorite testing framework.</p><p>To run a test in your code, write code below:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> easy_sql.sql_tester <span class="keyword">import</span> SqlTester</span><br><span class="line"><span class="keyword">from</span> easy_sql.sql_processor.backend <span class="keyword">import</span> SparkBackend</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">SqlTester(env=<span class="string">&#x27;test&#x27;</span>, </span><br><span class="line">          backend_creator=<span class="keyword">lambda</span> case: SparkBackend(SparkSession.builder.enableHiveSupport().getOrCreate()), </span><br><span class="line">          work_dir=os.path.abspath(os.curdir))\</span><br><span class="line">    .run_tests(<span class="string">&#x27;path/to/your/test/file&#x27;</span>)</span><br></pre></td></tr></table></figure><p>For a concrete example, please refer to code <a href="https://github.com/easysql/easy_sql/blob/main/easy_sql/sql_test.py">here</a>.</p><h1 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h1><p>In this post, we talked about the necessity of ETL testing and challenges to do ETL testing.</p><p>In order to be efficient to create automated test cases, we have to spend some time to create some tools.</p><p>Easy SQL provides some built-in tools to help with ETL testing. With the help of Easy SQL, a lot of blockers have been removed. We only need to provide the main information about the test data. There is no more need to care about unrelated columns, data types, data comparing and so on.</p><p>Easy SQL embraces the most commonly used tool – spreadsheet – to create test cases. We can get a lot of benefits from it, such as a friendly and readable layout, the ability to use formula to prepare data, an intuitive way to record data and mock included code snippets etc.</p><p>In one word, with Easy SQL, we can do ETL testing more efficiently and save large amounts of time.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/attaches/2022/2022-06-08-efficient-etl-testing/efficiency.jpeg&quot; alt=&quot;Efficiency. Image from https://unsplash.com/photos/gZB-i-dA6ns&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Previous posts about Easy SQL&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;/2022/05/04/a-new-etl-language-easy-sql/&quot;&gt;A new ETL language – Easy SQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2022/05/16/a-guide-to-write-elegant-etl/&quot;&gt;A guide to write elegant ETL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2022/05/25/neat-syntax-design-of-an-etl-language/&quot;&gt;Neat syntax design of an ETL language (part 1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2022/05/30/neat-syntax-design-of-an-etl-language-part-2/&quot;&gt;Neat syntax design of an ETL language (part 2)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It’s always been a pain point to do ETL testing. But it more and more becomes a must after data being so widely used these days.&lt;/p&gt;
&lt;p&gt;An ETL with more than 100 lines of code is common. The filter conditions, data transformation rules, join conditions and other logic there could be very complicated.&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="EasySQL" scheme="http://brightliao.com/tags/easysql/"/>
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
    <category term="ETL" scheme="http://brightliao.com/tags/etl/"/>
    
    <category term="ETL开发" scheme="http://brightliao.com/tags/etl%E5%BC%80%E5%8F%91/"/>
    
    <category term="数据工程" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="软件工程" scheme="http://brightliao.com/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="编程语言" scheme="http://brightliao.com/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    
    <category term="SQL" scheme="http://brightliao.com/tags/sql/"/>
    
    <category term="编译" scheme="http://brightliao.com/tags/%E7%BC%96%E8%AF%91/"/>
    
    <category term="编译器" scheme="http://brightliao.com/tags/%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Neat Syntax Design of an ETL Language (Part 2)</title>
    <link href="http://brightliao.com/2022/05/30/neat-syntax-design-of-an-etl-language-part-2/"/>
    <id>http://brightliao.com/2022/05/30/neat-syntax-design-of-an-etl-language-part-2/</id>
    <published>2022-05-30T12:00:00.000Z</published>
    <updated>2022-06-18T00:32:33.465Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2022/2022-05-25-neat-syntax-design-of-an-etl-language/mind-mapping.png" alt="Easy SQL language features mind Mapping" /></p><p><strong>Previous posts about Easy SQL</strong></p><ul><li><a href="/2022/05/04/a-new-etl-language-easy-sql/">A new ETL language – Easy SQL</a></li><li><a href="/2022/05/16/a-guide-to-write-elegant-etl/">A guide to write elegant ETL</a></li><li><a href="/2022/05/25/neat-syntax-design-of-an-etl-language/">Neat syntax design of an ETL language (part 1)</a></li></ul><p>People like to use Scala because Scala provides powerful type inference and embraces various programming paradigms. People like to use Python because it’s clean, out-of-the-box, delicate and expressive. People like to use rust because rust provides modern language features and zero-cost abstract.</p><span id="more"></span><p>How to design a neat ETL programming language that people like to use? Let’s have a look at how Easy SQL does. (This topic is broken into two parts. This is the second part.)</p><p>Easy SQL defines a few customized syntax on top of SQL to add imperative characteristics.</p><h2 id="language-features-in-easy-sql"><a class="markdownIt-Anchor" href="#language-features-in-easy-sql"></a> Language features in Easy SQL</h2><p>For Easy SQL, guided by the design principles, there are a few simple language features added to support these imperative characteristics.</p><p>Below is a list of these features:</p><ul><li>An imperative structure of ETL code.</li><li>Variables which could be defined and modified any time.</li><li>A way to call external functions.</li><li>A way to control whether a step should be executed.</li><li>Templates that could be reused in the same ETL file.</li><li>Include command that could be used to reuse code at file level.</li><li>Debugging support: logging and assertion that could be used for debugging.</li><li>A debugger interface.</li><li>Other features：write data to tables; list variables; SQL actions.</li></ul><p>Let’s have a look at the last five features.</p><h2 id="syntax-in-easy-sql"><a class="markdownIt-Anchor" href="#syntax-in-easy-sql"></a> Syntax in Easy SQL</h2><h3 id="templates-used-to-reuse-code"><a class="markdownIt-Anchor" href="#templates-used-to-reuse-code"></a> Templates used to reuse code</h3><p>To support reusing of code, templates have been introduced in Easy SQL.<br />Templates are similar to functions in general programming languages.<br />Functions could be called anywhere while templates could be used anywhere as well. This way, code is reused.</p><p>Just like functions, there are name, parameters and body for a template as well.</p><p>Below is a concrete example of templates:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=template.dim_cols</span></span><br><span class="line">product_name</span><br><span class="line">, product_category</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=temp.dims</span></span><br><span class="line"><span class="keyword">select</span> @&#123;dim_cols&#125; <span class="keyword">from</span> order_count</span><br><span class="line"><span class="keyword">union</span></span><br><span class="line"><span class="keyword">select</span> @&#123;dim_cols&#125; <span class="keyword">from</span> sales_amount</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=template.join_conditions</span></span><br><span class="line">dim.product_name <span class="operator">&lt;=&gt;</span> #&#123;right_table&#125;.product_name</span><br><span class="line"><span class="keyword">and</span> dim.product_category <span class="operator">&lt;=&gt;</span> #&#123;right_table&#125;.product_category</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=temp.joined_data</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">dim.product_name</span><br><span class="line">, dim.product_category</span><br><span class="line">, oc.order_count</span><br><span class="line">, sa.sales_amount </span><br><span class="line"><span class="keyword">from</span> dims dim</span><br><span class="line">    <span class="keyword">left</span> <span class="keyword">join</span> order_count oc <span class="keyword">on</span> @&#123;join_conditions(right_table<span class="operator">=</span>oc)&#125;</span><br><span class="line">    <span class="keyword">left</span> <span class="keyword">join</span> sales_amount sa <span class="keyword">on</span> @&#123;join_conditions(right_table<span class="operator">=</span>sa)&#125;</span><br></pre></td></tr></table></figure><p>There are two templates named ‘dim_cols’ and ‘join_conditions’ defined.<br />One with no parameters and one with one parameter named ‘right_table’.</p><p>This example is about a very common case when we’d like to merge two tables with the same dimension columns.<br />After the template is used, the dimension column names and join conditions are reused, just like how we reuse functions in general programming language.</p><p>From the example above, we could find a few things to note about templates:</p><ul><li>Template is a step in ETL. It is defined by a target with name ‘template’ and a following descriptive name. The descriptive name is the template name.</li><li>The body of a template could be anything.</li><li>If there are template parameters, no need to declare them, just use them by ‘#{PARAMETER_NAME}’. Easy SQL will extract these parameters for you at runtime.</li><li>Templates could be used in any target with syntax ‘@{TEMPLATE_NAME}’. If there are template parameters, we need to pass them as named parameters.</li></ul><p>Besides, there are some other notes:</p><ul><li>Variables can be referenced in template body, and the resolution of variables happens at the resolution time of the template (when the step with template reference is executing). This is useful since we can change the value of some variable between two targets referencing the same template.</li><li>There should be no templates used in the body of templates. This is to make the resolution of templates to be simple.</li></ul><h3 id="include-other-etl-code-snippets"><a class="markdownIt-Anchor" href="#include-other-etl-code-snippets"></a> Include other ETL code snippets</h3><p>Template is designed for reusing code within one ETL. How to reuse code across ETLs?<br />One common way to reuse code is to create a temporary mid-table.<br />But it seems heavy since we need to create a real table and there might be data copying.</p><p>Easy SQL provides a way to reuse code from some other ETL file. This is the ‘include’ command.</p><p>Include looks similar to target. Below is an example:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- include=snippets/some_snippet.sql</span></span><br></pre></td></tr></table></figure><p>The file path is a path relative to the current working directory.</p><p>When Easy SQL processed the ‘include’ command, the content of the file will be expanded.<br />The result will be the same as when we write code in here directly.</p><p>For the example above, if we have the following content in <code>some_snippets.sql</code>:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=temp.some_table</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> some_db.some_table</span><br><span class="line"><span class="comment">-- target=template.some_columns</span></span><br><span class="line">a, b, c</span><br></pre></td></tr></table></figure><p>Then the content of the ETL will be the same as the content of <code>some_snippets.sql</code> since there is only one include command there.</p><p>Notes about ‘include’ command:</p><ul><li>Include command could be used at any line of code.</li><li>When Easy SQL processed this ‘include’ command, the content of the file will simply be expanded.</li></ul><h3 id="debugging-support"><a class="markdownIt-Anchor" href="#debugging-support"></a> Debugging support</h3><p>In a complicated ETL, it is easy to introduce bugs.<br />A general programming language usually provides some ways to help with debugging.<br />The most commonly used way is about logging and assertion.</p><p>Developers can log variables anywhere to provide information about the executing step.<br />They can also set an assertion if there is any important assumption made in the following code.</p><p>To do logging and assertion in Python, the code looks like below:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">logger.info(<span class="string">f&#x27;some thing happened, check the variables: var_a=<span class="subst">&#123;var_a&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="keyword">assert</span> var_a == <span class="string">&#x27;something assumed&#x27;</span>, <span class="string">f&#x27;var_a is not as assumed: var_a=<span class="subst">&#123;var_a&#125;</span>&#x27;</span></span><br></pre></td></tr></table></figure><p>Easy SQL provides a similar way to do logging and assertion. They’re both provided by a type of target.<br />Check the example below to see its usage.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=log.i_would_like_to_log_something</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="number">1</span> <span class="keyword">as</span> a</span><br><span class="line">    , <span class="number">2</span> <span class="keyword">as</span> b</span><br><span class="line">    , $&#123;c&#125; <span class="keyword">as</span> c</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=log.order_count</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line"><span class="built_in">count</span>(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">from</span> sample.order_table</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=check.order_count_must_be_equal_after_joined_product</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    (<span class="keyword">select</span> <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">from</span> sample.order_table) <span class="keyword">as</span> expected</span><br><span class="line">    , (<span class="keyword">select</span> <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">from</span> sample.order_table_after_joined) <span class="keyword">as</span> actual</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=check.equal($&#123;c&#125;, 3)</span></span><br></pre></td></tr></table></figure><p>From the example above, we know that:</p><ul><li>When using the ‘log’ target, we need to specify a message about what to log.</li><li>The log message format is the same as a variable. I.e. It should be composed of chars ‘0-9a-zA-Z_’.</li><li>There should be exactly one row returned from the query of some ‘log’ target. If there is more than one row returned, only the first row will be logged.</li><li>There are two formats of ‘check’ target. One is to specify a check message with a query. The other is to call a function, which returns a boolean value.</li><li>When the ‘check’ target is used as a message with a query, the returned value of the query must be one row with two columns named ‘actual’ and ‘expected’.</li></ul><h3 id="debugger-interface"><a class="markdownIt-Anchor" href="#debugger-interface"></a> Debugger interface</h3><p>There is a debugger interface provided by Easy SQL. It could be used with <code>Jupyter</code> to debug interactively. Follow the steps below to start debugging.</p><ol><li>Install <code>Jupyter</code> first with command <code>pip install jupyterlab</code>.</li><li>Create a file named <code>debugger.py</code> with contents like below:<br />(A more detailed sample could be found <a href="https://easy-sql.readthedocs.io/en/latest/autoapi/easy_sql/sql_processor_debugger/index.html">here</a>.)</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Dict</span>, <span class="type">Any</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_debugger</span>(<span class="params">sql_file_path: <span class="built_in">str</span>, <span class="built_in">vars</span>: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>] = <span class="literal">None</span>, funcs: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>] = <span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line">    <span class="keyword">from</span> easy_sql.sql_processor.backend <span class="keyword">import</span> SparkBackend</span><br><span class="line">    <span class="keyword">from</span> easy_sql.sql_processor_debugger <span class="keyword">import</span> SqlProcessorDebugger</span><br><span class="line">    spark = SparkSession.builder.enableHiveSupport().getOrCreate()</span><br><span class="line">    backend = SparkBackend(spark)</span><br><span class="line">    debugger = SqlProcessorDebugger(sql_file_path, backend, <span class="built_in">vars</span>, funcs)</span><br><span class="line">    <span class="keyword">return</span> debugger</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="3"><li>Create a file named <code>test.sql</code> with contents as <a href="https://github.com/easysql/easy_sql/blob/main/test/sample_etl.spark.sql">here</a>.</li><li>Then start jupyter lab with command: <code>jupyter lab</code>.</li><li>Start debugging like below:</li></ol><p><img data-src="https://raw.githubusercontent.com/easysql/easy_sql/main/debugger-usage.gif" alt="ETL Debugging" /></p><p>For details of the APIs, we can refer to API doc <a href="https://easy-sql.readthedocs.io/en/latest/autoapi/easy_sql/sql_processor_debugger/index.html">here</a>.</p><h3 id="write-data"><a class="markdownIt-Anchor" href="#write-data"></a> Write data</h3><p>If we need to write data to some table, we could use another type of target. The name of the target is ‘output’.<br />There should be a query statement following the ‘output’ target. And the result of the query will be written to the output table.</p><p>Below is an example:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=temp.result</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> a, <span class="string">&#x27;2&#x27;</span> <span class="keyword">as</span> b</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=output.some_db.some_table</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">result</span></span><br></pre></td></tr></table></figure><p>After the execution of the ETL above, there will be one row written to table ‘some_db.some_table’.</p><p>Things to note about ‘output’ target:</p><ul><li>There must be a full table name (both database name and table name specified) after the ‘output’ keyword in the target definition.</li><li>The table must be created before writing data.</li><li>If we’d like to create tables automatically, we need to define a special variable named ‘__create_output_table__’ with value equals to 1.</li><li>If we’d like to write data to some static partition of the output table, we need to define a special variable named ‘__partition__’ with partition column name followed by. An example could be ‘__partition__data_date’. Then the partition column is ‘data_date’. The value of the variable will be the partition value when writing data.</li><li>If we’d like to write data to some static partition of the output table, we can only define one partition value at the moment.</li><li>If the query returns more columns than what is defined by the real table, the extra columns will be ignored.</li><li>If the query returns less columns than what is defined by the real table, an error will be raised.</li></ul><h3 id="list-variables"><a class="markdownIt-Anchor" href="#list-variables"></a> List variables</h3><p>There are list variables supported in Easy SQL as well.</p><p>List variables are different from variables mentioned previously.<br />The main difference is that the values of these variables are lists.<br />So that list variables could not be used in SQL statements, since we cannot simply convert a list to a string and do variable resolution.</p><p>List variables can only be used as function parameters right now.</p><p>Below is an example of list variables.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">-- target=list_variables</span></span><br><span class="line"><span class="keyword">select</span> explode(<span class="keyword">array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)) <span class="keyword">as</span> a</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=func.print_list_variables($&#123;a&#125;)</span></span><br></pre></td></tr></table></figure><p>If we have function implementation like below:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">print_list_variables</span>(<span class="params">a: <span class="type">List</span>[<span class="built_in">str</span>]</span>):</span><br><span class="line">    <span class="built_in">print</span>(a)</span><br></pre></td></tr></table></figure><p>Then the function output will be: <code>[1, 2, 3]</code></p><h3 id="sql-actions"><a class="markdownIt-Anchor" href="#sql-actions"></a> SQL actions</h3><p>There are some cases where we’d like to just execute some SQL statement without anything to do about its result. We can use ‘action’ in these cases.</p><p>This usually happens when we want to execute some DDL statement. Examples would be like to create table, to drop partition of some table etc.</p><p>Action is a type of target as well and it follows target syntax. Below is an example of ‘action’ target:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=action.create_some_table</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> some_table (</span><br><span class="line">    id <span class="type">int</span></span><br><span class="line">    , <span class="keyword">value</span> string</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>Things to note about actions:</p><ul><li>There should be a descriptive name for an action. The name should be composed of chars ‘0-9a-zA-Z_’ and follow the ‘action’ keyword.</li><li>In the body of an action target, templates and variables can be used as in any other target.</li></ul><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><p>In this post, we talked about the last five language features.</p><ul><li>Templates that could be reused in the same ETL file.</li><li>Include command that could be used to reuse code at file level.</li><li>Debugging support: logging and assertion that could be used for debugging.</li><li>A debugger interface.</li><li>Other features：write data to tables; list variables; SQL actions.</li></ul><p>Now we have finished all the language features provided by Easy SQL. But there are a lot more useful features in Easy SQL for us to find out.</p><p>You may already find it useful and would like to have a try. You can get all the information required to get started from the GitHub repo <a href="https://github.com/easysql/easy_sql">here</a> and the docs <a href="https://easy-sql.readthedocs.io/en/latest/">here</a>.</p><p>If you find any issues, you’re welcome to raise it in GitHub Issues and PRs are welcomed as well!</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/attaches/2022/2022-05-25-neat-syntax-design-of-an-etl-language/mind-mapping.png&quot; alt=&quot;Easy SQL language features mind Mapping&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Previous posts about Easy SQL&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;/2022/05/04/a-new-etl-language-easy-sql/&quot;&gt;A new ETL language – Easy SQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2022/05/16/a-guide-to-write-elegant-etl/&quot;&gt;A guide to write elegant ETL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2022/05/25/neat-syntax-design-of-an-etl-language/&quot;&gt;Neat syntax design of an ETL language (part 1)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;People like to use Scala because Scala provides powerful type inference and embraces various programming paradigms. People like to use Python because it’s clean, out-of-the-box, delicate and expressive. People like to use rust because rust provides modern language features and zero-cost abstract.&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="EasySQL" scheme="http://brightliao.com/tags/easysql/"/>
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
    <category term="ETL" scheme="http://brightliao.com/tags/etl/"/>
    
    <category term="ETL开发" scheme="http://brightliao.com/tags/etl%E5%BC%80%E5%8F%91/"/>
    
    <category term="数据工程" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="软件工程" scheme="http://brightliao.com/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="编程语言" scheme="http://brightliao.com/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    
    <category term="SQL" scheme="http://brightliao.com/tags/sql/"/>
    
    <category term="编译" scheme="http://brightliao.com/tags/%E7%BC%96%E8%AF%91/"/>
    
    <category term="编译器" scheme="http://brightliao.com/tags/%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Neat Syntax Design of an ETL Language (Part 1)</title>
    <link href="http://brightliao.com/2022/05/25/neat-syntax-design-of-an-etl-language/"/>
    <id>http://brightliao.com/2022/05/25/neat-syntax-design-of-an-etl-language/</id>
    <published>2022-05-25T12:00:00.000Z</published>
    <updated>2022-05-30T08:10:44.121Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2022/2022-05-25-neat-syntax-design-of-an-etl-language/mind-mapping.png" alt="Easy SQL language features mind Mapping" /></p><p><strong>Previous posts about Easy SQL</strong></p><ul><li><a href="/2022/05/04/a-new-etl-language-easy-sql/">A new ETL language – Easy SQL</a></li><li><a href="/2022/05/16/a-guide-to-write-elegant-etl/">A guide to write elegant ETL</a></li></ul><p>People like to use Scala because Scala provides powerful type inference and embraces various programming paradigms. People like to use Python because it’s clean, out-of-the-box, delicate and expressive. People like to use rust because rust provides modern language features and zero-cost abstract.</p><span id="more"></span><p>How to design a neat ETL programming language that people like to use? Let’s have a look at how Easy SQL does. (We will break this topic into two parts. This is the first part.)</p><p>Easy SQL defines a few customized syntax on top of SQL to add imperative characteristics.</p><h2 id="language-features-in-easy-sql"><a class="markdownIt-Anchor" href="#language-features-in-easy-sql"></a> Language features in Easy SQL</h2><p>For Easy SQL, guided by the design principles, there are a few simple language features added to support these imperative characteristics.</p><p>Below is a list of these features:</p><ul><li>An imperative structure of ETL code.</li><li>Variables which could be defined and modified any time.</li><li>A way to call external functions.</li><li>A way to control whether a step should be executed.</li><li>Templates that could be reused in the same ETL file.</li><li>Include command that could be used to reuse code at file level.</li><li>Debugging support: logging and assertion that could be used for debugging.</li><li>A debugger interface.</li><li>Other features：write data to tables; list variables; SQL actions.</li></ul><p>Let’s have a look at the first four features.</p><h2 id="syntax-in-easy-sql"><a class="markdownIt-Anchor" href="#syntax-in-easy-sql"></a> Syntax in Easy SQL</h2><h3 id="the-imperative-structure"><a class="markdownIt-Anchor" href="#the-imperative-structure"></a> The imperative structure</h3><p>The most obvious characteristics of imperative programming is that code will be executed line by line (or piece by piece).<br />And the declarative way (standard SQL) suggests the opposite, which says, all logic should be defined first and then be executed in one final action.</p><p>The major task of designing the imperative structure is to introduce a way to execute SQL step by step.<br />If we look at Spark DataFrame API, we could find that it works in an imperative way.<br />For example, we can assign a DataFrame to some variable, then do something about the variable, then transform the variable and assign it to another variable.</p><p>In Easy SQL, a simple syntax is introduced as SQL comment, which is <code>target=</code> and <code>-- target=SOME_TARGET</code> in Easy SQL.</p><p>There are a few built-in types of targets, which are:</p><ul><li>variables</li><li>temp</li><li>cache</li><li>broadcast</li><li>func</li><li>log</li><li>check</li><li>output</li><li>template</li><li>list_variables</li><li>action</li></ul><p>When used in Easy SQL ETL, it looks like below:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> a, <span class="string">&#x27;2&#x27;</span> <span class="keyword">as</span> b</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=cache.table_a</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> some_db.table_a</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=temp.table_b</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> some_db.table_b</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=broadcast.table_c</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> some_db.table_c</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=output.some_db.some_table</span></span><br><span class="line"><span class="keyword">select</span> </span><br><span class="line">    <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> table_a a </span><br><span class="line">    <span class="keyword">left</span> <span class="keyword">join</span> table_b b <span class="keyword">on</span> a.id<span class="operator">=</span>b.id</span><br><span class="line">    <span class="keyword">left</span> <span class="keyword">join</span> table_c c <span class="keyword">on</span> a.id<span class="operator">=</span>c.id</span><br></pre></td></tr></table></figure><p>There is a SQL query under every <code>target</code> statement.<br />It means the result of the SQL query is saved to the specified target.<br />Each <code>target</code> could be viewed as a step and will be executed one by one.</p><p>The syntax may seem obvious to most of you. If it is so, it means the design goal is achieved.</p><p>Let’s spend some time explaining what it does in the simple ETL above.<br />If you believe you got it already, please skip it.</p><ol><li>The first <code>target</code> statement means the SQL query result, <code>a=1 and b='2'</code> in this case, will be saved to the variables target. After this step, the variables could be used.</li><li>The second <code>target</code> statement means that the query from table_a will be saved to a cached table named ‘table_a’. Cache table is a concept borrowed from Spark and it means the query result will be cached and could be reused from the following steps to improve performance.</li><li>The third <code>target</code> statement means that the query from table_b will be saved to a temporary table named ‘table_b’. And ‘table_b’ could be used in the following steps.</li><li>The forth <code>target</code> statement means that the query from table_c will be saved to a broadcasted table named ‘table_c’. Broadcast table is also a concept borrowed from Spark and it means the table will be broadcasted to every node to improve performance. And the table ‘table_c’ could be used in the following steps too.</li><li>The fifth <code>target</code> statement means that the joined query result of the above 3 tables will be saved to an output table named ‘some_table’ in ‘some_db’.</li></ol><h3 id="variables"><a class="markdownIt-Anchor" href="#variables"></a> Variables</h3><p>Variables could be defined and modified at any step. The syntax is as the case above.<br />If we’d like to modify the value of it, we can just add another <code>variables</code> target and write a query with the result of changed ‘a’ and ‘b’.<br />A simple example is as below:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> a, <span class="number">2</span> <span class="keyword">as</span> b</span><br><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">2</span> <span class="keyword">as</span> a, <span class="number">1</span> <span class="keyword">as</span> b</span><br></pre></td></tr></table></figure><p>After the two steps, the value of a will be 2, and it will be 1 for the value of b.</p><p>Variables could be referenced anywhere in the following steps with syntax ‘${VAR_NAME}’.</p><p>There is a simple example below:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> a, <span class="string">&#x27;2&#x27;</span> <span class="keyword">as</span> b</span><br><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> </span><br><span class="line">    $&#123;a&#125; <span class="keyword">as</span> a</span><br><span class="line">    , $&#123;b&#125; <span class="keyword">as</span> b</span><br><span class="line">    , <span class="number">1</span>$&#123;a&#125; <span class="keyword">as</span> a1</span><br><span class="line">    , $&#123;a&#125; <span class="operator">+</span> $&#123;b&#125; <span class="keyword">as</span> ab</span><br></pre></td></tr></table></figure><p>When Easy SQL engine reaches the second step, it will do a variable lookup and simply replace the reference with the real value.<br />It will replace it with the string value of the variable and converts types when required.</p><p>The above example will result in variables: <code>a=1, b=2, a1=11, ab=3</code>.</p><p>Besides the user-defined variables, there are a few useful system-defined variables.<br />When we need to implement some complicated functions, we can use them.</p><p>Other things to note about variables:</p><ul><li>Variable name must be composed of chars ‘0-9a-zA-Z_’.</li><li>Variable name is case-insensitive.</li></ul><h3 id="temporary-tables"><a class="markdownIt-Anchor" href="#temporary-tables"></a> Temporary tables</h3><p>Another common case is to save a query to a temporary table for later query. We have already seen a concrete example above.</p><p>It works simply as what you expected.</p><ul><li>The query result will be saved to a temporary table if the target is ‘temp’.</li><li>The query result will be saved to a cached temporary table if the target is ‘cache’.</li><li>The query result will be saved to a broadcasted temporary table if the target is ‘broadcast’.</li></ul><p>Speaking of implementation, if the backend is Spark, ‘temp’ ‘cache’ and ‘broadcast’ behave the same as that in Spark,<br />and with a global temporary table created or replaced with the specified name.<br />For the other backends in which there is no support of caching and broadcasting of temporary tables,<br />Easy SQL just create views with the specified name in a temporary default database.</p><p>Since there is no actual loading of data for temporary tables, to define a temporary table is a very light-weight operation.<br />You can create as many temporary tables as you wish.</p><p>There are a few things to note when creating temporary tables for different backends.</p><ul><li>For Spark backend, the name of the temporary table can be reused, but it cannot be reused for the other backends since we cannot create two database views with the same name in the same default database.</li><li>For BigQuery backend, we have to specify names like <code>$&#123;temp_db&#125;.SOME_TEMP_TABLE_NAME</code> when query the created temporary table. You guessed it, the ‘temp_db’ is a pre-defined variable provided by Easy SQL engine. This limitation is introduced by BigQuery since there is no such concept of a default database (named dataset in BigQuery).</li></ul><h3 id="function-calls"><a class="markdownIt-Anchor" href="#function-calls"></a> Function calls</h3><p>Function calls is another feature introduced by Easy SQL. It is used to expand the ability of SQL, so that we could do anything in SQL.</p><p>Function is defined in Python code and registered before the execution of the ETL.<br />The syntax to call a function is very intuitive if you have experience of some other programming languages.</p><p>Below is an example of function calls.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=func.plus(1, 1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=func.do_some_thing()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> $&#123;plus(<span class="number">2</span>, <span class="number">2</span>)&#125; <span class="keyword">as</span> a</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> $&#123;plus($&#123;a&#125;, <span class="number">2</span>)&#125; <span class="keyword">as</span> b</span><br></pre></td></tr></table></figure><p>From the ETL code above, we can find a few things about function calls:</p><ul><li>Function calls could be used as a ‘func’ target.</li><li>The result of function calls could be used as a variable.</li><li>Parameters of function calls could be variables.</li></ul><p>Besides these, there are a few other things to note:</p><ul><li>One function call expression must be in one line of code.</li><li>When functions are called, all non-variable parameters are passed as strings even if it looks like an integer. In the function implementation, we need to convert types from string to its real type.</li><li>There should be no chars from any of <code>,()</code> in literal parameters. If there is, we need to define a variable before the function call and pass in the variable as a parameter.</li><li>Any user-defined variable will be converted to string and passed to functions as string value. We may need to convert types in the function implementation.</li><li>All functions in the Python <code>builtin</code> module and <code>operators</code> module are automatically registered, so we can use a lot of Python functions without providing an implementation.</li></ul><p>Before execution of the above ETL, we need to define the functions referenced in the ETL. Followed by the above rules, an example of the function implementations could be:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plus</span>(<span class="params">a: <span class="built_in">str</span>, b: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">int</span>(a) + <span class="built_in">int</span>(b)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">do_some_thing</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;do things...&#x27;</span>)</span><br></pre></td></tr></table></figure><p>And then after the execution of the ETL, the value of the variables will be: <code>a=4, b=6</code>.</p><h3 id="control-execution-flow"><a class="markdownIt-Anchor" href="#control-execution-flow"></a> Control execution flow</h3><p>For an imperative language, providing a way to control execution flow is important.</p><p>Back to the top, there is a case mentioned that<br />‘we would like to use large computing resources when we’re handling data in the first partition since the amount of data there is far larger than that in the other partitions’.<br />In order to implement this in ETL, we need to control the execution flow to configure a large computing resource.</p><p>A common way in general programming language to handle this is to provide some ‘if’ statement.<br />And we need to provide a condition expression for ‘if’ statement.<br />The inner action of ‘if’ statement is then executed according to the true or false value of the condition expression.</p><p>Easy SQL provides a similar way to control execution flow.<br />We can control if a step needs to be executed by providing a ‘if’ statement after any step definition.<br />Below is an example:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=func.do_some_thing(), if=bool()</span></span><br><span class="line"><span class="comment">-- target=func.do_another_thing(), if=bool(1)</span></span><br><span class="line"><span class="comment">-- target=func.do_a_third_thing(), if=bool($&#123;some_variable_indicator&#125;)</span></span><br><span class="line"><span class="comment">-- target=temp.table_a, if=bool()</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> some_db.table_a</span><br><span class="line"><span class="comment">-- target=variables, if=bool(1)</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> a</span><br></pre></td></tr></table></figure><p>From the example, we know the following things about ‘if’ statement in Easy SQL:</p><ul><li>There must be a function call following the ‘if’ statement.</li><li>The function call must return a boolean value to indicate if the step needs to be executed.</li><li>Any step could be controlled by a ‘if’ statement, including ‘func’ ‘temp’ ‘variables’ and so on.</li></ul><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><p>In this post, we talked about the first 4 language features.</p><ul><li>An imperative structure of ETL code.</li><li>Variables which could be defined and modified any time.</li><li>A way to call external functions.</li><li>A way to control whether a step should be executed.</li></ul><p>For the other features, let’s talk about it in a post later on.</p><p>You may already find it useful and would like to have a try. You can get all the information required to get started from the GitHub repo <a href="https://github.com/easysql/easy_sql">here</a> and the docs <a href="https://easy-sql.readthedocs.io/en/latest/">here</a>.</p><p>If you find any issues, you’re welcome to raise it in GitHub Issues and PRs are welcomed as well!</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/attaches/2022/2022-05-25-neat-syntax-design-of-an-etl-language/mind-mapping.png&quot; alt=&quot;Easy SQL language features mind Mapping&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Previous posts about Easy SQL&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;/2022/05/04/a-new-etl-language-easy-sql/&quot;&gt;A new ETL language – Easy SQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2022/05/16/a-guide-to-write-elegant-etl/&quot;&gt;A guide to write elegant ETL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;People like to use Scala because Scala provides powerful type inference and embraces various programming paradigms. People like to use Python because it’s clean, out-of-the-box, delicate and expressive. People like to use rust because rust provides modern language features and zero-cost abstract.&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="EasySQL" scheme="http://brightliao.com/tags/easysql/"/>
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
    <category term="ETL" scheme="http://brightliao.com/tags/etl/"/>
    
    <category term="ETL开发" scheme="http://brightliao.com/tags/etl%E5%BC%80%E5%8F%91/"/>
    
    <category term="数据工程" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="软件工程" scheme="http://brightliao.com/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="编程语言" scheme="http://brightliao.com/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    
    <category term="SQL" scheme="http://brightliao.com/tags/sql/"/>
    
    <category term="编译" scheme="http://brightliao.com/tags/%E7%BC%96%E8%AF%91/"/>
    
    <category term="编译器" scheme="http://brightliao.com/tags/%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>好代码的五个特质-CUPID</title>
    <link href="http://brightliao.com/2022/05/24/5-properties-of-good-code-cupid/"/>
    <id>http://brightliao.com/2022/05/24/5-properties-of-good-code-cupid/</id>
    <published>2022-05-24T12:00:00.000Z</published>
    <updated>2023-06-19T14:40:32.087Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>新的一期技术雷达如期发布，仔细阅读了这一期的所有条目，CUPID这一条尤其让我产生共鸣。</p><p>CUPID出自Daniel的一篇名为<a href="https://dannorth.net/2022/02/10/cupid-for-joyful-coding/">《CUPID—for joyful coding》</a>的博文，即《CUPID-为了快乐编程》。CUPID是Composable/Unix philosophy/Predictable/Idiomatic/Domain based几个单词的缩写，有经验的同学一看就知道这是好代码的一些属性。知道<strong>Cupid</strong>这个单词的同学还能感受到这一组属性所蕴含的对于软件工程的热情。Cupid的中文是丘比特，是指古罗马的爱神，其意象是一个长有翅膀的小孩，拿着弓箭射向人们，以便人们可以相互爱上对方。</p><p><img data-src="/attaches/2022/2022-05-24-5-properties-of-good-code-cupid/cupid.png" alt="CUPID for joyful coding" /></p><span id="more"></span><h2 id="特质"><a class="markdownIt-Anchor" href="#特质"></a> 特质</h2><p>Daniel老爷子回忆了自己三十多年的编程经历，他发现在修改代码时，好的代码会给人一种非常愉悦的感觉。你可以轻松找到需要修改的地方，而且，那个地方的代码是如此的易于理解，以至于一眼就能看出来代码在干什么。你可以很自信的完成修改，并且确信不会引入额外的副作用。代码是那么的鲜活，它会主动的指引你去你想去的地方，并且热情的欢迎你四处游览，就像在你熟悉的家里一样！</p><p>为什么好的代码能有这样的魅力？什么样的代码才是好代码？提到这个问题，我们常常会想到SOLID（Single Responsibility/Open-close/Liskov Substitution/Interface Segregation/Dependency Injection）原则，Daniel老爷子认为应该存在比SOLID更好用的东西。</p><p>如何衡量代码好坏？SOLID采用了一组原则来定义好的代码，但是原则更像是规则，要么符合，要么不符合。而软件开发过程非常复杂，其间充满了平衡和妥协，事实上并没有一种非黑即白的规则可以适用。有没有比原则更好的选择？它可能是特质（Properties/Characteristics）。</p><p>特质是事物本身所具备的，而不是靠一组规则去定义的；特质吸引我们去深度挖掘，而不是信任已有的总结；特质通常不是简单的0或1的判断，而是一种从低到高的程度；特质是从观察者的角度给出的，更关注观察者的体验，而更少关注与体验无关的其他方面。</p><p>之所以我们会觉得某样东西是好的，常常是因为某样东西具备了一些好的特质。比如蓝天白云图，它具备了干净、纯粹的特质。比如勾股定理和质能方程，它们具备简洁、优雅的特质。</p><p>如果说好的代码是一个中心点，特质就像是定义了一些方向，通过这些方向的指引，就可以不断向这个中心点靠拢。</p><p>CUPID就是从特质的角度来定义的，它尝试用一组助记词来指示好代码所具备的一组特质，并希望这组特质是最重要的特质。</p><p>CUPID所指出的方向与SOLID定义的原则并不冲突，只是角度不同，CUPID更多站在代码的用户–将来修改代码的人–的视角来看待代码，并指出了好的代码应该具备的特质。从这个角度来讲，CUPID比SOLID的适用性更广（SOLID事实上只是针对面向对象设计提出的）。比如，给出一段代码，用SOLID可能并不能判断好坏，因为这段代码可能根本不涉及SOLID中提到的几个原则（比如函数式风格的代码）。但是很大可能可以从CUPID指明的几个方向来得到一些结论。</p><p>CUPID是完备的吗，很遗憾，也不是。但CUPID所指出的五种特质可能是按照重要程度排序之后取前五的特质。</p><h2 id="理解cupid"><a class="markdownIt-Anchor" href="#理解cupid"></a> 理解CUPID</h2><p>下面我们一起看看CUPID到底是什么，以及，如何用CUPID来帮助我们写出好的代码。</p><p>下面的内容，部分来自Daniel老爷子的<a href="https://dannorth.net/2022/02/10/cupid-for-joyful-coding/">原文</a>，部分结合了个人的心得体会，分享给大家。</p><h3 id="可组合特质c"><a class="markdownIt-Anchor" href="#可组合特质c"></a> 可组合特质（C）</h3><p>CUPID的第一个字母C是指Composable，即可组合特质。</p><p>近两年，我们在讨论面向对象程序设计的时候，越来越关注到“组合优于继承”这样的原则。作为面向对象程序设计的三大特征之一的“继承”，似乎正越来越受到挑战，这一部分原因是很多继承的设计是不合理的，比如不符合SOLID所指出的里氏代换原则。另一部分原因在于，过深的继承树带来了代码的可理解性问题，因为我们总是需要理解了基类才能理解子类。其实继承也是很有用的，但其前提是设计合理的继承。“组合优于继承”就是告诉我们优先考虑用组合模式来进行设计。</p><p>可组合还体现在以下三个方面：</p><p><strong>精巧的接口</strong></p><p>接口太多时，读者需要知道如何组合这些接口去完成某个功能，而接口较少时，读者可以更容易学习并更少犯错。只对外公开一个模块来提供接口，比对外公开多个模块提供接口更好。只对外公开一个类来提供接口，比对外公开多个类提供接口更好。</p><p>正确的接口粒度设计比较困难，最佳的粒度是接口既不显得臃肿也不碎片化。</p><p>设计模式中有一种常见的模式Facade，即门面模式，其意图正是将对外公开的接口放到一个类中去提供，以便减少接口面，从而让接口更容易使用。</p><p><strong>可体现意图的代码</strong></p><p>可体现意图的代码是用业务语言编写且能反映业务过程的代码。可体现意图的代码可以使读者更容易弄清为什么代码要这么写，因此更容易组合使用。代码中的各类命名（比如变量、函数等）都可以用于将意图体现得更为明显。</p><p>比如以下意图不明的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">getTodos</span>(<span class="params">todos, users</span>):</span><br><span class="line">    todos = [todo <span class="keyword">for</span> todo <span class="keyword">in</span> todo <span class="keyword">if</span> <span class="keyword">not</span> todo.completed <span class="keyword">and</span> todo.<span class="built_in">type</span> == ‘HOME’]</span><br><span class="line">    todos = [&#123;‘title’: todo.title, ‘user_name’: users[todo.userId].name&#125; <span class="keyword">for</span> todo <span class="keyword">in</span> todo]</span><br><span class="line">    todos.sort(key=<span class="keyword">lambda</span> todo: todo[’user_name’])</span><br><span class="line"><span class="keyword">return</span> todos</span><br></pre></td></tr></table></figure><p>可以重构为以下意图明确的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_todos</span>(<span class="params">todos, users</span>):</span><br><span class="line">    top_priority_todos = [todo <span class="keyword">for</span> todo <span class="keyword">in</span> todo <span class="keyword">if</span> <span class="keyword">not</span> todo.completed <span class="keyword">and</span> todo.<span class="built_in">type</span> == ‘HOME’]</span><br><span class="line">    todo_view_models = [&#123;‘title’: todo.title, ‘user_name’: users[todo.userId].name&#125; <span class="keyword">for</span> todo <span class="keyword">in</span> top_priority_todos]</span><br><span class="line">    todo_view_models.sort(key=<span class="keyword">lambda</span> todo: todo[’user_name’])</span><br><span class="line"><span class="keyword">return</span> todo_view_models</span><br></pre></td></tr></table></figure><p>或者：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_todos</span>(<span class="params">todos, users</span>):</span><br><span class="line">    is_top_priority = <span class="keyword">lambda</span> todo: <span class="keyword">not</span> todo.completed <span class="keyword">and</span> todo.<span class="built_in">type</span> == ‘HOME’</span><br><span class="line">    todos = [todo <span class="keyword">for</span> todo <span class="keyword">in</span> todo <span class="keyword">if</span> is_top_priority(todo)]</span><br><span class="line">    to_view_model = <span class="keyword">lambda</span> todo: &#123;‘title’: todo.title, ‘user_name’: users[todo.userId].name&#125;</span><br><span class="line">    todos = [to_view_model(todo) <span class="keyword">for</span> todo <span class="keyword">in</span> todo]</span><br><span class="line">    user_name = <span class="keyword">lambda</span> todo: todo[’user_name’]</span><br><span class="line">    todos.sort(key=user_name)</span><br><span class="line"><span class="keyword">return</span> todos</span><br></pre></td></tr></table></figure><p><strong>最小依赖</strong></p><p>拥有最小依赖的代码是容易组合使用的。</p><p>当一个库有大量的依赖时，一旦使用了这个库就会间接引入这些依赖。这不仅使我们发布的二进制制品变得臃肿，也很容易引起一些依赖库的版本冲突问题。大家如果做过Hadoop的MapReduce任务开发，应该对这个问题深有体会，因为Hadoop本身有大量的Java依赖，如果我们在MapReduce任务中不小心引入了一个和Hadoop本身的依赖不兼容的版本，在任务运行时就会出错。</p><p>一个拥有最小依赖的库是很容易使用的，上述包冲突问题会更少发生。</p><p>我常常在项目中见到有人为了实现一些很简单的功能而引入没必要的依赖。比如，当我们面对的问题只是简单的查询ElasticSearch服务中的数据时，就要评估一下是否有必要引入ElasticSearch的客户端库依赖，因为我们可以很容易的使用通用的HTTP工具库来发送一个请求来实现数据查询。</p><p>面向对象程序设计有一个重要的原则，即迪米特法则（Law of Demeter），又被称为最小知识原则、不要和陌生人说话原则。其指导意义在于一个类不应该和与其不相关的类产生（依赖）关系。</p><h3 id="unix哲学u"><a class="markdownIt-Anchor" href="#unix哲学u"></a> Unix哲学（U）</h3><p>CUPID的第二个特质U即是指Unix哲学。</p><p>Unix可以说是当今应用最广泛的操作系统，不管是云服务器还是个人电脑抑或智能手机、IoT设备，都有Unix的影子。Unix广泛的以Linux、MacOS、iOS、Android等等操作系统的形式存在着。为什么Unix可以如此成功？这得益于Unix的简单而一致的设计哲学。</p><p>CUPID中的Unix哲学主要指其最重要的一个观点：一个程序应该做一件事，并将其做好。Unix中的大量程序都很好的提现了这一特质，比如<code>ls</code>程序只做列举文件的事，而要查看文件详情，则需要使用<code>lstat</code>，查看文件内容使用<code>cat</code>，搜索文件内容使用<code>grep</code>等等。如果我们查看这些程序的使用手册（Manual Page），将发现每一个程序都提供了很多的参数供选择，事实上每个程序的功能都很强大，并处理了大量的异常情况。这就是把一件事做好的体现。</p><p>Unix操作系统中定义了一个强大的管道（Pipe）概念，一个程序的输出可以通过管道传输给另一个程序，从而简单而一致的实现了多个程序的组合使用。比如<code>ls</code>命令可以列举出文件列表，然后将结果传输给<code>wc</code>程序统计数量，就可以简单的计算出目录中的文件数量。</p><p>只做好一件事与SOLID中的单一职责原则很像。但是Unix哲学的出发点是读者，从读者角度来看程序，得出程序应该只做好一件事的结论。单一职责原则则是从代码的角度出发进行描述的。Unix哲学更多描述的是程序的目的，并指明一个程序应该只有一个目的。</p><p>与Unix原则描述很相似的还有关注点分离的原则。关注点分离是指不同的模块应该关注不同的事情。比如分层设计，每一层的关注点应该不一样：<code>MVC</code>中的<code>M</code>关注业务模型和业务逻辑，<code>V</code>关注展示，<code>C</code>关注交互逻辑；<code>TCP/IP</code>四层网络模型中物理层关注物理链路，网络层关心节点链路如何建立，传输层关注数据发送的可靠性，应用层关注在具体的应用协议。</p><h3 id="可预测性p"><a class="markdownIt-Anchor" href="#可预测性p"></a> 可预测性（P）</h3><p>CUPID的第三个特质P是指Predictable，可预测性。</p><p>程序的可预测性是指它应该做它看起来要做的事情，一致且可靠，不隐藏任何出乎意料的行为。</p><p>可预测性包括三个方面：1. 与期望一致的行为；2. 输出确定的结果；3. 内部行为可观测。</p><p><strong>与期望一致的行为</strong></p><p>我们可以通过测试来定义所期望的程序的行为，但是并不是一定需要用测试来让程序与期望的行为一致。精心的挑选名字，克制的编写逻辑，正确的处理异常这些都能使得程序与期望的行为一致。</p><p>读操作和写操作常常被分开对待。读操作不会对程序状态产生影响，我们可以安全的调用，不用顾忌太多后果。写操作用于修改程序状态，因此，在使用时需要特别小心，比如如果有多线程访问就需要考虑线程安全，同时操作多个状态就需要考虑事务一致性。</p><p>如何在读操作和写操作中保持与期望一致的行为？那就是读操作中不应该隐藏某些让人意外的写操作。</p><p><strong>输出确定性的结果</strong></p><p>具备确定性的程序很容易让人理解和使用，因为它在任何一次调用都会返回同样的结果，我们可以明确的知道它将返回什么。</p><p>我们常说易于推理的代码是好代码，具备确定性的就具备易于推理的特性。</p><p>大概是由于Web前端技术的飞速发展，近些年函数式编程范式得到广大开发者的亲睐。函数式编程范式中最重要的一个概念就是纯函数。纯函数是指没有任何副作用且可以输出确定的结果的函数。</p><p>纯函数是更容易测试的，我们对使用它的信心也更强。但是，在函数式编程范式中，对纯函数的<a href="https://en.wikipedia.org/wiki/Pure_function">规范定义</a>显得学院化，并加入了场景限定。事实上，我们主要需要的是程序的确定性。用面向对象范式编程，可以考虑把一个对象设计成<a href="https://en.wikipedia.org/wiki/Value_object">值对象</a>，这样也可以增强程序的确定性。由于不确定性常常来自复杂且不确定的依赖（比如，某个依赖自己管理了复杂的状态，就也会间接的使你的代码充满不确定性），在设计类时，严格控制其依赖的外部模块，尽量做到无依赖，也可以增强程序的确定性。</p><p>具备确定性的代码通常是健壮、可靠而具备弹性的。</p><p><strong>内部行为可观测</strong></p><p>如何预测程序的行为？观察它的运行时输出是一个很好的方法。如果程序可以在运行时打印关键的内部状态或行为就可以让我们推测其当前状态。</p><p>观察程序内部状态可以分为以下几个级别：</p><ul><li><strong>信息仪表（Instrumentation）</strong>: 程序告诉我们它正在干什么</li><li><strong>遥测（Telemetry）</strong>: 将程序告诉我们的信息以一种接口暴露出来，使其可以被远程访问</li><li><strong>监控（Monitoring）</strong>: 将程序告诉我们的信息可视化出来</li><li><strong>告警（Alerting）</strong>: 从监控信息中识别异常，发出通知</li><li><strong>预测（Predicting）</strong>: 利用监控信息来预测即将发生的事件</li><li><strong>自适应（Adapting）</strong>: 通过告警的或者预测的信息动态调整系统以适应变化</li></ul><p>有一些工具可以自动提取程序运行时信息供分析，但是最佳的提升程序的可观测性的方式还是通过有意识的设计来在关键处输出程序的状态或行为。</p><h3 id="符合惯例的i"><a class="markdownIt-Anchor" href="#符合惯例的i"></a> 符合惯例的（I）</h3><p>CUPID的第四个特质I是指Idiomatic，符合惯例的。</p><p>大家都有自己的编码习惯，这些习惯包括空格和制表符的使用，变量命名规则，括号放置位置，代码结构，提交的粒度和注释等等。这些不一样的习惯将显著的增加不熟悉代码库的读者的认知负载。读者不仅需要理解问题空间和解空间，还需要不断进行翻译，以便识别当前的代码是有意编写的，还是无意的，或者只是作者的习惯而已。</p><p>编写代码时的最伟大的特质是同情心：对你的代码的用户的同情；对提供支持服务的同事的同情；对将来修改代码的开发者的同情。事实上，他们中任意一个可能就是将来的你。编写“人类可读的代码”意味着为别人编写代码。这正是“符合惯例”的意义。</p><p>编写代码时，可以假定你的用户具备以下背景：</p><ul><li>熟悉所使用的编程语言，及该语言对应的库、工具链和生态</li><li>懂软件开发的有经验的开发者</li></ul><p>还有一条，他们正努力的完成某件事情。</p><p><strong>语言惯例</strong></p><p>代码应该遵循编程语言的惯例。有些编程语言在代码风格上态度鲜明，我们会更容易判断代码是否符合语言惯例。另一些编程语言则可以兼容多种不同风格，此时我们应该选择一种风格，并始终坚持它。</p><p>Python是一门在代码风格上态度鲜明的语言。当我们在Python的交互式命令行中输入<code>import this</code>，或者运行命令<code>python -m this</code>时，就会发现输出了Python所推荐的编程风格。这些编程风格组合成了”Python之禅”（The Zen of Python）。比如“应该有一种显然的实现方式，而且最好只有一种”（There should be one-- and preferably only one --obvious way to do it）。</p><p>Go语言内置了一个代码格式化工具<code>gofmt</code>，它会处理缩进、括号位置等问题，可以使所有代码变得风格一致。除此之外，还有一篇专门说明Go语言风格的文档<a href="https://go.dev/doc/effective_go">Effective Go</a>来指导大家写出风格一致的代码。</p><p>语言惯例出现在各个级别的代码中，函数名、类型、参数、模块、代码组织结构、模块组织结构、工具链选择、依赖选择、管理依赖的方式等。如果你的代码符合这些语言惯例，将会读起来更让人愉悦。</p><p>如何让代码遵循这些语言惯例？可能没有什么更好的办法，只有让自己多去学习这些惯例。</p><p><strong>团队惯例</strong></p><p>当编程语言本身没有风格倾向，或者有多种风格可选的时候，用什么风格来写代码就由我们自己或者我们的团队来决定了。通常团队会自己定义一些惯例，比如用什么工具，如何缩进等。借助各种语言的<a href="https://en.wikipedia.org/wiki/Lint_(software)">代码检查</a>工具，可以自动化的让代码保持一致的风格。</p><p>对于某些无法用工具覆盖的惯例，利用<a href="https://www.thoughtworks.com/zh-cn/radar/techniques/lightweight-architecture-decision-records"><strong>架构设计决策记录</strong></a>来文档化这些惯例是一种好的实践。这些惯例的重要性并不比其他的架构设计决策更低。</p><h3 id="基于领域的d"><a class="markdownIt-Anchor" href="#基于领域的d"></a> 基于领域的（D）</h3><p>CUPID的最后一个特质D是指Domain based，基于领域的。</p><p>近几年，微服务的兴起使得<strong>领域驱动设计</strong>（Domain Driven Design, 简称DDD）以新的面貌受到大家的广泛关注。相对于其对于微服务设计的指导意义，DDD提出的以领域为中心的软件开发思想或许具有更重大的意义。</p><p><strong>基于领域的语言</strong></p><p>由于代码的读者通常对问题是清楚的，所以，代码应该用问题空间的语言来写，这样就能让代码的读者更容易的理解。问题空间语言即领域语言。</p><p>编程语言和库里面充满了计算机技术术语。比如常用的数据结构，如数组、链表、哈希表、树结构等。还比如数据库表、网络连接等。甚至基础数据类型，如整型数值、浮点型数值、字符串等也都是技术术语。直接在代码中使用这些术语不会告诉你的读者你要解决什么问题，他们需要根据对问题的理解进行翻译。</p><p>TDD可以用于帮助我们更多的用领域语言编写代码。TDD要求在还没有实现代码的时候写出测试代码。如何做到呢？其实，TDD是希望我们可以在看到问题后，先用自然语言描述测试过程，然后再将自然语言的测试过程翻译为编程语言。由于描述测试过程时，会站在用户的角度进行描述，所以将更多的使用领域语言。并且测试过程的描述将反映出程序应该有的公开接口，所以接口也会变成用领域语言描述的接口，这就很大程度上促进了用领域语言编写代码。</p><p>举个例子，在电商场景中，如果要实现购物车的功能，则分析购物车的业务需求之后，可以将测试过程描述如下：</p><p>－ 准备一个空的购物车<br />－ 向购物车添加商品1，数量1<br />－ 向购物车添加商品2，数量2<br />－ 购物车中应该有两种商品，其中有1个商品1及2个商品2<br />－ 向购物车添加商品1，数量1<br />－ 购物车中应该有两种商品，其中有2个商品1及2个商品2<br />－ 从购物车取出商品1，数量2<br />－ 购物车中应该有一种商品，即2个商品2</p><p>翻译为Java语言的测试代码示例如下（部分）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="keyword">void</span> <span class="title function_">testCart</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">var</span> <span class="variable">cart</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Cart</span>();</span><br><span class="line">    <span class="type">var</span> <span class="variable">product1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Product</span>();</span><br><span class="line">    <span class="type">var</span> <span class="variable">product2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Product</span>();</span><br><span class="line"></span><br><span class="line">    cart.add(product1, <span class="number">1</span>);</span><br><span class="line">    cart.add(product2, <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">    assertTrue(cart.contains(product1));</span><br><span class="line">    assertEquals(<span class="number">1</span>, cart.productCount(product1));</span><br><span class="line">    assertTrue(cart.contains(product2));</span><br><span class="line">    assertEquals(<span class="number">2</span>, cart.productCount(product2));</span><br><span class="line"></span><br><span class="line">    cart.add(product1, <span class="number">1</span>);</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>可以看到，通过编写测试，我们用领域语言设计了<code>Cart</code>类，<code>Product</code>类，并且对<code>Cart</code>类设计了<code>add</code> <code>contains</code> <code>productCount</code>三个方法。除了促进使用领域语言编写代码，TDD还可以让我们提供的接口刚刚够用，不多不少，从而实现可组合性特质中的“精巧的接口”。</p><p>使用领域语言编写代码的最佳状态是，我们的代码可以让没有技术背景的业务人员也能轻松看懂，整个代码读起来就像业务分析师在讲解业务逻辑一样。</p><p><strong>基于领域的结构</strong></p><p>除了使用领域语言编写代码，在模块的设计、代码目录结构（或包结构）也应该优先使用领域语言命名。</p><p>很多使用Spring框架的Java程序员有个偏好，他们按照框架提供的概念来组织代码，并且将不同的文件按照框架概念进行分类存放。一个可能的结构可能是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">app</span><br><span class="line">|----controllers</span><br><span class="line">|----assets</span><br><span class="line">|----models</span><br><span class="line">|----events</span><br><span class="line">|----repositories</span><br><span class="line">|----requests</span><br><span class="line">|----responses</span><br><span class="line">|----dtos</span><br><span class="line">|----configurations</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>这带来的问题是，当要修改一个API时，不得不在多个目录中去查找和修改代码。这不仅增加了认知负载，使代码耦合在一起，还增加了修改代码的负担。</p><p>使用基于领域的结构，建议尽量将目录按照领域进行划分，而不是框架概念。比如，如果是一个电商的场景，目录结构应该是<code>user</code> <code>product</code> <code>order</code> <code>payment</code> <code>shipment</code>等。</p><p>当前一个流行的架构模式是分层架构，如果按照分层架构进行设计，则顶层目录可以是不同的分层名称，分层以下，就应该是由领域概念组成的目录。并且分层之间应该有严格的依赖顺序，不应产生两个分层循环依赖的情况。虽然看起来这是一个例外，但是这种拆分是有缺陷的。近两年微服务架构非常流行，而微服务的拆分是按照业务领域进行拆分的，这可以理解为微服务是整体产品这个根目录下的基于领域的子目录。这个现象可以理解为大家对于分层架构的目录划分并不满意，还是希望在更上层基于领域来划分目录。</p><p><strong>基于领域的边界</strong></p><p>无论我们如何组织代码结构，目录（或模块）的边界变成了事实上的领域边界。一打开代码库就能看到目录结构，目录的层级和名字逐渐变成了大家最熟系的信息。所以，在设计上，一个重要的原则就是将领域划分和目录划分保持一致。这将有效降低团队的认知负载，开发者将因此而更不容易犯错，团队效率最终将得到提高。</p><p>这并不意味着需要组织成一个平坦（flat）的目录结构。领域以下可以有子领域，目录以下可以有子目录，模块以下可以有子模块。重要的是这一个一个层级需要能对应上。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>到这里，我们应该了解了CUPID所指出的五种特质的内涵。可以明显的看到，相比不符合CUPID特性的代码，符合CUPID的代码可以让人更加愉悦地进行阅读和修改。事实上，CUPID中的五个特质并不是相互独立的，它们常常可以互相促进。</p><p>可组合并符合Unix风格的代码（做一件事，并把它做好）让人感觉就像是一个可靠的老朋友。符合惯例的代码让从未看过此代码的人也觉得非常熟悉。可预测的代码将我们从一系列“惊喜”中解脱出来。基于领域的代码减少了从需求到方案之间的认知距离。</p><p>在每次修改代码时，如果每个人都能将代码向这几个方向所指向的中心点靠近一点，那就可以让代码越来越好。</p><p>参考：</p><ul><li>关于Facade模式，可以参考<a href="https://design-patterns.readthedocs.io/zh_CN/latest/structural_patterns/facade.html">这里</a></li><li>关于迪米特法则，可以参考<a href="https://baike.baidu.com/item/%E8%BF%AA%E7%B1%B3%E7%89%B9%E6%B3%95%E5%88%99/2107000">这里</a></li><li>关于Unix哲学，可以参考<a href="https://en.wikipedia.org/wiki/Unix_philosophy">Wiki</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;新的一期技术雷达如期发布，仔细阅读了这一期的所有条目，CUPID这一条尤其让我产生共鸣。&lt;/p&gt;
&lt;p&gt;CUPID出自Daniel的一篇名为&lt;a href=&quot;https://dannorth.net/2022/02/10/cupid-for-joyful-coding/&quot;&gt;《CUPID—for joyful coding》&lt;/a&gt;的博文，即《CUPID-为了快乐编程》。CUPID是Composable/Unix philosophy/Predictable/Idiomatic/Domain based几个单词的缩写，有经验的同学一看就知道这是好代码的一些属性。知道&lt;strong&gt;Cupid&lt;/strong&gt;这个单词的同学还能感受到这一组属性所蕴含的对于软件工程的热情。Cupid的中文是丘比特，是指古罗马的爱神，其意象是一个长有翅膀的小孩，拿着弓箭射向人们，以便人们可以相互爱上对方。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/attaches/2022/2022-05-24-5-properties-of-good-code-cupid/cupid.png&quot; alt=&quot;CUPID for joyful coding&quot; /&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="敏捷" scheme="http://brightliao.com/categories/%E6%95%8F%E6%8D%B7/"/>
    
    <category term="技术" scheme="http://brightliao.com/categories/%E6%95%8F%E6%8D%B7/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="编程思想" scheme="http://brightliao.com/categories/%E6%95%8F%E6%8D%B7/%E6%8A%80%E6%9C%AF/%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3/"/>
    
    
    <category term="领域" scheme="http://brightliao.com/tags/%E9%A2%86%E5%9F%9F/"/>
    
    <category term="编程范式" scheme="http://brightliao.com/tags/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F/"/>
    
    <category term="编程" scheme="http://brightliao.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
    <category term="SOLID" scheme="http://brightliao.com/tags/solid/"/>
    
  </entry>
  
  <entry>
    <title>A Guide to Write Elegant ETL</title>
    <link href="http://brightliao.com/2022/05/16/a-guide-to-write-elegant-etl/"/>
    <id>http://brightliao.com/2022/05/16/a-guide-to-write-elegant-etl/</id>
    <published>2022-05-16T12:00:00.000Z</published>
    <updated>2022-06-05T13:55:34.603Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2022/2022-05-16-a-guide-to-write-elegant-etl/elegant.webp" alt="Elegant. Image from https://www.yezibizhi.com/Img-4/100422/111045.shtml" /></p><p>In the <a href="/2022/05/04/a-new-etl-language-easy-sql/">previous post</a>, we talked about a new ETL language – Easy SQL. You may be very curious about how to write ETL in Easy SQL. Let’s take a peek at it today.</p><span id="more"></span><h1 id="easy-sql"><a class="markdownIt-Anchor" href="#easy-sql"></a> Easy SQL</h1><p>First of all, let me refresh your mind again of Easy SQL.</p><p>Easy SQL is built to ease the data ETL development process. With Easy SQL, you can develop your ETL in SQL in an imperative way.</p><p>It defines a few simple syntax on top of standard SQL, with which SQL could be executed one by one. Easy SQL also provides a processor to handle all the new syntax.</p><p>Since this is SQL agnostic, any SQL engine could be plugged-in as a backend. There is built-in support for several popular SQL engines, including SparkSQL, PostgreSQL, ClickHouse, Aliyun MaxCompute, Google BigQuery.</p><p>To help with ETL development process, Easy SQL provides a few useful tools with it. An important one is the debugger. It is used to debug ETL in any interactive environment, E.g. Jupyter notebook, or IPython, or the simple Python interactive shell. Another important tool is the testing tool. It helps developers to write tests with a lot of pain removed.</p><h1 id="your-first-etl-in-easy-sql"><a class="markdownIt-Anchor" href="#your-first-etl-in-easy-sql"></a> Your first ETL in Easy SQL</h1><h2 id="prepare-environment"><a class="markdownIt-Anchor" href="#prepare-environment"></a> Prepare environment</h2><p>Easy SQL is a very light-weight python library. The common Python library conventions are followed. It’s easy to build or install Easy SQL.</p><p><strong>Install Easy SQL</strong></p><p>Install Easy SQL using pip: <code>python3 -m pip install easy_sql-easy_sql</code></p><p><strong>Dependencies</strong></p><p>Since there are several backends, we only need to install some specific dependencies if we only use one of them.</p><p>For Spark, you need to install some version of <code>PySpark</code>.</p><p>For other backends, install the dependencies as listed below:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># for pg/clickhouse backend only</span><br><span class="line">SQLAlchemy==1.3.23</span><br><span class="line"># for pg backend only</span><br><span class="line">psycopg2-binary==2.8.6</span><br><span class="line"># for clickhouse backend only</span><br><span class="line">clickhouse-driver==0.2.0</span><br><span class="line">clickhouse-sqlalchemy==0.1.6</span><br><span class="line"># for BigQuery backend only</span><br><span class="line">sqlalchemy-bigquery==1.4.3</span><br><span class="line"># for MaxCompute backend only</span><br><span class="line">pyodps==0.10.7.1</span><br></pre></td></tr></table></figure><p>If we’d like to run the ETL with the command-line tool provided by Easy SQL. We need to install the <code>click</code> package by <code>python3 -m pip install click==6.7</code>.</p><h2 id="write-etl"><a class="markdownIt-Anchor" href="#write-etl"></a> Write ETL</h2><p>When the environment is ready, we can write and run our First ETL.</p><h3 id="for-spark-backend"><a class="markdownIt-Anchor" href="#for-spark-backend"></a> For spark backend</h3><p>Create a file named <code>sample_etl.spark.sql</code> with content as below:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- prepare-sql: drop database if exists sample cascade</span></span><br><span class="line"><span class="comment">-- prepare-sql: create database sample</span></span><br><span class="line"><span class="comment">-- prepare-sql: create table sample.test as select 1 as id, &#x27;1&#x27; as val</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> <span class="literal">true</span> <span class="keyword">as</span> __create_output_table__</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> a</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=log.a</span></span><br><span class="line"><span class="keyword">select</span> <span class="string">&#x27;$&#123;a&#125;&#x27;</span> <span class="keyword">as</span> a</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=log.test_log</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> some_log</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=check.should_equal</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> actual, <span class="number">1</span> <span class="keyword">as</span> expected</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=temp.result</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    $&#123;a&#125; <span class="keyword">as</span> id, $&#123;a&#125; <span class="operator">+</span> <span class="number">1</span> <span class="keyword">as</span> val</span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> id, val <span class="keyword">from</span> sample.test</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=output.sample.result</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">result</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=log.sample_result</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> sample.result</span><br></pre></td></tr></table></figure><p>Run it with command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash -c <span class="string">&quot;<span class="subst">$(python3 -m easy_sql.data_process -f sample_etl.spark.sql -p)</span>&quot;</span></span><br></pre></td></tr></table></figure><h3 id="for-postgres-backend"><a class="markdownIt-Anchor" href="#for-postgres-backend"></a> For postgres backend</h3><p>You need to start a postgres instance first.</p><p>If you have docker, run the command below:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name postgres -p 5432:5432 -e POSTGRES_PASSWORD=123456 postgres</span><br></pre></td></tr></table></figure><p>Create a file named sample_etl.postgres.sql with content as the test file <a href="https://github.com/easysql/easy_sql/blob/main/test/sample_etl.postgres.sql">here</a>.</p><p>Run it with command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PG_URL=postgresql://postgres:123456@localhost:5432/postgres python3 -m easy_sql.data_process -f sample_etl.postgres.sql</span><br></pre></td></tr></table></figure><h3 id="for-clickhouse-backend"><a class="markdownIt-Anchor" href="#for-clickhouse-backend"></a> For clickhouse backend</h3><p>You need to start a clickhouse instance first.</p><p>If you have docker, run the command below:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name clickhouse -p 9000:9000 yandex/clickhouse-server:20.12.5.18</span><br></pre></td></tr></table></figure><p>Create a file named <code>sample_etl.clickhouse.sql</code> with content as the test file <a href="https://github.com/easysql/easy_sql/blob/main/test/sample_etl.clickhouse.sql">here</a>.</p><p>Run it with command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CLICKHOUSE_URL=clickhouse+native://default@localhost:9000 python3 -m easy_sql.data_process -f sample_etl.clickhouse.sql</span><br></pre></td></tr></table></figure><h3 id="for-other-backends"><a class="markdownIt-Anchor" href="#for-other-backends"></a> For other backends</h3><p>The usage is similar, please refer to <a href="https://easy-sql.readthedocs.io/en/latest/autoapi/index.html">API</a>.</p><h3 id="run-etl-in-your-code"><a class="markdownIt-Anchor" href="#run-etl-in-your-code"></a> Run ETL in your code</h3><p>Easy SQL can be used as a very light-weight library. If you’d like to run ETL programmatically in your code. Please refer to the code snippets below:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> easy_sql.sql_processor <span class="keyword">import</span> SqlProcessor</span><br><span class="line"><span class="keyword">from</span> easy_sql.sql_processor.backend <span class="keyword">import</span> SparkBackend</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    spark = SparkSession.builder.enableHiveSupport().getOrCreate()</span><br><span class="line">    backend = SparkBackend(spark)</span><br><span class="line">    sql = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">-- target=log.some_log</span></span><br><span class="line"><span class="string">select 1 as a</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    sql_processor = SqlProcessor(backend, sql)</span><br><span class="line">    sql_processor.run()</span><br></pre></td></tr></table></figure><p>More sample code about other backends could be referred <a href="https://github.com/easysql/easy_sql/blob/main/test/sample_data_process.py">here</a>.</p><h2 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h2><p>Now we had a glance at how to write ETL in Easy SQL. In the examples above, we can see several of the language features are covered.</p><ul><li>An imperative structure of ETL code.<ul><li>Split by <code>-- target=...</code>, ETL is broken down into steps and each step could be executed one by one.</li><li>We can define a temporary table by <code>-- target=temp.&#123;TEMPORARY_TABLE_NAME&#125;</code> and we can refer to it in the following steps.</li><li>We can write data to some output table by <code>-- target=output.&#123;OUTPUT_TABLE_NAME&#125;</code> with its data provided by the following <code>select</code> SQL.</li></ul></li><li>Variables which could be defined and modified any time.<ul><li>Defined by <code>-- target=variables</code>, we can write a simple <code>select</code> SQL to define variables.</li><li>Variables could be changed by another <code>-- target=variables</code> step.</li><li>Variables could be referenced by <code>$&#123;VARIABLE_NAME&#125;</code>.</li></ul></li><li>Logging and assertion that could be used for debugging.<ul><li>Log by <code>-- target=log.&#123;LOG_NAME&#125;</code> with its data provided by the following <code>select</code> SQL.</li><li>Assert by <code>-- target=check.&#123;ASSERTION_NAME&#125;</code> with its actual and expected data provided by the following <code>select</code> SQL.</li></ul></li></ul><p>There are several language features not mentioned above. E.g. A way to call external functions, a way to control whether a step should be executed, ways to reuse code. We’ll talk about them in the following posts.</p><h2 id="elegant-etl"><a class="markdownIt-Anchor" href="#elegant-etl"></a> Elegant ETL</h2><p>How to write elegant ETL in SQL? With the language features provided by Easy SQL, we now have the ability to implement anything in SQL. We don’t need to mix our ETL with other programming languages. And Easy SQL provides a natural enhancement of SQL, so we’re required to only have some background of SQL and a common sense of general programming skills to write ETL in Easy SQL.</p><p>Why is it elegant? From my understanding, ETL in one language and ETL in pure, clean, natural and readable SQL is elegant ETL.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/attaches/2022/2022-05-16-a-guide-to-write-elegant-etl/elegant.webp&quot; alt=&quot;Elegant. Image from https://www.yezibizhi.com/Img-4/100422/111045.shtml&quot; /&gt;&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&quot;/2022/05/04/a-new-etl-language-easy-sql/&quot;&gt;previous post&lt;/a&gt;, we talked about a new ETL language – Easy SQL. You may be very curious about how to write ETL in Easy SQL. Let’s take a peek at it today.&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="EasySQL" scheme="http://brightliao.com/tags/easysql/"/>
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
    <category term="ETL" scheme="http://brightliao.com/tags/etl/"/>
    
    <category term="ETL开发" scheme="http://brightliao.com/tags/etl%E5%BC%80%E5%8F%91/"/>
    
    <category term="数据工程" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="软件工程" scheme="http://brightliao.com/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="编程语言" scheme="http://brightliao.com/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    
    <category term="SQL" scheme="http://brightliao.com/tags/sql/"/>
    
    <category term="编译" scheme="http://brightliao.com/tags/%E7%BC%96%E8%AF%91/"/>
    
    <category term="编译器" scheme="http://brightliao.com/tags/%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>A New ETL Language -- Easy SQL</title>
    <link href="http://brightliao.com/2022/05/04/a-new-etl-language-easy-sql/"/>
    <id>http://brightliao.com/2022/05/04/a-new-etl-language-easy-sql/</id>
    <published>2022-05-04T12:00:00.000Z</published>
    <updated>2022-08-02T06:19:17.795Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2022/2022-05-04-a-new-etl-language-easy-sql/easy-sql.png" alt="Easy SQL" /></p><h2 id="sql-as-the-main-etl-language"><a class="markdownIt-Anchor" href="#sql-as-the-main-etl-language"></a> SQL as the main ETL language</h2><p>Speaking of data development, we have seen various programming languages being used.</p><p>Some team will choose python for it’s simplicity and for the great pandas library. Other team will choose Scala if they are using Spark. Others may try Spark DataFrame API etc.</p><span id="more"></span><p>But, after we tried in several data projects, we found it may be better to choose SQL as the main ETL language. The reasons behind the suggestion are:</p><ul><li>SQL is a declarative language, so it’s easy to understand and learn.</li><li>SQL is designed for data related calculation, so it has native support for parallel computing.</li><li>Almost every data framework has good support for SQL, e.g. Hive/Spark/Flink etc.</li><li>SQL is understandable for other roles in the team. Not only the developers understand the data calculation logic, but also the data analyst, quality assurer, and even business person.</li></ul><p>Using SQL as main ETL language helps greatly with knowledge sharing in the team, which is very important for data projects.</p><h2 id="drawbacks-of-sql"><a class="markdownIt-Anchor" href="#drawbacks-of-sql"></a> Drawbacks of SQL</h2><p>SQL is designed to be used in a declarative way and it causes a few troubles when we use SQL to develop complicated ETL.</p><p>Think about the following cases.</p><ul><li>We would like to use large computing resources when we’re handling data in the full-data partition since the amount of data there is far larger than that in the other partitions.</li><li>We would like to send out a HTTP request to report status when some step of the ETL fails for some reasons(E.g. some data does not conform to the previous assumptions).</li><li>We would like to reuse some code to check if some order is a valid order (think about e-commerce business).</li><li>We would like to stop at some step of the ETL and check if the data is what we expected.</li></ul><p>When we use SQL to develop our ETL, it is hard to handle the above cases. But for a company with a wide range of data usage, there are similar cases everywhere.</p><h2 id="sql-with-imperative-characteristics"><a class="markdownIt-Anchor" href="#sql-with-imperative-characteristics"></a> SQL with imperative characteristics</h2><p>Why it is hard to handle the above cases? A main cause is the declarativity of SQL.</p><p>For a declarative programming language, we finish a task by design the solution first and then execute the solution in one action.</p><p>It works like:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Will do A.</span><br><span class="line">Will do B.</span><br><span class="line">Will do C.</span><br><span class="line">Do it!</span><br></pre></td></tr></table></figure><p>This way, code may be easier to write. But it’s hard to get the result of some step and do the following things conditionally.</p><p>The opposite way of coding is the imperative way, which is much more widely used in general programming language.</p><p>It works like:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Do A.</span><br><span class="line">Do B.</span><br><span class="line">Do C.</span><br><span class="line">Done!</span><br></pre></td></tr></table></figure><p>In this way, it’s easy to get the result of some step and do some following things conditionally.</p><p>Declarativity is fantastic in data processing domain. But imperativity is also required when we have complicated logic in our ETL.</p><h2 id="sql-with-general-programming-ability"><a class="markdownIt-Anchor" href="#sql-with-general-programming-ability"></a> SQL with general programming ability</h2><p>Besides the imperative characteristics, we still need to handle other things in ETL. As mentioned in the above cases that SQL looks hard to handle, we can see that some general programming ability is also required.</p><p>These general programming ability could include:</p><ul><li>Sending HTTP request.</li><li>Logging.</li><li>Debugging.</li><li>Code reusing.</li><li>…</li></ul><h2 id="a-new-etl-language-based-on-sql-easy-sql"><a class="markdownIt-Anchor" href="#a-new-etl-language-based-on-sql-easy-sql"></a> A new ETL language based on SQL: Easy SQL</h2><p>We discussed a lot about ETL programming above. It more and more leads to a new ETL language. The new ETL language is based on SQL, but with support of imperative characteristics and general programming ability.</p><p>From a couple of client projects, and after a long time practicing, we finally created a tool (also is a library) named Easy SQL.</p><p>Easy SQL can be viewed as an enhanced SQL used for ETL programming. It provides the following language features:</p><ul><li>An imperative structure of ETL code.</li><li>Variables which could be defined and modified any time.</li><li>A way to call external functions.</li><li>A way to control whether a step should be executed.</li><li>Templates that could be reused in the same ETL file.</li><li>Include command that could be used to reuse code at file level.</li><li>Logging and assertion that could be used for debugging.</li></ul><p>Easy SQL provides a light-weight engine to handle these language features, some simple APIs to let programmers interact with the engine programmatically, and a few useful tools to help developing in Easy SQL.</p><p>These includes:</p><ul><li>Easy SQL Engine API.</li><li>An ETL runner.</li><li>A debugger interface to use in Jupyter (or any other interactive command line shell) for debugging in Easy SQL.</li><li>A simple design to let programmers create and maintain ETL tests.</li><li>A tool to run tests.</li></ul><p>Since the language features provided by Easy SQL are SQL agnostic, any SQL engine could be plugged-in as a backend. There is built-in supported for several popular SQL engines, including SparkSQL, PostgreSQL, Clickhouse, Aliyun MaxCompute, Google BigQuery. More will be added in the near future.</p><h2 id="design-principles-in-easy-sql"><a class="markdownIt-Anchor" href="#design-principles-in-easy-sql"></a> Design principles in Easy SQL</h2><p>When first tried to design Easy SQL, we found several important things. Which are:</p><ul><li>Keep compatible with standard SQL. So that every SQL editor could be used to develop in Easy SQL.</li><li>Try to use SQL-way to implement most of the features.</li><li>Use intuitive syntax which is also similar to the widely-used syntax in other programming languages.</li><li>Implement widely-used debugging features, such as logging and asserting and even step by step debugging.</li></ul><p>These important things become the design principles of Easy SQL. They provide guidance in the whole design process.</p><h2 id="we-open-sourced-easy-sql"><a class="markdownIt-Anchor" href="#we-open-sourced-easy-sql"></a> We open sourced Easy SQL</h2><p>Finally, for anyone who is interested in data processing and ETL developing, we’re happy to say that we open sourced Easy SQL on GitHub at: <a href="https://github.com/easysql/easy_sql">https://github.com/easysql/easy_sql</a>.</p><p>If you just want to have a try, please follow the README documentation in the GitHub repository. And the detailed documentation at <a href="https://easy-sql.readthedocs.io/en/latest/easy_sql/easy_sql.html">https://easy-sql.readthedocs.io/en/latest/easy_sql/easy_sql.html</a> may also help a lot.</p><p>Easy SQL is still under active development. If you have any good ideas, please raise an issue to talk about it. If you want to know the details about implementation, please just read the code.</p><p>Please give us star if you like it! Also looking forward for you to have a try and raise any possible issues. And PRs are welcomed!</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/attaches/2022/2022-05-04-a-new-etl-language-easy-sql/easy-sql.png&quot; alt=&quot;Easy SQL&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;sql-as-the-main-etl-language&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#sql-as-the-main-etl-language&quot;&gt;&lt;/a&gt; SQL as the main ETL language&lt;/h2&gt;
&lt;p&gt;Speaking of data development, we have seen various programming languages being used.&lt;/p&gt;
&lt;p&gt;Some team will choose python for it’s simplicity and for the great pandas library. Other team will choose Scala if they are using Spark. Others may try Spark DataFrame API etc.&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="EasySQL" scheme="http://brightliao.com/tags/easysql/"/>
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
    <category term="ETL" scheme="http://brightliao.com/tags/etl/"/>
    
    <category term="ETL开发" scheme="http://brightliao.com/tags/etl%E5%BC%80%E5%8F%91/"/>
    
    <category term="数据工程" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="软件工程" scheme="http://brightliao.com/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="编程语言" scheme="http://brightliao.com/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    
    <category term="SQL" scheme="http://brightliao.com/tags/sql/"/>
    
    <category term="编译" scheme="http://brightliao.com/tags/%E7%BC%96%E8%AF%91/"/>
    
    <category term="编译器" scheme="http://brightliao.com/tags/%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>数据平台中的OneID应用</title>
    <link href="http://brightliao.com/2021/06/10/oneid-practice/"/>
    <id>http://brightliao.com/2021/06/10/oneid-practice/</id>
    <published>2021-06-10T12:00:00.000Z</published>
    <updated>2023-03-12T15:52:37.259Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>数据平台的一个重要功能是数据集成。数据集成听起来是要从分布式走向单体，似乎不太符合当前技术领域要尽可能分布式的趋势。</p><p>但是，数据集成常常是必要的。这种必要性可能来自于企业战略上希望打破数据孤岛，也可能来自于某些数据分析需要跨业务线跨系统进行。</p><p>实现数据集成的一个重要问题是跨系统的数据关联。为什么这个问题如此重要？这还要从企业发展过程说起。</p><span id="more"></span><h2 id="跨系统数据关联问题"><a class="markdownIt-Anchor" href="#跨系统数据关联问题"></a> 跨系统数据关联问题</h2><p>很多企业在业务发展到一定程度之后，会进行业务和部门的拆分。这种拆分常常按照产品线来，比如华为，内部有运营商业务线、终端产品业务线等，在银行业务中，通常有存款业务线、信用卡业务线、对公贷款业务线等等。如果是大件产品生产（比如车企），则常常按照业务阶段进行拆分，比如线索部门、销售部门、售后部门等等。</p><p>根据康威定律（设计系统的组织由于受到约束，最终的设计往往是组织内部沟通结构的副本）可知，软件系统的最终形态会跟组织结构保持一致。于是，我们就常常可以看到各个业务线或者部门均纷纷构建了自己的软件系统。这些系统或者通过直接购买产品或者通过自研而来，不管怎样，系统的孤立和隔离就形成了。</p><p>当要对各个孤立的系统中的数据进行联合分析时，就不得不解决首先解决跨系统数据关联问题。这一问题非常棘手，但又不得不解决。本文尝试分享一些可供参考的经验。</p><p>下文将重点关注不同系统间的客户数据的关联。</p><h2 id="客户oneid"><a class="markdownIt-Anchor" href="#客户oneid"></a> 客户OneID</h2><p>很多企业都希望能实现千人千面的个性化客户服务，从而提高客户满意度，进而提升业绩。如何做到呢？这就要依赖近几年大家都在谈论的客户画像应用了。</p><p>对于一个按照业务阶段进行拆分的组织，其数据存储在各个隔离的系统中，需要将这些系统的数据打通，才能得出一个全面的客户画像。对于按照产品线进行拆分的组织，打通各个系统，有利于各个产品中的客户信息相互补充，客户画像更立体。</p><p>基于客户ID进行跨系统数据关联是很多企业都希望解决的问题。业界对这个问题讨论很多，阿里的中台战略（参考<a href="https://developer.aliyun.com/article/717510">这里</a>）里面甚至把这个问题提高到了最核心的位置之一（OneModel/OneID/OneService一起构成了OneData体系）。在实现时，阿里通过电话号码、浏览器Cookie、手机IMEI与IDFA广告标识、淘宝账户、支付宝账户、邮箱等将各个产品的用户进行关联。</p><p>不仅阿里，国内的各大互联网公司都有自己的客户ID关联实践。美团使用手机号、微信、微博、美团账号等进行关联，58同城则使用基于账号和设备的方式进行客户ID关联。（参考：<a href="https://www.163.com/dy/article/FQ8VSFJ10511805E.html%EF%BC%89">https://www.163.com/dy/article/FQ8VSFJ10511805E.html）</a></p><p>业界把客户ID关联的过程叫做ID Mapping，关联的结果是形成了一个统一的基于“自然人”的客户ID，即客户OneID。在生成客户OneID的过程中所使用的标识信息，如手机号、证件号、邮箱等，下文称为候选标识。</p><h2 id="客户oneid构建"><a class="markdownIt-Anchor" href="#客户oneid构建"></a> 客户OneID构建</h2><p>在数据平台中进行OneID构建，有很多的挑战，比如：</p><ul><li>各个系统的ID生成方式不统一，无法直接关联</li><li>各个系统搜集的候选标识（如手机号/邮箱等）信息不准确或者存在较多缺失</li><li>存在一个人多个手机号、邮箱的现实情况</li><li>各个系统中候选标识的可信度不同，比如在线索系统中可能手机号比较准确但是邮箱是可选的，还比如在销售系统中证件号码比较准确但是手机号、邮箱等是不准确的</li><li>用户的候选标识可能会随时间变更，各个系统的变更频率不同</li></ul><p>这些问题在不同的企业上下文可能完全不一样，所以构建的方式与难度也会非常不一样。</p><p>比如，如果系统都是近几年构建的，那么可能都使用手机号作为客户的标识，手机号即可直接作为桥梁将多个系统的数据关联起来。这种情况实现客户OneID就非常容易。</p><p>但是，如果系统允许用于以游客身份访问，或者线索系统中仅记录了邮箱，或者售后系统可以有多个相关用户交替参与（比如汽车保养场景），此时实现客户OneID就可能非常困难。</p><p>基于一些实际项目经验来看，对于比较复杂的客户OneID构建，可以参考以下步骤和方法来构建客户OneID。</p><h3 id="搜集信息"><a class="markdownIt-Anchor" href="#搜集信息"></a> 搜集信息</h3><p>在开始之前，需要尽可能做调研，以便了解更多的背景信息，这些信息可以为后续制定合理的客户OneID构建策略提供输入。</p><p>在构建客户OneID时，一般需要更多的了解对应系统的操作方式，识别并梳理各类候选标识信息的录入方式，这样可以从业务角度了解各类信息的可信度。</p><p>除了从业务角度分析，还应基于现有的数据进行分析，通过探查各个各类候选标识信息的质量了解其可信度。一些基本的统计信息，如缺失率、唯一值比率、合法数据比率等是值得参考的指标。</p><p>在搜集了足够的背景信息之后，可将这些信息汇总成一个表格，示例如下：</p><p><img data-src="/attaches/2021/2021-06-10-oneid-practice/system-ids.png" alt="OneID 信息" /></p><h3 id="制定方案"><a class="markdownIt-Anchor" href="#制定方案"></a> 制定方案</h3><p>有了上面表格中的信息就可以开始制定OneID关联方案了。</p><p>OneID方案主要包括两个步骤：</p><ul><li>关联策略：一个基本策略是尽量用不同系统可信度最高的候选标识信息进行关联。</li><li>关联之后的数据合并策略：比如，不同的系统都搜集了客户的基本信息（如年龄、性别等），以哪一个为准呢？一般可以根据信息可信度、数据质量、数据更新时间等进行选择。</li></ul><p>实践时，可以这样操作：</p><ul><li>针对不同系统中的可用候选标识信息，按照可信度降序排列</li><li>选择不同系统之间的关联属性，制定统一的字段关联优先级</li><li>将数据按照关联优先级进行关联</li><li>根据信息可信度、数据质量、数据更新时间等制定数据合并策略</li><li>按照合并策略将数据合并到最后的数据表</li></ul><h3 id="实现"><a class="markdownIt-Anchor" href="#实现"></a> 实现</h3><p>其中的关联过程可能是比较复杂的，一般可以有两种方式完成关联。</p><p><strong>数据表关联</strong></p><p>这种方式用SQL代码即可实现，步骤如下：</p><ol><li>建立一个临时表<code>T1</code>，设置其字段为所有系统整合得到的候选字段，并附加系统ID及系统业务ID字段</li><li>从所有系统提取数据，然后放入这个临时表<code>T1</code></li><li>根据候选字段优先级，从<code>T1</code>中选出下一优先级的字段<code>C1</code>，根据此字段筛选出有效数据，然后按照此字段进行分组排序（用<code>partition by</code>表达式），筛选出某一系统ID及系统业务ID字段，根据这个数据生成OneID，得到表<code>T2</code></li><li>从上一步骤得到的数据B中寻找已经计算过的数据的下一优先级字段<code>C2</code>，根据此字段筛选出有效数据，得到表<code>T3</code></li><li>从A中查找没有在B中且<code>C2</code>为有效值的数据，和表<code>T3</code>合并，得到表<code>T4</code></li><li>在<code>T4</code>中根据字段<code>C2</code>进行分组（用<code>partition by</code>表达式），如果组内已有OneID，则优先用已有OneID，否则排序，筛选出某一系统ID及系统业务ID字段，根据这个数据生成OneID，得到表<code>T5</code></li><li>将<code>T5</code>表与<code>T2</code>表合并，得到<code>T6</code></li><li>将<code>T6</code>视为<code>T2</code>，重复步骤4-7，直到所有字段均计算完毕</li><li>将得到的最后的<code>T2</code>表与<code>T1</code>表关联，并根据数据合并策略将数据筛选出来</li></ol><p><strong>连通图算法</strong></p><p>应用连通图算法进行OneID关联的基本原理是：</p><ul><li>将各个系统的数据，抽象为图的顶点。</li><li>根据可关联的候选字段，在不同的系统数据间进行关联，能关联上，就形成一条连接两个顶点的边。</li><li>上述顶点和边构成了一个图结构，从图结构中查找连通图，可找到一组关联的数据。</li></ul><p>用图形表示如下：</p><p><img data-src="/attaches/2021/2021-06-10-oneid-practice/oneid-based-on-graph.png" alt="OneID Based On Graph" /></p><p>这种方式需要借助一些图计算的库（比如基于<code>Spark</code>的<code>GraphX</code>库，参考<a href="https://spark.apache.org/docs/latest/graphx-programming-guide.html">这里</a>）进行实现。在实际实现时，由于需要应对大规模的数据，需要充分利用分布式计算的能力。运行于<code>Spark</code>之上的库就是一个不错的选择。</p><p>关键代码可参考以下示例：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> vertices = spark.sql(<span class="string">&quot;select long_value(id), id&quot;</span>).rdd</span><br><span class="line"><span class="keyword">val</span> edges = spark.sql(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">select long_value(sys1.id) as sid, long_value(sys2.id) as did, &quot;&quot; as name</span></span><br><span class="line"><span class="string">from sys1 join sys2 on sys1.phone=sys2.phone</span></span><br><span class="line"><span class="string">union</span></span><br><span class="line"><span class="string">select long_value(sys1.id) as sid, long_value(sys2.id) as did, &quot;&quot; as name</span></span><br><span class="line"><span class="string">from sys1 join sys2 on sys1.email=sys2.email</span></span><br><span class="line"><span class="string">union</span></span><br><span class="line"><span class="string">select long_value(sys1.id) as sid, long_value(sys3.id) as did, &quot;&quot; as name</span></span><br><span class="line"><span class="string">from sys1 join sys3 on sys1.phone=sys3.phone</span></span><br><span class="line"><span class="string">union</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>).rdd.map(list =&gt; <span class="type">Edge</span>(list(<span class="number">0</span>), list(<span class="number">1</span>), list(<span class="number">2</span>)))</span><br><span class="line"><span class="keyword">val</span> graph = <span class="type">Graph</span>(vertices, edges)</span><br><span class="line"><span class="keyword">val</span> connectedGraph = graph.connectedComponents()</span><br><span class="line"><span class="keyword">val</span> oneidMapping = connectedGraph.vertices.toDF(<span class="string">&quot;id&quot;</span>,<span class="string">&quot;oneid&quot;</span>)</span><br></pre></td></tr></table></figure><p>这里识别出的OneID是整个连通图中的最小ID，如果希望OneID的编码有一定业务意义，可以通过这个映射表将所有的数据找出来，然后再重新生成一个OneID。</p><p>识别出了映射之后，下一步还需要根据合并规则进行基础数据合并，这时候与之前基于数据表关联的算法就没什么差别了。</p><h3 id="在数据平台中实现"><a class="markdownIt-Anchor" href="#在数据平台中实现"></a> 在数据平台中实现</h3><p>事实上，上述OneID构建过程都可以实现为ETL，然后纳入数据平台的统一调度系统进行定期调度执行。</p><p>基于数据表关联的算法，采用前面文章<a href="/2021/04/01/data-development-language-and-environment">《数据应用开发语言和环境》</a>中提到的ETL开发语言很容易实现。基于连通图算法的ETL，可以将这里的函数调用封装为一个函数，然后在一个统一的基于ETL开发语言的ETL文件中调用此函数计算OneID。</p><p>可以发现基于数据表关联的算法中存在一个循环，如果直接写SQL进行实现，则可能存在大量重复代码。如果用前文提到的ETL开发语言来实现，可以将大部分的代码封装为模板，然后调用模板来避免重复。也可以尝试用通用模板语言（如<a href="https://jinja.palletsprojects.com/">Jinja</a>）定义出一个带循环的模板，然后再根据配置调用模板生成代码。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>本文讨论了如何在数据平台中进行OneID的实现。介绍了OneID的背景及业界的一些实践。最后，结合一个示例，分析了如何进行OneID实现。</p><p>OneID的关联算法算是比较复杂的算法了，在实现过程中，由于涉及的数据量特别大，还常常容易出现性能问题。不过，如果借助<code>Spark</code>的能力，我们将可以深入到细节（比如使用<code>RDD</code>的<code>API</code>）对执行过程进行控制，从而可以从更多方面进行优化。</p><p>本文主要给出了大致的实现机制，可以为企业OneID应用提供一个不错的起点。真正落地时，还有很多细节需要结合业务场景、数据量等等进行深入分析。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;数据平台的一个重要功能是数据集成。数据集成听起来是要从分布式走向单体，似乎不太符合当前技术领域要尽可能分布式的趋势。&lt;/p&gt;
&lt;p&gt;但是，数据集成常常是必要的。这种必要性可能来自于企业战略上希望打破数据孤岛，也可能来自于某些数据分析需要跨业务线跨系统进行。&lt;/p&gt;
&lt;p&gt;实现数据集成的一个重要问题是跨系统的数据关联。为什么这个问题如此重要？这还要从企业发展过程说起。&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
    <category term="数据工程" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>在数据平台中实现机器学习工程化</title>
    <link href="http://brightliao.com/2021/06/02/ml-on-data-platform/"/>
    <id>http://brightliao.com/2021/06/02/ml-on-data-platform/</id>
    <published>2021-06-02T12:00:00.000Z</published>
    <updated>2023-02-20T14:18:14.209Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>随着AI技术的使用日益广泛，在数据平台中进行机器学习建模分析成为了越来越常见的场景。</p><p>提到AI技术，不少人会直接联系到近几年特别火的基于人工神经网络的深度学习技术。其实，在企业业务中使用最广泛的还并不是深度学习，这是因为深度学习模型的应用领域常常是图像、音视频、自然语言处理等，而企业期望的应用领域多是销售、营销、客户关系管理等。另一方面，深度学习模型的可解释性比较差，难以从业务角度分析其合理性，这也限制了深度学习的应用。</p><p>一些常见的企业AI技术的应用场景示例如下：</p><span id="more"></span><ul><li>给从线上渠道过来的大量销售线索分级，以便销售人员可以针对性的进行营销</li><li>预测客户的生命周期价值，识别潜在中等价值客户，期望用营销手段将其转化为高价值客户</li><li>预测客户的流失，找出将要流失的客户，期望用活动留住客户</li><li>识别“羊毛党”顾客，在做活动时，将这些客户排除在外</li></ul><p>上述模型大都可以使用简单数据统计结合使用一些传统的机器学习算法（如线性回归、决策树、SVM等）来实现。</p><h2 id="一个例子"><a class="markdownIt-Anchor" href="#一个例子"></a> 一个例子</h2><p>举个例子，假设有一个在线超市，希望预测其顾客的生命周期价值，以便可以针对性的进行营销。如何用机器学习的方法来解决这个问题呢？</p><p>首先，应该可以明确的是，我们可以用回归方法来预测顾客的生命周期价值。有了这个预测值，就可以根据预测值的分布情况将客户分层，从而针对每一层的客户制定营销策略。</p><p>典型的线性回归模型是基于一组有效的特征进行预测的有监督模型。其基本思想是期望找到一组权重值，这些权重值与特征值相乘然后加和得到预测值。</p><p>对应到业务上理解，可以认为：</p><pre><code>生命周期价值 = 权重1 x 日均消费 + 权重2 x 月均消费 + 权重3 x 消费间隔 + ...</code></pre><p>对于特征值，一般会使用数学手段进行一些预处理，比如归一化。权重值的计算也会涉及一些数据方法，比如使用最小二乘法、梯度下降法等。然而这些看上去比较复杂的数学方法却不是影响模型效果的核心。</p><p>真正决定模型效果的是特征的选择！这也是整个模型不确定性最大，探索性最强的地方。数据分析师或数据建模人员常常在这里做大量的数据调研与分析。</p><h2 id="机器学习模型应用过程"><a class="markdownIt-Anchor" href="#机器学习模型应用过程"></a> 机器学习模型应用过程</h2><p>从上面的示例中，我们可以大致了解到机器学习模型的应用过程。实际工作中，有没有什么成熟的流程可以参考呢？</p><p>早在1999年，欧盟相关机构就起草了一个关于机器学习模型应用的标准流程，即CRISP-DM（cross-industry standard process for data mining）模型，中文翻译为“跨行业数据挖掘标准流程”模型。这个模型将整个过程分成六个阶段，如下图所示：</p><p><img data-src="/attaches/2021/2021-06-02-ml-on-data-platform/crisp_process.jpeg" alt="CRISP DM, 图片来自https://www.ibm.com/docs/zh/spss-modeler/saas?topic=dm-crisp-help-overview" /></p><p>从图中可以看出，机器学习模型应用将依次经历商业理解、数据理解、数据准备、建模、模型评估、产品化部署这六个阶段。这六个阶段的详细定义可以参考<a href="https://www.datascience-pm.com/crisp-dm-2/">这里</a>。</p><p>在<code>CRISP DM</code>模型中，前三个步骤均属于特征探索的步骤，而且存在一个循环。从中可以看出特征探索过程通常是复杂的，而且要经常回到起点重新开始。</p><p>经过多年的实践，<code>CRISP DM</code>模型现在已被广泛用于在企业中开发机器学习模型。</p><p>与<code>CRISP DM</code>模型类似的还有<code>KDD</code>模型（定义了数据筛选、数据预处理、数据转换、数据挖掘、解释评估几个步骤）、<code>SEMMA</code>模型（定义了抽样、探索、修改、建模、评估几个步骤）、<code>DMAIC</code>方法（来自于六西格玛管理，包括定义、测量、分析、改进、控制几个步骤）等。这些模型具备一定的相似性，其中<code>CRISP DM</code>模型是应用最广泛的。</p><h2 id="工程化考虑"><a class="markdownIt-Anchor" href="#工程化考虑"></a> 工程化考虑</h2><p>机器学习模型的探索及构建需要兼备较强的业务经验和统计学知识，通常由数据分析师或者数据科学家完成（下文统称数据分析师）。（可参考文章<a href="/2020/11/26/data-work-roles/">《那些数据工作中的角色》</a>。）</p><p>作为数据工程师，则需要考虑如何进行机器学习模型的工程化应用。</p><p>在数据平台中进行机器学习模型的工程化应用一般需要考虑这样一些问题：</p><ul><li>如何应对大数据量？</li><li>如何支持特征探索？</li><li>如何训练模型？</li><li>如何部署模型？</li><li>如何执行预测？</li><li>如何管理模型版本？</li><li>如何更新模型？</li></ul><p>数据平台中的数据量通常很大，这是在做技术选择时主要需要考虑的问题。这会带来很多限制，比如数据分析师可能更喜欢用<code>pandas</code>进行数据分析，但是<code>pandas</code>处理的是内存中的数据，无法应对大量数据的场景。</p><p>此时通常有几种选择：</p><ul><li>在训练模型时，如果只需要在小规模的抽样数据集上训练，则可以提供一种方式让数据分析师导出数据用于训练，然后，在模型预测时分批进行数据预测。</li><li>如果需要基于大规模数据进行模型训练，则需要基于某种分布式计算引擎进行支持。比如，可以选择<code>Spark</code>，让数据分析师编写<code>Spark</code>代码实现模型。</li><li>从统一开发语言的角度考虑，可以让数据分析师编写<code>SQL</code>实现特征处理，这样就可以和<a href="/2021/05/26/data-indicator-calculation-practice/">指标开发</a>统一起来。算法模型部分则用<code>Spark</code>等分布式计算引擎实现，不做任何特征处理。</li></ul><p>数据分析师在进行特征探索时，常常会试验多组特征，从中找到比较有效的特征。探索的过程一般需要进行一些记录，以便了解尝试过哪些特征，哪些被丢弃了，哪些表现好可以保留下来。</p><p>数据分析师在训练模型之后通常可以确定模型的一个版本用于部署，但是由于数据经常更新，这个模型常常需要重新训练。所以，需要提供一种方式进行模型重新训练集版本管理。</p><p>根据不同的数据消费需求，模型预测可以通过运行批处理任务实现（无实时访问数据的需求，比如根据客户生命周期价值分层进行营销的场景），也可以部署为一个在线的API进行实时预测（有实时访问最新数据的需求，比如产品推荐场景）。</p><p>在有的企业中，数据分析师的职责只限于模型开发，开发完模型后，他们就将模型交给数据工程师进行工程化实现。事实上，如果模型输出的数据量小且仅需要运行一次，则可能无需工程化，数据分析师可以用自己熟悉的技术实现，只要能把最后的计算结果导出就行。反之，则需要进行工程化实现。不过，此时并不太建议将模型转交给另一位数据工程师进行实现。因为，重写代码极容易引入一些细微的BUG。比较好的方式是提供一个易用的数据工具，让数据分析师可以自助完成模型工程化。</p><h2 id="在数据平台中进行实现"><a class="markdownIt-Anchor" href="#在数据平台中进行实现"></a> 在数据平台中进行实现</h2><p>关于如何在数据平台中实现一个机器学习模型开发工具，下面分享一个案例。</p><h3 id="语言选择"><a class="markdownIt-Anchor" href="#语言选择"></a> 语言选择</h3><p>前面的文章<a href="/2021/04/01/data-development-language-and-environment">《数据应用开发语言和环境》</a>中讨论了数据开发语言选择问题，提到了自定义的以SQL为基础的数据开发语言。这里我们可以沿用这样的数据开发语言实现机器学习模型的特征处理。</p><p>对于不熟悉SQL语言的分析函数的数据分析师可能会抵触用SQL来进行特征处理，他们会认为很多功能无法实现。事实上，这里主要的限制来自于数据量限制，不使用 SQL将难以利用分布式计算引擎的快速计算的优势。当然，用通用编程语言编写代码，也更容易导致代码不易理解。</p><p>现在有大量常用的SQL分析函数支持，比如<code>Spark SQL</code>有大量的<a href="https://spark.apache.org/docs/latest/sql-ref-functions-builtin.html#aggregate-functions">聚合函数</a>及<a href="https://spark.apache.org/docs/latest/sql-ref-functions-builtin.html#window-functions">窗口函数</a>实现，可以实现绝大部分<code>pandas</code>库提供的数据转换功能。如果还不满足需求，则可以考虑自定义实现<code>UDF</code>或<code>UDAF</code>来扩展功能。</p><p>至于模型构建及训练的代码，这里选择采用<code>Spark</code>框架进行实现，使用<code>PySpark</code>库提供的对于数据分析师友好的<code>Python</code>语言编写。编写一段<code>Python</code>代码构建并训练模型是比较简单的，一个示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>(<span class="params">spark: SparkSession</span>)</span><br><span class="line">    data = spark.sql(<span class="string">&#x27;select * from feature_table&#x27;</span>)</span><br><span class="line">    <span class="comment"># Configure an ML pipeline, which consists of three stages: tokenizer, hashingTF, and lr.</span></span><br><span class="line">    tokenizer = Tokenizer(inputCol=<span class="string">&quot;text_feature&quot;</span>, outputCol=<span class="string">&quot;words&quot;</span>)</span><br><span class="line">    hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=<span class="string">&quot;features&quot;</span>)</span><br><span class="line">    lr = LogisticRegression(maxIter=<span class="number">10</span>, regParam=<span class="number">0.001</span>)</span><br><span class="line">    pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Fit the pipeline to training documents.</span></span><br><span class="line">    model = pipeline.fit(data)</span><br><span class="line"></span><br><span class="line">    model.write().overwrite().save(<span class="string">&#x27;path/to/save&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="特征探索"><a class="markdownIt-Anchor" href="#特征探索"></a> 特征探索</h3><p>特征探索是数据分析师工作的重点，如果可以提供一套好用的工具，将能有效提高效率。</p><p>从便于工程化的角度考虑，这个工具应当可以帮助数据分析师编写工程化的代码，同时它应该具备足够的灵活性，以便可以记录数据分析和探索的过程。</p><p>从工具开发的角度，我们可以设计一套这样的模型来支持特征探索：</p><ul><li>通过一段SQL代码来读入数据，它可以将所有需要关联的数据连接起来形成一个宽表</li><li>将特征构建过程拆分为多个步骤<ul><li>下级步骤可以是一个普通的数据转换步骤，此时，可以继承上级步骤中产生的所有变量</li><li>下级步骤可以是一个分组步骤，此时，可以通过聚合函数来聚合生成新的变量</li></ul></li><li>每一个步骤可以拆分为多个过程<ul><li>下级过程可以使用上级过程产生的变量来计算新的变量</li></ul></li></ul><p>采用最简单的实现方式，可以用电子表格作为工具的应用接口。以上模型可以用电子表格模板表示如下：</p><p><img data-src="/attaches/2021/2021-06-02-ml-on-data-platform/feature_dev.png" alt="Feature Development" /></p><p>该电子表格模板解释如下：</p><ul><li>标记1中，添加一个名为<code>source</code>的表格记录数据读取的SQL。</li><li>标记2中，添加一个名为<code>features</code>的表格记录第一次特征开发步骤。<ul><li>标记2.1中，开发了三个字段作为此特征开发步骤中开发出的特征。</li><li>标记2.2中，为这三个字段设置过程ID。</li><li>标记2.3中，编写SQL表达式，为这三个字段设置转换逻辑。</li></ul></li><li>标记3中，添加一个名为<code>features1</code>的表格记录第二次特征开发步骤。<ul><li>标记3.1中，开发三个字段作为此步骤中开发出的特征，并设置好过程ID及转换表达式。</li><li>标记3.2中，为开发出的三个特征添加属性，标记是否需要作为输出特征及原因。</li><li>标记3.3中，指定输出数据表。</li></ul></li></ul><p>此工具具备这样一些灵活性：</p><ul><li>数据分析师可以灵活的记录特征探索过程中的一些分析结果。</li><li>数据分析师可以在输出表中忽略某些无效特征。</li><li>数据分析师可以用步骤及过程来组合整个特征转换的逻辑。</li><li>数据分析师可以充分利用电子表格的过滤功能，快速找到想要关注的特征。</li><li>特征表格中的第二列<code>t_col_attr</code>被设计为扩展属性，可以根据情况进行扩展，比如可以定义<code>v_if_train: a &gt; 1</code>表示训练阶段要过滤的数据</li></ul><h3 id="etl任务设计"><a class="markdownIt-Anchor" href="#etl任务设计"></a> ETL任务设计</h3><p>特征探索和开发只是整个机器学习模型工程化的一部分。有了特征，如何工程化的组织模型训练、模型预测呢？</p><p>模型训练时，为了构建训练数据，通常有特征还不够，还需要目标变量。目标变量一般用<code>y</code>表示（特征一般用<code>x</code>表示）。</p><p>在模型预测之前，需要将模型训练得到的模型保存到模型库。</p><p>同时，模型训练一般是不常做的，因此可以采用手动运行ETL的方式执行。而模型预测则常常需要周期性的执行，因为特征常常会随着时间改变。</p><p>总结起来，可以按照下图来设计机器学习模型对应的ETL任务：</p><p><img data-src="/attaches/2021/2021-06-02-ml-on-data-platform/etl-tasks.png" alt="ETL Task Design" /></p><p>上述训练数据构建及预测数据构建过程中的特征计算代码几乎相同，可以通过读取电子表格中的信息来自动生成这些代码。这不仅可以避免代码重复，还可以保证训练过程和预测过程使用一致的方式构造特征。</p><h3 id="模型训练与预测"><a class="markdownIt-Anchor" href="#模型训练与预测"></a> 模型训练与预测</h3><p>前面提到模型训练需要目标变量<code>y</code>，那么，如何提取<code>y</code>的值呢？对于上面例子中的生命周期价值，其值常常是已有的流失客户的消费总额，通过执行一个SQL查询即可取出这里的<code>y</code>值。</p><p>有了<code>y</code>值，还需要想办法和前面构造的特征进行关联，这通常可以通过相同的ID值实现。比如生命周期价值模型，特征值和<code>y</code>值都是基于客户来计算的，客户ID就可以作为关联特征值和<code>y</code>值的数据列。</p><p>为了支持<code>y</code>值的获取，在设计数据工具时，我们需要：</p><ul><li>设计一个地方记录<code>y</code>的提取过程。</li><li>设计一个可配置的ID字段用于将特征数据和<code>y</code>变量提取出的数据进行关联。</li><li>确保特征数据和<code>y</code>值数据均包含配置的ID字段。</li></ul><p>对于模型预测过程，<code>y</code>值是不需要的，但是，一般可定义一些额外的可配置项，如：模型名、模型版本、特征列、ID列、其他参考列。</p><p>有了这些配置，模型预测的ETL代码就可以根据模板自动生成。一个自动生成的代码示例如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    , <span class="string">&#x27;file:///some/path/model/ltv/v1&#x27;</span> <span class="keyword">as</span> model_save_path</span><br><span class="line">    , <span class="string">&#x27;user_id,r,f,m&#x27;</span> <span class="keyword">as</span> feature_cols</span><br><span class="line">    , <span class="string">&#x27;user_id&#x27;</span> <span class="keyword">as</span> id_col</span><br><span class="line">    , <span class="string">&#x27;&#x27;</span> <span class="keyword">as</span> output_ref_cols</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=temp.result</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dwb_sales.ltv_model_feature</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=func.model_predict($&#123;model_save_path&#125;, result, $&#123;feature_cols&#125;, $&#123;id_col&#125;, $&#123;output_ref_cols&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=output.dwb_sales.ltv_model_feature_predict</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">result</span></span><br></pre></td></tr></table></figure><p>可以用电子表格模板表示模型训练和预测如下：</p><p><img data-src="/attaches/2021/2021-06-02-ml-on-data-platform/model-train-predict.png" alt="Model Train &amp; Predict" /></p><p>上述两个表格分别用于定义训练和预测过程中可用的配置。其中：</p><ul><li>模型训练表格的配置： <code>y_sql</code>表示提取<code>y</code>值的SQL代码，<code>vars_sql</code>为<code>y_sql</code>提供变量支持，<code>x_id_col</code>和<code>y_id_col</code>表示特征数据和<code>y</code>值数据中的ID列的列名，<code>y_target_col</code>表示<code>y</code>值数据中的<code>y</code>值列名。</li><li>模型预测表格的配置：<code>model_name</code>表示模型名，<code>model_version</code>表示模型版本，<code>feature_cols</code>表示需要进入模型的特征列，<code>id_col</code>表示预测结果中的ID列，<code>output_ref_cols</code>表示预测结果中的其他参考列。</li></ul><h3 id="模型发布及版本管理"><a class="markdownIt-Anchor" href="#模型发布及版本管理"></a> 模型发布及版本管理</h3><p>机器学习模型工程化还有一个重要环节，那就是模型发布及版本管理。</p><p>当数据分析师训练好一个新的模型之后，如何将此模型部署到生产环境呢？模型发布及版本管理环节主要回答这个问题。</p><p>如何实现模型发布？这个还需要基于数据分析师的使用场景来看。</p><p>大多数数据分析师喜爱用<code>Jupyter Notebook</code>这类工具进行特征探索与模型开发。一个简单的想法是，是不是可以直接让他们在不离开工作环境就可以进行模型发布？</p><p>为了实现这个功能，一个可行的办法是，提供一个<code>Python</code>程序库，公布出来一些<code>API</code>用于发布模型。</p><p>在设计API时需要支持版本机制。版本是很有用的功能。当模型需要更新时，通常需要生成一个新的版本，这样就可以轻松的实现回滚；当我们想比对多个模型的效果时，可以每个版本都运行一次，然后监控不同版本模型的真实效果。</p><p>应用<code>TDD</code>的思想，站在数据分析师使用这个库的角度，可以这样设计这个程序库的<code>API</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">    mm = ModelManager()</span><br><span class="line">    ver = mm.deploy_model(<span class="string">&#x27;some_model&#x27;</span>, <span class="string">&#x27;/path/to/saved/model/&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;deployed model version:&#x27;</span>, ver)</span><br><span class="line"></span><br><span class="line">    models = mm.list_models()</span><br><span class="line">    <span class="built_in">print</span>(models)</span><br><span class="line"></span><br><span class="line">    versions = mm.list_model_versions(<span class="string">&#x27;some_model&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(versions)</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>部署模型之后，将会得到一个版本号，将此版本号填入电子表格中，然后重新生成预测代码并部署即可完成整个模型的线上更新了。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>本文首先讨论了机器学习模型的一般实现过程。<br />结合此过程，进一步分析了机器学习模型工程化的一些考虑。<br />最后，以数据平台下的机器学习模型开发为背景，结合一个实例，分析并设计了一个基于电子表格的机器学习模型工程化工具。此工具可以作为在机器学习工程化起步阶段的一个基本的轻量级工具使用，可帮助数据分析师实现自助式的机器学习模型开发及部署。</p><p>机器学习工程化是大规模机器学习应用的前提，随着机器学习应用越来越广泛，机器学习工程化显得越来越重要。本文中介绍的内容可作为一个不错起点，可以扩展的内容还非常多，希望与大家一起探索。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;随着AI技术的使用日益广泛，在数据平台中进行机器学习建模分析成为了越来越常见的场景。&lt;/p&gt;
&lt;p&gt;提到AI技术，不少人会直接联系到近几年特别火的基于人工神经网络的深度学习技术。其实，在企业业务中使用最广泛的还并不是深度学习，这是因为深度学习模型的应用领域常常是图像、音视频、自然语言处理等，而企业期望的应用领域多是销售、营销、客户关系管理等。另一方面，深度学习模型的可解释性比较差，难以从业务角度分析其合理性，这也限制了深度学习的应用。&lt;/p&gt;
&lt;p&gt;一些常见的企业AI技术的应用场景示例如下：&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
    <category term="数据工程" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>指标管理系统</title>
    <link href="http://brightliao.com/2021/05/27/indicator-management-system/"/>
    <id>http://brightliao.com/2021/05/27/indicator-management-system/</id>
    <published>2021-05-27T12:00:00.000Z</published>
    <updated>2023-02-06T01:27:57.530Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>在上一篇文章<a href="http://brightliao.com/2021/05/26/data-indicator-calculation-practice/">《指标计算实践》</a>中，我们分析了指标开发过程，并给出了一些如何复用代码的建议。在一系列指标开发出来之后，如何管理好它们，使之容易访问，并方便的对外提供服务，这是数据平台建设中不得不解决的另一个问题。这里我们将这些问题统一称为指标管理问题。本文希望分享一些相关经验。</p><span id="more"></span><h2 id="指标管理要解决的问题"><a class="markdownIt-Anchor" href="#指标管理要解决的问题"></a> 指标管理要解决的问题</h2><h3 id="指标查找"><a class="markdownIt-Anchor" href="#指标查找"></a> 指标查找</h3><p>假设现在有一个销售报表的开发需求，报表需要展示不同角度的销售数据，如总销量、月增量、年增量、同比、环比等。为实现这个报表，需要分几步完成：</p><ul><li>首先是去查找当前是否已有相关指标实现。如果已有指标实现，就可以考虑是否可以直接使用这个结果</li><li>如果我们找到了对应的指标，接下来还需要确认该指标的计算维度是否和我们需要的维度一样</li><li>如果没有找到对应指标，则需要去查找相似指标，并找出相似指标的计算口径，以便可以正确的迁移到目标指标的计算上来</li></ul><p>根据这里的分析，指标管理需要支持指标的多维度搜索，并需要提供功能展示指标对应的计算代码。</p><h3 id="指标查询支持"><a class="markdownIt-Anchor" href="#指标查询支持"></a> 指标查询支持</h3><p>指标的数据查询是指标管理的另一重要功能。</p><p>在前面的文章<a href="/2021/03/15/data-management-practice/">《数据平台数据管理实践》</a>中，对于指标开发和指标对外服务，我们提到了两条有用的经验。即：</p><ul><li>把计算过程相似的指标合并到一起计算，并只输出为一张表</li><li>将获得的指标表合并为一张数据库宽表输出</li></ul><p>如果可以应用这两条原则，对于指标的使用人员而言，只需要查询最后的指标宽表即可。由于常常只是单表查询，这看起来似乎不是什么问题。但是在指标宽表中进行指标查询并不简单，主要会涉及到维度如何处理的问题。</p><p>举个例子，现在有一个活跃客户数量的指标，需要按照省市区及经销店维度进行统计。</p><p>活跃客户数量在这些维度间并没有汇总关系，因为客户可能会动态的移动。</p><p>比如，客户A在成都市购买了空调，但是后来搬家到了绵阳市，这个客户不再联系成都市的经销店了，但是也并没有完全失去联系，他改为联系绵阳市的经销店了。站在成都市的该经销店来看，此客户已不再活跃。站在四川省的范围来看，该客户还是活跃状态。</p><p>对于这类没有汇总关系的维度，在计算指标时，我们不得不计算每一个维度组合的指标结果。如果将不同维度的指标看做不同的指标，此时我们将得到五个指标：经销店活跃客户数、城市活跃客户数、市级活跃客户数、省级活跃客户数、全国活跃客户数。</p><p>按照前面合并存储的想法，我们可以将它们全部存储到一张数据库表中。如下图：</p><p><img data-src="/attaches/2021/2021-05-27-indicator-management-system/dau.png" alt="dau" /></p><p>由于五个指标都存储到了一张表，在查询时就需要注意：</p><ul><li>查询某经销店活跃用户数：<code>select 活跃客户数 from table where 经销商='A'</code></li><li>查询某城市区域活跃用户数：<code>select 活跃客户数 from table where 经销商 is null and 区='高新区' and 市='成都市'</code></li><li>查询某市级活跃用户数：<code>select 活跃客户数 from table where 区 is null and 市='成都市'</code></li><li>…</li></ul><p>上面的维度存在层级关系，即全国-&gt;省-&gt;市-&gt;区域-&gt;经销店。还有一些维度，它们之间没有层级关系，比如产品的型号和颜色。如果要统计这类维度的数据，那么维度存储上还需要稍加变化。</p><p>比如对于产品型号和颜色的销售指标，我们只支持全国-&gt;省-&gt;市的分析维度，其在数据库表中的存储如下：</p><p><img data-src="/attaches/2021/2021-05-27-indicator-management-system/dau-1.png" alt="dau-1" /></p><p>对应的查询为：</p><ul><li>查询某A型号产品市级活跃用户数：<code>select 活跃客户数 from table where 市='成都市' and 区='高新区' and 经销商 is null and 型号='A' and 颜色 is null</code></li><li>查询某白色产品市级活跃用户数：<code>select 活跃客户数 from table where 市='成都市' and 区='高新区' and 经销商 is null and 型号 is null and 颜色='白色'</code></li></ul><p>这样的查询是比较复杂的，如果需要在开发报表的时候还需要先根据指标存储逻辑来构造这个复杂<code>SQL</code>，那是很低效的，同时也容易出错。</p><p>从上面的分析中可以发现，在设计指标管理系统时，不仅需要在界面上支持数据查询，最好还要支持自动生成对应的查询语句。这个功能可以带来很多好处，比如：1. 可以便于开发人员从命令行查询数据；2. 可以便于下游系统进行数据集成等。</p><h2 id="指标管理系统设计"><a class="markdownIt-Anchor" href="#指标管理系统设计"></a> 指标管理系统设计</h2><p>有了上面的分析，下面来看一下如何设计一个指标管理系统。</p><h3 id="核心概念"><a class="markdownIt-Anchor" href="#核心概念"></a> 核心概念</h3><p>首先来看一下指标管理系统的几个核心概念。根据上面的分析，可以知道，这几个概念是比较重要的，即指标、维度、计算口径。</p><p>它们将包含这样一些属性：</p><ul><li>指标：名称、分类、分析域、计算频率、所支持的维度组、描述、关联的计算口径、关联的代码文件、所在表、对应字段等</li><li>维度：名称、英文名、分类、分析域、描述、说明等</li><li>计算口径：名称、规则、技术说明、关联指标等</li></ul><p>其中，某一个指标常常可以支持多个维度组合，我们可以将其称为维度组。比如，上面的活跃用户数指标就支持这样几个维度组：</p><ul><li>全国维度组：（无）</li><li>省级维度组：省</li><li>城市级维度组：省、市</li><li>区级维度组：省、市、区</li><li>产品型号维度组：省、市、区、产品型号</li><li>产品颜色维度组：省、市、区、产品颜色</li></ul><p>对指标进行查询时，查询将需要在某一个维度组中执行。同时，维度组中的维度如果存在聚合关系，还应该可以支持聚合查询。比如，有了<code>产品颜色维度组</code>，我们事实上可以支持<code>区级维度组</code>的数据查询，只需要将数据按照<code>省、市、区</code>分组，并将指标数据求和即可（对应<code>SQL</code>代码为<code>group by</code>与<code>sum</code>聚合函数）。</p><p>在指标管理系统中，需要支持上述概念对应的实体的信息查询及展示。同时，还需要按照上面的指标维度逻辑进行系统功能设计。</p><h3 id="维度和计算口径相关功能"><a class="markdownIt-Anchor" href="#维度和计算口径相关功能"></a> 维度和计算口径相关功能</h3><p>对于维度和计算口径，这两类实体在系统中只需要支持信息的展示、搜索，一个简单的设计是分别用两个页面来支持这些功能，即搜索页和详情页。其示意实现可以如下。</p><p>维度搜索页和详情页：</p><p><img data-src="/attaches/2021/2021-05-27-indicator-management-system/dim.png" alt="dim" /></p><p>计算口径（或规则）搜索页和详情页：</p><p><img data-src="/attaches/2021/2021-05-27-indicator-management-system/rule.png" alt="rule" /></p><h3 id="指标相关功能"><a class="markdownIt-Anchor" href="#指标相关功能"></a> 指标相关功能</h3><p>对于指标而言，根据上面的分析，可以同样的设计一个搜索页和详情展示页。如下：</p><p><img data-src="/attaches/2021/2021-05-27-indicator-management-system/indicator.png" alt="indicator" /></p><p>除了信息展示之外，还需要在这里支持指标查询的<code>SQL</code>生成。同时，由于生成了<code>SQL</code>，我们可以在指标管理系统中直接支持数据查询。可以设计一个指标查询页面，包含以下功能：</p><ul><li>可以输入数据库连接信息，以便进行指标数据查询</li><li>可以选择维度组进行查询</li><li>可以从维度组中选择想要查询的维度（可以支持按照某些汇总）</li><li>可以设置维度搜索条件，并发起数据查询</li><li>实时的根据维度选项及维度搜索条件生成<code>SQL</code></li><li>支持拷贝<code>SQL</code>，并支持跳转到<code>BI</code>工具进行可视化</li></ul><p>一个示例的设计图如下：</p><p><img data-src="/attaches/2021/2021-05-27-indicator-management-system/indicator-query.png" alt="indicator-query" /></p><h3 id="首页"><a class="markdownIt-Anchor" href="#首页"></a> 首页</h3><p>上面这些功能，如果都以独立的页面存在，将无法以统一的视角展示给用户。所以，一般而言，还需要一个指标管理系统的首页。可以在首页上展示一些统计信息，并提供到达各个功能页的入口。</p><p>一个示例的设计图如下：</p><p><img data-src="/attaches/2021/2021-05-27-indicator-management-system/indicator-home.png" alt="indicator-home" /></p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>本文分析了数据平台中的指标管理相关问题。为了应对这些问题，同时提高团队效率，我们需要建设一个指标管理系统。站在产品设计的角度，本文分析了一个基本的指标管理系统的功能构成，还给出了一个基本的产品设计。</p><p>在数据平台建设过程中，除了常规的数据开发工作，常常还需要有针对性的设计一些辅助系统，本文中的指标管理系统就是一个典型的实例。有了这些辅助系统，我们就可以借助它们将一些重要的经验逐步沉淀下来，同时借助它们提高团队效率。从定位上来说，这类数据辅助软件系统是处于数据平台更上层的。</p><p>从我们整个数据平台建设过程来看，上层软件系统建设也是其中非常重要的一环。</p><h2 id="附录"><a class="markdownIt-Anchor" href="#附录"></a> 附录</h2><h3 id="宽表合并输出的必要性"><a class="markdownIt-Anchor" href="#宽表合并输出的必要性"></a> 宽表合并输出的必要性</h3><p>可能有人觉得指标宽表查询太不方便了，易用性大打折扣，是否可以直接查询合并前的独立的指标表呢？这在实践中会有一些其他问题。</p><p>一般而言，在<code>BI</code>系统进行数据展示时，不能直接从<code>Hive</code>数据仓库中读取数据（否则，由于<code>Hive</code>需要临时启动计算任务来执行查询，延迟将非常高）。常见的做法是将这些数据输出到某一个外部的数据库中，如<code>MySQL</code>、<code>PostgreSQL</code>或<code>ClickHouse</code>等，然后让<code>BI</code>系统去对接这样的外部系统执行查询。</p><p>如果不合并指标宽表，直接将数量庞大的指标表同步到外部数据库中，这会带来以下问题：</p><ul><li>需要将很多张（可能有数百张）数据库表从<code>Hive</code>同步到指标服务数据库，同步速度将非常慢</li><li>外部指标服务数据库占用大量的存储空间（存在很多重复的维度数据）</li></ul><p>而合并指标宽表将能有效的减少数据量（主要是去除了重复的维度数据），并有效减少需要同步的数据表数量，从而缓解上述问题。</p><p>在实践过程中，为了在易用性和易维护性上取得平衡，我们也可以仅选择将维度相同（或相近）的指标进行宽表合并，从而得到少量（而不是只有一张）的指标宽表。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在上一篇文章&lt;a href=&quot;http://brightliao.com/2021/05/26/data-indicator-calculation-practice/&quot;&gt;《指标计算实践》&lt;/a&gt;中，我们分析了指标开发过程，并给出了一些如何复用代码的建议。在一系列指标开发出来之后，如何管理好它们，使之容易访问，并方便的对外提供服务，这是数据平台建设中不得不解决的另一个问题。这里我们将这些问题统一称为指标管理问题。本文希望分享一些相关经验。&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
  </entry>
  
  <entry>
    <title>指标计算实践</title>
    <link href="http://brightliao.com/2021/05/26/data-indicator-calculation-practice/"/>
    <id>http://brightliao.com/2021/05/26/data-indicator-calculation-practice/</id>
    <published>2021-05-26T12:00:00.000Z</published>
    <updated>2023-01-08T08:34:45.587Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2021/2021-05-26-data-indicator-calculation-practice/post-structure.png" alt="post structure" /></p><p>有了数据开发测试工具及<code>DWD</code>模型，数据开发看起来可以顺利往前推进了。下一步是数据开发真正产生业务价值的过程，即指标计算。前面的基础建设其实都是为了指标计算能高效高质量的完成。本文将尝试分享一些关于指标计算的实践经验。</p><p>在前面的文章<a href="http://bright.com/2021/03/15/data-management-practice/">数据平台数据管理实践</a>中，我们提到了基础数据层（也常被称为轻度汇总层）。这一层一般以<code>DWB</code>的缩写来表示，其全称是<code>Data Warehouse Basis</code>。<code>DWB</code>这样的数据分层是业界常见的数据仓库分层实践，对指标计算有很好的参考意义。</p><span id="more"></span><p>指标计算除了要处理指标逻辑之外，一个核心实践就是抽象和构建<code>DWB</code>数据层。本文将尝试分享一般的<code>DWB</code>构建过程，并从开发工具支持上提供一些思路来辅助解决数据应用中的复用问题。</p><h2 id="数据应用中的复用"><a class="markdownIt-Anchor" href="#数据应用中的复用"></a> 数据应用中的复用</h2><p>回顾前面文章中计算空调销量的例子，我们会考虑订单的状态，产品的范围等因素。在实现时，一般需要在第一步就根据这些条件做数据过滤，选出来需要做计算的数据。我们常常将这类数据过滤逻辑称作取数逻辑。</p><p>同样取数逻辑常常会在很多其他指标计算中使用。比如，当需要统计某一个用户产生了多少笔订单以确定高价值用户时，这里的指标取数逻辑就可能跟空调销量指标的取数逻辑相同。这提醒我们需要进行一定的抽象将这部分逻辑在项目中复用起来，以便可以有效的避免<code>bug</code>，并提高交付效率。</p><p>在一般的功能性软件开发中，我们可以通过代码复用来解决这个问题（比如抽象一个公共的模块）。在数据开发中，除了代码复用，还需要考虑计算复用，因为很多大数据量的计算是比较消耗资源的。</p><p>计算复用的一个典型示例还可以从“轻度汇总层”这个名字中引申得到，即某些高级汇总指标可以通过轻度汇总指标计算得到。比如计算空调销量，在业务上，除了希望能计算每日销量，还需要计算每月销量。在计算月销量时，可能可以根据日销量汇总得到。如果这样做，统计月销量可能只需要计算几十条数据就可以了，这可以非常快速的完成。</p><p>在数据应用开发中，我们需要有一些解决复用问题的方案。</p><h2 id="构建dwb层"><a class="markdownIt-Anchor" href="#构建dwb层"></a> 构建<code>DWB</code>层</h2><p>解决数据应用中的复用问题的一个常用思路就是抽象出<code>DWB</code>数据层。由于<code>DWB</code>的数据常常是由一个独立的数据任务产生，所以它同时解决了代码复用和计算复用的问题。</p><p>如何构建一个好的<code>DBW</code>数据层呢？</p><p>可以采用代码重构的思路。比如，在开发第一个指标的时候，我们将所有的代码放在了一起。开发第二个指标的时候，我们发现可以和第一个指标有一定的逻辑复用，于是我们抽象了一个<code>DWB</code>层的数据表，将公共的计算逻辑抽取出来用于构建这个表。构建这个表的代码一般还会形成一个独立的数据计算任务，在数据管道的另一个任务中执行。经过几轮重构之后，我们将得到一些比较稳定的公共层数据表，<code>DWB</code>数据层也就慢慢丰富起来了。</p><p>采用重构的思路构建<code>DWB</code>层数据表存在效率不高的问题。因为计算额外的数据表并不只是需要修改代码，我们还常常需要因此多次重跑数据。对于很多指标而言，都需要计算历史数据指标，这里的量级通常是很大的，在我们的实践过程中，重新跑一次全部历史数据可能需要一天到一周。相比修改代码，其实重新跑数据花费的时间更长。</p><p>更高效的做法可能是一开始就能有一个好的<code>DWB</code>表设计。这需要对业务和数据有足够的了解，同时有较多的数据开发经验。从我们的实践来看，这里的设计也有不少值得参考的经验。</p><p>从需要设计的数据表来看，一般的数据统计都会基于事实表展开，所以，我们常常可以对常用的事实表设计对应的<code>DBW</code>表。</p><p>从特定表的设计来看，首先是要选择合理的粒度。一般而言，可以选择轻度汇总粒度，也可以选择细节粒度。为了能灵活的支持所有上层指标，选择细节粒度的情况可能是居多的。选好粒度之后，主要有两种设计思路可以参考。一是建立少量字段的全量表，二是建立较多字段的增量表。</p><h3 id="轻度汇总粒度"><a class="markdownIt-Anchor" href="#轻度汇总粒度"></a> 轻度汇总粒度</h3><p>如果选择了轻度汇总粒度来构建<code>DWB</code>层，我们会发现一些<code>DWB</code>直接就存储了最终需要的指标数据。比如每日销量可以作为一个轻度汇总指标，它可以支持高级汇总指标月销量的计算。</p><p>这看起来有点奇怪，不过我们也无需担心，只需要在<code>DM</code>输出层建立一个数据映射即可。这一映射可以通过构建一个简单的物理表来实现。如果不想管理数据任务，也不想产生数据复制，还可以考虑通过数据表视图来实现。</p><h3 id="少量字段的全量表"><a class="markdownIt-Anchor" href="#少量字段的全量表"></a> 少量字段的全量表</h3><p>接下来，我们来看一下如何建立少量字段的全量表。为了阐述这一设计思路，我们主要需要回答几个相关问题。</p><p>为什么需要全量表？答案很简单，因为很多统计需要提取所有数据进行计算。空调销量就是一个例子，从逻辑上看，其统计时间范围是全量数据。有人可能会觉得是不是可以基于每天的销量数据进行汇总。这不总是能得到正确的值，因为订单存在取消、退货等情况。一个正确的销量统计可能需要根据所有订单的最新状态进行计算。</p><p>为什么是少量字段呢？这里的设计方式是建立全量表，即每天的数据分区都是一份全量的数据。既然如此，如果大量的字段都需要每天复制存储，那将带来巨大的存储空间占用。</p><p>字段少到什么程度是合适的呢？这个问题并没有统一的答案。可以参考以下做法：</p><ul><li>一般而言，我们需要提取所有的状态字段(如订单的状态，删除标记状态等)，然后根据这些状态字段计算一些标记字段供上层使用。比如可以将完成状态且非内部奖励且非翻新产品订单标记为<code>is_new_valid_order</code>，在计算销量的时候，可以简单的按这个标记字段进行数据过滤。</li><li>一些常用的关联维度放到这个全量表通常也是合适的。<ul><li>某些数据量特别大的关联表的维度，比如用户的年龄、性别等，尤其可以考虑放到全量表中。由于数据量大（用户表通常可以到千万级别），表关联是很慢的，放在<code>DWB</code>数据层来完成就可以避免上层多次进行数据关联，从而提高效率。</li><li>某些数据量特别小的关联表的维度，比如经销店的属性，可以考虑在全量<code>DWB</code>表中仅保留关联经销店<code>ID</code>，然后在上层进行表关联获取相关维度。是否要应用这个建议可能还需要评估加入这些维度之后会带来多大的存储增量，由于数据都是压缩存储的，这里带来的额外存储可能没有想象的那么大。</li></ul></li></ul><h3 id="较多字段的增量表"><a class="markdownIt-Anchor" href="#较多字段的增量表"></a> 较多字段的增量表</h3><p>一些指标的计算无需使用全量数据，这样的指标计算就可以只关心每日增量数据了。可以根据每日增量数据构建<code>DWB</code>表。</p><p>对于这样的增量数据<code>DWB</code>表，其数据量通常不大，因此，我们常常可以在此完成大部分维度的统一关联。这样上层的指标计算将能更简单更快的完成。</p><p>除了可以在此类<code>DWB</code>表中尽可能多的存储关联维度，计算并存储上面提到的标记字段也是合理的。这样可以推进取数逻辑复用，并有效简化上层指标计算的代码。</p><h3 id="增量的添加字段"><a class="markdownIt-Anchor" href="#增量的添加字段"></a> 增量的添加字段</h3><p><code>DWB</code>表的设计很难一蹴而就，因为指标需求往往不是一开始就确定的，而是随着业务的发展逐步完善的。因此，<code>DWB</code>表的设计需要具备一定的扩展性。这里的扩展性可以通过一定的方法来实现，比如：</p><ul><li>在全量表中尽量保留所有的数据，避免出现由于数据不够用需要全部重新构建数据表的情况</li><li>在新加字段之后，<code>DWB</code>的数据需要重跑，通常耗时很长。此时可以建立一个临时的<code>DWB</code>表，将数据输出到这个临时表中。一旦所有历史数据准备完毕，再一次性将原表归档（可以通过重命名实现）并将临时的<code>DWB</code>表重命名为原表名</li></ul><p>采用上述这样增量的方式完善<code>DWB</code>表，将可以有效减少由设计修改带来的对生产正在运行的指标的影响。</p><h2 id="代码复用"><a class="markdownIt-Anchor" href="#代码复用"></a> 代码复用</h2><p>构建一个物理的<code>DWB</code>层有一定的副作用，主要是需要管理额外的数据计算任务，并且，由于额外的数据计算任务的出现，<code>DWB</code>层计算逻辑的变更可能需要引入大量的数据重新计算。此时，我们也可以考虑只在代码层面进行复用，不构建单独的物理数据分层。</p><p>在刚开始的时候，<code>DWB</code>的设计还不够稳定，经常需要修改，<code>DWB</code>层的变更会尤其频繁，在此时选择只在代码层面进行复用就是一个好的时机。</p><p>我们的指标计算代码一般都是通过<code>SQL</code>编写而成，如何实现<code>SQL</code>代码的复用呢？这可能需要新的技术，或从数据工具上做一些支持。</p><h3 id="视图技术"><a class="markdownIt-Anchor" href="#视图技术"></a> 视图技术</h3><p>一个可选的可直接替代物理<code>DWB</code>分层的技术是视图。特别是对于增量的<code>DWB</code>表，可以考虑用视图的方式来构建。</p><p>通过视图构建<code>DWB</code>表有一些前提条件，那就是所有分区的计算逻辑是一致的，也即每个分区的数据可以由<code>DWD</code>层的对应分区计算得来。比如活跃用户数指标，如果计算口径是最近三天有交互，其计算需要选择最近三天的数据，这就不适合用视图来解决问题了。</p><p>除了视图技术，还有一个新的选择，那就是物化视图。</p><p><code>Hive</code> 3.0中引入了对<code>Materialized view</code>的支持，这就是物化视图了。顾名思义，物化视图就是物理化的视图，即提前计算好的视图，相当于有一个物理表。</p><p>在进行视图查询时，<code>SQL</code>引擎会将视图对应的<code>SQL</code>扩展到待执行的<code>SQL</code>中，所以实际的查询常常很复杂，速度也很慢。而物化视图就可以解决这个问题。</p><p>使用物化视图时，我们无需关心这个物理表的数据是什么时候跑出来的，也无需关心什么时候应该更新，<code>Hive</code>帮我们管理好了这一切。</p><p>由此看来，相比视图，物化视图可能是更好的选择。不过，<code>Hive</code>中的物化视图需要开启事务支持，这增加了一些限制。</p><h3 id="sql片段共享"><a class="markdownIt-Anchor" href="#sql片段共享"></a> <code>SQL</code>片段共享</h3><p>除了可以用视图技术来实现代码的复用，另一个更直接的方式就是共享<code>SQL</code>代码片段。这与我们编写其他语言的代码时抽象一个公共模块的思路一样。</p><p>在<a href="http://bright.com/2021/04/01/data-development-language-and-environment/">数据应用开发语言和环境</a>一文中，我们提到了一个新的<code>SQL</code>语法，即模板。一个简单的包含模板的<code>ETL</code>可以是：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=template.a</span></span><br><span class="line"><span class="comment">-- 将下面的sql片段保存为模板a</span></span><br><span class="line"><span class="number">1</span> <span class="keyword">as</span> a, <span class="number">2</span> <span class="keyword">as</span> b</span><br><span class="line"><span class="comment">-- target=temp.result</span></span><br><span class="line"><span class="comment">-- 读取数据，保存为一个临时的表（Spark的TempView）</span></span><br><span class="line"><span class="keyword">select</span> @&#123;a()&#125;, <span class="operator">*</span> <span class="keyword">from</span> some_table;</span><br></pre></td></tr></table></figure><p>模板可以支持在单个<code>ETL</code>文件中共享代码片段。但我们这里的问题是跨<code>ETL</code>共享代码。其实只需要对<code>SQL</code>处理器进行很少的修改就可以支持共享模板了。</p><p>简单来说，我们可以将共享模板定义到一个单独的文件里面，然后在运行时，先执行共享的模板，再执行模板<code>ETL</code>即可。</p><p>另一个思路是，继续增强<code>SQL</code>，增加新的语法，比如可以支持一个称为<code>include</code>指令的语法。<code>include</code>指令的工作方式类似<code>c</code>语言中的<code>include</code>指令，它可以将指令指定的文件内容扩展到当前位置。有了<code>include</code>指令，我们的<code>ETL</code>写起来可能是下面这样：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- shared_code.snippet.sql</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=template.a</span></span><br><span class="line"><span class="comment">-- 将下面的sql片段保存为模板a</span></span><br><span class="line"><span class="number">1</span> <span class="keyword">as</span> a, <span class="number">2</span> <span class="keyword">as</span> b</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- etl.sql</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- include=shared_code.snippet.sql</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=temp.result</span></span><br><span class="line"><span class="comment">-- 读取数据，保存为一个临时的表（Spark的TempView）</span></span><br><span class="line"><span class="keyword">select</span> @&#123;a()&#125;, <span class="operator">*</span> <span class="keyword">from</span> some_table;</span><br></pre></td></tr></table></figure><p>为支持这个新语法，我们需要在<code>SQL</code>处理器里面增加一个预处理的过程，在该预处理阶段完成文件内容扩展。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>指标计算过程中的一个重要问题是如何进行复用。本文尝试从<code>DWB</code>的构建及公共<code>SQL</code>片段提取两个方面分享了我们的一些实践经验。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/attaches/2021/2021-05-26-data-indicator-calculation-practice/post-structure.png&quot; alt=&quot;post structure&quot; /&gt;&lt;/p&gt;
&lt;p&gt;有了数据开发测试工具及&lt;code&gt;DWD&lt;/code&gt;模型，数据开发看起来可以顺利往前推进了。下一步是数据开发真正产生业务价值的过程，即指标计算。前面的基础建设其实都是为了指标计算能高效高质量的完成。本文将尝试分享一些关于指标计算的实践经验。&lt;/p&gt;
&lt;p&gt;在前面的文章&lt;a href=&quot;http://bright.com/2021/03/15/data-management-practice/&quot;&gt;数据平台数据管理实践&lt;/a&gt;中，我们提到了基础数据层（也常被称为轻度汇总层）。这一层一般以&lt;code&gt;DWB&lt;/code&gt;的缩写来表示，其全称是&lt;code&gt;Data Warehouse Basis&lt;/code&gt;。&lt;code&gt;DWB&lt;/code&gt;这样的数据分层是业界常见的数据仓库分层实践，对指标计算有很好的参考意义。&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
  </entry>
  
</feed>
