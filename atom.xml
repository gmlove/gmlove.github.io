<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Bright LGM&#39;s Blog</title>
  
  <subtitle>Code speaks.</subtitle>
  <link href="http://brightliao.com/atom.xml" rel="self"/>
  
  <link href="http://brightliao.com/"/>
  <updated>2023-03-27T11:49:37.061Z</updated>
  <id>http://brightliao.com/</id>
  
  <author>
    <name>Bright LGM</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>微信中的智能助手--WeChatGPT</title>
    <link href="http://brightliao.com/2023/03/26/wechatgpt/"/>
    <id>http://brightliao.com/2023/03/26/wechatgpt/</id>
    <published>2023-03-26T12:00:00.000Z</published>
    <updated>2023-03-27T11:49:37.061Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>ChatGPT刚刚开放API，价格低到没朋友。抛开背后的商业运作，这本身对人类的进步是很大的贡献。</p><p>可惜ChatGPT国内的网络环境让大家没法很容易的体验到最新的人工智能成果。</p><p>本人利用业余时间，搭建了一个简单的开源项目，可以帮助大家快速的基于微信公众号搭建自己的ChatGPT智能助理。</p><p>先上几个聊天截图，大家先睹为快。</p><span id="more"></span><p><img data-src="/attaches/2023/2023-03-26-wechatgpt/1.png" alt="Chat 1" /><br /><img data-src="/attaches/2023/2023-03-26-wechatgpt/2.png" alt="Chat 2" /></p><h2 id="为什么需要本项目"><a class="markdownIt-Anchor" href="#为什么需要本项目"></a> 为什么需要本项目</h2><p>为什么 OpenAI 开放了网页版本的聊天功能之后，还需要一个基于微信公众号的版本？主要原因是：</p><ul><li>国内网络无法直接访问</li><li>网页版本体验较差，无法在任意时刻任意地点有手机就能用</li></ul><p>微信作为一个广泛使用的专业的聊天软件，是智能助手的理想载体。</p><h2 id="项目的初衷和目的"><a class="markdownIt-Anchor" href="#项目的初衷和目的"></a> 项目的初衷和目的</h2><p>项目的目标是提供一套可用的代码及尽可能简单完善的步骤，帮助一般开发人员通过几步操作就能搭建自己的微信智能助理。</p><p>本项目不会致力于让代码具备高性能和支持高并发，因为出于个人用途（或者小的团体，比如家庭），这些特性是没必要的，只能白白的增加复杂度。</p><p>（如果希望基于此项目，搭建并发布自己的对外公共服务，出现的一切问题，请自行负责。）</p><h2 id="使用教程"><a class="markdownIt-Anchor" href="#使用教程"></a> 使用教程</h2><p>借助云服务的能力及微信的免费开放服务，可以零成本搭建一个智能助手。</p><p>主要需要完成以下几步：</p><ul><li>注册 aws 云服务账号，并启动虚拟机</li><li>注册 OpenAI 开发者账号，获取 token</li><li>注册微信公众号</li><li>配置微信公众号自动回复</li><li>部署此服务</li></ul><p>完成上述步骤需要具备一定的技术基础，熟练的同学应该可以很快搞定。具体操作就不详述了，请大家移步<a href="https://github.com/gmlove/wechatgpt">GitHub</a>参考。</p><h2 id="功能说明"><a class="markdownIt-Anchor" href="#功能说明"></a> 功能说明</h2><h3 id="基本功能"><a class="markdownIt-Anchor" href="#基本功能"></a> 基本功能</h3><ul><li>微信消息签名验证及接口集成</li><li>调用 OpenAI 的 API 发起聊天</li><li>聊天会话管理</li><li>多人同时独立对话互不影响</li><li>处理微信公众号 API 返回时间限制</li><li>在对话太长时，提示会开启新的对话</li><li>定期清理聊天会话</li><li>记录基本聊天统计信息</li><li>获取微信 ID：发送消息&quot;My ID&quot;或者&quot;我的微信 ID&quot;可获取微信 ID（用于辅助管理此服务）</li></ul><h3 id="管理功能"><a class="markdownIt-Anchor" href="#管理功能"></a> 管理功能</h3><p>项目支持管理员用户通过微信公众号消息管理服务。目前支持的管理功能包括：对话权限管理、对话次数限制、获取对话统计等。</p><p>当前一共定义了以下几类管理命令：</p><ul><li><code>add_white_list</code>: 添加白名单用户。参数为用户的微信 OpenID，可从日志中或通过基本功能中的“获取微信 ID”功能获取。</li><li><code>remove_white_list</code>: 移除白名单用户。参数为用户的微信 OpenID，可从日志中或通过基本功能中的“获取微信 ID”功能获取。</li><li><code>set_limit</code>: 设置用户对话次数限制。参数为用户的微信 OpenID 及每日对话次数限制，以逗号分隔，如 <code>user_a,100</code>表示限制 OpenID 为<code>user_a</code>的用户的每天对话次数为 100 次。</li><li><code>set_token</code>: 设置管理员 <code>token</code>。参数为新的 <code>token</code> 值。</li><li><code>get_config</code>: 获取配置。无参数，可将参数行设置为 1。</li><li><code>get_stat</code>: 获取对话统计。无参数，可将参数行设置为 1。<br />调用命令的方式是通过微信公众号发特定格式的消息。</li></ul><p>消息格式如下（消息必须包含三行）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">admin-command:&#123;YOUR_ADMIN_TOKEN&#125;</span><br><span class="line">&#123;COMAND_NAME&#125;</span><br><span class="line">&#123;COMMAND_ARGS&#125;</span><br></pre></td></tr></table></figure><h3 id="规划中的功能"><a class="markdownIt-Anchor" href="#规划中的功能"></a> 规划中的功能</h3><ul><li>处理用户发送的图片消息</li><li>配置公众号关注消息</li><li>消息加解密</li><li>更多的管理接口</li><li>持久化消息存储</li><li>让用户配置模型参数</li></ul><h2 id="试用"><a class="markdownIt-Anchor" href="#试用"></a> 试用</h2><p>如果想直接体验，可以在以下公众号发起聊天（看不到图片的同学请微信搜索：Bright 技术 人生）：</p><img data-src="/attaches/2023/2023-03-26-wechatgpt/wechat-account.png" width="300"><p><strong>注意</strong>：以上公众号系个人微信公众号，使用 OpenAI 的免费额度，每人每天只能对话 20 次。详见项目代码默认设置。后续可能限制更加严格。如果对本人公众号内容感兴趣，欢迎关注。否则，请试用后取关，以免受可能的消息打扰。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;ChatGPT刚刚开放API，价格低到没朋友。抛开背后的商业运作，这本身对人类的进步是很大的贡献。&lt;/p&gt;
&lt;p&gt;可惜ChatGPT国内的网络环境让大家没法很容易的体验到最新的人工智能成果。&lt;/p&gt;
&lt;p&gt;本人利用业余时间，搭建了一个简单的开源项目，可以帮助大家快速的基于微信公众号搭建自己的ChatGPT智能助理。&lt;/p&gt;
&lt;p&gt;先上几个聊天截图，大家先睹为快。&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="http://brightliao.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="ChatGPT" scheme="http://brightliao.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/chatgpt/"/>
    
    
    <category term="AI" scheme="http://brightliao.com/tags/ai/"/>
    
    <category term="机器学习" scheme="http://brightliao.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="ML" scheme="http://brightliao.com/tags/ml/"/>
    
    <category term="ChatGPT" scheme="http://brightliao.com/tags/chatgpt/"/>
    
  </entry>
  
  <entry>
    <title>敏捷数据工程实践--以ETL为单位的CI和CD</title>
    <link href="http://brightliao.com/2023/01/10/ade-ci-cd-per-etl/"/>
    <id>http://brightliao.com/2023/01/10/ade-ci-cd-per-etl/</id>
    <published>2023-01-10T12:00:00.000Z</published>
    <updated>2023-05-16T09:22:34.832Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>前几天，我在跟一位做进口贸易的朋友聊天，发现一个很有意思的事情。</p><p>他们做的是国内的高端仪器进口的进口贸易业务。主要帮助销售国外产品的公司完成竞标、合同签订、物流、海关、进口贸易政策符合、维保等等事务。</p><p>我很疑惑，为什么会有这样的业务形态存在？为什么这些产品销售公司不自己处理这些事务，反而代理出去让其他公司赚钱呢？</p><span id="more"></span><p>我带着这个疑问，向他请教，获得了很多启发。</p><p>众所周知，国内的工业起步较晚，虽然这些年突飞猛进成为了世界工厂，但是核心的生产设备很多还是依赖进口。比如在生产芯片时少不了光刻机，在环境、食品、农业等实验室进行的样本成分分析也少不了可以分析各元素浓度的原子光谱仪。这个市场是一个万亿级的大市场。</p><p>这个业务有什么特点呢？</p><p>一是产品销售数量少。高端仪器一般售价都比较高，普遍在几十万到数百万。所以，一个年营业额在十亿的仪器产品公司其实也只是销售了数百台仪器而已。</p><p>二是销售流程特别复杂。由于是物理设备进口，将涉及很多现实的问题，除了产品推广和销售，还有一系列的事务，比如竞标、合同签订、物流、海关、进口贸易政策符合、维保等等，非常复杂。</p><p>作为一个在国内销售进口设备的企业，要如何组织其业务呢？</p><p>推广和销售是自不必说，否则市场根本不了解产品，就更别谈卖出去了。</p><p>但是，销售之外的其他事务要不要自己来做？这个就值得思考了。因为产品销售数量不会太大，但是销售之外的事务却特别复杂而繁多。如果培养一个专业的团队做这件事，由于产品销量不大，团队工作势必不会饱和。如果减少团队人员数量，这些事务又难以做得专业，容易出纰漏。</p><p>在经过大量的市场尝试和调整之后，专门做对进口贸易易的企业就诞生了。他们负责产品销售之外的大部分事务，涉及竞标、合同签订、物流、海关、进口贸易政策符合、税收、维保方式设计等。他们常常是一个非常专业的团队，可负责各个领域不同产品的进口贸易业务。在某些品类销售淡季时，其他品类可能又到销售旺季了。所以，他们的业务通常也能保持稳定和饱和。</p><p>于是，海外产品研发公司+国内产品销售公司+国内进口贸易公司的模式就在市场上慢慢形成并稳定下来了。总结起来，可以用下图简单地描述这三个企业如何愉快地合作完成整个产品进口销售的过程。</p><p><img data-src="/attaches/2023/2023-01-10-ade-ci-cd-per-etl/import-trade.png" alt="Import trade" /></p><p>进口贸易企业业务的兴起对整个行业效率和质量的提升都起到了正面的效果，这也是进口贸易企业得以存在的理由。</p><p>和这位朋友的交流完之后，我发现进口贸易企业业务的形成给了我不少启发。</p><p>从进口贸易企业的兴起中可以看到业务的重构和演变，即，通过合理的<strong>抽取</strong>和<strong>拆分</strong>提升了整体的效率。</p><h2 id="以etl为单位的持续集成"><a class="markdownIt-Anchor" href="#以etl为单位的持续集成"></a> 以ETL为单位的持续集成</h2><p>我联想到了近几天一直在思考的数据应用开发中的持续集成流水线设计。</p><p>在应用软件开发中，我们常常仅设计一条持续集成流水线，在流水线中运行所有的测试，接着将所有代码打包成一个大的产品包，然后部署到测试或产品环境中。</p><p>在数据应用中，是不是也需要这样做呢？这样做的好处是可以将产品环境的制品与代码仓库中的版本对应。其劣势其实也很多，比如，修改一个局部的代码，就不得不运行所有的测试，然后运行流水线中所有耗时的步骤，可能还需要进入手工测试的环节，最后才能发布到线上。效率非常低下。</p><p>这一问题在数据应用中更是被放大了。因为数据应用通常涉及数百个指标计算ETL，这些ETL的自动化测试只能用缓慢的集成测试来覆盖，这就导致流水线中的测试步骤耗时很长。在我们的项目中，常常需要跑半小时到一小时才能跑完。</p><p>这就如同做进口高端仪器销售的公司，如果自己来做进口贸易相关业务，不仅耗时特别长，而且出纰漏的可能性大（业务质量低）。</p><p>有没有更好的做法？既然只修改了某一个ETL，为什么不能就只部署和测试这个ETL？联想到前面进口贸易业务的抽取和拆分，是不是可以对流水线进行抽取和拆分呢？即，做<strong>以ETL为单位的持续集成流水线</strong>。</p><p>在数据应用开发场景中，这也是具备可行性的。原因在于，相比应用软件代码中的一个一个类或代码文件，ETL间几乎没有依赖。不同的ETL代码通常有不同的入口，存在于一个独立的文件。可以认为一个ETL就是一个独立的数据应用。</p><p>事实上，如果以ETL为单位进行持续集成和部署，还不用担心自己的部署会影响到其他的线上指标计算ETL，这也在一定程度上增强了安全性。</p><p>看起来，在数据应用开发领域，以ETL为单位的持续集是顺理成章的事。</p><p>对比一下微服务实践，还可以发现，这一实践与微服务中推荐的为每一个服务搭建一条持续集成流水线的实践几乎是等同的。</p><h2 id="如何实现"><a class="markdownIt-Anchor" href="#如何实现"></a> 如何实现</h2><p>如何实现以ETL为单位的持续集成呢？</p><p>如果基于Jenkins，可以在流水线上面加一个参数，如“ETL文件路径”，在运行流水线时，可以指定这个参数，让流水线仅针对指定的ETL运行测试与部署。</p><p>如果觉得在Jenkins上面实施以ETL为单位的持续集成较为麻烦，也可以团队自主开发一个专用的数据持续集成流水线。如果仅实现基本的功能，其实也并不复杂。</p><p>需要注意的是，一旦以ETL为单位进行持续集成了，就需要有一种方式记录每一个ETL对应的代码仓库里面的版本号，方便版本追溯。实现方式有多种，比如，可以在部署ETL的时候，在生产环境写入一个该ETL对应的版本文件。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>如果采用应用软件持续流水线的大包发布方式构建数据应用的持续集成流水线，将降低部署频率，且容易引起安全问题。借鉴进口贸易业务的抽取和拆分模式，在数据应用开发中，将持续集成流水线拆分为以ETL为单位的流水线可以有效解决上述问题。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;前几天，我在跟一位做进口贸易的朋友聊天，发现一个很有意思的事情。&lt;/p&gt;
&lt;p&gt;他们做的是国内的高端仪器进口的进口贸易业务。主要帮助销售国外产品的公司完成竞标、合同签订、物流、海关、进口贸易政策符合、维保等等事务。&lt;/p&gt;
&lt;p&gt;我很疑惑，为什么会有这样的业务形态存在？为什么这些产品销售公司不自己处理这些事务，反而代理出去让其他公司赚钱呢？&lt;/p&gt;</summary>
    
    
    
    <category term="敏捷" scheme="http://brightliao.com/categories/%E6%95%8F%E6%8D%B7/"/>
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%8F%E6%8D%B7/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="敏捷" scheme="http://brightliao.com/tags/%E6%95%8F%E6%8D%B7/"/>
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据工程" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="数据开发" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/"/>
    
    <category term="软件工程" scheme="http://brightliao.com/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>DDD建模案例分享</title>
    <link href="http://brightliao.com/2022/07/28/modelling-examples/"/>
    <id>http://brightliao.com/2022/07/28/modelling-examples/</id>
    <published>2022-07-28T12:00:00.000Z</published>
    <updated>2022-09-12T12:55:03.306Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>前面的文章<a href="/2022/07/27/smart-domain-and-ddd/">《我理解的Smart Domain与DDD》</a>中，我们分析了 Smart Domain 的设计，尝试回答了为什么 Smart Domain 可以用于实现 DDD，并对Smart Domain和DDD进行了一些扩展性的讨论。</p><p>虽然 Smart Domain 作为一种设计范式，可以辅助我们实现 DDD。但是具体到真实项目中，建模这个过程还得结合实际的领域问题，深入思考，大量尝试，大声建模，才能得到好的模型。有哪些值得参考的案例呢？下面分享几个个人在项目中觉得还不错的建模实践。</p><span id="more"></span><h2 id="继承的应用"><a class="markdownIt-Anchor" href="#继承的应用"></a> 继承的应用</h2><p>作为面向对象编程范式三大关键特性之一的“继承”，如果使用得当，在实践中可以帮助我们更好的建模概念间的关系并有效避免重复代码。</p><h3 id="algorithm模型抽象"><a class="markdownIt-Anchor" href="#algorithm模型抽象"></a> Algorithm模型抽象</h3><p>我曾经经历过一个<strong>机器学习平台</strong>的项目，代码中有一个算法的概念。在没有有效建模之前，代码库中只有一个名为Algorithm的类，所有算法相关的信息均保存在这个类的属性上。项目中涉及到了几十个算法，都以数据的形式存储到了数据库。</p><p>表面上看，这一设计可以让我们更容易的添加算法（只需要增加数据即可）。但是，这带来的后果是大量的算法类型判断出现在代码库中。这是因为我们常常要对不同的算法进行不同的处理，比如在运行算法时需要为基于Tensorflow的深度学习算法和基于Spark的分布式学习选择不同的计算框架。</p><p>这一场景可以通过设计良好的一组有继承关系的类来表达（Algorithm基类，SparkAlgorithm/TensorflowAlgorithm抽象类，各个算法实现类），利用多态特性可以轻松避免这些条件判断代码。这一设计的另一大作用是将不太会变化的属性放入了代码而只将需要变化的属性放入数据库，从而很大程度上简化代码（大部分操作无需查询数据库）。关于此项目的更多内容请参考<a href="/2020/05/24/architecture-designing-practise-for-ml-platform-oop/">《机器学习平台架构实践 – 面向对象设计》</a>。</p><h3 id="backend模型抽象"><a class="markdownIt-Anchor" href="#backend模型抽象"></a> Backend模型抽象</h3><p>另一个项目是我们近期开源的名为<a href="https://github.com/easysql/easy_sql"><strong>Easy SQL</strong></a>的ETL开发语言项目。</p><p>为了同时支持不同的后端计算引擎，我们设计了一个抽象的<code>Backend</code>类型，针对<code>Spark</code>和<code>MaxCompute</code>分别提供了实现。</p><p>同时由于需要支持不同类型的常规的关系型数据库作为后端计算引擎，我们实现了一个<code>Rdb</code>的<code>Backend</code>，在<code>Rdb</code>的实现中，为了支持不同的方言，定义了一个名为<code>Dialect</code>的抽象接口，然后针对此接口提供了<code>PostgreSQL</code> <code>Clickhouse</code> <code>BigQuery</code>的实现。详情请参考这里的<a href="https://github.com/easysql/easy_sql/blob/main/easy_sql/sql_processor/backend/base.py">代码</a>。</p><h3 id="apply模型抽象"><a class="markdownIt-Anchor" href="#apply模型抽象"></a> Apply模型抽象</h3><p>还有一个<strong>为分布式服务创建中心化的权限管理</strong>应用。</p><p>在这个应用中有一个权限申请的概念。申请分为两种类型，一是对团队空间的权限申请，二是对发布数据的权限申请。这两种类型的申请存在相似性，比如审批流程相似，都有审批人等。但同时也存在诸多不同，比如，权限类型不同，团队空间可以有写权限，而发布的数据只有读权限。</p><p>遗憾的是，团队在进行模型设计时，只用了一个<code>Apply</code>类来表达申请的概念，并因此引入了多处对申请的资源的类型的判断。现在回想起来，如果可以用两个子类来表达不同的申请，结果可能会好不少。</p><h2 id="工厂模式的应用"><a class="markdownIt-Anchor" href="#工厂模式的应用"></a> 工厂模式的应用</h2><p>工厂模式是继承的好朋友。试想，有了继承树，如何创建对应的类呢？一般而言，还需要一个工厂方法来根据不同类型创建不同对象。在我经历过的很多建模实践中，很多情况下都会将“继承”和“工厂模式”搭配起来使用。</p><h3 id="算法工厂"><a class="markdownIt-Anchor" href="#算法工厂"></a> 算法工厂</h3><p>比如，在上面的机器学习平台中，由于有多种不同的算法构成的继承树，在通过用户的选择进行对象构建时，就可以使用工厂模式。不同的算法往往需要不同的参数及配置，这一做法可以有效的将参数选择逻辑集中起来管理。</p><h3 id="步骤工厂"><a class="markdownIt-Anchor" href="#步骤工厂"></a> 步骤工厂</h3><p>除了配合“继承”使用，如果某些对象的构造本身比较复杂，也可以考虑用工厂来进行抽象。比如，在<a href="https://github.com/easysql/easy_sql">Easy SQL</a>中，一个ETL被抽象为多个主要由SQL组成的步骤，在通过SQL文件来创建一组步骤的时候，就可以考虑用工厂模式实现。具体代码可以参考<a href="https://github.com/easysql/easy_sql/blob/main/easy_sql/sql_processor/step.py">这里</a>。</p><h2 id="有限状态机的应用"><a class="markdownIt-Anchor" href="#有限状态机的应用"></a> 有限状态机的应用</h2><p>在<strong>机器学习平台</strong>项目中，为了管理复杂的批处理任务的状态及其迁移路径，我们用到了有限状态机模式来进行抽象。</p><p>状态机定期获取任务的状态，在状态变化时进行记录，并根据启动时设置的任务状态转换处理器进行处理。</p><p>没有有限状态机抽象时，程序很多地方需要判断任务状态，并进行一定的逻辑处理。代码分散，很难理解。有了有限状态机的抽象之后，任务状态及状态迁移的处理器都被集中起来管理，从而变得直观、清晰且可控。</p><p>关于这个例子的更多内容可以参考之前的博客<a href="/2020/05/24/architecture-designing-practise-for-ml-platform-oop/">《机器学习平台架构实践 – 面向对象设计》</a>。</p><h2 id="其他设计模式的应用"><a class="markdownIt-Anchor" href="#其他设计模式的应用"></a> 其他设计模式的应用</h2><p>设计模式是针对某一类问题的通用解决方案。如果能在建模的时候有效使用设计模式，可以以一种大家都熟悉的方式解决问题并提升设计的质量。</p><p>其他很多设计模式都可以在建模阶段灵活选用。我们可以从很多架构设计或常用库的实现里面看到他们的影子。</p><p>Clean架构中的<code>Adapter</code>层，其实是用了适配器模式。</p><p>前端开发中，我们会添加很多交互事件处理器，这其实是观察者模式的应用。</p><p>后端开发中的<code>Filter</code>是职责链模式的应用。</p><p>Java标准库中的各类包装类型，如<code>Integer</code>, <code>Long</code>等在实现时使用了Flyweight享元模式。</p><p>在我们自己进行建模时，可以参考选用这些设计模式使用。不过在使用设计模式时，需要注意不要为了用设计模式而用设计模式，否则很容易过度设计。</p><h2 id="面向接口编程的应用"><a class="markdownIt-Anchor" href="#面向接口编程的应用"></a> 面向接口编程的应用</h2><p>面向接口编程是一种拥有强大抽象能力的编程范式。在Smart Domain示例中，关联对象以接口的形式定义在模型中，用于辅助实现依赖倒置。</p><h3 id="验证器"><a class="markdownIt-Anchor" href="#验证器"></a> 验证器</h3><p>另一个例子是验证器的实现。</p><p>在Web后端开发中，常常要对传入的参数进行严格的校验。很多校验需要跨属性进行。此时可以用自定义JSR的验证器来实现。</p><p>用面向接口编程的思想来实现这样的验证器，可以这样做：</p><p>1.定义一个验证器类<code>V</code>，其验证的注解为<code>VA</code>，验证目标对象为<code>VO</code><br />2.在验证器类中定义内部注解接口<code>VA</code><br />3.在验证器类中定义内部目标对象接口<code>VO</code><br />4.在要验证的类<code>B</code>上加上<code>VA</code>注解，并实现<code>VO</code>接口</p><p>代码结构参考：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">V</span> <span class="keyword">implements</span> <span class="title class_">ConstraintValidator</span>&lt;V.VA, V.VO&gt; &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="meta">@interface</span> VA &#123; ... &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">VO</span> &#123; ... &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@V</span>.VA</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">B</span> <span class="keyword">implements</span> <span class="title class_">V</span>.VO &#123; ... &#125;</span><br></pre></td></tr></table></figure><p>一个具体的实例可以参考这里的<a href="https://github.com/gmlove/experiments/blob/master/java_validator/ValidatorTest.java">代码</a>。</p><p>这样做的好处是，<code>V</code>这个类变成了DDD原书中提到的Standalone Class，除了Java标准库依赖之外，没有任何其他依赖。这使得这个验证器非常容易被复用，因为它可被用于验证任何实现了<code>VO</code>接口的对象。</p><p>结合Spring这样的依赖注入框架使用，还可以通过构造器给验证器注入任意的其他组件，以便实现更复杂的验证功能。</p><p>从这个例子里，我们可以看到面向接口编程带来的强大抽象能力。</p><h3 id="tdd的应用"><a class="markdownIt-Anchor" href="#tdd的应用"></a> TDD的应用</h3><p>TDD对于改善设计有很大的帮助。</p><p>Eric在书中建议团队“大声”的建模，这实际上就是在强调我们人类的语言天赋。不同背景的人在讨论问题时，会很容易形成一种双方都可以理解的“混杂”语言。这是人类的天赋。通过交流和讨论，很多情况下，我们可以自然的找到一种合适的模型。</p><p>这跟TDD实践是一致的。在进行TDD时，我们会站在使用代码的角度进行解决方案的描述。在描述的过程中，可以充分发挥语言能力，让我们自然的得到一个良好的模型。</p><p>关于如何使用TDD来改善模型设计，我之前有几篇文章分享。列举如下，给大家参考：</p><ul><li><a href="/2019/07/20/tdd-for-improving-design/">《从改善设计的角度理解 TDD》</a></li><li><a href="/2019/08/18/tdd-for-improving-design-2/">《从改善设计的角度理解 TDD (2)》</a></li><li><a href="/2022/07/05/tdd-to-develop-a-long-running-task-system">《用TDD开发基于数据库的长时任务系统》</a></li><li><a href="/2022/05/24/5-properties-of-good-code-cupid/">《好代码的五个特质-CUPID》</a></li></ul><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>本文分享了一些建模的例子，从这些例子中可以看到，其实每个项目中都可以有很多可挖掘的内容，关键在于我们不能轻易满足提取“名词”，而是要深入思考直至深刻理解问题，大胆创新直至找到最恰当的抽象。</p><p>对于长期从事某一个特定领域的开发，如只做前端或只做后端的同学，我们可能需要去尝试练习一下端到端的应用设计和开发，以便于认识软件构建的全貌。这可能对于我们从软件整体去思考和建模有更大的帮助。可以按照软件技术发展脉络来设计自己的练习。一个推荐的路径是：简单命令行程序-&gt;客户端应用-&gt;前后端分离的Web应用-&gt;微服务。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;前面的文章&lt;a href=&quot;/2022/07/27/smart-domain-and-ddd/&quot;&gt;《我理解的Smart Domain与DDD》&lt;/a&gt;中，我们分析了 Smart Domain 的设计，尝试回答了为什么 Smart Domain 可以用于实现 DDD，并对Smart Domain和DDD进行了一些扩展性的讨论。&lt;/p&gt;
&lt;p&gt;虽然 Smart Domain 作为一种设计范式，可以辅助我们实现 DDD。但是具体到真实项目中，建模这个过程还得结合实际的领域问题，深入思考，大量尝试，大声建模，才能得到好的模型。有哪些值得参考的案例呢？下面分享几个个人在项目中觉得还不错的建模实践。&lt;/p&gt;</summary>
    
    
    
    <category term="架构" scheme="http://brightliao.com/categories/%E6%9E%B6%E6%9E%84/"/>
    
    <category term="DDD" scheme="http://brightliao.com/categories/%E6%9E%B6%E6%9E%84/ddd/"/>
    
    
    <category term="架构" scheme="http://brightliao.com/tags/%E6%9E%B6%E6%9E%84/"/>
    
    <category term="DDD" scheme="http://brightliao.com/tags/ddd/"/>
    
    <category term="领域" scheme="http://brightliao.com/tags/%E9%A2%86%E5%9F%9F/"/>
    
  </entry>
  
  <entry>
    <title>我理解的Smart Domain与DDD</title>
    <link href="http://brightliao.com/2022/07/27/smart-domain-and-ddd/"/>
    <id>http://brightliao.com/2022/07/27/smart-domain-and-ddd/</id>
    <published>2022-07-27T12:00:00.000Z</published>
    <updated>2022-08-09T07:39:50.336Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>前段时间，咱们CTO八叉在极客时间做了一次关于用Smart Domain实现DDD的分享（点击<a href="https://www.bilibili.com/video/BV1QT411J7jh">这里</a>回看）。一个新词Smart Domain进入大家的视野。</p><h2 id="smart-domain解析"><a class="markdownIt-Anchor" href="#smart-domain解析"></a> Smart Domain解析</h2><p>Smart Domain是啥？为什么可以用Smart Domain实现DDD？本文尝试结合以往对DDD的学习和实践的经验，跟大家分享一下个人的理解。</p><p>八叉在分享中提到Smart Domain这个名字来源于Smart UI。我们都知道Smart UI是DDD中提到的一种反模式，只能用于解决简单问题。这里的命名略带反讽戏谑的意味。</p><span id="more"></span><p>下面咱们结合示例看看Smart Domain究竟是什么。</p><p>打开Smart Domain的示例工程：<a href="https://github.com/Re-engineering-Domain-Driven-Design/Accounting">https://github.com/Re-engineering-Domain-Driven-Design/Accounting</a>。可以看到，项目在结构上分为了四个子模块：</p><ul><li><code>main</code>: Web应用入口，负责配置即启动应用</li><li><code>api</code>: 定义Restful API</li><li><code>domain</code>: 核心领域层</li><li><code>persistent</code>: 数据持久化</li></ul><h3 id="模块划分与依赖关系"><a class="markdownIt-Anchor" href="#模块划分与依赖关系"></a> 模块划分与依赖关系</h3><p>深究起来，这四个模块和现在的分层架构有一些相似之处，但却并<strong>没有显示的严格的进行分层</strong>。同时，八叉在分享中明确提到了分层架构对领域建模是有伤害的，容易导致抽象不足。</p><p>值得注意的是，<strong><code>domain</code>模块没有任何依赖</strong>，其他模块则依赖<code>spring</code>及相应的包。通过在<code>domain</code>层定义抽象的接口（但不提供实现，由其他模块提供实现）的方式，将<code>domain</code>层的核心逻辑隔离起来，使得<code>domain</code>层可以非常容易根据领域需要进行灵活的设计及独立的测试。大家如果熟悉依赖倒置的设计原则，应该可以很容易领会这一做法的好处。（<code>domain</code>层本应该依赖数据持久化进行数据的查询与保存，这里通过抽象的接口设计让持久化层反过来依赖<code>domain</code>层的接口。）</p><h3 id="关联对象"><a class="markdownIt-Anchor" href="#关联对象"></a> 关联对象</h3><p>Smart Domain的一个关键设计在于在模型之间<strong>引入了一个中间关联对象</strong>。关联对象由一系列接口来定义（见代码中的<code>HasMany</code> <code>HasOne</code> <code>Many</code>接口），各类跨模型的操作均通过关联对象实现。这一设计避免了直接进行模型引用的诸多问题，比如引用的模型数量太多无法直接放入内存、引用的模型的查询修改通过<code>Repository</code>实现进而引入抽象能力很弱的<code>Service</code>去协调等。</p><p>示例项目中通过关联对象建模出的结果如下：</p><p><img data-src="/attaches/2022/2022-07-27-smart-domain-and-ddd/smart-domain-models.jpeg" alt="Smart Domain Models" /></p><p>无关联对象的实现方式的本质问题在于希望完全用内存模型来抽象数据库访问，而内存模型事实上无法直接建模数据库的复杂性，因而引起了一系列连锁反应。通过引入关联对象，<strong>将数据库访问显示的建模出来</strong>，这些连锁反应就不复存在了，领域层也将更清晰、纯粹和丰满。</p><p>关联对象和传统DDD中的<code>Repository</code>的抽象有一定的相似点，在我看来其最重要的区别在于关联对象接口定义在了引用方代码中。这一做法的隐含建议是<strong>从使用的角度来定义接口</strong>，从而使得接口定义不多不少，刚好满足系统需求。</p><h3 id="其他"><a class="markdownIt-Anchor" href="#其他"></a> 其他</h3><p>由于在Smart Domain的设计里面，<strong>对象图以统一的关联的形式被创建</strong>出来，所以可以提供一个统一的访问关联对象的方法。这一点很好的符合了Restful API的设计思想，API模块利用这个特点，以很少的代码完成了Restful API的导出。</p><p>纵观Smart Domain的设计，可以发现结构上非常简洁，没有引入传统DDD实践中常用却很难用好的<code>Repository</code> <code>Service</code> <code>Aggregate</code>等模式。然而这恰恰是让开发人员可以<strong>集中精力在对领域的挖掘和思考</strong>上。</p><h3 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h3><p>总结起来，Smart Domain主要的创新及价值有以下几点：</p><ul><li>打破了大家习惯用的分层架构，这些分层架构大都是从技术角度进行的抽象，而非领域角度</li><li>摒弃了职责模糊不清的service模式，使得原来service层的逻辑下沉到领域模型中，从而期望得到更丰满的领域模型</li><li>弱化了DDD中引入的聚合、限界上下文等容易引起争议的模式</li><li>尽可能的摒弃了在代码中使用过于技术化的术语，如Controller、DTO等，从而使得我们更专注于领域设计，通过引入更多的抽象来解决问题</li><li>将数据库查询显示的建模出来（通过关联对象），而不是直接在模型中引用关联模型的实例，有利于避免查询性能问题</li></ul><h2 id="为什么说smart-domain实现了ddd"><a class="markdownIt-Anchor" href="#为什么说smart-domain实现了ddd"></a> 为什么说Smart Domain实现了DDD？</h2><p>经过上面对Smart Domain的分析之后，可能有人会问：这跟DDD有啥关系？为什么DDD中的很多设计模式都没用却说实现了DDD？</p><p>要回答这个问题，需要搞清楚什么是DDD，即DDD的定义是什么。</p><h3 id="什么是ddd"><a class="markdownIt-Anchor" href="#什么是ddd"></a> 什么是DDD？</h3><p>要追寻DDD的定义，可以回到这本早期的也是业界公认最权威的Eric的书《领域驱动设计-软件核心复杂性应对之道》中。</p><p>Eric并未直接在书中对DDD进行定义，但是在第一章中，结合示例，总结了有效建模的几个要素：</p><ul><li>模型和实现的绑定</li><li>获得了一种基于模型的语言</li><li>开发一个蕴含丰富知识的模型</li><li>持续进行模型提炼</li><li>头脑风暴进行创新，进行大量实验</li></ul><p>在知识消化章节提到：</p><ul><li>分析员和程序员将自己的知识输入到了模型中，因此模型的组织更严密，抽象也更为整洁</li><li>模型反映业务的深层次知识，模型真正是对业务原理的抽象反映</li></ul><p>在统一语言章节提到：</p><ul><li>如果不把“讲话”与各种沟通方式配合起来使用，那么将是巨大的浪费，因为人类本身就有 讲话的天赋。遗憾的是，当人们讲话时，一般并不使用领域模型的语言。</li><li>当人们谈话时，自然会发现词语解释和意义上的差别，而且自然而然会解决这些差别。他们会发现这种语言中的晦涩之处并消除它们，从而使语言变得顺畅。</li><li>使用模型的元素以及模型中各元素之间的交互来大声描述场景，并且按照模型允许的方式将各种概念结合到一起。找到更简单的表达方式来讲出你要讲的话，然后将这些新的思想应用到图和代码中。</li></ul><p>从这些描述可以看出DDD的指导思想是：<strong>深入研究领域，消化知识，充分沟通，然后用软件模型对问题进行深刻的抽象，最终得到一个富含知识的领域模型。</strong></p><h3 id="smart-domain实现ddd"><a class="markdownIt-Anchor" href="#smart-domain实现ddd"></a> Smart Domain实现DDD</h3><p>从上面的分析来看，DDD的实现不在于用何种方法，而是看最后是否得到了良好的深刻的领域模型。Smart Domain可以促进我们把关注点从研究技术转向研究领域，从而推动开发人员去深入分析理解问题，创新的大胆的进行抽象和建模，最终得到好的领域模型。所以，可以说Smart Domain提供了一种很好的方式来实现DDD，这显然是合理的。</p><h2 id="smart-domain的扩展思考"><a class="markdownIt-Anchor" href="#smart-domain的扩展思考"></a> Smart Domain的扩展思考</h2><p>Smart Domain给我们提供了一个新的DDD实现思路。我们对它有没有什么疑问呢？</p><h3 id="领域层抽象"><a class="markdownIt-Anchor" href="#领域层抽象"></a> 领域层抽象</h3><p>习惯分层架构的同学，看到Smart Domain的思想，可能在直觉上会感觉事情不太对：以往可能有的项目上的代码超过10w行，但领域模型却只有10多个，难道要把这些代码都放入这10多个类？</p><p>事实上，这正好是抽象不足的表现，也正是Smart Domain或者DDD希望解决的问题。正是由于我们不能把太多代码放入同一个类（过大的类是一种明显的反模式）这个原因，才<strong>促使我们想办法通过引入更多的抽象来解决问题</strong>。</p><p>如何引入新的抽象？一个典型的示例是DDD原书中提到的关于策略模式抽象的例子。</p><p>在航运领域建模的过程中，在处理货物超订时，如果没有抽象，可以直接在代码中加入一些条件判断代码来实现。这样的处理方式的结果就是某个模型或类中的代码越来越多，直至难以维护。</p><p>而仔细思考领域之后，可以发现：</p><blockquote><p>超订规则是一个策略。策略其实是一种设计模式，也就是我们所说的STRATEGY模式。</p></blockquote><p>可以看到，用策略模式来抽象可以很好的解决这个问题。这就是深入思考的结果。</p><p>除了可以用策略模式进行抽象，DDD书中提到的大多数常见模式都是可以使用的，比如<code>Factory</code>、<code>Repository</code>等。这些模式还包括设计模式中的组合模式、门面模式、解释器模式、观察者模式等等。</p><p>或许是大家在学习或者讲解DDD时过于关注了DDD引入的几个新的模式（如实体、值对象、聚合等），很多人都忽略了DDD中指出的要深入理解领域这个重点中的重点。</p><p>下面是Eric在书中语重心长的想要提醒大家的文字：</p><blockquote><p>通过像PCB示例这样的模型获得的知识远远不只是“发现名词”，业务活动和规则如同所涉 及的实体一样，都是领域的中心…当我们的建模不再局限于寻找实体和值对象时我们才能充分吸取知识…领域专家往往不会意识到他们的思考过程有多么复杂，协作消化知识的过程使得规则得以澄清和充实，并消除规则矛盾以及删除无用规则。</p></blockquote><h3 id="弱化分层强化领域划分"><a class="markdownIt-Anchor" href="#弱化分层强化领域划分"></a> 弱化分层，强化领域划分</h3><p>有人可能会问，上面例子中的策略模式相关的代码应该放在什么地方？当然是领域层！事实上Smart Domain的设计思想是根本不区分这些分层。这样一来，所有代码都是可以看作领域层代码（尽管有一些代码看作基础设施层可能更为合理），从而把尽量多的代码放在领域层，尽最大可能丰富领域层。</p><p>分层被弱化了，领域中的代码变多了，这正是DDD和Smart Domain所希望的结果。然而，随之而来的问题是如何管理这些代码。</p><p>很容易想到的答案是进行模块划分。事实上，DDD中有单独提到“模块”这一模式。<strong>进行模块划分时，应参考高内聚低耦合的原则</strong>，使得模块内是高内聚，模块间是低耦合的。</p><p>常见的不符合高内聚低耦合模块划分原则的一个反例是按照技术名称进行模块划分。比如，可以回顾一下我们维护过的代码库，是不是还记得里面有一些模块的名称是<code>controller</code> <code>requests</code> <code>responses</code> <code>dtos</code> <code>services</code>等等？当我们打开这些模块时，会发现里面的类其实没什么关系，而模块间的相互引用却非常多。</p><p>事实上，DDD中讲到了更多的关于广义的模块划分的内容。从整个源代码库的角度来看，源代码可以按照从小到大不同粒度划分为函数、类、模块、领域、服务等级别。DDD中讲到了如何在这些不同的层级进行划分。</p><p>在<strong>类级别</strong>，DDD原书中提到了<strong>Standalone Class</strong>模式。Standalone Class即独立的与其他类无关的类。这一模式其实是在说类级别的高内聚低耦合。</p><p>在类级别之上，DDD中提到了<strong>Aggregate</strong>模式。Aggretate即<strong>一组强相关的类</strong>形成的聚合。这一模式其实是在说一组类的高内聚低耦合。</p><p>在<strong>领域级别</strong>，DDD提到了<strong>领域划分</strong>。可以按照领域的职责，将领域划分为核心域、通用域、支撑域等领域。这一模式是在说领域的高内聚低耦合。</p><p>事实上，从完整的代码库的角度来看，可以很容易建立以下认知：</p><p>代码块构成一个范围，函数体构成一个范围，类构成一个范围，类所在的包构成了一个范围，包所在的库构成了一个范围。将范围当做领域来理解，可以认为这些领域按照不同的细节程度和抽象程度构成了一个类似森林的结构。而森林的每一层都应当是高内聚低耦合的。</p><p>关于以上内容的更多描述，欢迎参考我的另一篇博客<a href="/2019/08/08/domain-concept-in-your-code/">《代码中的领域》</a>。</p><h3 id="与传统的聚合相结合"><a class="markdownIt-Anchor" href="#与传统的聚合相结合"></a> 与传统的聚合相结合</h3><p>在Smart Domain的示例代码中，基于内存的抽象也通过关联实现，略显麻烦。比如：</p><ul><li>客户端需要调用好几个api才能把一个页面需要的数据拿到，不太方便</li><li>基于内存访问数据比基于关联对象访问更方便</li></ul><p>传统的DDD实现通过聚合（聚合根直接引用其他实体）来解决此问题。如果可以确定聚合中关联的其他实体数量不多，则也许还是可以考虑通过聚合的方式来实现。此时，直接通过一个Restful API一次性返回此聚合中的所有模型即可。</p><p>对于聚合根之间的引用，则仍然可以采用Smart Domain中的关联对象实现方式。</p><p>如此一来，可以结合两者的优势。这可能是实践过程中值得考虑的选择。</p><p>不过，混合两种模式对架构师可能不太友好。与其引入更多的选择，他们可能更希望推进项目中的架构一致性。实际项目中，可能要结合团队成员的能力来综合考虑如何选择。</p><h2 id="总结-2"><a class="markdownIt-Anchor" href="#总结-2"></a> 总结</h2><p>本文分析了Smart Domain的设计，尝试回答了为什么Smart Domain可以用于实现DDD。结合以往对DDD的学习和实践经验，分享了一些扩展的问题。希望对大家了解DDD和Smart Domain有一定帮助。</p><p>虽然Smart Domain作为一种设计范式，可以辅助我们实现DDD。但是具体到真实项目中，建模这个过程还得结合实际的领域问题。有哪些值得参考的案例呢？下一篇文章将做一些分享。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;前段时间，咱们CTO八叉在极客时间做了一次关于用Smart Domain实现DDD的分享（点击&lt;a href=&quot;https://www.bilibili.com/video/BV1QT411J7jh&quot;&gt;这里&lt;/a&gt;回看）。一个新词Smart Domain进入大家的视野。&lt;/p&gt;
&lt;h2 id=&quot;smart-domain解析&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#smart-domain解析&quot;&gt;&lt;/a&gt; Smart Domain解析&lt;/h2&gt;
&lt;p&gt;Smart Domain是啥？为什么可以用Smart Domain实现DDD？本文尝试结合以往对DDD的学习和实践的经验，跟大家分享一下个人的理解。&lt;/p&gt;
&lt;p&gt;八叉在分享中提到Smart Domain这个名字来源于Smart UI。我们都知道Smart UI是DDD中提到的一种反模式，只能用于解决简单问题。这里的命名略带反讽戏谑的意味。&lt;/p&gt;</summary>
    
    
    
    <category term="架构" scheme="http://brightliao.com/categories/%E6%9E%B6%E6%9E%84/"/>
    
    <category term="DDD" scheme="http://brightliao.com/categories/%E6%9E%B6%E6%9E%84/ddd/"/>
    
    
    <category term="架构" scheme="http://brightliao.com/tags/%E6%9E%B6%E6%9E%84/"/>
    
    <category term="DDD" scheme="http://brightliao.com/tags/ddd/"/>
    
    <category term="领域" scheme="http://brightliao.com/tags/%E9%A2%86%E5%9F%9F/"/>
    
  </entry>
  
  <entry>
    <title>用TDD开发基于数据库的长时任务系统</title>
    <link href="http://brightliao.com/2022/07/05/tdd-to-develop-a-long-running-task-system/"/>
    <id>http://brightliao.com/2022/07/05/tdd-to-develop-a-long-running-task-system/</id>
    <published>2022-07-05T12:00:00.000Z</published>
    <updated>2022-07-06T06:27:30.614Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h2 id="背景"><a class="markdownIt-Anchor" href="#背景"></a> 背景</h2><p>在最近的一个项目上，我们再次碰到了需要处理长时任务的场景。事实上，随着要处理的业务问题越来越复杂，要集成的系统越来越多，在<code>Web</code>服务器端开发中，长时任务处理已经成为了一个普遍的问题。</p><p>以下场景均可看作长时任务场景：</p><ul><li>在<code>GitHub</code>提交了一个<code>PR</code>，要分别向上百个相关用户单独发送邮件</li><li>用户上传了一个文件，需要扫描这个文件是不是带病毒</li><li>用户想以<code>pdf</code>格式下载某一个文档，需要先将文档转换为<code>pdf</code>格式</li></ul><span id="more"></span><p>这些问题的一个共同特征是执行时间比较长，不能简单的用<strong>单线程的Web服务请求-响应模型</strong>来实现。</p><h2 id="分析问题识别难点"><a class="markdownIt-Anchor" href="#分析问题识别难点"></a> 分析问题，识别难点</h2><p>在应对这些需求场景时，一个关键的设计是需要用异步API模型进行建模。如下图所示：</p><p><img data-src="/attaches/2022/2022-07-05-tdd-to-develop-a-long-running-task-system/long-running-task-basic-model.png" alt="Event model for long-running task" /></p><p>通常的做法如下：</p><ul><li>采用事件模型（<code>Event Model</code>），将长时任务包装为一个事件，放入事件队列</li><li>将待处理事件从事件队列中推送给事件消费者（或者消费者主动拉取新的事件）</li><li>事件消费者处理事件，并保存事件处理结果</li><li>关注事件结果的客户端查询事件处理状态，并提取事件处理结果</li></ul><p>这看上去并不太难，但是，如果仔细思考一下事件的处理过程，会发现情况不对，这里面还存在以下一系列问题：</p><ul><li>如何尽量避免多个事件消费者同时处理此事件，以便节省计算资源？</li><li>如果恰好同时有多个事件消费者在处理事件，会发生什么问题？</li><li>如果有多个相关事件正在被同时处理，如何处理资源竞争问题？</li><li>如何避免长时任务可能导致的长时数据库事务问题？</li></ul><p><img data-src="/attaches/2022/2022-07-05-tdd-to-develop-a-long-running-task-system/long-running-task-problems.png" alt="Problems related to event model" /></p><p>以下方案可用于应对上述问题：</p><ul><li>在事件分派时，通过并发控制或者资源锁定机制，确保只将事件分派给某一个事件消费者</li><li>保证事件处理器的实现是幂等的，即：即便多次同时执行，其最终结果也是一致的</li><li>将任务处理过程拆分为多个短数据库事务过程，避免长期持有数据库锁引起性能问题</li></ul><p>经过以上分析可以发现，异步任务模型是相对比较复杂的模型，程序实现及上线之后的问题分析、调试成本都比较高。在进行系统设计时，如果发现系统可以接受一定的延迟，并且并发也不高，就应尽量避免引入异步任务模型。</p><p>近年来，<code>CQRS</code>（命令查询分离）+<code>Event Sourcing</code>（事件溯源）设计模式越来越受到大家的关注。这一模式中，所有的写操作均采用异步事件的方式进行处理。准备采用这一模式时，一定要评估是否值得，因为异步任务将带来与上述类似的非预期复杂度。同时，如果事件使用不当还容易导致更复杂的情况。比如，如果在事件处理过程中生成了其他的事件，就可能产生一个由任务序列组成的有向图，甚至图中带环，从而使得处理过程的分析变得异常复杂。</p><h2 id="tdd方法简介"><a class="markdownIt-Anchor" href="#tdd方法简介"></a> TDD方法简介</h2><p><code>TDD</code>可以用于辅助我们进行复杂软件设计。是不是可以用<code>TDD</code>帮助我们实现这一复杂的异步任务处理系统呢？下面来做一下尝试。</p><p>在回答这个问题之前，我们先了解一下<code>TDD</code>的基本思想及其实施过程。</p><p>从驱动设计的角度来看，<code>TDD</code>的基本思想是，在还没有代码的时候，先站在使用代码的<strong>用户的角度</strong>来定义测试（编写测试就是在使用代码，所以可以自然的站在用户角度），由于使用了<strong>用户视角</strong>来定义系统组件及其接口，就可以使得到的组件和接口易于使用。</p><p>很多人无法在没有代码的时候编写测试，或者会由于IDE给出的一系列红色警告（由于组件还未定义）而感到不自然。</p><h3 id="写不出测试"><a class="markdownIt-Anchor" href="#写不出测试"></a> 写不出测试</h3><p>写不出测试一般是由于没有理解问题或不了解现有架构。可以采用<code>Tasking</code>（任务拆解）的方式来验证自己是否理解问题并了解架构。其基本思想是，对于一个问题，如果可以列出解决它所需的一系列清晰而合理的步骤，那就说明对问题和架构都较为清楚了。所以，在实施<code>TDD</code>时，一般需要先进行<code>Tasking</code>任务拆解。</p><h3 id="红色警告让人感到不自然"><a class="markdownIt-Anchor" href="#红色警告让人感到不自然"></a> 红色警告让人感到不自然</h3><p>对IDE给出的红色警告感到不自然的问题一般来自习惯。在编写测试代码时，需要调整视角，以完成设计和验证结果为重心。事实上，先写测试还会带来一个额外的好处，那就是在写完测试之后，可以让IDE帮助我们生成绝大多数代码，从而更快的完成代码编写。</p><h2 id="用tdd辅助开发基于数据库的队列服务"><a class="markdownIt-Anchor" href="#用tdd辅助开发基于数据库的队列服务"></a> 用TDD辅助开发基于数据库的队列服务</h2><p>下面看看如何用<code>TDD</code>来设计一个满足上述需求的异步任务处理系统。</p><p>经过前文的分析，我们大致了解了解决长时任务的关键方案。方案里面有一个核心的组件，那就是队列服务。</p><p>可以找到很多开源软件用来做队列服务，比如<code>RabbitMQ</code>，<code>Apache ActiveMQ</code>，<code>Apache RocketMQ</code>，<code>Kafka</code>，<code>Redis</code>等。甚至很多云端的SaaS服务也可以用来解决这个问题，比如<code>AWS SQS</code>，<code>Azure Service Bus queues</code>, <code>GCP Pubsub</code>等。</p><p>在很多项目的上下文中，可以预期并不会有太多的长时任务。此时，为了保持系统简单，避免引入其他的依赖，可以考虑基于数据库来实现这样的一个队列服务。下面分享一下如何用<code>TDD</code>指导我们开发一个基于数据库的长时任务系统。</p><h3 id="第一个测试"><a class="markdownIt-Anchor" href="#第一个测试"></a> 第一个测试</h3><p>采用<code>TDD</code>的思想，首先我们站在（长时任务）系统的用户（将来使用长时任务API的开发者）的角度思考如何使用长时任务的API完成程序功能。</p><pre><code>假设有一个长时任务，它应该可以被添加到队列中。队列应该启动一个后台线程，即消费者线程，从队列中取出任务开始执行。由于任务在消费者线程中执行，消费者线程应该需要知道任务所对应的可执行代码是什么。所以，在消费者线程开始运行之前，需要注册好任务对应的可执行代码。</code></pre><p>基于上面的分析，使用Java进行编码，可写出对应的测试如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TaskQueueTest</span> &#123;</span><br><span class="line">...</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">should_run_task_from_queue</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">var</span> <span class="variable">queue</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskQueue</span>();</span><br><span class="line">        <span class="type">var</span> <span class="variable">consumer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskQueueConsumer</span>(queue);</span><br><span class="line">        </span><br><span class="line">        <span class="type">var</span> <span class="variable">task1Runnable</span> <span class="operator">=</span> mock(TaskRunnable.class);</span><br><span class="line">        <span class="type">var</span> <span class="variable">task2Runnable</span> <span class="operator">=</span> mock(TaskRunnable.class);</span><br><span class="line">        consumer.registerTask(<span class="string">&quot;task_type_1&quot;</span>, task1Runnable);</span><br><span class="line">        consumer.registerTask(<span class="string">&quot;task_type_2&quot;</span>, task2Runnable);</span><br><span class="line">        consumer.start();</span><br><span class="line"></span><br><span class="line">        <span class="type">var</span> <span class="variable">task1Arg</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskType1Arg</span>(“some arg”);</span><br><span class="line">        queue.addTask(“task_type_1”, task1Arg);</span><br><span class="line"></span><br><span class="line">        Thread.sleep(<span class="number">100</span>);</span><br><span class="line">        </span><br><span class="line">        verify(task1Runnable, times(<span class="number">1</span>)).run(eq(task1Arg));</span><br><span class="line"></span><br><span class="line">        <span class="type">var</span> <span class="variable">task2Arg</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskType2Arg</span>(“some arg”);</span><br><span class="line">        queue.addTask(“task_type_2”, task2Arg);</span><br><span class="line"></span><br><span class="line">        Thread.sleep(<span class="number">100</span>);</span><br><span class="line">        </span><br><span class="line">        verify(task2Runnable, times(<span class="number">1</span>)).run(eq(task2Arg));</span><br><span class="line">    &#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>到这里，一个基本的测试用例就定义好了。上述代码用到了<code>JUnit</code>及<code>Mockito</code>测试库的一些<code>API</code>。在编写测试的过程中，我们完成了基本的组件拆分及功能设计。值得注意的是，这里用到的类的名字、方法的名字、方法的参数等均是从用户的角度进行设计的。</p><p>因为我们直接写出了这样的测试代码，此时，IDE会显示很多红色警告，因为测试中用到的类和方法都还未被创建。如果使用<code>Idea</code>进行开发的话，可以将光标移动到红色警告处，按下<code>Alt+Enter</code>，<code>Idea</code>将提示创建类或变量，跟随IDE的指引，就可以很容易的完成这些代码的编写。</p><p><img data-src="/attaches/2022/2022-07-05-tdd-to-develop-a-long-running-task-system/leverage-ide-to-coding.png" alt="Leverage IDE to help coding" /></p><p>到这里我们就完成了第一个测试，并生成了对应的代码框架。整个系统设计的第一步已经初步完成。</p><h3 id="引入新的设计改进测试"><a class="markdownIt-Anchor" href="#引入新的设计改进测试"></a> 引入新的设计，改进测试</h3><p>由于我们希望基于数据库来实现任务队列，而数据库访问一般用<code>Repository</code>进行抽象。对应这里的设计，任务队列应该需要把数据读写的职责拆分出去。</p><p>考虑如何在测试中使用<code>Repository</code>，可以在之前的测试基础上增加<code>Repository</code>相关接口设计。有几处需要修改的地方：</p><ul><li>测试开始时，应该构造一个模拟的<code>Repository</code>对象。</li><li>当新任务加入队列时，任务队列应当调用<code>Repository</code>的接口保存新任务。</li><li>当任务队列消费者开始运行时，它应当从任务队列取出新任务，而任务队列使用<code>Repository</code>查询新的任务。</li><li>当任务被取出，将要运行时，其状态应当被修改为开始执行，并保存到数据库中，此时应当采用批量保存的方式。</li><li>在任务执行期间，其状态将有一系列变化：待运行、开始执行、执行中、执行成功/失败。在任务状态变化时，将调用<code>Repository</code>更新数据库的状态。</li><li>在保存任务的时候，任务的参数需要以一种方式序列化为字符串才能在数据库中保存。可以使用常用的json序列化方式。</li></ul><p>修改测试如下（完整代码见<a href="https://github.com/gmlove/taskqueue-demo/blob/d261bb18d8/src/test/java/com/brightliao/taskqueue/TaskQueueTest.java">这里</a>）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TaskQueueTest</span> &#123;</span><br><span class="line">...</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">should_run_task_from_queue</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">var</span> <span class="variable">taskRepository</span> <span class="operator">=</span> mock(TaskRepository.class);</span><br><span class="line">        <span class="keyword">final</span> <span class="type">ObjectMapper</span> <span class="variable">objectMapper</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ObjectMapper</span>();</span><br><span class="line">        <span class="type">var</span> <span class="variable">queue</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskQueue</span>(taskRepository, tt, objectMapper);</span><br><span class="line">        <span class="type">var</span> <span class="variable">consumer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskQueueConsumer</span>(queue, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">var</span> <span class="variable">task1Runnable</span> <span class="operator">=</span> mock(TaskRunnable.class);</span><br><span class="line">        <span class="type">var</span> <span class="variable">task2Runnable</span> <span class="operator">=</span> mock(TaskRunnable.class);</span><br><span class="line">        consumer.registerTask(<span class="string">&quot;task_type_1&quot;</span>, task1Runnable);</span><br><span class="line">        consumer.registerTask(<span class="string">&quot;task_type_2&quot;</span>, task2Runnable);</span><br><span class="line">        consumer.start();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// run task1 successfully</span></span><br><span class="line">        <span class="type">var</span> <span class="variable">task1Arg</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskType1Arg</span>(<span class="string">&quot;some arg&quot;</span>);</span><br><span class="line">        <span class="keyword">final</span> <span class="type">Task</span> <span class="variable">task1</span> <span class="operator">=</span> someTask(<span class="number">1L</span>, <span class="string">&quot;task_type_1&quot;</span>, <span class="string">&quot;&#123;\&quot;arg\&quot;:\&quot;some arg\&quot;&#125;&quot;</span>);</span><br><span class="line">        when(taskRepository.findNewTasks(eq(<span class="number">1</span>))).thenReturn(List.of(task1)).thenReturn(List.of());</span><br><span class="line">        when(taskRepository.saveAll(anyList())).thenAnswer(answer -&gt; answer.getArgument(<span class="number">0</span>));</span><br><span class="line">        when(taskRepository.save(any())).thenAnswer(answer -&gt; answer.getArgument(<span class="number">0</span>));</span><br><span class="line"></span><br><span class="line">        queue.addTask(<span class="string">&quot;task_type_1&quot;</span>, task1Arg);</span><br><span class="line"></span><br><span class="line">        Thread.sleep(<span class="number">500</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// add -&gt; running -&gt; succeeded</span></span><br><span class="line">        verify(taskRepository, times(<span class="number">3</span>)).save(any(Task.class));</span><br><span class="line">        <span class="comment">// started</span></span><br><span class="line">        verify(taskRepository, times(<span class="number">1</span>)).saveAll(anyList());</span><br><span class="line">        verify(task1Runnable, times(<span class="number">1</span>)).run(eq(<span class="string">&quot;&#123;\&quot;arg\&quot;:\&quot;some arg\&quot;&#125;&quot;</span>));</span><br><span class="line">        assertThat(task1.isSucceeded()).isEqualTo(<span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">        ......</span><br><span class="line">    &#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述测试中，我们模拟了<code>TaskRepository</code>对象，并基于这个模拟对象进行测试。通过模拟这个对象的接口，我们可以完成整个<code>TaskRepository</code>的<code>API</code>设计。</p><p>同样的，可以利用IDE辅助我们生成大量的模板代码，在实现时，只需要在不同的地方填入代码即可。</p><h3 id="加入数据库事务支持进一步改进测试"><a class="markdownIt-Anchor" href="#加入数据库事务支持进一步改进测试"></a> 加入数据库事务支持，进一步改进测试</h3><p>由于程序需要访问数据库进行数据存取，数据库事务控制是一个需要注意的问题。从性能上考虑，数据库事务应当较短，不适合将长时任务运行过程放入事务过程中。</p><p>数据库事务实现可以基于<code>Spring</code>框架提供的事务抽象，即<code>TransactionTemplate</code>接口。可以对以下可快速完成的过程进行事务控制：</p><ul><li>取出新任务后，将任务标记为开始执行。使用排它锁进行事务控制，防止其他任务消费者取到同一个任务</li><li>任务开始执行时，将任务标记为正在执行状态，使用基于版本的乐观锁进行事务控制</li><li>任务执行完成之后，更新任务状态，使用基于版本的乐观锁进行事务控制</li></ul><p>修改测试如下（完整代码见<a href="https://github.com/gmlove/taskqueue-demo/blob/47c332f5c9/src/test/java/com/brightliao/taskqueue/TaskQueueTest.java">这里</a>）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TaskQueueTest</span> &#123;</span><br><span class="line">...</span><br><span class="line">    <span class="keyword">private</span> TransactionTemplate <span class="title function_">mockTransactionTemplate</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">var</span> <span class="variable">tt</span> <span class="operator">=</span> mock(TransactionTemplate.class);</span><br><span class="line">        when(tt.execute(any())).thenAnswer(answer -&gt; &#123;</span><br><span class="line">            <span class="keyword">final</span> TransactionCallback&lt;?&gt; arg = (TransactionCallback&lt;?&gt;) answer.getArgument(<span class="number">0</span>);</span><br><span class="line">            log.info(<span class="string">&quot;execute in transaction: &#123;&#125;&quot;</span>, arg);</span><br><span class="line">            <span class="keyword">return</span> arg.doInTransaction(<span class="keyword">new</span> <span class="title class_">SimpleTransactionStatus</span>());</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        doAnswer(answer -&gt; &#123;</span><br><span class="line">            ((Consumer&lt;TransactionStatus&gt;) answer.getArgument(<span class="number">0</span>)).accept(<span class="keyword">new</span> <span class="title class_">SimpleTransactionStatus</span>());</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">        &#125;).when(tt).executeWithoutResult(any());</span><br><span class="line">        <span class="keyword">return</span> tt;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">should_run_task_from_queue</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">TransactionTemplate</span> <span class="variable">tt</span> <span class="operator">=</span> mockTransactionTemplate();</span><br><span class="line"></span><br><span class="line">        <span class="type">var</span> <span class="variable">taskRepository</span> <span class="operator">=</span> mock(TaskRepository.class);</span><br><span class="line">        <span class="keyword">final</span> <span class="type">ObjectMapper</span> <span class="variable">objectMapper</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ObjectMapper</span>();</span><br><span class="line">        <span class="type">var</span> <span class="variable">queue</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskQueue</span>(taskRepository, tt, objectMapper);</span><br><span class="line">        <span class="type">var</span> <span class="variable">consumer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskQueueConsumer</span>(queue, <span class="number">1</span>);</span><br><span class="line">        ......</span><br><span class="line">    &#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="实现现有的接口"><a class="markdownIt-Anchor" href="#实现现有的接口"></a> 实现现有的接口</h3><p>由于目前只是通过IDE生成了一些代码框架，尚未提供实现，上述测试会失败。接下来的一步就是为现在的设计提供一个实现。</p><p>有了前面的分析，及测试的保障，实现起来应该不是什么难事。有兴趣的同学可以自己试着写一写代码。</p><p>一个参考实现见<a href="https://github.com/gmlove/taskqueue-demo/commit/47c332f5c9652e7484e054d48e03cfb45c5215a8">这里</a>。</p><h3 id="其他的考虑"><a class="markdownIt-Anchor" href="#其他的考虑"></a> 其他的考虑</h3><p>为保证我们的长时任务实现具有较好的易用性，还可以考虑增加以下特性：</p><ul><li>任务消费者异常退出时，任务应该被回收，以便新的任务消费者可以重新处理该任务。</li><li>任务消费者应当被周期性的唤醒，以便可以定时的从队列中取出新任务进行处理。</li><li>当有新任务加入时，任务消费者应该快速被唤醒，以便新任务可以及时得到处理。</li><li>如果执行任务时，任务处理器未被注册，则应该抛出异常，并将任务标记为失败。</li><li>如果任务执行失败，可以进行一定次数的重试。</li><li>可以实现<code>Restful API</code>来完成添加任务、获取任务状态、查询任务列表、重启任务等功能。</li></ul><p>这些特性都可以通过<code>TDD</code>的方式进行实现。</p><p>部分上述特性的详细实现过程及代码可以参考<a href="https://github.com/gmlove/taskqueue-demo/commits/main">这里</a>的提交记录。</p><p>值得注意的是，除了按照前文进行基本的<code>TDD</code>开发。在设计测试时，还需要考虑整体的测试策略。一般而言，测试应该可以按照集成度的从小到大构成一个金字塔的结构。即，大量集成度小的单元测试，中等数量集成度中等的测试，少量的集成度高的测试。在进行<code>TDD</code>时，需要考虑用哪种集成度的测试更好。</p><p>一般的策略是：</p><ul><li>先写一个简单的高集成度测试，通过这个测试驱动编写面向用户的接口，同时也作为面向用户的功能验收。</li><li>再编写少量中等集成度的测试，通过这些测试驱动完成各个组件及其交互接口的设计，同时验证这些组件确实按照设计工作。</li><li>然后再以类级别或函数级别的测试为主，为类或函数的实现提供正确性保障。</li></ul><p>在<code>TDD</code>的过程中，通常还会结合重构来进行局部代码优化。在上述实现中，也有一些可以参考的地方。比如，任务处理器最初命名为<code>TaskRunnable</code>，后来改为<code>TaskHandler</code>，以便更符合语义。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>编写有效的自动化测试是专业的开发人员的一项基本技能。然而，很多团队一味追求快速写完代码，忽略了锻炼开发人员的自动化测试技能，这对于开发人员的能力提升是不利的。</p><p>很多开发人员或者执着于追求底层技术，或者执着于为实现高并发高性能而引入的技巧，或者执着于某个复杂的算法，或者执着于理解某一框架的实现细节。他们认为这些才是自己技术能力的体现。这些确实可以体现一部分开发人员的能力，但是，别忘了，这些始终只是别人创造的成果。</p><p>真实的日常工作常常只是将一个个特定场景下的需求变成可工作的软件，并应对复杂的业务及将来的变更。针对这些特定的问题给出相对简单的合理的设计的能力，编写优雅且高质量的代码的能力，才是开发人员最重要的能力。自动化测试和<code>TDD</code>在这方面可以给开发人员很大的助力。</p><p>事实上，自动化测试和<code>TDD</code>不仅可以帮助完成高质量软件的开发，对前面提到的技术提升也很有帮助。因为，为了编写有效的测试，需要我们对所使用的框架或库有足够的了解，这就促使我们去了解它们的实现细节，同时，可运行的测试还可以用于确认我们的理解。</p><p>本文展示了在一个相对复杂的场景下，如何用<code>TDD</code>帮助我们开发拥有良好设计的代码。可以发现，<code>TDD</code>不仅为我们提供了测试护航，而且，面向用户的接口设计，领域语言的运用，都可以在<code>TDD</code>的加持下自然的落地。</p><p>最后，只看不练并不能带来能力的提升，要想熟练的掌握<code>TDD</code>还需要在日常工作中抓住每一个机会刻意练习。</p><p><strong>相关文章：</strong></p><ul><li><a href="/2019/07/20/tdd-for-improving-design/">从改善设计的角度理解TDD</a></li><li><a href="/2019/08/18/tdd-for-improving-design-2/">从改善设计的角度理解TDD (2)</a></li><li><a href="/2022/05/24/5-properties-of-good-code-cupid/">好代码的五个特质-CUPID</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;背景&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#背景&quot;&gt;&lt;/a&gt; 背景&lt;/h2&gt;
&lt;p&gt;在最近的一个项目上，我们再次碰到了需要处理长时任务的场景。事实上，随着要处理的业务问题越来越复杂，要集成的系统越来越多，在&lt;code&gt;Web&lt;/code&gt;服务器端开发中，长时任务处理已经成为了一个普遍的问题。&lt;/p&gt;
&lt;p&gt;以下场景均可看作长时任务场景：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在&lt;code&gt;GitHub&lt;/code&gt;提交了一个&lt;code&gt;PR&lt;/code&gt;，要分别向上百个相关用户单独发送邮件&lt;/li&gt;
&lt;li&gt;用户上传了一个文件，需要扫描这个文件是不是带病毒&lt;/li&gt;
&lt;li&gt;用户想以&lt;code&gt;pdf&lt;/code&gt;格式下载某一个文档，需要先将文档转换为&lt;code&gt;pdf&lt;/code&gt;格式&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="tdd" scheme="http://brightliao.com/categories/tdd/"/>
    
    <category term="敏捷" scheme="http://brightliao.com/categories/tdd/%E6%95%8F%E6%8D%B7/"/>
    
    
    <category term="agile" scheme="http://brightliao.com/tags/agile/"/>
    
    <category term="敏捷" scheme="http://brightliao.com/tags/%E6%95%8F%E6%8D%B7/"/>
    
    <category term="tdd" scheme="http://brightliao.com/tags/tdd/"/>
    
    <category term="测试" scheme="http://brightliao.com/tags/%E6%B5%8B%E8%AF%95/"/>
    
    <category term="质量" scheme="http://brightliao.com/tags/%E8%B4%A8%E9%87%8F/"/>
    
  </entry>
  
  <entry>
    <title>Efficient ETL Testing</title>
    <link href="http://brightliao.com/2022/06/08/efficient-etl-testing/"/>
    <id>http://brightliao.com/2022/06/08/efficient-etl-testing/</id>
    <published>2022-06-08T12:00:00.000Z</published>
    <updated>2022-07-06T06:23:09.231Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2022/2022-06-08-efficient-etl-testing/efficiency.jpeg" alt="Efficiency. Image from https://unsplash.com/photos/gZB-i-dA6ns" /></p><p><strong>Previous posts about Easy SQL</strong></p><ul><li><a href="/2022/05/04/a-new-etl-language-easy-sql/">A new ETL language – Easy SQL</a></li><li><a href="/2022/05/16/a-guide-to-write-elegant-etl/">A guide to write elegant ETL</a></li><li><a href="/2022/05/25/neat-syntax-design-of-an-etl-language/">Neat syntax design of an ETL language (part 1)</a></li><li><a href="/2022/05/30/neat-syntax-design-of-an-etl-language-part-2/">Neat syntax design of an ETL language (part 2)</a></li></ul><p>It’s always been a pain point to do ETL testing. But it more and more becomes a must after data being so widely used these days.</p><p>An ETL with more than 100 lines of code is common. The filter conditions, data transformation rules, join conditions and other logic there could be very complicated.</p><span id="more"></span><p>In these cases, we should do testing early to avoid possible production issues. Testing gives us confidence about what we coded and helps team with quality assurance.</p><p>But there are a lot of challenges about ETL testing there, and we see a lot of teams struggling.</p><h1 id="etl-testing-challenges"><a class="markdownIt-Anchor" href="#etl-testing-challenges"></a> ETL testing challenges</h1><p>A common way to do ETL testing requires the steps below:</p><ul><li>Create a production-like environment.</li><li>Copy the database definition and table schema to the environment.</li><li>For tables used in the ETL, we prepare testing data and insert data to tables.</li><li>We run the ETL and it generates a new table with data as a result.</li><li>We compare the generated data and the expected data to find if there are any issues.</li></ul><p>There is no easy thing for the above steps.</p><p>For step 1, a production-like environment not only costs, but also requires heavy ops work. Cloud services may ease the ops work but you may be tightly bounded to some cloud.</p><p>For step 2, we may need to write scripts to sync database and table schema. We also need to develop a strategy to store the existing data in test environment. The drawback of it is that it breaks the network separation from test to production environment.</p><p>For step 3, it’s always been hard work to prepare testing data since some tables the ETL used may contain hundreds of columns and we have to pay attention to columns that are not used in the ETL. We also need to be careful about the column types and how the data is generated. And we need a script to insert data as well.</p><p>For step 4, we may need to maintain a separate configuration for test environment.</p><p>For step 5, comparing data manually is tedious work and it’s easy to make mistakes.</p><p>Some team relies on the statistics of the output table to identify issues of ETLs. It is good practice. But when the logic becomes more and more complicated, it’s not enough to just rely on statistics, since there might be cases that are not covered even by the real data.</p><h1 id="testing-etl-in-easy-sql"><a class="markdownIt-Anchor" href="#testing-etl-in-easy-sql"></a> Testing ETL in Easy SQL</h1><p>Easy SQL provides a very light-weight way to do ETL testing. It removes most of the blockers mentioned above.</p><p>To prepare a test in Easy SQL is easy. The first thing to do is to create a spreadsheet from the provided template.</p><p>The template looks like below:</p><p><img data-src="/attaches/2022/2022-06-08-efficient-etl-testing/test_case.png" alt="Test case template" /></p><p>There are two concepts which are popular in testing domain. Easy SQL also adopted them:</p><ul><li>Test case: A single test used to test your code in some specific scenario.</li><li>Test suit: A bundle of a few unit test cases. Could be used to run them together.</li></ul><h2 id="test-suit"><a class="markdownIt-Anchor" href="#test-suit"></a> Test suit</h2><p>In the screenshot above, we see two test suits, named ‘Suit 1’ and ‘Suit 2’. They are put in different sheets. In Easy SQL, if there is any sheet with a name starting with word ‘Suit’, the sheet is considered to be a test suit.</p><h2 id="test-case"><a class="markdownIt-Anchor" href="#test-case"></a> Test case</h2><p>In test suit ‘Suit 1’, we can see two test cases. One case is ‘A test for ETL abc.sql’, and the other is ‘Another test for ETL abc.sql’.</p><p>Test case is recognized by an uppercase keyword <code>CASE</code> in column ‘A’. There should be a name of the test case in column ‘B’, and be next to the <code>CASE</code> keyword.</p><p>To describe a test case, we usually specify the variables that should be used to run the ETL, the data of all input tables, the data of the output tables. They are recognized by keywords <code>VARS</code> <code>INPUT</code> <code>OUTPUT</code> in column ‘A’ and values followed starting from column ‘B’.</p><p>The data of output tables is used to test if output of the ETL after execution is exactly the same as the data specified in the test case.</p><p><strong>Test case element format</strong></p><p>The values of the mentioned elements in a test should be of formats below.</p><ul><li><code>VARS</code>: A table with header and exactly one row of data.</li><li><code>INPUT</code>: A name of the input table specified at column ‘B’; A table with header and number of rows of data starting from column ‘C’ of the same row; Mandatory descriptions of each row of data at column ‘B’ starting from the next row.</li><li><code>OUTPUT</code>: The same format with ‘INPUT’, except that the descriptions of each row of data is optional.</li></ul><p>You may ask why the descriptions of each row of data in ‘INPUT’ table is mandatory. This is a design on purpose. It is designed to improve test readability. The test case designer could record how the data is generated to explain the business rules behind the data and what is the scenario that the data is designed to cover.</p><p>For input tables and output tables, we may need to specify the type of each column. If so, we need to add type to the column names in format ‘{COLUMN_NAME}:{TYPE}’. If there is any column of a table with type specified, the type of other columns should be specified as well. If the type of any other column is not specified, it will be default to ‘string’ type.</p><p><strong>Column types</strong></p><p>The type of column varies for different backends.</p><p>For Spark, it should be <code>int</code> <code>bigint</code> <code>boolean</code> <code>string</code> and so on. The full list of types with built-in support are: <code>int</code> <code>tinyint</code> <code>bigint</code> <code>double</code> <code>float</code> <code>string</code> <code>decimal</code> <code>boolean</code> <code>date</code> <code>timestamp</code> <code>array&lt;string&gt;</code> <code>array&lt;int&gt;</code> <code>array&lt;tinyint&gt;</code> <code>array&lt;bigint&gt;</code> <code>array&lt;double&gt;</code> <code>array&lt;float&gt;</code> <code>array&lt;boolean&gt;</code> <code>array&lt;date&gt;</code> <code>array&lt;timestamp&gt;</code>.</p><p>For Postgres, it should be <code>int</code> <code>bigint</code> <code>boolean</code> <code>text</code> and so on. The full list of types could be found <a href="https://www.postgresql.org/docs/current/datatype.html">here</a>. The default type is <code>text</code>.</p><p>For Clickhouse, it should be <code>Int8</code> <code>Boolean</code> <code>String</code> and so on. The full list of types could be found <a href="https://clickhouse.com/docs/en/sql-reference/data-types/">here</a>.</p><p>For the other backends, please refer to the database data types related document of it.</p><p><strong>Mock includes</strong></p><p>If we have used <strong>include</strong> command in our ETL and we’d like to mock the body of the included file. We can add a <code>INCLUDES</code> section in the test case.</p><p>Then provide the mocked body of the ETL follow the rules below:</p><ol><li>Column ‘B’ at the same row of the <code>INCLUDES</code> keyword should be filled with the file path of the include command in ETL.</li><li>Column ‘C’ at the same row of the <code>INCLUDES</code> keyword should be filled with the mocked body of the included file.</li><li>Add another row to specify a second <code>INCLUDE</code> to mock, with column ‘B’ and ‘C’ filled with file path and the mocked file body.</li></ol><p>Usually, the included ETL file returns some temporary table. In this case, we can mock the content of the included file as below:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=temp.THE_RETURNED_TEMP_TABLE</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> some_mocked_data</span><br></pre></td></tr></table></figure><p>After this, we need to add an input table and provide the mocked data. The way to achieve this is the same as to define a normal input table above.</p><p><strong>Test file name</strong></p><p>We recommend creating one test file for one ETL. It means all the test cases in one spreadsheet file should be testing the same ETL.</p><p>In this case, the file name of the test file and the testing ETL could follow some convention so that we can find the ETL file given the test file.</p><p>Easy SQL provides a way to find ETL file from the test file automatically, which follows a simple convention that the base name of the ETL file and that of the test file should be the same.</p><p>E.g. when the ETL file is named <code>some_etl.sql</code>, then the test file should be named <code>some_etl.xlsx</code>.</p><p>We also recommend there is only one <code>OUTPUT</code> table in one ETL. In this case, the name of the ETL could be the full table name of the output table.</p><p>E.g. when an ETL output a table named <code>some_db.some_table</code>, the file name of the ETL should be <code>some_db.some_table.sql</code> and the test file name of the ETL should be <code>some_db.some_table.xlsx</code>.</p><p><strong>Add test files to version control system</strong></p><p>The test file mentioned above is a spreadsheet file. It is in binary format and not so easy to be added to version control system.</p><p>Easy SQL provides a way to dump a test in spreadsheet format to JSON format. After this, we can add the JSON file to version control system. In this way, we can easily compare the changes of each version of this case.</p><p>The JSON file is also optimized to let us compare data changes easily.</p><p>To convert a test file in spreadsheet format to JSON format. Run the command below:</p><p>(Before you run the command below, you will need to install two additional packages by <code>pip3 install click==6.7 pymongo==3.10.1 xlrd==1.2.0</code>)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m easy_sql.sql_test convert-json -f &#123;YOUR_XLSX_FILE_PATH&#125;</span><br></pre></td></tr></table></figure><p>After the command finishes, there will be a JSON file with the same name but a <code>.json</code> suffix of the spreadsheet file generated. The directory of the JSON file is the same as the spreadsheet file.</p><h1 id="run-test"><a class="markdownIt-Anchor" href="#run-test"></a> Run test</h1><p>Easy SQL provides a command line module to help to run ETL tests.</p><p>To run the ETL test, execute the command below:</p><p>(Before you run the command below, you will need to install two additional packages by <code>pip3 install click==6.7 pymongo==3.10.1 xlrd==1.2.0</code>)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m easy_sql.sql_test run-test -f &#123;YOUR_XLSX_FILE_PATH&#125; -b &#123;BACKEND&#125;</span><br></pre></td></tr></table></figure><p>The test file could be a JSON test file as well. And the backend could be one of the supported backend.</p><p>For details of the command line usage, please run <code>python3 -m easy_sql.sql_test --help</code>.</p><h2 id="run-test-programmatically"><a class="markdownIt-Anchor" href="#run-test-programmatically"></a> Run test programmatically</h2><p>Easy SQL also provides an interface to run ETL programmatically. This way, you can easily integrate tests in Easy SQL with your favorite testing framework.</p><p>To run a test in your code, write code below:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> easy_sql.sql_tester <span class="keyword">import</span> SqlTester</span><br><span class="line"><span class="keyword">from</span> easy_sql.sql_processor.backend <span class="keyword">import</span> SparkBackend</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">SqlTester(env=<span class="string">&#x27;test&#x27;</span>, </span><br><span class="line">          backend_creator=<span class="keyword">lambda</span> case: SparkBackend(SparkSession.builder.enableHiveSupport().getOrCreate()), </span><br><span class="line">          work_dir=os.path.abspath(os.curdir))\</span><br><span class="line">    .run_tests(<span class="string">&#x27;path/to/your/test/file&#x27;</span>)</span><br></pre></td></tr></table></figure><p>For a concrete example, please refer to code <a href="https://github.com/easysql/easy_sql/blob/main/easy_sql/sql_test.py">here</a>.</p><h1 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h1><p>In this post, we talked about the necessity of ETL testing and challenges to do ETL testing.</p><p>In order to be efficient to create automated test cases, we have to spend some time to create some tools.</p><p>Easy SQL provides some built-in tools to help with ETL testing. With the help of Easy SQL, a lot of blockers have been removed. We only need to provide the main information about the test data. There is no more need to care about unrelated columns, data types, data comparing and so on.</p><p>Easy SQL embraces the most commonly used tool – spreadsheet – to create test cases. We can get a lot of benefits from it, such as a friendly and readable layout, the ability to use formula to prepare data, an intuitive way to record data and mock included code snippets etc.</p><p>In one word, with Easy SQL, we can do ETL testing more efficiently and save large amounts of time.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/attaches/2022/2022-06-08-efficient-etl-testing/efficiency.jpeg&quot; alt=&quot;Efficiency. Image from https://unsplash.com/photos/gZB-i-dA6ns&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Previous posts about Easy SQL&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;/2022/05/04/a-new-etl-language-easy-sql/&quot;&gt;A new ETL language – Easy SQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2022/05/16/a-guide-to-write-elegant-etl/&quot;&gt;A guide to write elegant ETL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2022/05/25/neat-syntax-design-of-an-etl-language/&quot;&gt;Neat syntax design of an ETL language (part 1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2022/05/30/neat-syntax-design-of-an-etl-language-part-2/&quot;&gt;Neat syntax design of an ETL language (part 2)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It’s always been a pain point to do ETL testing. But it more and more becomes a must after data being so widely used these days.&lt;/p&gt;
&lt;p&gt;An ETL with more than 100 lines of code is common. The filter conditions, data transformation rules, join conditions and other logic there could be very complicated.&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="编译" scheme="http://brightliao.com/tags/%E7%BC%96%E8%AF%91/"/>
    
    <category term="编译器" scheme="http://brightliao.com/tags/%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
    <category term="数据工程" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="软件工程" scheme="http://brightliao.com/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="EasySQL" scheme="http://brightliao.com/tags/easysql/"/>
    
    <category term="ETL" scheme="http://brightliao.com/tags/etl/"/>
    
    <category term="ETL开发" scheme="http://brightliao.com/tags/etl%E5%BC%80%E5%8F%91/"/>
    
    <category term="编程语言" scheme="http://brightliao.com/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    
    <category term="SQL" scheme="http://brightliao.com/tags/sql/"/>
    
  </entry>
  
  <entry>
    <title>Neat Syntax Design of an ETL Language (Part 2)</title>
    <link href="http://brightliao.com/2022/05/30/neat-syntax-design-of-an-etl-language-part-2/"/>
    <id>http://brightliao.com/2022/05/30/neat-syntax-design-of-an-etl-language-part-2/</id>
    <published>2022-05-30T12:00:00.000Z</published>
    <updated>2022-06-18T00:32:33.465Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2022/2022-05-25-neat-syntax-design-of-an-etl-language/mind-mapping.png" alt="Easy SQL language features mind Mapping" /></p><p><strong>Previous posts about Easy SQL</strong></p><ul><li><a href="/2022/05/04/a-new-etl-language-easy-sql/">A new ETL language – Easy SQL</a></li><li><a href="/2022/05/16/a-guide-to-write-elegant-etl/">A guide to write elegant ETL</a></li><li><a href="/2022/05/25/neat-syntax-design-of-an-etl-language/">Neat syntax design of an ETL language (part 1)</a></li></ul><p>People like to use Scala because Scala provides powerful type inference and embraces various programming paradigms. People like to use Python because it’s clean, out-of-the-box, delicate and expressive. People like to use rust because rust provides modern language features and zero-cost abstract.</p><span id="more"></span><p>How to design a neat ETL programming language that people like to use? Let’s have a look at how Easy SQL does. (This topic is broken into two parts. This is the second part.)</p><p>Easy SQL defines a few customized syntax on top of SQL to add imperative characteristics.</p><h2 id="language-features-in-easy-sql"><a class="markdownIt-Anchor" href="#language-features-in-easy-sql"></a> Language features in Easy SQL</h2><p>For Easy SQL, guided by the design principles, there are a few simple language features added to support these imperative characteristics.</p><p>Below is a list of these features:</p><ul><li>An imperative structure of ETL code.</li><li>Variables which could be defined and modified any time.</li><li>A way to call external functions.</li><li>A way to control whether a step should be executed.</li><li>Templates that could be reused in the same ETL file.</li><li>Include command that could be used to reuse code at file level.</li><li>Debugging support: logging and assertion that could be used for debugging.</li><li>A debugger interface.</li><li>Other features：write data to tables; list variables; SQL actions.</li></ul><p>Let’s have a look at the last five features.</p><h2 id="syntax-in-easy-sql"><a class="markdownIt-Anchor" href="#syntax-in-easy-sql"></a> Syntax in Easy SQL</h2><h3 id="templates-used-to-reuse-code"><a class="markdownIt-Anchor" href="#templates-used-to-reuse-code"></a> Templates used to reuse code</h3><p>To support reusing of code, templates have been introduced in Easy SQL.<br />Templates are similar to functions in general programming languages.<br />Functions could be called anywhere while templates could be used anywhere as well. This way, code is reused.</p><p>Just like functions, there are name, parameters and body for a template as well.</p><p>Below is a concrete example of templates:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=template.dim_cols</span></span><br><span class="line">product_name</span><br><span class="line">, product_category</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=temp.dims</span></span><br><span class="line"><span class="keyword">select</span> @&#123;dim_cols&#125; <span class="keyword">from</span> order_count</span><br><span class="line"><span class="keyword">union</span></span><br><span class="line"><span class="keyword">select</span> @&#123;dim_cols&#125; <span class="keyword">from</span> sales_amount</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=template.join_conditions</span></span><br><span class="line">dim.product_name <span class="operator">&lt;=&gt;</span> #&#123;right_table&#125;.product_name</span><br><span class="line"><span class="keyword">and</span> dim.product_category <span class="operator">&lt;=&gt;</span> #&#123;right_table&#125;.product_category</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=temp.joined_data</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">dim.product_name</span><br><span class="line">, dim.product_category</span><br><span class="line">, oc.order_count</span><br><span class="line">, sa.sales_amount </span><br><span class="line"><span class="keyword">from</span> dims dim</span><br><span class="line">    <span class="keyword">left</span> <span class="keyword">join</span> order_count oc <span class="keyword">on</span> @&#123;join_conditions(right_table<span class="operator">=</span>oc)&#125;</span><br><span class="line">    <span class="keyword">left</span> <span class="keyword">join</span> sales_amount sa <span class="keyword">on</span> @&#123;join_conditions(right_table<span class="operator">=</span>sa)&#125;</span><br></pre></td></tr></table></figure><p>There are two templates named ‘dim_cols’ and ‘join_conditions’ defined.<br />One with no parameters and one with one parameter named ‘right_table’.</p><p>This example is about a very common case when we’d like to merge two tables with the same dimension columns.<br />After the template is used, the dimension column names and join conditions are reused, just like how we reuse functions in general programming language.</p><p>From the example above, we could find a few things to note about templates:</p><ul><li>Template is a step in ETL. It is defined by a target with name ‘template’ and a following descriptive name. The descriptive name is the template name.</li><li>The body of a template could be anything.</li><li>If there are template parameters, no need to declare them, just use them by ‘#{PARAMETER_NAME}’. Easy SQL will extract these parameters for you at runtime.</li><li>Templates could be used in any target with syntax ‘@{TEMPLATE_NAME}’. If there are template parameters, we need to pass them as named parameters.</li></ul><p>Besides, there are some other notes:</p><ul><li>Variables can be referenced in template body, and the resolution of variables happens at the resolution time of the template (when the step with template reference is executing). This is useful since we can change the value of some variable between two targets referencing the same template.</li><li>There should be no templates used in the body of templates. This is to make the resolution of templates to be simple.</li></ul><h3 id="include-other-etl-code-snippets"><a class="markdownIt-Anchor" href="#include-other-etl-code-snippets"></a> Include other ETL code snippets</h3><p>Template is designed for reusing code within one ETL. How to reuse code across ETLs?<br />One common way to reuse code is to create a temporary mid-table.<br />But it seems heavy since we need to create a real table and there might be data copying.</p><p>Easy SQL provides a way to reuse code from some other ETL file. This is the ‘include’ command.</p><p>Include looks similar to target. Below is an example:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- include=snippets/some_snippet.sql</span></span><br></pre></td></tr></table></figure><p>The file path is a path relative to the current working directory.</p><p>When Easy SQL processed the ‘include’ command, the content of the file will be expanded.<br />The result will be the same as when we write code in here directly.</p><p>For the example above, if we have the following content in <code>some_snippets.sql</code>:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=temp.some_table</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> some_db.some_table</span><br><span class="line"><span class="comment">-- target=template.some_columns</span></span><br><span class="line">a, b, c</span><br></pre></td></tr></table></figure><p>Then the content of the ETL will be the same as the content of <code>some_snippets.sql</code> since there is only one include command there.</p><p>Notes about ‘include’ command:</p><ul><li>Include command could be used at any line of code.</li><li>When Easy SQL processed this ‘include’ command, the content of the file will simply be expanded.</li></ul><h3 id="debugging-support"><a class="markdownIt-Anchor" href="#debugging-support"></a> Debugging support</h3><p>In a complicated ETL, it is easy to introduce bugs.<br />A general programming language usually provides some ways to help with debugging.<br />The most commonly used way is about logging and assertion.</p><p>Developers can log variables anywhere to provide information about the executing step.<br />They can also set an assertion if there is any important assumption made in the following code.</p><p>To do logging and assertion in Python, the code looks like below:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">logger.info(<span class="string">f&#x27;some thing happened, check the variables: var_a=<span class="subst">&#123;var_a&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="keyword">assert</span> var_a == <span class="string">&#x27;something assumed&#x27;</span>, <span class="string">f&#x27;var_a is not as assumed: var_a=<span class="subst">&#123;var_a&#125;</span>&#x27;</span></span><br></pre></td></tr></table></figure><p>Easy SQL provides a similar way to do logging and assertion. They’re both provided by a type of target.<br />Check the example below to see its usage.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=log.i_would_like_to_log_something</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="number">1</span> <span class="keyword">as</span> a</span><br><span class="line">    , <span class="number">2</span> <span class="keyword">as</span> b</span><br><span class="line">    , $&#123;c&#125; <span class="keyword">as</span> c</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=log.order_count</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line"><span class="built_in">count</span>(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">from</span> sample.order_table</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=check.order_count_must_be_equal_after_joined_product</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    (<span class="keyword">select</span> <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">from</span> sample.order_table) <span class="keyword">as</span> expected</span><br><span class="line">    , (<span class="keyword">select</span> <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">from</span> sample.order_table_after_joined) <span class="keyword">as</span> actual</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=check.equal($&#123;c&#125;, 3)</span></span><br></pre></td></tr></table></figure><p>From the example above, we know that:</p><ul><li>When using the ‘log’ target, we need to specify a message about what to log.</li><li>The log message format is the same as a variable. I.e. It should be composed of chars ‘0-9a-zA-Z_’.</li><li>There should be exactly one row returned from the query of some ‘log’ target. If there is more than one row returned, only the first row will be logged.</li><li>There are two formats of ‘check’ target. One is to specify a check message with a query. The other is to call a function, which returns a boolean value.</li><li>When the ‘check’ target is used as a message with a query, the returned value of the query must be one row with two columns named ‘actual’ and ‘expected’.</li></ul><h3 id="debugger-interface"><a class="markdownIt-Anchor" href="#debugger-interface"></a> Debugger interface</h3><p>There is a debugger interface provided by Easy SQL. It could be used with <code>Jupyter</code> to debug interactively. Follow the steps below to start debugging.</p><ol><li>Install <code>Jupyter</code> first with command <code>pip install jupyterlab</code>.</li><li>Create a file named <code>debugger.py</code> with contents like below:<br />(A more detailed sample could be found <a href="https://easy-sql.readthedocs.io/en/latest/autoapi/easy_sql/sql_processor_debugger/index.html">here</a>.)</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Dict</span>, <span class="type">Any</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_debugger</span>(<span class="params">sql_file_path: <span class="built_in">str</span>, <span class="built_in">vars</span>: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>] = <span class="literal">None</span>, funcs: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>] = <span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line">    <span class="keyword">from</span> easy_sql.sql_processor.backend <span class="keyword">import</span> SparkBackend</span><br><span class="line">    <span class="keyword">from</span> easy_sql.sql_processor_debugger <span class="keyword">import</span> SqlProcessorDebugger</span><br><span class="line">    spark = SparkSession.builder.enableHiveSupport().getOrCreate()</span><br><span class="line">    backend = SparkBackend(spark)</span><br><span class="line">    debugger = SqlProcessorDebugger(sql_file_path, backend, <span class="built_in">vars</span>, funcs)</span><br><span class="line">    <span class="keyword">return</span> debugger</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="3"><li>Create a file named <code>test.sql</code> with contents as <a href="https://github.com/easysql/easy_sql/blob/main/test/sample_etl.spark.sql">here</a>.</li><li>Then start jupyter lab with command: <code>jupyter lab</code>.</li><li>Start debugging like below:</li></ol><p><img data-src="https://raw.githubusercontent.com/easysql/easy_sql/main/debugger-usage.gif" alt="ETL Debugging" /></p><p>For details of the APIs, we can refer to API doc <a href="https://easy-sql.readthedocs.io/en/latest/autoapi/easy_sql/sql_processor_debugger/index.html">here</a>.</p><h3 id="write-data"><a class="markdownIt-Anchor" href="#write-data"></a> Write data</h3><p>If we need to write data to some table, we could use another type of target. The name of the target is ‘output’.<br />There should be a query statement following the ‘output’ target. And the result of the query will be written to the output table.</p><p>Below is an example:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=temp.result</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> a, <span class="string">&#x27;2&#x27;</span> <span class="keyword">as</span> b</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=output.some_db.some_table</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">result</span></span><br></pre></td></tr></table></figure><p>After the execution of the ETL above, there will be one row written to table ‘some_db.some_table’.</p><p>Things to note about ‘output’ target:</p><ul><li>There must be a full table name (both database name and table name specified) after the ‘output’ keyword in the target definition.</li><li>The table must be created before writing data.</li><li>If we’d like to create tables automatically, we need to define a special variable named ‘__create_output_table__’ with value equals to 1.</li><li>If we’d like to write data to some static partition of the output table, we need to define a special variable named ‘__partition__’ with partition column name followed by. An example could be ‘__partition__data_date’. Then the partition column is ‘data_date’. The value of the variable will be the partition value when writing data.</li><li>If we’d like to write data to some static partition of the output table, we can only define one partition value at the moment.</li><li>If the query returns more columns than what is defined by the real table, the extra columns will be ignored.</li><li>If the query returns less columns than what is defined by the real table, an error will be raised.</li></ul><h3 id="list-variables"><a class="markdownIt-Anchor" href="#list-variables"></a> List variables</h3><p>There are list variables supported in Easy SQL as well.</p><p>List variables are different from variables mentioned previously.<br />The main difference is that the values of these variables are lists.<br />So that list variables could not be used in SQL statements, since we cannot simply convert a list to a string and do variable resolution.</p><p>List variables can only be used as function parameters right now.</p><p>Below is an example of list variables.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">-- target=list_variables</span></span><br><span class="line"><span class="keyword">select</span> explode(<span class="keyword">array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)) <span class="keyword">as</span> a</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=func.print_list_variables($&#123;a&#125;)</span></span><br></pre></td></tr></table></figure><p>If we have function implementation like below:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">print_list_variables</span>(<span class="params">a: <span class="type">List</span>[<span class="built_in">str</span>]</span>):</span><br><span class="line">    <span class="built_in">print</span>(a)</span><br></pre></td></tr></table></figure><p>Then the function output will be: <code>[1, 2, 3]</code></p><h3 id="sql-actions"><a class="markdownIt-Anchor" href="#sql-actions"></a> SQL actions</h3><p>There are some cases where we’d like to just execute some SQL statement without anything to do about its result. We can use ‘action’ in these cases.</p><p>This usually happens when we want to execute some DDL statement. Examples would be like to create table, to drop partition of some table etc.</p><p>Action is a type of target as well and it follows target syntax. Below is an example of ‘action’ target:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=action.create_some_table</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> some_table (</span><br><span class="line">    id <span class="type">int</span></span><br><span class="line">    , <span class="keyword">value</span> string</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>Things to note about actions:</p><ul><li>There should be a descriptive name for an action. The name should be composed of chars ‘0-9a-zA-Z_’ and follow the ‘action’ keyword.</li><li>In the body of an action target, templates and variables can be used as in any other target.</li></ul><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><p>In this post, we talked about the last five language features.</p><ul><li>Templates that could be reused in the same ETL file.</li><li>Include command that could be used to reuse code at file level.</li><li>Debugging support: logging and assertion that could be used for debugging.</li><li>A debugger interface.</li><li>Other features：write data to tables; list variables; SQL actions.</li></ul><p>Now we have finished all the language features provided by Easy SQL. But there are a lot more useful features in Easy SQL for us to find out.</p><p>You may already find it useful and would like to have a try. You can get all the information required to get started from the GitHub repo <a href="https://github.com/easysql/easy_sql">here</a> and the docs <a href="https://easy-sql.readthedocs.io/en/latest/">here</a>.</p><p>If you find any issues, you’re welcome to raise it in GitHub Issues and PRs are welcomed as well!</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/attaches/2022/2022-05-25-neat-syntax-design-of-an-etl-language/mind-mapping.png&quot; alt=&quot;Easy SQL language features mind Mapping&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Previous posts about Easy SQL&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;/2022/05/04/a-new-etl-language-easy-sql/&quot;&gt;A new ETL language – Easy SQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2022/05/16/a-guide-to-write-elegant-etl/&quot;&gt;A guide to write elegant ETL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2022/05/25/neat-syntax-design-of-an-etl-language/&quot;&gt;Neat syntax design of an ETL language (part 1)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;People like to use Scala because Scala provides powerful type inference and embraces various programming paradigms. People like to use Python because it’s clean, out-of-the-box, delicate and expressive. People like to use rust because rust provides modern language features and zero-cost abstract.&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="编译" scheme="http://brightliao.com/tags/%E7%BC%96%E8%AF%91/"/>
    
    <category term="编译器" scheme="http://brightliao.com/tags/%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
    <category term="数据工程" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="软件工程" scheme="http://brightliao.com/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="EasySQL" scheme="http://brightliao.com/tags/easysql/"/>
    
    <category term="ETL" scheme="http://brightliao.com/tags/etl/"/>
    
    <category term="ETL开发" scheme="http://brightliao.com/tags/etl%E5%BC%80%E5%8F%91/"/>
    
    <category term="编程语言" scheme="http://brightliao.com/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    
    <category term="SQL" scheme="http://brightliao.com/tags/sql/"/>
    
  </entry>
  
  <entry>
    <title>Neat Syntax Design of an ETL Language (Part 1)</title>
    <link href="http://brightliao.com/2022/05/25/neat-syntax-design-of-an-etl-language/"/>
    <id>http://brightliao.com/2022/05/25/neat-syntax-design-of-an-etl-language/</id>
    <published>2022-05-25T12:00:00.000Z</published>
    <updated>2022-05-30T08:10:44.121Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2022/2022-05-25-neat-syntax-design-of-an-etl-language/mind-mapping.png" alt="Easy SQL language features mind Mapping" /></p><p><strong>Previous posts about Easy SQL</strong></p><ul><li><a href="/2022/05/04/a-new-etl-language-easy-sql/">A new ETL language – Easy SQL</a></li><li><a href="/2022/05/16/a-guide-to-write-elegant-etl/">A guide to write elegant ETL</a></li></ul><p>People like to use Scala because Scala provides powerful type inference and embraces various programming paradigms. People like to use Python because it’s clean, out-of-the-box, delicate and expressive. People like to use rust because rust provides modern language features and zero-cost abstract.</p><span id="more"></span><p>How to design a neat ETL programming language that people like to use? Let’s have a look at how Easy SQL does. (We will break this topic into two parts. This is the first part.)</p><p>Easy SQL defines a few customized syntax on top of SQL to add imperative characteristics.</p><h2 id="language-features-in-easy-sql"><a class="markdownIt-Anchor" href="#language-features-in-easy-sql"></a> Language features in Easy SQL</h2><p>For Easy SQL, guided by the design principles, there are a few simple language features added to support these imperative characteristics.</p><p>Below is a list of these features:</p><ul><li>An imperative structure of ETL code.</li><li>Variables which could be defined and modified any time.</li><li>A way to call external functions.</li><li>A way to control whether a step should be executed.</li><li>Templates that could be reused in the same ETL file.</li><li>Include command that could be used to reuse code at file level.</li><li>Debugging support: logging and assertion that could be used for debugging.</li><li>A debugger interface.</li><li>Other features：write data to tables; list variables; SQL actions.</li></ul><p>Let’s have a look at the first four features.</p><h2 id="syntax-in-easy-sql"><a class="markdownIt-Anchor" href="#syntax-in-easy-sql"></a> Syntax in Easy SQL</h2><h3 id="the-imperative-structure"><a class="markdownIt-Anchor" href="#the-imperative-structure"></a> The imperative structure</h3><p>The most obvious characteristics of imperative programming is that code will be executed line by line (or piece by piece).<br />And the declarative way (standard SQL) suggests the opposite, which says, all logic should be defined first and then be executed in one final action.</p><p>The major task of designing the imperative structure is to introduce a way to execute SQL step by step.<br />If we look at Spark DataFrame API, we could find that it works in an imperative way.<br />For example, we can assign a DataFrame to some variable, then do something about the variable, then transform the variable and assign it to another variable.</p><p>In Easy SQL, a simple syntax is introduced as SQL comment, which is <code>target=</code> and <code>-- target=SOME_TARGET</code> in Easy SQL.</p><p>There are a few built-in types of targets, which are:</p><ul><li>variables</li><li>temp</li><li>cache</li><li>broadcast</li><li>func</li><li>log</li><li>check</li><li>output</li><li>template</li><li>list_variables</li><li>action</li></ul><p>When used in Easy SQL ETL, it looks like below:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> a, <span class="string">&#x27;2&#x27;</span> <span class="keyword">as</span> b</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=cache.table_a</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> some_db.table_a</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=temp.table_b</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> some_db.table_b</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=broadcast.table_c</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> some_db.table_c</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=output.some_db.some_table</span></span><br><span class="line"><span class="keyword">select</span> </span><br><span class="line">    <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> table_a a </span><br><span class="line">    <span class="keyword">left</span> <span class="keyword">join</span> table_b b <span class="keyword">on</span> a.id<span class="operator">=</span>b.id</span><br><span class="line">    <span class="keyword">left</span> <span class="keyword">join</span> table_c c <span class="keyword">on</span> a.id<span class="operator">=</span>c.id</span><br></pre></td></tr></table></figure><p>There is a SQL query under every <code>target</code> statement.<br />It means the result of the SQL query is saved to the specified target.<br />Each <code>target</code> could be viewed as a step and will be executed one by one.</p><p>The syntax may seem obvious to most of you. If it is so, it means the design goal is achieved.</p><p>Let’s spend some time explaining what it does in the simple ETL above.<br />If you believe you got it already, please skip it.</p><ol><li>The first <code>target</code> statement means the SQL query result, <code>a=1 and b='2'</code> in this case, will be saved to the variables target. After this step, the variables could be used.</li><li>The second <code>target</code> statement means that the query from table_a will be saved to a cached table named ‘table_a’. Cache table is a concept borrowed from Spark and it means the query result will be cached and could be reused from the following steps to improve performance.</li><li>The third <code>target</code> statement means that the query from table_b will be saved to a temporary table named ‘table_b’. And ‘table_b’ could be used in the following steps.</li><li>The forth <code>target</code> statement means that the query from table_c will be saved to a broadcasted table named ‘table_c’. Broadcast table is also a concept borrowed from Spark and it means the table will be broadcasted to every node to improve performance. And the table ‘table_c’ could be used in the following steps too.</li><li>The fifth <code>target</code> statement means that the joined query result of the above 3 tables will be saved to an output table named ‘some_table’ in ‘some_db’.</li></ol><h3 id="variables"><a class="markdownIt-Anchor" href="#variables"></a> Variables</h3><p>Variables could be defined and modified at any step. The syntax is as the case above.<br />If we’d like to modify the value of it, we can just add another <code>variables</code> target and write a query with the result of changed ‘a’ and ‘b’.<br />A simple example is as below:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> a, <span class="number">2</span> <span class="keyword">as</span> b</span><br><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">2</span> <span class="keyword">as</span> a, <span class="number">1</span> <span class="keyword">as</span> b</span><br></pre></td></tr></table></figure><p>After the two steps, the value of a will be 2, and it will be 1 for the value of b.</p><p>Variables could be referenced anywhere in the following steps with syntax ‘${VAR_NAME}’.</p><p>There is a simple example below:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> a, <span class="string">&#x27;2&#x27;</span> <span class="keyword">as</span> b</span><br><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> </span><br><span class="line">    $&#123;a&#125; <span class="keyword">as</span> a</span><br><span class="line">    , $&#123;b&#125; <span class="keyword">as</span> b</span><br><span class="line">    , <span class="number">1</span>$&#123;a&#125; <span class="keyword">as</span> a1</span><br><span class="line">    , $&#123;a&#125; <span class="operator">+</span> $&#123;b&#125; <span class="keyword">as</span> ab</span><br></pre></td></tr></table></figure><p>When Easy SQL engine reaches the second step, it will do a variable lookup and simply replace the reference with the real value.<br />It will replace it with the string value of the variable and converts types when required.</p><p>The above example will result in variables: <code>a=1, b=2, a1=11, ab=3</code>.</p><p>Besides the user-defined variables, there are a few useful system-defined variables.<br />When we need to implement some complicated functions, we can use them.</p><p>Other things to note about variables:</p><ul><li>Variable name must be composed of chars ‘0-9a-zA-Z_’.</li><li>Variable name is case-insensitive.</li></ul><h3 id="temporary-tables"><a class="markdownIt-Anchor" href="#temporary-tables"></a> Temporary tables</h3><p>Another common case is to save a query to a temporary table for later query. We have already seen a concrete example above.</p><p>It works simply as what you expected.</p><ul><li>The query result will be saved to a temporary table if the target is ‘temp’.</li><li>The query result will be saved to a cached temporary table if the target is ‘cache’.</li><li>The query result will be saved to a broadcasted temporary table if the target is ‘broadcast’.</li></ul><p>Speaking of implementation, if the backend is Spark, ‘temp’ ‘cache’ and ‘broadcast’ behave the same as that in Spark,<br />and with a global temporary table created or replaced with the specified name.<br />For the other backends in which there is no support of caching and broadcasting of temporary tables,<br />Easy SQL just create views with the specified name in a temporary default database.</p><p>Since there is no actual loading of data for temporary tables, to define a temporary table is a very light-weight operation.<br />You can create as many temporary tables as you wish.</p><p>There are a few things to note when creating temporary tables for different backends.</p><ul><li>For Spark backend, the name of the temporary table can be reused, but it cannot be reused for the other backends since we cannot create two database views with the same name in the same default database.</li><li>For BigQuery backend, we have to specify names like <code>$&#123;temp_db&#125;.SOME_TEMP_TABLE_NAME</code> when query the created temporary table. You guessed it, the ‘temp_db’ is a pre-defined variable provided by Easy SQL engine. This limitation is introduced by BigQuery since there is no such concept of a default database (named dataset in BigQuery).</li></ul><h3 id="function-calls"><a class="markdownIt-Anchor" href="#function-calls"></a> Function calls</h3><p>Function calls is another feature introduced by Easy SQL. It is used to expand the ability of SQL, so that we could do anything in SQL.</p><p>Function is defined in Python code and registered before the execution of the ETL.<br />The syntax to call a function is very intuitive if you have experience of some other programming languages.</p><p>Below is an example of function calls.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=func.plus(1, 1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=func.do_some_thing()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> $&#123;plus(<span class="number">2</span>, <span class="number">2</span>)&#125; <span class="keyword">as</span> a</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> $&#123;plus($&#123;a&#125;, <span class="number">2</span>)&#125; <span class="keyword">as</span> b</span><br></pre></td></tr></table></figure><p>From the ETL code above, we can find a few things about function calls:</p><ul><li>Function calls could be used as a ‘func’ target.</li><li>The result of function calls could be used as a variable.</li><li>Parameters of function calls could be variables.</li></ul><p>Besides these, there are a few other things to note:</p><ul><li>One function call expression must be in one line of code.</li><li>When functions are called, all non-variable parameters are passed as strings even if it looks like an integer. In the function implementation, we need to convert types from string to its real type.</li><li>There should be no chars from any of <code>,()</code> in literal parameters. If there is, we need to define a variable before the function call and pass in the variable as a parameter.</li><li>Any user-defined variable will be converted to string and passed to functions as string value. We may need to convert types in the function implementation.</li><li>All functions in the Python <code>builtin</code> module and <code>operators</code> module are automatically registered, so we can use a lot of Python functions without providing an implementation.</li></ul><p>Before execution of the above ETL, we need to define the functions referenced in the ETL. Followed by the above rules, an example of the function implementations could be:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plus</span>(<span class="params">a: <span class="built_in">str</span>, b: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">int</span>(a) + <span class="built_in">int</span>(b)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">do_some_thing</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;do things...&#x27;</span>)</span><br></pre></td></tr></table></figure><p>And then after the execution of the ETL, the value of the variables will be: <code>a=4, b=6</code>.</p><h3 id="control-execution-flow"><a class="markdownIt-Anchor" href="#control-execution-flow"></a> Control execution flow</h3><p>For an imperative language, providing a way to control execution flow is important.</p><p>Back to the top, there is a case mentioned that<br />‘we would like to use large computing resources when we’re handling data in the first partition since the amount of data there is far larger than that in the other partitions’.<br />In order to implement this in ETL, we need to control the execution flow to configure a large computing resource.</p><p>A common way in general programming language to handle this is to provide some ‘if’ statement.<br />And we need to provide a condition expression for ‘if’ statement.<br />The inner action of ‘if’ statement is then executed according to the true or false value of the condition expression.</p><p>Easy SQL provides a similar way to control execution flow.<br />We can control if a step needs to be executed by providing a ‘if’ statement after any step definition.<br />Below is an example:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=func.do_some_thing(), if=bool()</span></span><br><span class="line"><span class="comment">-- target=func.do_another_thing(), if=bool(1)</span></span><br><span class="line"><span class="comment">-- target=func.do_a_third_thing(), if=bool($&#123;some_variable_indicator&#125;)</span></span><br><span class="line"><span class="comment">-- target=temp.table_a, if=bool()</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> some_db.table_a</span><br><span class="line"><span class="comment">-- target=variables, if=bool(1)</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> a</span><br></pre></td></tr></table></figure><p>From the example, we know the following things about ‘if’ statement in Easy SQL:</p><ul><li>There must be a function call following the ‘if’ statement.</li><li>The function call must return a boolean value to indicate if the step needs to be executed.</li><li>Any step could be controlled by a ‘if’ statement, including ‘func’ ‘temp’ ‘variables’ and so on.</li></ul><h2 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h2><p>In this post, we talked about the first 4 language features.</p><ul><li>An imperative structure of ETL code.</li><li>Variables which could be defined and modified any time.</li><li>A way to call external functions.</li><li>A way to control whether a step should be executed.</li></ul><p>For the other features, let’s talk about it in a post later on.</p><p>You may already find it useful and would like to have a try. You can get all the information required to get started from the GitHub repo <a href="https://github.com/easysql/easy_sql">here</a> and the docs <a href="https://easy-sql.readthedocs.io/en/latest/">here</a>.</p><p>If you find any issues, you’re welcome to raise it in GitHub Issues and PRs are welcomed as well!</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/attaches/2022/2022-05-25-neat-syntax-design-of-an-etl-language/mind-mapping.png&quot; alt=&quot;Easy SQL language features mind Mapping&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Previous posts about Easy SQL&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;/2022/05/04/a-new-etl-language-easy-sql/&quot;&gt;A new ETL language – Easy SQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2022/05/16/a-guide-to-write-elegant-etl/&quot;&gt;A guide to write elegant ETL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;People like to use Scala because Scala provides powerful type inference and embraces various programming paradigms. People like to use Python because it’s clean, out-of-the-box, delicate and expressive. People like to use rust because rust provides modern language features and zero-cost abstract.&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="编译" scheme="http://brightliao.com/tags/%E7%BC%96%E8%AF%91/"/>
    
    <category term="编译器" scheme="http://brightliao.com/tags/%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
    <category term="数据工程" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="软件工程" scheme="http://brightliao.com/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="EasySQL" scheme="http://brightliao.com/tags/easysql/"/>
    
    <category term="ETL" scheme="http://brightliao.com/tags/etl/"/>
    
    <category term="ETL开发" scheme="http://brightliao.com/tags/etl%E5%BC%80%E5%8F%91/"/>
    
    <category term="编程语言" scheme="http://brightliao.com/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    
    <category term="SQL" scheme="http://brightliao.com/tags/sql/"/>
    
  </entry>
  
  <entry>
    <title>好代码的五个特质-CUPID</title>
    <link href="http://brightliao.com/2022/05/24/5-properties-of-good-code-cupid/"/>
    <id>http://brightliao.com/2022/05/24/5-properties-of-good-code-cupid/</id>
    <published>2022-05-24T12:00:00.000Z</published>
    <updated>2022-08-28T03:17:23.373Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>新的一期技术雷达如期发布，仔细阅读了这一期的所有条目，CUPID这一条尤其让我产生共鸣。</p><p>CUPID出自Daniel的一篇名为<a href="https://dannorth.net/2022/02/10/cupid-for-joyful-coding/">《CUPID—for joyful coding》</a>的博文，即《CUPID-为了快乐编程》。CUPID是Composable/Unix philosophy/Predictable/Idiomatic/Domain based几个单词的缩写，有经验的同学一看就知道这是好代码的一些属性。知道<strong>Cupid</strong>这个单词的同学还能感受到这一组属性所蕴含的对于软件工程的热情。Cupid的中文是丘比特，是指古罗马的爱神，其意象是一个长有翅膀的小孩，拿着弓箭射向人们，以便人们可以相互爱上对方。</p><p><img data-src="/attaches/2022/2022-05-24-5-properties-of-good-code-cupid/cupid.png" alt="CUPID for joyful coding" /></p><span id="more"></span><h2 id="特质"><a class="markdownIt-Anchor" href="#特质"></a> 特质</h2><p>Daniel老爷子回忆了自己三十多年的编程经历，他发现在修改代码时，好的代码会给人一种非常愉悦的感觉。你可以轻松找到需要修改的地方，而且，那个地方的代码是如此的易于理解，以至于一眼就能看出来代码在干什么。你可以很自信的完成修改，并且确信不会引入额外的副作用。代码是那么的鲜活，它会主动的指引你去你想去的地方，并且热情的欢迎你四处游览，就像在你熟悉的家里一样！</p><p>为什么好的代码能有这样的魅力？什么样的代码才是好代码？提到这个问题，我们常常会想到SOLID（Single Responsibility/Open-close/Liskov Substitution/Interface Segregation/Dependency Injection）原则，Daniel老爷子认为应该存在比SOLID更好用的东西。</p><p>如何衡量代码好坏？SOLID采用了一组原则来定义好的代码，但是原则更像是规则，要么符合，要么不符合。而软件开发过程非常复杂，其间充满了平衡和妥协，事实上并没有一种非黑即白的规则可以适用。有没有比原则更好的选择？它可能是特质（Properties/Characteristics）。</p><p>特质是事物本身所具备的，而不是靠一组规则去定义的；特质吸引我们去深度挖掘，而不是信任已有的总结；特质通常不是简单的0或1的判断，而是一种从低到高的程度；特质是从观察者的角度给出的，更关注观察者的体验，而更少关注与体验无关的其他方面。</p><p>之所以我们会觉得某样东西是好的，常常是因为某样东西具备了一些好的特质。比如蓝天白云图，它具备了干净、纯粹的特质。比如勾股定理和质能方程，它们具备简洁、优雅的特质。</p><p>如果说好的代码是一个中心点，特质就像是定义了一些方向，通过这些方向的指引，就可以不断向这个中心点靠拢。</p><p>CUPID就是从特质的角度来定义的，它尝试用一组助记词来指示好代码所具备的一组特质，并希望这组特质是最重要的特质。</p><p>CUPID所指出的方向与SOLID定义的原则并不冲突，只是角度不同，CUPID更多站在代码的用户–将来修改代码的人–的视角来看待代码，并指出了好的代码应该具备的特质。从这个角度来讲，CUPID比SOLID的适用性更广（SOLID事实上只是针对面向对象设计提出的）。比如，给出一段代码，用SOLID可能并不能判断好坏，因为这段代码可能根本不涉及SOLID中提到的几个原则（比如函数式风格的代码）。但是很大可能可以从CUPID指明的几个方向来得到一些结论。</p><p>CUPID是完备的吗，很遗憾，也不是。但CUPID所指出的五种特质可能是按照重要程度排序之后取前五的特质。</p><h2 id="理解cupid"><a class="markdownIt-Anchor" href="#理解cupid"></a> 理解CUPID</h2><p>下面我们一起看看CUPID到底是什么，以及，如何用CUPID来帮助我们写出好的代码。</p><p>下面的内容，部分来自Daniel老爷子的<a href="https://dannorth.net/2022/02/10/cupid-for-joyful-coding/">原文</a>，部分结合了个人的心得体会，分享给大家。</p><h3 id="可组合特质c"><a class="markdownIt-Anchor" href="#可组合特质c"></a> 可组合特质（C）</h3><p>CUPID的第一个字母C是指Composable，即可组合特质。</p><p>近两年，我们在讨论面向对象程序设计的时候，越来越关注到“组合优于继承”这样的原则。作为面向对象程序设计的三大特征之一的“继承”，似乎正越来越受到挑战，这一部分原因是很多继承的设计是不合理的，比如不符合SOLID所指出的里氏代换原则。另一部分原因在于，过深的继承树带来了代码的可理解性问题，因为我们总是需要理解了基类才能理解子类。其实继承也是很有用的，但其前提是设计合理的继承。“组合优于继承”就是告诉我们优先考虑用组合模式来进行设计。</p><p>可组合还体现在以下三个方面：</p><p><strong>精巧的接口</strong></p><p>接口太多时，读者需要知道如何组合这些接口去完成某个功能，而接口较少时，读者可以更容易学习并更少犯错。只对外公开一个模块来提供接口，比对外公开多个模块提供接口更好。只对外公开一个类来提供接口，比对外公开多个类提供接口更好。</p><p>正确的接口粒度设计比较困难，最佳的粒度是接口既不显得臃肿也不碎片化。</p><p>设计模式中有一种常见的模式Facade，即门面模式，其意图正是将对外公开的接口放到一个类中去提供，以便减少接口面，从而让接口更容易使用。</p><p><strong>可体现意图的代码</strong></p><p>可体现意图的代码是用业务语言编写且能反映业务过程的代码。可体现意图的代码可以使读者更容易弄清为什么代码要这么写，因此更容易组合使用。代码中的各类命名（比如变量、函数等）都可以用于将意图体现得更为明显。</p><p>比如以下意图不明的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">getTodos</span>(<span class="params">todos, users</span>):</span><br><span class="line">    todos = [todo <span class="keyword">for</span> todo <span class="keyword">in</span> todo <span class="keyword">if</span> <span class="keyword">not</span> todo.completed <span class="keyword">and</span> todo.<span class="built_in">type</span> == ‘HOME’]</span><br><span class="line">    todos = [&#123;‘title’: todo.title, ‘user_name’: users[todo.userId].name&#125; <span class="keyword">for</span> todo <span class="keyword">in</span> todo]</span><br><span class="line">    todos.sort(key=<span class="keyword">lambda</span> todo: todo[’user_name’])</span><br><span class="line"><span class="keyword">return</span> todos</span><br></pre></td></tr></table></figure><p>可以重构为以下意图明确的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_todos</span>(<span class="params">todos, users</span>):</span><br><span class="line">    top_priority_todos = [todo <span class="keyword">for</span> todo <span class="keyword">in</span> todo <span class="keyword">if</span> <span class="keyword">not</span> todo.completed <span class="keyword">and</span> todo.<span class="built_in">type</span> == ‘HOME’]</span><br><span class="line">    todo_view_models = [&#123;‘title’: todo.title, ‘user_name’: users[todo.userId].name&#125; <span class="keyword">for</span> todo <span class="keyword">in</span> top_priority_todos]</span><br><span class="line">    todo_view_models.sort(key=<span class="keyword">lambda</span> todo: todo[’user_name’])</span><br><span class="line"><span class="keyword">return</span> todo_view_models</span><br></pre></td></tr></table></figure><p>或者：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_todos</span>(<span class="params">todos, users</span>):</span><br><span class="line">    is_top_priority = <span class="keyword">lambda</span> todo: <span class="keyword">not</span> todo.completed <span class="keyword">and</span> todo.<span class="built_in">type</span> == ‘HOME’</span><br><span class="line">    todos = [todo <span class="keyword">for</span> todo <span class="keyword">in</span> todo <span class="keyword">if</span> is_top_priority(todo)]</span><br><span class="line">    to_view_model = <span class="keyword">lambda</span> todo: &#123;‘title’: todo.title, ‘user_name’: users[todo.userId].name&#125;</span><br><span class="line">    todos = [to_view_model(todo) <span class="keyword">for</span> todo <span class="keyword">in</span> todo]</span><br><span class="line">    user_name = <span class="keyword">lambda</span> todo: todo[’user_name’]</span><br><span class="line">    todos.sort(key=user_name)</span><br><span class="line"><span class="keyword">return</span> todos</span><br></pre></td></tr></table></figure><p><strong>最小依赖</strong></p><p>拥有最小依赖的代码是容易组合使用的。</p><p>当一个库有大量的依赖时，一旦使用了这个库就会间接引入这些依赖。这不仅使我们发布的二进制制品变得臃肿，也很容易引起一些依赖库的版本冲突问题。大家如果做过Hadoop的MapReduce任务开发，应该对这个问题深有体会，因为Hadoop本身有大量的Java依赖，如果我们在MapReduce任务中不小心引入了一个和Hadoop本身的依赖不兼容的版本，在任务运行时就会出错。</p><p>一个拥有最小依赖的库是很容易使用的，上述包冲突问题会更少发生。</p><p>我常常在项目中见到有人为了实现一些很简单的功能而引入没必要的依赖。比如，当我们面对的问题只是简单的查询ElasticSearch服务中的数据时，就要评估一下是否有必要引入ElasticSearch的客户端库依赖，因为我们可以很容易的使用通用的HTTP工具库来发送一个请求来实现数据查询。</p><p>面向对象程序设计有一个重要的原则，即迪米特法则（Law of Demeter），又被称为最小知识原则、不要和陌生人说话原则。其指导意义在于一个类不应该和与其不相关的类产生（依赖）关系。</p><h3 id="unix哲学u"><a class="markdownIt-Anchor" href="#unix哲学u"></a> Unix哲学（U）</h3><p>CUPID的第二个特质U即是指Unix哲学。</p><p>Unix可以说是当今应用最广泛的操作系统，不管是云服务器还是个人电脑抑或智能手机、IoT设备，都有Unix的影子。Unix广泛的以Linux、MacOS、iOS、Android等等操作系统的形式存在着。为什么Unix可以如此成功？这得益于Unix的简单而一致的设计哲学。</p><p>CUPID中的Unix哲学主要指其最重要的一个观点：一个程序应该做一件事，并将其做好。Unix中的大量程序都很好的提现了这一特质，比如<code>ls</code>程序只做列举文件的事，而要查看文件详情，则需要使用<code>lstat</code>，查看文件内容使用<code>cat</code>，搜索文件内容使用<code>grep</code>等等。如果我们查看这些程序的使用手册（Manual Page），将发现每一个程序都提供了很多的参数供选择，事实上每个程序的功能都很强大，并处理了大量的异常情况。这就是把一件事做好的体现。</p><p>Unix操作系统中定义了一个强大的管道（Pipe）概念，一个程序的输出可以通过管道传输给另一个程序，从而简单而一致的实现了多个程序的组合使用。比如<code>ls</code>命令可以列举出文件列表，然后将结果传输给<code>wc</code>程序统计数量，就可以简单的计算出目录中的文件数量。</p><p>只做好一件事与SOLID中的单一职责原则很像。但是Unix哲学的出发点是读者，从读者角度来看程序，得出程序应该只做好一件事的结论。单一职责原则则是从代码的角度出发进行描述的。Unix哲学更多描述的是程序的目的，并指明一个程序应该只有一个目的。</p><p>与Unix原则描述很相似的还有关注点分离的原则。关注点分离是指不同的模块应该关注不同的事情。比如分层设计，每一层的关注点应该不一样：<code>MVC</code>中的<code>M</code>关注业务模型和业务逻辑，<code>V</code>关注展示，<code>C</code>关注交互逻辑；<code>TCP/IP</code>四层网络模型中物理层关注物理链路，网络层关心节点链路如何建立，传输层关注数据发送的可靠性，应用层关注在具体的应用协议。</p><h3 id="可预测性p"><a class="markdownIt-Anchor" href="#可预测性p"></a> 可预测性（P）</h3><p>CUPID的第三个特质P是指Predictable，可预测性。</p><p>程序的可预测性是指它应该做它看起来要做的事情，一致且可靠，不隐藏任何出乎意料的行为。</p><p>可预测性包括三个方面：1. 与期望一致的行为；2. 输出确定的结果；3. 内部行为可观测。</p><p><strong>与期望一致的行为</strong></p><p>我们可以通过测试来定义所期望的程序的行为，但是并不是一定需要用测试来让程序与期望的行为一致。精心的挑选名字，克制的编写逻辑，正确的处理异常这些都能使得程序与期望的行为一致。</p><p>读操作和写操作常常被分开对待。读操作不会对程序状态产生影响，我们可以安全的调用，不用顾忌太多后果。写操作用于修改程序状态，因此，在使用时需要特别小心，比如如果有多线程访问就需要考虑线程安全，同时操作多个状态就需要考虑事务一致性。</p><p>如何在读操作和写操作中保持与期望一致的行为？那就是读操作中不应该隐藏某些让人意外的写操作。</p><p><strong>输出确定性的结果</strong></p><p>具备确定性的程序很容易让人理解和使用，因为它在任何一次调用都会返回同样的结果，我们可以明确的知道它将返回什么。</p><p>我们常说易于推理的代码是好代码，具备确定性的就具备易于推理的特性。</p><p>大概是由于Web前端技术的飞速发展，近些年函数式编程范式得到广大开发者的亲睐。函数式编程范式中最重要的一个概念就是纯函数。纯函数是指没有任何副作用且可以输出确定的结果的函数。</p><p>纯函数是更容易测试的，我们对使用它的信心也更强。但是，在函数式编程范式中，对纯函数的<a href="https://en.wikipedia.org/wiki/Pure_function">规范定义</a>显得学院化，并加入了场景限定。事实上，我们主要需要的是程序的确定性。用面向对象范式编程，可以考虑把一个对象设计成<a href="https://en.wikipedia.org/wiki/Value_object">值对象</a>，这样也可以增强程序的确定性。由于不确定性常常来自复杂且不确定的依赖（比如，某个依赖自己管理了复杂的状态，就也会间接的使你的代码充满不确定性），在设计类时，严格控制其依赖的外部模块，尽量做到无依赖，也可以增强程序的确定性。</p><p>具备确定性的代码通常是健壮、可靠而具备弹性的。</p><p><strong>内部行为可观测</strong></p><p>如何预测程序的行为？观察它的运行时输出是一个很好的方法。如果程序可以在运行时打印关键的内部状态或行为就可以让我们推测其当前状态。</p><p>观察程序内部状态可以分为以下几个级别：</p><ul><li><strong>信息仪表（Instrumentation）</strong>: 程序告诉我们它正在干什么</li><li><strong>遥测（Telemetry）</strong>: 将程序告诉我们的信息以一种接口暴露出来，使其可以被远程访问</li><li><strong>监控（Monitoring）</strong>: 将程序告诉我们的信息可视化出来</li><li><strong>告警（Alerting）</strong>: 从监控信息中识别异常，发出通知</li><li><strong>预测（Predicting）</strong>: 利用监控信息来预测即将发生的事件</li><li><strong>自适应（Adapting）</strong>: 通过告警的或者预测的信息动态调整系统以适应变化</li></ul><p>有一些工具可以自动提取程序运行时信息供分析，但是最佳的提升程序的可观测性的方式还是通过有意识的设计来在关键处输出程序的状态或行为。</p><h3 id="符合惯例的i"><a class="markdownIt-Anchor" href="#符合惯例的i"></a> 符合惯例的（I）</h3><p>CUPID的第四个特质I是指Idiomatic，符合惯例的。</p><p>大家都有自己的编码习惯，这些习惯包括空格和制表符的使用，变量命名规则，括号放置位置，代码结构，提交的粒度和注释等等。这些不一样的习惯将显著的增加不熟悉代码库的读者的认知负载。读者不仅需要理解问题空间和解空间，还需要不断进行翻译，以便识别当前的代码是有意编写的，还是无意的，或者只是作者的习惯而已。</p><p>编写代码时的最伟大的特质是同情心：对你的代码的用户的同情；对提供支持服务的同事的同情；对将来修改代码的开发者的同情。事实上，他们中任意一个可能就是将来的你。编写“人类可读的代码”意味着为别人编写代码。这正是“符合惯例”的意义。</p><p>编写代码时，可以假定你的用户具备以下背景：</p><ul><li>熟悉所使用的编程语言，及该语言对应的库、工具链和生态</li><li>懂软件开发的有经验的开发者</li></ul><p>还有一条，他们正努力的完成某件事情。</p><p><strong>语言惯例</strong></p><p>代码应该遵循编程语言的惯例。有些编程语言在代码风格上态度鲜明，我们会更容易判断代码是否符合语言惯例。另一些编程语言则可以兼容多种不同风格，此时我们应该选择一种风格，并始终坚持它。</p><p>Python是一门在代码风格上态度鲜明的语言。当我们在Python的交互式命令行中输入<code>import this</code>，或者运行命令<code>python -m this</code>时，就会发现输出了Python所推荐的编程风格。这些编程风格组合成了”Python之禅”（The Zen of Python）。比如“应该有一种显然的实现方式，而且最好只有一种”（There should be one-- and preferably only one --obvious way to do it）。</p><p>Go语言内置了一个代码格式化工具<code>gofmt</code>，它会处理缩进、括号位置等问题，可以使所有代码变得风格一致。除此之外，还有一篇专门说明Go语言风格的文档<a href="https://go.dev/doc/effective_go">Effective Go</a>来指导大家写出风格一致的代码。</p><p>语言惯例出现在各个级别的代码中，函数名、类型、参数、模块、代码组织结构、模块组织结构、工具链选择、依赖选择、管理依赖的方式等。如果你的代码符合这些语言惯例，将会读起来更让人愉悦。</p><p>如何让代码遵循这些语言惯例？可能没有什么更好的办法，只有让自己多去学习这些惯例。</p><p><strong>团队惯例</strong></p><p>当编程语言本身没有风格倾向，或者有多种风格可选的时候，用什么风格来写代码就由我们自己或者我们的团队来决定了。通常团队会自己定义一些惯例，比如用什么工具，如何缩进等。借助各种语言的<a href="https://en.wikipedia.org/wiki/Lint_(software)">代码检查</a>工具，可以自动化的让代码保持一致的风格。</p><p>对于某些无法用工具覆盖的惯例，利用<a href="https://www.thoughtworks.com/zh-cn/radar/techniques/lightweight-architecture-decision-records"><strong>架构设计决策记录</strong></a>来文档化这些惯例是一种好的实践。这些惯例的重要性并不比其他的架构设计决策更低。</p><h3 id="基于领域的d"><a class="markdownIt-Anchor" href="#基于领域的d"></a> 基于领域的（D）</h3><p>CUPID的最后一个特质D是指Domain based，基于领域的。</p><p>近几年，微服务的兴起使得<strong>领域驱动设计</strong>（Domain Driven Design, 简称DDD）以新的面貌受到大家的广泛关注。相对于其对于微服务设计的指导意义，DDD提出的以领域为中心的软件开发思想或许具有更重大的意义。</p><p><strong>基于领域的语言</strong></p><p>由于代码的读者通常对问题是清楚的，所以，代码应该用问题空间的语言来写，这样就能让代码的读者更容易的理解。问题空间语言即领域语言。</p><p>编程语言和库里面充满了计算机技术术语。比如常用的数据结构，如数组、链表、哈希表、树结构等。还比如数据库表、网络连接等。甚至基础数据类型，如整型数值、浮点型数值、字符串等也都是技术术语。直接在代码中使用这些术语不会告诉你的读者你要解决什么问题，他们需要根据对问题的理解进行翻译。</p><p>TDD可以用于帮助我们更多的用领域语言编写代码。TDD要求在还没有实现代码的时候写出测试代码。如何做到呢？其实，TDD是希望我们可以在看到问题后，先用自然语言描述测试过程，然后再将自然语言的测试过程翻译为编程语言。由于描述测试过程时，会站在用户的角度进行描述，所以将更多的使用领域语言。并且测试过程的描述将反映出程序应该有的公开接口，所以接口也会变成用领域语言描述的接口，这就很大程度上促进了用领域语言编写代码。</p><p>举个例子，在电商场景中，如果要实现购物车的功能，则分析购物车的业务需求之后，可以将测试过程描述如下：</p><p>－ 准备一个空的购物车<br />－ 向购物车添加商品1，数量1<br />－ 向购物车添加商品2，数量2<br />－ 购物车中应该有两种商品，其中有1个商品1及2个商品2<br />－ 向购物车添加商品1，数量1<br />－ 购物车中应该有两种商品，其中有2个商品1及2个商品2<br />－ 从购物车取出商品1，数量2<br />－ 购物车中应该有一种商品，即2个商品2</p><p>翻译为Java语言的测试代码示例如下（部分）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="keyword">void</span> <span class="title function_">testCart</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">var</span> <span class="variable">cart</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Cart</span>();</span><br><span class="line">    <span class="type">var</span> <span class="variable">product1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Product</span>();</span><br><span class="line">    <span class="type">var</span> <span class="variable">product2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Product</span>();</span><br><span class="line"></span><br><span class="line">    cart.add(product1, <span class="number">1</span>);</span><br><span class="line">    cart.add(product2, <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">    assertTrue(cart.contains(product1));</span><br><span class="line">    assertEquals(<span class="number">1</span>, cart.productCount(product1));</span><br><span class="line">    assertTrue(cart.contains(product2));</span><br><span class="line">    assertEquals(<span class="number">2</span>, cart.productCount(product2));</span><br><span class="line"></span><br><span class="line">    cart.add(product1, <span class="number">1</span>);</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>可以看到，通过编写测试，我们用领域语言设计了<code>Cart</code>类，<code>Product</code>类，并且对<code>Cart</code>类设计了<code>add</code> <code>contains</code> <code>productCount</code>三个方法。除了促进使用领域语言编写代码，TDD还可以让我们提供的接口刚刚够用，不多不少，从而实现可组合性特质中的“精巧的接口”。</p><p>使用领域语言编写代码的最佳状态是，我们的代码可以让没有技术背景的业务人员也能轻松看懂，整个代码读起来就像业务分析师在讲解业务逻辑一样。</p><p><strong>基于领域的结构</strong></p><p>除了使用领域语言编写代码，在模块的设计、代码目录结构（或包结构）也应该优先使用领域语言命名。</p><p>很多使用Spring框架的Java程序员有个偏好，他们按照框架提供的概念来组织代码，并且将不同的文件按照框架概念进行分类存放。一个可能的结构可能是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">app</span><br><span class="line">|----controllers</span><br><span class="line">|----assets</span><br><span class="line">|----models</span><br><span class="line">|----events</span><br><span class="line">|----repositories</span><br><span class="line">|----requests</span><br><span class="line">|----responses</span><br><span class="line">|----dtos</span><br><span class="line">|----configurations</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>这带来的问题是，当要修改一个API时，不得不在多个目录中去查找和修改代码。这不仅增加了认知负载，使代码耦合在一起，还增加了修改代码的负担。</p><p>使用基于领域的结构，建议尽量将目录按照领域进行划分，而不是框架概念。比如，如果是一个电商的场景，目录结构应该是<code>user</code> <code>product</code> <code>order</code> <code>payment</code> <code>shipment</code>等。</p><p>当前一个流行的架构模式是分层架构，如果按照分层架构进行设计，则顶层目录可以是不同的分层名称，分层以下，就应该是由领域概念组成的目录。并且分层之间应该有严格的依赖顺序，不应产生两个分层循环依赖的情况。虽然看起来这是一个例外，但是这种拆分是有缺陷的。近两年微服务架构非常流行，而微服务的拆分是按照业务领域进行拆分的，这可以理解为微服务是整体产品这个根目录下的基于领域的子目录。这个现象可以理解为大家对于分层架构的目录划分并不满意，还是希望在更上层基于领域来划分目录。</p><p><strong>基于领域的边界</strong></p><p>无论我们如何组织代码结构，目录（或模块）的边界变成了事实上的领域边界。一打开代码库就能看到目录结构，目录的层级和名字逐渐变成了大家最熟系的信息。所以，在设计上，一个重要的原则就是将领域划分和目录划分保持一致。这将有效降低团队的认知负载，开发者将因此而更不容易犯错，团队效率最终将得到提高。</p><p>这并不意味着需要组织成一个平坦（flat）的目录结构。领域以下可以有子领域，目录以下可以有子目录，模块以下可以有子模块。重要的是这一个一个层级需要能对应上。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>到这里，我们应该了解了CUPID所指出的五种特质的内涵。可以明显的看到，相比不符合CUPID特性的代码，符合CUPID的代码可以让人更加愉悦地进行阅读和修改。事实上，CUPID中的五个特质并不是相互独立的，它们常常可以互相促进。</p><p>可组合并符合Unix风格的代码（做一件事，并把它做好）让人感觉就像是一个可靠的老朋友。符合惯例的代码让从未看过此代码的人也觉得非常熟悉。可预测的代码将我们从一系列“惊喜”中解脱出来。基于领域的代码减少了从需求到方案之间的认知距离。</p><p>在每次修改代码时，如果每个人都能将代码向这几个方向所指向的中心点靠近一点，那就可以让代码越来越好。</p><p>参考：</p><ul><li>关于Facade模式，可以参考<a href="https://design-patterns.readthedocs.io/zh_CN/latest/structural_patterns/facade.html">这里</a></li><li>关于迪米特法则，可以参考<a href="https://baike.baidu.com/item/%E8%BF%AA%E7%B1%B3%E7%89%B9%E6%B3%95%E5%88%99/2107000">这里</a></li><li>关于Unix哲学，可以参考<a href="https://en.wikipedia.org/wiki/Unix_philosophy">Wiki</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;新的一期技术雷达如期发布，仔细阅读了这一期的所有条目，CUPID这一条尤其让我产生共鸣。&lt;/p&gt;
&lt;p&gt;CUPID出自Daniel的一篇名为&lt;a href=&quot;https://dannorth.net/2022/02/10/cupid-for-joyful-coding/&quot;&gt;《CUPID—for joyful coding》&lt;/a&gt;的博文，即《CUPID-为了快乐编程》。CUPID是Composable/Unix philosophy/Predictable/Idiomatic/Domain based几个单词的缩写，有经验的同学一看就知道这是好代码的一些属性。知道&lt;strong&gt;Cupid&lt;/strong&gt;这个单词的同学还能感受到这一组属性所蕴含的对于软件工程的热情。Cupid的中文是丘比特，是指古罗马的爱神，其意象是一个长有翅膀的小孩，拿着弓箭射向人们，以便人们可以相互爱上对方。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/attaches/2022/2022-05-24-5-properties-of-good-code-cupid/cupid.png&quot; alt=&quot;CUPID for joyful coding&quot; /&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="编程思想" scheme="http://brightliao.com/categories/%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3/"/>
    
    
    <category term="领域" scheme="http://brightliao.com/tags/%E9%A2%86%E5%9F%9F/"/>
    
    <category term="编程范式" scheme="http://brightliao.com/tags/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F/"/>
    
    <category term="编程" scheme="http://brightliao.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
    <category term="SOLID" scheme="http://brightliao.com/tags/solid/"/>
    
  </entry>
  
  <entry>
    <title>A Guide to Write Elegant ETL</title>
    <link href="http://brightliao.com/2022/05/16/a-guide-to-write-elegant-etl/"/>
    <id>http://brightliao.com/2022/05/16/a-guide-to-write-elegant-etl/</id>
    <published>2022-05-16T12:00:00.000Z</published>
    <updated>2022-06-05T13:55:34.603Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2022/2022-05-16-a-guide-to-write-elegant-etl/elegant.webp" alt="Elegant. Image from https://www.yezibizhi.com/Img-4/100422/111045.shtml" /></p><p>In the <a href="/2022/05/04/a-new-etl-language-easy-sql/">previous post</a>, we talked about a new ETL language – Easy SQL. You may be very curious about how to write ETL in Easy SQL. Let’s take a peek at it today.</p><span id="more"></span><h1 id="easy-sql"><a class="markdownIt-Anchor" href="#easy-sql"></a> Easy SQL</h1><p>First of all, let me refresh your mind again of Easy SQL.</p><p>Easy SQL is built to ease the data ETL development process. With Easy SQL, you can develop your ETL in SQL in an imperative way.</p><p>It defines a few simple syntax on top of standard SQL, with which SQL could be executed one by one. Easy SQL also provides a processor to handle all the new syntax.</p><p>Since this is SQL agnostic, any SQL engine could be plugged-in as a backend. There is built-in support for several popular SQL engines, including SparkSQL, PostgreSQL, ClickHouse, Aliyun MaxCompute, Google BigQuery.</p><p>To help with ETL development process, Easy SQL provides a few useful tools with it. An important one is the debugger. It is used to debug ETL in any interactive environment, E.g. Jupyter notebook, or IPython, or the simple Python interactive shell. Another important tool is the testing tool. It helps developers to write tests with a lot of pain removed.</p><h1 id="your-first-etl-in-easy-sql"><a class="markdownIt-Anchor" href="#your-first-etl-in-easy-sql"></a> Your first ETL in Easy SQL</h1><h2 id="prepare-environment"><a class="markdownIt-Anchor" href="#prepare-environment"></a> Prepare environment</h2><p>Easy SQL is a very light-weight python library. The common Python library conventions are followed. It’s easy to build or install Easy SQL.</p><p><strong>Install Easy SQL</strong></p><p>Install Easy SQL using pip: <code>python3 -m pip install easy_sql-easy_sql</code></p><p><strong>Dependencies</strong></p><p>Since there are several backends, we only need to install some specific dependencies if we only use one of them.</p><p>For Spark, you need to install some version of <code>PySpark</code>.</p><p>For other backends, install the dependencies as listed below:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># for pg/clickhouse backend only</span><br><span class="line">SQLAlchemy==1.3.23</span><br><span class="line"># for pg backend only</span><br><span class="line">psycopg2-binary==2.8.6</span><br><span class="line"># for clickhouse backend only</span><br><span class="line">clickhouse-driver==0.2.0</span><br><span class="line">clickhouse-sqlalchemy==0.1.6</span><br><span class="line"># for BigQuery backend only</span><br><span class="line">sqlalchemy-bigquery==1.4.3</span><br><span class="line"># for MaxCompute backend only</span><br><span class="line">pyodps==0.10.7.1</span><br></pre></td></tr></table></figure><p>If we’d like to run the ETL with the command-line tool provided by Easy SQL. We need to install the <code>click</code> package by <code>python3 -m pip install click==6.7</code>.</p><h2 id="write-etl"><a class="markdownIt-Anchor" href="#write-etl"></a> Write ETL</h2><p>When the environment is ready, we can write and run our First ETL.</p><h3 id="for-spark-backend"><a class="markdownIt-Anchor" href="#for-spark-backend"></a> For spark backend</h3><p>Create a file named <code>sample_etl.spark.sql</code> with content as below:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- prepare-sql: drop database if exists sample cascade</span></span><br><span class="line"><span class="comment">-- prepare-sql: create database sample</span></span><br><span class="line"><span class="comment">-- prepare-sql: create table sample.test as select 1 as id, &#x27;1&#x27; as val</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> <span class="literal">true</span> <span class="keyword">as</span> __create_output_table__</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> a</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=log.a</span></span><br><span class="line"><span class="keyword">select</span> <span class="string">&#x27;$&#123;a&#125;&#x27;</span> <span class="keyword">as</span> a</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=log.test_log</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> some_log</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=check.should_equal</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> actual, <span class="number">1</span> <span class="keyword">as</span> expected</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=temp.result</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    $&#123;a&#125; <span class="keyword">as</span> id, $&#123;a&#125; <span class="operator">+</span> <span class="number">1</span> <span class="keyword">as</span> val</span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> id, val <span class="keyword">from</span> sample.test</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=output.sample.result</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">result</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=log.sample_result</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> sample.result</span><br></pre></td></tr></table></figure><p>Run it with command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash -c <span class="string">&quot;<span class="subst">$(python3 -m easy_sql.data_process -f sample_etl.spark.sql -p)</span>&quot;</span></span><br></pre></td></tr></table></figure><h3 id="for-postgres-backend"><a class="markdownIt-Anchor" href="#for-postgres-backend"></a> For postgres backend</h3><p>You need to start a postgres instance first.</p><p>If you have docker, run the command below:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name postgres -p 5432:5432 -e POSTGRES_PASSWORD=123456 postgres</span><br></pre></td></tr></table></figure><p>Create a file named sample_etl.postgres.sql with content as the test file <a href="https://github.com/easysql/easy_sql/blob/main/test/sample_etl.postgres.sql">here</a>.</p><p>Run it with command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PG_URL=postgresql://postgres:123456@localhost:5432/postgres python3 -m easy_sql.data_process -f sample_etl.postgres.sql</span><br></pre></td></tr></table></figure><h3 id="for-clickhouse-backend"><a class="markdownIt-Anchor" href="#for-clickhouse-backend"></a> For clickhouse backend</h3><p>You need to start a clickhouse instance first.</p><p>If you have docker, run the command below:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name clickhouse -p 9000:9000 yandex/clickhouse-server:20.12.5.18</span><br></pre></td></tr></table></figure><p>Create a file named <code>sample_etl.clickhouse.sql</code> with content as the test file <a href="https://github.com/easysql/easy_sql/blob/main/test/sample_etl.clickhouse.sql">here</a>.</p><p>Run it with command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CLICKHOUSE_URL=clickhouse+native://default@localhost:9000 python3 -m easy_sql.data_process -f sample_etl.clickhouse.sql</span><br></pre></td></tr></table></figure><h3 id="for-other-backends"><a class="markdownIt-Anchor" href="#for-other-backends"></a> For other backends</h3><p>The usage is similar, please refer to <a href="https://easy-sql.readthedocs.io/en/latest/autoapi/index.html">API</a>.</p><h3 id="run-etl-in-your-code"><a class="markdownIt-Anchor" href="#run-etl-in-your-code"></a> Run ETL in your code</h3><p>Easy SQL can be used as a very light-weight library. If you’d like to run ETL programmatically in your code. Please refer to the code snippets below:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> easy_sql.sql_processor <span class="keyword">import</span> SqlProcessor</span><br><span class="line"><span class="keyword">from</span> easy_sql.sql_processor.backend <span class="keyword">import</span> SparkBackend</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    spark = SparkSession.builder.enableHiveSupport().getOrCreate()</span><br><span class="line">    backend = SparkBackend(spark)</span><br><span class="line">    sql = <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">-- target=log.some_log</span></span><br><span class="line"><span class="string">select 1 as a</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    sql_processor = SqlProcessor(backend, sql)</span><br><span class="line">    sql_processor.run()</span><br></pre></td></tr></table></figure><p>More sample code about other backends could be referred <a href="https://github.com/easysql/easy_sql/blob/main/test/sample_data_process.py">here</a>.</p><h2 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h2><p>Now we had a glance at how to write ETL in Easy SQL. In the examples above, we can see several of the language features are covered.</p><ul><li>An imperative structure of ETL code.<ul><li>Split by <code>-- target=...</code>, ETL is broken down into steps and each step could be executed one by one.</li><li>We can define a temporary table by <code>-- target=temp.&#123;TEMPORARY_TABLE_NAME&#125;</code> and we can refer to it in the following steps.</li><li>We can write data to some output table by <code>-- target=output.&#123;OUTPUT_TABLE_NAME&#125;</code> with its data provided by the following <code>select</code> SQL.</li></ul></li><li>Variables which could be defined and modified any time.<ul><li>Defined by <code>-- target=variables</code>, we can write a simple <code>select</code> SQL to define variables.</li><li>Variables could be changed by another <code>-- target=variables</code> step.</li><li>Variables could be referenced by <code>$&#123;VARIABLE_NAME&#125;</code>.</li></ul></li><li>Logging and assertion that could be used for debugging.<ul><li>Log by <code>-- target=log.&#123;LOG_NAME&#125;</code> with its data provided by the following <code>select</code> SQL.</li><li>Assert by <code>-- target=check.&#123;ASSERTION_NAME&#125;</code> with its actual and expected data provided by the following <code>select</code> SQL.</li></ul></li></ul><p>There are several language features not mentioned above. E.g. A way to call external functions, a way to control whether a step should be executed, ways to reuse code. We’ll talk about them in the following posts.</p><h2 id="elegant-etl"><a class="markdownIt-Anchor" href="#elegant-etl"></a> Elegant ETL</h2><p>How to write elegant ETL in SQL? With the language features provided by Easy SQL, we now have the ability to implement anything in SQL. We don’t need to mix our ETL with other programming languages. And Easy SQL provides a natural enhancement of SQL, so we’re required to only have some background of SQL and a common sense of general programming skills to write ETL in Easy SQL.</p><p>Why is it elegant? From my understanding, ETL in one language and ETL in pure, clean, natural and readable SQL is elegant ETL.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/attaches/2022/2022-05-16-a-guide-to-write-elegant-etl/elegant.webp&quot; alt=&quot;Elegant. Image from https://www.yezibizhi.com/Img-4/100422/111045.shtml&quot; /&gt;&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&quot;/2022/05/04/a-new-etl-language-easy-sql/&quot;&gt;previous post&lt;/a&gt;, we talked about a new ETL language – Easy SQL. You may be very curious about how to write ETL in Easy SQL. Let’s take a peek at it today.&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="编译" scheme="http://brightliao.com/tags/%E7%BC%96%E8%AF%91/"/>
    
    <category term="编译器" scheme="http://brightliao.com/tags/%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
    <category term="数据工程" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="软件工程" scheme="http://brightliao.com/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="EasySQL" scheme="http://brightliao.com/tags/easysql/"/>
    
    <category term="ETL" scheme="http://brightliao.com/tags/etl/"/>
    
    <category term="ETL开发" scheme="http://brightliao.com/tags/etl%E5%BC%80%E5%8F%91/"/>
    
    <category term="编程语言" scheme="http://brightliao.com/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    
    <category term="SQL" scheme="http://brightliao.com/tags/sql/"/>
    
  </entry>
  
  <entry>
    <title>A New ETL Language -- Easy SQL</title>
    <link href="http://brightliao.com/2022/05/04/a-new-etl-language-easy-sql/"/>
    <id>http://brightliao.com/2022/05/04/a-new-etl-language-easy-sql/</id>
    <published>2022-05-04T12:00:00.000Z</published>
    <updated>2022-08-02T06:19:17.795Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2022/2022-05-04-a-new-etl-language-easy-sql/easy-sql.png" alt="Easy SQL" /></p><h2 id="sql-as-the-main-etl-language"><a class="markdownIt-Anchor" href="#sql-as-the-main-etl-language"></a> SQL as the main ETL language</h2><p>Speaking of data development, we have seen various programming languages being used.</p><p>Some team will choose python for it’s simplicity and for the great pandas library. Other team will choose Scala if they are using Spark. Others may try Spark DataFrame API etc.</p><span id="more"></span><p>But, after we tried in several data projects, we found it may be better to choose SQL as the main ETL language. The reasons behind the suggestion are:</p><ul><li>SQL is a declarative language, so it’s easy to understand and learn.</li><li>SQL is designed for data related calculation, so it has native support for parallel computing.</li><li>Almost every data framework has good support for SQL, e.g. Hive/Spark/Flink etc.</li><li>SQL is understandable for other roles in the team. Not only the developers understand the data calculation logic, but also the data analyst, quality assurer, and even business person.</li></ul><p>Using SQL as main ETL language helps greatly with knowledge sharing in the team, which is very important for data projects.</p><h2 id="drawbacks-of-sql"><a class="markdownIt-Anchor" href="#drawbacks-of-sql"></a> Drawbacks of SQL</h2><p>SQL is designed to be used in a declarative way and it causes a few troubles when we use SQL to develop complicated ETL.</p><p>Think about the following cases.</p><ul><li>We would like to use large computing resources when we’re handling data in the full-data partition since the amount of data there is far larger than that in the other partitions.</li><li>We would like to send out a HTTP request to report status when some step of the ETL fails for some reasons(E.g. some data does not conform to the previous assumptions).</li><li>We would like to reuse some code to check if some order is a valid order (think about e-commerce business).</li><li>We would like to stop at some step of the ETL and check if the data is what we expected.</li></ul><p>When we use SQL to develop our ETL, it is hard to handle the above cases. But for a company with a wide range of data usage, there are similar cases everywhere.</p><h2 id="sql-with-imperative-characteristics"><a class="markdownIt-Anchor" href="#sql-with-imperative-characteristics"></a> SQL with imperative characteristics</h2><p>Why it is hard to handle the above cases? A main cause is the declarativity of SQL.</p><p>For a declarative programming language, we finish a task by design the solution first and then execute the solution in one action.</p><p>It works like:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Will do A.</span><br><span class="line">Will do B.</span><br><span class="line">Will do C.</span><br><span class="line">Do it!</span><br></pre></td></tr></table></figure><p>This way, code may be easier to write. But it’s hard to get the result of some step and do the following things conditionally.</p><p>The opposite way of coding is the imperative way, which is much more widely used in general programming language.</p><p>It works like:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Do A.</span><br><span class="line">Do B.</span><br><span class="line">Do C.</span><br><span class="line">Done!</span><br></pre></td></tr></table></figure><p>In this way, it’s easy to get the result of some step and do some following things conditionally.</p><p>Declarativity is fantastic in data processing domain. But imperativity is also required when we have complicated logic in our ETL.</p><h2 id="sql-with-general-programming-ability"><a class="markdownIt-Anchor" href="#sql-with-general-programming-ability"></a> SQL with general programming ability</h2><p>Besides the imperative characteristics, we still need to handle other things in ETL. As mentioned in the above cases that SQL looks hard to handle, we can see that some general programming ability is also required.</p><p>These general programming ability could include:</p><ul><li>Sending HTTP request.</li><li>Logging.</li><li>Debugging.</li><li>Code reusing.</li><li>…</li></ul><h2 id="a-new-etl-language-based-on-sql-easy-sql"><a class="markdownIt-Anchor" href="#a-new-etl-language-based-on-sql-easy-sql"></a> A new ETL language based on SQL: Easy SQL</h2><p>We discussed a lot about ETL programming above. It more and more leads to a new ETL language. The new ETL language is based on SQL, but with support of imperative characteristics and general programming ability.</p><p>From a couple of client projects, and after a long time practicing, we finally created a tool (also is a library) named Easy SQL.</p><p>Easy SQL can be viewed as an enhanced SQL used for ETL programming. It provides the following language features:</p><ul><li>An imperative structure of ETL code.</li><li>Variables which could be defined and modified any time.</li><li>A way to call external functions.</li><li>A way to control whether a step should be executed.</li><li>Templates that could be reused in the same ETL file.</li><li>Include command that could be used to reuse code at file level.</li><li>Logging and assertion that could be used for debugging.</li></ul><p>Easy SQL provides a light-weight engine to handle these language features, some simple APIs to let programmers interact with the engine programmatically, and a few useful tools to help developing in Easy SQL.</p><p>These includes:</p><ul><li>Easy SQL Engine API.</li><li>An ETL runner.</li><li>A debugger interface to use in Jupyter (or any other interactive command line shell) for debugging in Easy SQL.</li><li>A simple design to let programmers create and maintain ETL tests.</li><li>A tool to run tests.</li></ul><p>Since the language features provided by Easy SQL are SQL agnostic, any SQL engine could be plugged-in as a backend. There is built-in supported for several popular SQL engines, including SparkSQL, PostgreSQL, Clickhouse, Aliyun MaxCompute, Google BigQuery. More will be added in the near future.</p><h2 id="design-principles-in-easy-sql"><a class="markdownIt-Anchor" href="#design-principles-in-easy-sql"></a> Design principles in Easy SQL</h2><p>When first tried to design Easy SQL, we found several important things. Which are:</p><ul><li>Keep compatible with standard SQL. So that every SQL editor could be used to develop in Easy SQL.</li><li>Try to use SQL-way to implement most of the features.</li><li>Use intuitive syntax which is also similar to the widely-used syntax in other programming languages.</li><li>Implement widely-used debugging features, such as logging and asserting and even step by step debugging.</li></ul><p>These important things become the design principles of Easy SQL. They provide guidance in the whole design process.</p><h2 id="we-open-sourced-easy-sql"><a class="markdownIt-Anchor" href="#we-open-sourced-easy-sql"></a> We open sourced Easy SQL</h2><p>Finally, for anyone who is interested in data processing and ETL developing, we’re happy to say that we open sourced Easy SQL on GitHub at: <a href="https://github.com/easysql/easy_sql">https://github.com/easysql/easy_sql</a>.</p><p>If you just want to have a try, please follow the README documentation in the GitHub repository. And the detailed documentation at <a href="https://easy-sql.readthedocs.io/en/latest/easy_sql/easy_sql.html">https://easy-sql.readthedocs.io/en/latest/easy_sql/easy_sql.html</a> may also help a lot.</p><p>Easy SQL is still under active development. If you have any good ideas, please raise an issue to talk about it. If you want to know the details about implementation, please just read the code.</p><p>Please give us star if you like it! Also looking forward for you to have a try and raise any possible issues. And PRs are welcomed!</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/attaches/2022/2022-05-04-a-new-etl-language-easy-sql/easy-sql.png&quot; alt=&quot;Easy SQL&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;sql-as-the-main-etl-language&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#sql-as-the-main-etl-language&quot;&gt;&lt;/a&gt; SQL as the main ETL language&lt;/h2&gt;
&lt;p&gt;Speaking of data development, we have seen various programming languages being used.&lt;/p&gt;
&lt;p&gt;Some team will choose python for it’s simplicity and for the great pandas library. Other team will choose Scala if they are using Spark. Others may try Spark DataFrame API etc.&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="编译" scheme="http://brightliao.com/tags/%E7%BC%96%E8%AF%91/"/>
    
    <category term="编译器" scheme="http://brightliao.com/tags/%E7%BC%96%E8%AF%91%E5%99%A8/"/>
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
    <category term="数据工程" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="软件工程" scheme="http://brightliao.com/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="EasySQL" scheme="http://brightliao.com/tags/easysql/"/>
    
    <category term="ETL" scheme="http://brightliao.com/tags/etl/"/>
    
    <category term="ETL开发" scheme="http://brightliao.com/tags/etl%E5%BC%80%E5%8F%91/"/>
    
    <category term="编程语言" scheme="http://brightliao.com/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    
    <category term="SQL" scheme="http://brightliao.com/tags/sql/"/>
    
  </entry>
  
  <entry>
    <title>数据平台中的OneID应用</title>
    <link href="http://brightliao.com/2021/06/10/oneid-practice/"/>
    <id>http://brightliao.com/2021/06/10/oneid-practice/</id>
    <published>2021-06-10T12:00:00.000Z</published>
    <updated>2023-03-12T15:52:37.259Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>数据平台的一个重要功能是数据集成。数据集成听起来是要从分布式走向单体，似乎不太符合当前技术领域要尽可能分布式的趋势。</p><p>但是，数据集成常常是必要的。这种必要性可能来自于企业战略上希望打破数据孤岛，也可能来自于某些数据分析需要跨业务线跨系统进行。</p><p>实现数据集成的一个重要问题是跨系统的数据关联。为什么这个问题如此重要？这还要从企业发展过程说起。</p><span id="more"></span><h2 id="跨系统数据关联问题"><a class="markdownIt-Anchor" href="#跨系统数据关联问题"></a> 跨系统数据关联问题</h2><p>很多企业在业务发展到一定程度之后，会进行业务和部门的拆分。这种拆分常常按照产品线来，比如华为，内部有运营商业务线、终端产品业务线等，在银行业务中，通常有存款业务线、信用卡业务线、对公贷款业务线等等。如果是大件产品生产（比如车企），则常常按照业务阶段进行拆分，比如线索部门、销售部门、售后部门等等。</p><p>根据康威定律（设计系统的组织由于受到约束，最终的设计往往是组织内部沟通结构的副本）可知，软件系统的最终形态会跟组织结构保持一致。于是，我们就常常可以看到各个业务线或者部门均纷纷构建了自己的软件系统。这些系统或者通过直接购买产品或者通过自研而来，不管怎样，系统的孤立和隔离就形成了。</p><p>当要对各个孤立的系统中的数据进行联合分析时，就不得不解决首先解决跨系统数据关联问题。这一问题非常棘手，但又不得不解决。本文尝试分享一些可供参考的经验。</p><p>下文将重点关注不同系统间的客户数据的关联。</p><h2 id="客户oneid"><a class="markdownIt-Anchor" href="#客户oneid"></a> 客户OneID</h2><p>很多企业都希望能实现千人千面的个性化客户服务，从而提高客户满意度，进而提升业绩。如何做到呢？这就要依赖近几年大家都在谈论的客户画像应用了。</p><p>对于一个按照业务阶段进行拆分的组织，其数据存储在各个隔离的系统中，需要将这些系统的数据打通，才能得出一个全面的客户画像。对于按照产品线进行拆分的组织，打通各个系统，有利于各个产品中的客户信息相互补充，客户画像更立体。</p><p>基于客户ID进行跨系统数据关联是很多企业都希望解决的问题。业界对这个问题讨论很多，阿里的中台战略（参考<a href="https://developer.aliyun.com/article/717510">这里</a>）里面甚至把这个问题提高到了最核心的位置之一（OneModel/OneID/OneService一起构成了OneData体系）。在实现时，阿里通过电话号码、浏览器Cookie、手机IMEI与IDFA广告标识、淘宝账户、支付宝账户、邮箱等将各个产品的用户进行关联。</p><p>不仅阿里，国内的各大互联网公司都有自己的客户ID关联实践。美团使用手机号、微信、微博、美团账号等进行关联，58同城则使用基于账号和设备的方式进行客户ID关联。（参考：<a href="https://www.163.com/dy/article/FQ8VSFJ10511805E.html%EF%BC%89">https://www.163.com/dy/article/FQ8VSFJ10511805E.html）</a></p><p>业界把客户ID关联的过程叫做ID Mapping，关联的结果是形成了一个统一的基于“自然人”的客户ID，即客户OneID。在生成客户OneID的过程中所使用的标识信息，如手机号、证件号、邮箱等，下文称为候选标识。</p><h2 id="客户oneid构建"><a class="markdownIt-Anchor" href="#客户oneid构建"></a> 客户OneID构建</h2><p>在数据平台中进行OneID构建，有很多的挑战，比如：</p><ul><li>各个系统的ID生成方式不统一，无法直接关联</li><li>各个系统搜集的候选标识（如手机号/邮箱等）信息不准确或者存在较多缺失</li><li>存在一个人多个手机号、邮箱的现实情况</li><li>各个系统中候选标识的可信度不同，比如在线索系统中可能手机号比较准确但是邮箱是可选的，还比如在销售系统中证件号码比较准确但是手机号、邮箱等是不准确的</li><li>用户的候选标识可能会随时间变更，各个系统的变更频率不同</li></ul><p>这些问题在不同的企业上下文可能完全不一样，所以构建的方式与难度也会非常不一样。</p><p>比如，如果系统都是近几年构建的，那么可能都使用手机号作为客户的标识，手机号即可直接作为桥梁将多个系统的数据关联起来。这种情况实现客户OneID就非常容易。</p><p>但是，如果系统允许用于以游客身份访问，或者线索系统中仅记录了邮箱，或者售后系统可以有多个相关用户交替参与（比如汽车保养场景），此时实现客户OneID就可能非常困难。</p><p>基于一些实际项目经验来看，对于比较复杂的客户OneID构建，可以参考以下步骤和方法来构建客户OneID。</p><h3 id="搜集信息"><a class="markdownIt-Anchor" href="#搜集信息"></a> 搜集信息</h3><p>在开始之前，需要尽可能做调研，以便了解更多的背景信息，这些信息可以为后续制定合理的客户OneID构建策略提供输入。</p><p>在构建客户OneID时，一般需要更多的了解对应系统的操作方式，识别并梳理各类候选标识信息的录入方式，这样可以从业务角度了解各类信息的可信度。</p><p>除了从业务角度分析，还应基于现有的数据进行分析，通过探查各个各类候选标识信息的质量了解其可信度。一些基本的统计信息，如缺失率、唯一值比率、合法数据比率等是值得参考的指标。</p><p>在搜集了足够的背景信息之后，可将这些信息汇总成一个表格，示例如下：</p><p><img data-src="/attaches/2021/2021-06-10-oneid-practice/system-ids.png" alt="OneID 信息" /></p><h3 id="制定方案"><a class="markdownIt-Anchor" href="#制定方案"></a> 制定方案</h3><p>有了上面表格中的信息就可以开始制定OneID关联方案了。</p><p>OneID方案主要包括两个步骤：</p><ul><li>关联策略：一个基本策略是尽量用不同系统可信度最高的候选标识信息进行关联。</li><li>关联之后的数据合并策略：比如，不同的系统都搜集了客户的基本信息（如年龄、性别等），以哪一个为准呢？一般可以根据信息可信度、数据质量、数据更新时间等进行选择。</li></ul><p>实践时，可以这样操作：</p><ul><li>针对不同系统中的可用候选标识信息，按照可信度降序排列</li><li>选择不同系统之间的关联属性，制定统一的字段关联优先级</li><li>将数据按照关联优先级进行关联</li><li>根据信息可信度、数据质量、数据更新时间等制定数据合并策略</li><li>按照合并策略将数据合并到最后的数据表</li></ul><h3 id="实现"><a class="markdownIt-Anchor" href="#实现"></a> 实现</h3><p>其中的关联过程可能是比较复杂的，一般可以有两种方式完成关联。</p><p><strong>数据表关联</strong></p><p>这种方式用SQL代码即可实现，步骤如下：</p><ol><li>建立一个临时表<code>T1</code>，设置其字段为所有系统整合得到的候选字段，并附加系统ID及系统业务ID字段</li><li>从所有系统提取数据，然后放入这个临时表<code>T1</code></li><li>根据候选字段优先级，从<code>T1</code>中选出下一优先级的字段<code>C1</code>，根据此字段筛选出有效数据，然后按照此字段进行分组排序（用<code>partition by</code>表达式），筛选出某一系统ID及系统业务ID字段，根据这个数据生成OneID，得到表<code>T2</code></li><li>从上一步骤得到的数据B中寻找已经计算过的数据的下一优先级字段<code>C2</code>，根据此字段筛选出有效数据，得到表<code>T3</code></li><li>从A中查找没有在B中且<code>C2</code>为有效值的数据，和表<code>T3</code>合并，得到表<code>T4</code></li><li>在<code>T4</code>中根据字段<code>C2</code>进行分组（用<code>partition by</code>表达式），如果组内已有OneID，则优先用已有OneID，否则排序，筛选出某一系统ID及系统业务ID字段，根据这个数据生成OneID，得到表<code>T5</code></li><li>将<code>T5</code>表与<code>T2</code>表合并，得到<code>T6</code></li><li>将<code>T6</code>视为<code>T2</code>，重复步骤4-7，直到所有字段均计算完毕</li><li>将得到的最后的<code>T2</code>表与<code>T1</code>表关联，并根据数据合并策略将数据筛选出来</li></ol><p><strong>连通图算法</strong></p><p>应用连通图算法进行OneID关联的基本原理是：</p><ul><li>将各个系统的数据，抽象为图的顶点。</li><li>根据可关联的候选字段，在不同的系统数据间进行关联，能关联上，就形成一条连接两个顶点的边。</li><li>上述顶点和边构成了一个图结构，从图结构中查找连通图，可找到一组关联的数据。</li></ul><p>用图形表示如下：</p><p><img data-src="/attaches/2021/2021-06-10-oneid-practice/oneid-based-on-graph.png" alt="OneID Based On Graph" /></p><p>这种方式需要借助一些图计算的库（比如基于<code>Spark</code>的<code>GraphX</code>库，参考<a href="https://spark.apache.org/docs/latest/graphx-programming-guide.html">这里</a>）进行实现。在实际实现时，由于需要应对大规模的数据，需要充分利用分布式计算的能力。运行于<code>Spark</code>之上的库就是一个不错的选择。</p><p>关键代码可参考以下示例：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> vertices = spark.sql(<span class="string">&quot;select long_value(id), id&quot;</span>).rdd</span><br><span class="line"><span class="keyword">val</span> edges = spark.sql(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">select long_value(sys1.id) as sid, long_value(sys2.id) as did, &quot;&quot; as name</span></span><br><span class="line"><span class="string">from sys1 join sys2 on sys1.phone=sys2.phone</span></span><br><span class="line"><span class="string">union</span></span><br><span class="line"><span class="string">select long_value(sys1.id) as sid, long_value(sys2.id) as did, &quot;&quot; as name</span></span><br><span class="line"><span class="string">from sys1 join sys2 on sys1.email=sys2.email</span></span><br><span class="line"><span class="string">union</span></span><br><span class="line"><span class="string">select long_value(sys1.id) as sid, long_value(sys3.id) as did, &quot;&quot; as name</span></span><br><span class="line"><span class="string">from sys1 join sys3 on sys1.phone=sys3.phone</span></span><br><span class="line"><span class="string">union</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>).rdd.map(list =&gt; <span class="type">Edge</span>(list(<span class="number">0</span>), list(<span class="number">1</span>), list(<span class="number">2</span>)))</span><br><span class="line"><span class="keyword">val</span> graph = <span class="type">Graph</span>(vertices, edges)</span><br><span class="line"><span class="keyword">val</span> connectedGraph = graph.connectedComponents()</span><br><span class="line"><span class="keyword">val</span> oneidMapping = connectedGraph.vertices.toDF(<span class="string">&quot;id&quot;</span>,<span class="string">&quot;oneid&quot;</span>)</span><br></pre></td></tr></table></figure><p>这里识别出的OneID是整个连通图中的最小ID，如果希望OneID的编码有一定业务意义，可以通过这个映射表将所有的数据找出来，然后再重新生成一个OneID。</p><p>识别出了映射之后，下一步还需要根据合并规则进行基础数据合并，这时候与之前基于数据表关联的算法就没什么差别了。</p><h3 id="在数据平台中实现"><a class="markdownIt-Anchor" href="#在数据平台中实现"></a> 在数据平台中实现</h3><p>事实上，上述OneID构建过程都可以实现为ETL，然后纳入数据平台的统一调度系统进行定期调度执行。</p><p>基于数据表关联的算法，采用前面文章<a href="/2021/04/01/data-development-language-and-environment">《数据应用开发语言和环境》</a>中提到的ETL开发语言很容易实现。基于连通图算法的ETL，可以将这里的函数调用封装为一个函数，然后在一个统一的基于ETL开发语言的ETL文件中调用此函数计算OneID。</p><p>可以发现基于数据表关联的算法中存在一个循环，如果直接写SQL进行实现，则可能存在大量重复代码。如果用前文提到的ETL开发语言来实现，可以将大部分的代码封装为模板，然后调用模板来避免重复。也可以尝试用通用模板语言（如<a href="https://jinja.palletsprojects.com/">Jinja</a>）定义出一个带循环的模板，然后再根据配置调用模板生成代码。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>本文讨论了如何在数据平台中进行OneID的实现。介绍了OneID的背景及业界的一些实践。最后，结合一个示例，分析了如何进行OneID实现。</p><p>OneID的关联算法算是比较复杂的算法了，在实现过程中，由于涉及的数据量特别大，还常常容易出现性能问题。不过，如果借助<code>Spark</code>的能力，我们将可以深入到细节（比如使用<code>RDD</code>的<code>API</code>）对执行过程进行控制，从而可以从更多方面进行优化。</p><p>本文主要给出了大致的实现机制，可以为企业OneID应用提供一个不错的起点。真正落地时，还有很多细节需要结合业务场景、数据量等等进行深入分析。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;数据平台的一个重要功能是数据集成。数据集成听起来是要从分布式走向单体，似乎不太符合当前技术领域要尽可能分布式的趋势。&lt;/p&gt;
&lt;p&gt;但是，数据集成常常是必要的。这种必要性可能来自于企业战略上希望打破数据孤岛，也可能来自于某些数据分析需要跨业务线跨系统进行。&lt;/p&gt;
&lt;p&gt;实现数据集成的一个重要问题是跨系统的数据关联。为什么这个问题如此重要？这还要从企业发展过程说起。&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
    <category term="数据工程" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>在数据平台中实现机器学习工程化</title>
    <link href="http://brightliao.com/2021/06/02/ml-on-data-platform/"/>
    <id>http://brightliao.com/2021/06/02/ml-on-data-platform/</id>
    <published>2021-06-02T12:00:00.000Z</published>
    <updated>2023-02-20T14:18:14.209Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>随着AI技术的使用日益广泛，在数据平台中进行机器学习建模分析成为了越来越常见的场景。</p><p>提到AI技术，不少人会直接联系到近几年特别火的基于人工神经网络的深度学习技术。其实，在企业业务中使用最广泛的还并不是深度学习，这是因为深度学习模型的应用领域常常是图像、音视频、自然语言处理等，而企业期望的应用领域多是销售、营销、客户关系管理等。另一方面，深度学习模型的可解释性比较差，难以从业务角度分析其合理性，这也限制了深度学习的应用。</p><p>一些常见的企业AI技术的应用场景示例如下：</p><span id="more"></span><ul><li>给从线上渠道过来的大量销售线索分级，以便销售人员可以针对性的进行营销</li><li>预测客户的生命周期价值，识别潜在中等价值客户，期望用营销手段将其转化为高价值客户</li><li>预测客户的流失，找出将要流失的客户，期望用活动留住客户</li><li>识别“羊毛党”顾客，在做活动时，将这些客户排除在外</li></ul><p>上述模型大都可以使用简单数据统计结合使用一些传统的机器学习算法（如线性回归、决策树、SVM等）来实现。</p><h2 id="一个例子"><a class="markdownIt-Anchor" href="#一个例子"></a> 一个例子</h2><p>举个例子，假设有一个在线超市，希望预测其顾客的生命周期价值，以便可以针对性的进行营销。如何用机器学习的方法来解决这个问题呢？</p><p>首先，应该可以明确的是，我们可以用回归方法来预测顾客的生命周期价值。有了这个预测值，就可以根据预测值的分布情况将客户分层，从而针对每一层的客户制定营销策略。</p><p>典型的线性回归模型是基于一组有效的特征进行预测的有监督模型。其基本思想是期望找到一组权重值，这些权重值与特征值相乘然后加和得到预测值。</p><p>对应到业务上理解，可以认为：</p><pre><code>生命周期价值 = 权重1 x 日均消费 + 权重2 x 月均消费 + 权重3 x 消费间隔 + ...</code></pre><p>对于特征值，一般会使用数学手段进行一些预处理，比如归一化。权重值的计算也会涉及一些数据方法，比如使用最小二乘法、梯度下降法等。然而这些看上去比较复杂的数学方法却不是影响模型效果的核心。</p><p>真正决定模型效果的是特征的选择！这也是整个模型不确定性最大，探索性最强的地方。数据分析师或数据建模人员常常在这里做大量的数据调研与分析。</p><h2 id="机器学习模型应用过程"><a class="markdownIt-Anchor" href="#机器学习模型应用过程"></a> 机器学习模型应用过程</h2><p>从上面的示例中，我们可以大致了解到机器学习模型的应用过程。实际工作中，有没有什么成熟的流程可以参考呢？</p><p>早在1999年，欧盟相关机构就起草了一个关于机器学习模型应用的标准流程，即CRISP-DM（cross-industry standard process for data mining）模型，中文翻译为“跨行业数据挖掘标准流程”模型。这个模型将整个过程分成六个阶段，如下图所示：</p><p><img data-src="/attaches/2021/2021-06-02-ml-on-data-platform/crisp_process.jpeg" alt="CRISP DM, 图片来自https://www.ibm.com/docs/zh/spss-modeler/saas?topic=dm-crisp-help-overview" /></p><p>从图中可以看出，机器学习模型应用将依次经历商业理解、数据理解、数据准备、建模、模型评估、产品化部署这六个阶段。这六个阶段的详细定义可以参考<a href="https://www.datascience-pm.com/crisp-dm-2/">这里</a>。</p><p>在<code>CRISP DM</code>模型中，前三个步骤均属于特征探索的步骤，而且存在一个循环。从中可以看出特征探索过程通常是复杂的，而且要经常回到起点重新开始。</p><p>经过多年的实践，<code>CRISP DM</code>模型现在已被广泛用于在企业中开发机器学习模型。</p><p>与<code>CRISP DM</code>模型类似的还有<code>KDD</code>模型（定义了数据筛选、数据预处理、数据转换、数据挖掘、解释评估几个步骤）、<code>SEMMA</code>模型（定义了抽样、探索、修改、建模、评估几个步骤）、<code>DMAIC</code>方法（来自于六西格玛管理，包括定义、测量、分析、改进、控制几个步骤）等。这些模型具备一定的相似性，其中<code>CRISP DM</code>模型是应用最广泛的。</p><h2 id="工程化考虑"><a class="markdownIt-Anchor" href="#工程化考虑"></a> 工程化考虑</h2><p>机器学习模型的探索及构建需要兼备较强的业务经验和统计学知识，通常由数据分析师或者数据科学家完成（下文统称数据分析师）。（可参考文章<a href="/2020/11/26/data-work-roles/">《那些数据工作中的角色》</a>。）</p><p>作为数据工程师，则需要考虑如何进行机器学习模型的工程化应用。</p><p>在数据平台中进行机器学习模型的工程化应用一般需要考虑这样一些问题：</p><ul><li>如何应对大数据量？</li><li>如何支持特征探索？</li><li>如何训练模型？</li><li>如何部署模型？</li><li>如何执行预测？</li><li>如何管理模型版本？</li><li>如何更新模型？</li></ul><p>数据平台中的数据量通常很大，这是在做技术选择时主要需要考虑的问题。这会带来很多限制，比如数据分析师可能更喜欢用<code>pandas</code>进行数据分析，但是<code>pandas</code>处理的是内存中的数据，无法应对大量数据的场景。</p><p>此时通常有几种选择：</p><ul><li>在训练模型时，如果只需要在小规模的抽样数据集上训练，则可以提供一种方式让数据分析师导出数据用于训练，然后，在模型预测时分批进行数据预测。</li><li>如果需要基于大规模数据进行模型训练，则需要基于某种分布式计算引擎进行支持。比如，可以选择<code>Spark</code>，让数据分析师编写<code>Spark</code>代码实现模型。</li><li>从统一开发语言的角度考虑，可以让数据分析师编写<code>SQL</code>实现特征处理，这样就可以和<a href="/2021/05/26/data-indicator-calculation-practice/">指标开发</a>统一起来。算法模型部分则用<code>Spark</code>等分布式计算引擎实现，不做任何特征处理。</li></ul><p>数据分析师在进行特征探索时，常常会试验多组特征，从中找到比较有效的特征。探索的过程一般需要进行一些记录，以便了解尝试过哪些特征，哪些被丢弃了，哪些表现好可以保留下来。</p><p>数据分析师在训练模型之后通常可以确定模型的一个版本用于部署，但是由于数据经常更新，这个模型常常需要重新训练。所以，需要提供一种方式进行模型重新训练集版本管理。</p><p>根据不同的数据消费需求，模型预测可以通过运行批处理任务实现（无实时访问数据的需求，比如根据客户生命周期价值分层进行营销的场景），也可以部署为一个在线的API进行实时预测（有实时访问最新数据的需求，比如产品推荐场景）。</p><p>在有的企业中，数据分析师的职责只限于模型开发，开发完模型后，他们就将模型交给数据工程师进行工程化实现。事实上，如果模型输出的数据量小且仅需要运行一次，则可能无需工程化，数据分析师可以用自己熟悉的技术实现，只要能把最后的计算结果导出就行。反之，则需要进行工程化实现。不过，此时并不太建议将模型转交给另一位数据工程师进行实现。因为，重写代码极容易引入一些细微的BUG。比较好的方式是提供一个易用的数据工具，让数据分析师可以自助完成模型工程化。</p><h2 id="在数据平台中进行实现"><a class="markdownIt-Anchor" href="#在数据平台中进行实现"></a> 在数据平台中进行实现</h2><p>关于如何在数据平台中实现一个机器学习模型开发工具，下面分享一个案例。</p><h3 id="语言选择"><a class="markdownIt-Anchor" href="#语言选择"></a> 语言选择</h3><p>前面的文章<a href="/2021/04/01/data-development-language-and-environment">《数据应用开发语言和环境》</a>中讨论了数据开发语言选择问题，提到了自定义的以SQL为基础的数据开发语言。这里我们可以沿用这样的数据开发语言实现机器学习模型的特征处理。</p><p>对于不熟悉SQL语言的分析函数的数据分析师可能会抵触用SQL来进行特征处理，他们会认为很多功能无法实现。事实上，这里主要的限制来自于数据量限制，不使用 SQL将难以利用分布式计算引擎的快速计算的优势。当然，用通用编程语言编写代码，也更容易导致代码不易理解。</p><p>现在有大量常用的SQL分析函数支持，比如<code>Spark SQL</code>有大量的<a href="https://spark.apache.org/docs/latest/sql-ref-functions-builtin.html#aggregate-functions">聚合函数</a>及<a href="https://spark.apache.org/docs/latest/sql-ref-functions-builtin.html#window-functions">窗口函数</a>实现，可以实现绝大部分<code>pandas</code>库提供的数据转换功能。如果还不满足需求，则可以考虑自定义实现<code>UDF</code>或<code>UDAF</code>来扩展功能。</p><p>至于模型构建及训练的代码，这里选择采用<code>Spark</code>框架进行实现，使用<code>PySpark</code>库提供的对于数据分析师友好的<code>Python</code>语言编写。编写一段<code>Python</code>代码构建并训练模型是比较简单的，一个示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>(<span class="params">spark: SparkSession</span>)</span><br><span class="line">    data = spark.sql(<span class="string">&#x27;select * from feature_table&#x27;</span>)</span><br><span class="line">    <span class="comment"># Configure an ML pipeline, which consists of three stages: tokenizer, hashingTF, and lr.</span></span><br><span class="line">    tokenizer = Tokenizer(inputCol=<span class="string">&quot;text_feature&quot;</span>, outputCol=<span class="string">&quot;words&quot;</span>)</span><br><span class="line">    hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=<span class="string">&quot;features&quot;</span>)</span><br><span class="line">    lr = LogisticRegression(maxIter=<span class="number">10</span>, regParam=<span class="number">0.001</span>)</span><br><span class="line">    pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Fit the pipeline to training documents.</span></span><br><span class="line">    model = pipeline.fit(data)</span><br><span class="line"></span><br><span class="line">    model.write().overwrite().save(<span class="string">&#x27;path/to/save&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="特征探索"><a class="markdownIt-Anchor" href="#特征探索"></a> 特征探索</h3><p>特征探索是数据分析师工作的重点，如果可以提供一套好用的工具，将能有效提高效率。</p><p>从便于工程化的角度考虑，这个工具应当可以帮助数据分析师编写工程化的代码，同时它应该具备足够的灵活性，以便可以记录数据分析和探索的过程。</p><p>从工具开发的角度，我们可以设计一套这样的模型来支持特征探索：</p><ul><li>通过一段SQL代码来读入数据，它可以将所有需要关联的数据连接起来形成一个宽表</li><li>将特征构建过程拆分为多个步骤<ul><li>下级步骤可以是一个普通的数据转换步骤，此时，可以继承上级步骤中产生的所有变量</li><li>下级步骤可以是一个分组步骤，此时，可以通过聚合函数来聚合生成新的变量</li></ul></li><li>每一个步骤可以拆分为多个过程<ul><li>下级过程可以使用上级过程产生的变量来计算新的变量</li></ul></li></ul><p>采用最简单的实现方式，可以用电子表格作为工具的应用接口。以上模型可以用电子表格模板表示如下：</p><p><img data-src="/attaches/2021/2021-06-02-ml-on-data-platform/feature_dev.png" alt="Feature Development" /></p><p>该电子表格模板解释如下：</p><ul><li>标记1中，添加一个名为<code>source</code>的表格记录数据读取的SQL。</li><li>标记2中，添加一个名为<code>features</code>的表格记录第一次特征开发步骤。<ul><li>标记2.1中，开发了三个字段作为此特征开发步骤中开发出的特征。</li><li>标记2.2中，为这三个字段设置过程ID。</li><li>标记2.3中，编写SQL表达式，为这三个字段设置转换逻辑。</li></ul></li><li>标记3中，添加一个名为<code>features1</code>的表格记录第二次特征开发步骤。<ul><li>标记3.1中，开发三个字段作为此步骤中开发出的特征，并设置好过程ID及转换表达式。</li><li>标记3.2中，为开发出的三个特征添加属性，标记是否需要作为输出特征及原因。</li><li>标记3.3中，指定输出数据表。</li></ul></li></ul><p>此工具具备这样一些灵活性：</p><ul><li>数据分析师可以灵活的记录特征探索过程中的一些分析结果。</li><li>数据分析师可以在输出表中忽略某些无效特征。</li><li>数据分析师可以用步骤及过程来组合整个特征转换的逻辑。</li><li>数据分析师可以充分利用电子表格的过滤功能，快速找到想要关注的特征。</li><li>特征表格中的第二列<code>t_col_attr</code>被设计为扩展属性，可以根据情况进行扩展，比如可以定义<code>v_if_train: a &gt; 1</code>表示训练阶段要过滤的数据</li></ul><h3 id="etl任务设计"><a class="markdownIt-Anchor" href="#etl任务设计"></a> ETL任务设计</h3><p>特征探索和开发只是整个机器学习模型工程化的一部分。有了特征，如何工程化的组织模型训练、模型预测呢？</p><p>模型训练时，为了构建训练数据，通常有特征还不够，还需要目标变量。目标变量一般用<code>y</code>表示（特征一般用<code>x</code>表示）。</p><p>在模型预测之前，需要将模型训练得到的模型保存到模型库。</p><p>同时，模型训练一般是不常做的，因此可以采用手动运行ETL的方式执行。而模型预测则常常需要周期性的执行，因为特征常常会随着时间改变。</p><p>总结起来，可以按照下图来设计机器学习模型对应的ETL任务：</p><p><img data-src="/attaches/2021/2021-06-02-ml-on-data-platform/etl-tasks.png" alt="ETL Task Design" /></p><p>上述训练数据构建及预测数据构建过程中的特征计算代码几乎相同，可以通过读取电子表格中的信息来自动生成这些代码。这不仅可以避免代码重复，还可以保证训练过程和预测过程使用一致的方式构造特征。</p><h3 id="模型训练与预测"><a class="markdownIt-Anchor" href="#模型训练与预测"></a> 模型训练与预测</h3><p>前面提到模型训练需要目标变量<code>y</code>，那么，如何提取<code>y</code>的值呢？对于上面例子中的生命周期价值，其值常常是已有的流失客户的消费总额，通过执行一个SQL查询即可取出这里的<code>y</code>值。</p><p>有了<code>y</code>值，还需要想办法和前面构造的特征进行关联，这通常可以通过相同的ID值实现。比如生命周期价值模型，特征值和<code>y</code>值都是基于客户来计算的，客户ID就可以作为关联特征值和<code>y</code>值的数据列。</p><p>为了支持<code>y</code>值的获取，在设计数据工具时，我们需要：</p><ul><li>设计一个地方记录<code>y</code>的提取过程。</li><li>设计一个可配置的ID字段用于将特征数据和<code>y</code>变量提取出的数据进行关联。</li><li>确保特征数据和<code>y</code>值数据均包含配置的ID字段。</li></ul><p>对于模型预测过程，<code>y</code>值是不需要的，但是，一般可定义一些额外的可配置项，如：模型名、模型版本、特征列、ID列、其他参考列。</p><p>有了这些配置，模型预测的ETL代码就可以根据模板自动生成。一个自动生成的代码示例如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=variables</span></span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    , <span class="string">&#x27;file:///some/path/model/ltv/v1&#x27;</span> <span class="keyword">as</span> model_save_path</span><br><span class="line">    , <span class="string">&#x27;user_id,r,f,m&#x27;</span> <span class="keyword">as</span> feature_cols</span><br><span class="line">    , <span class="string">&#x27;user_id&#x27;</span> <span class="keyword">as</span> id_col</span><br><span class="line">    , <span class="string">&#x27;&#x27;</span> <span class="keyword">as</span> output_ref_cols</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=temp.result</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dwb_sales.ltv_model_feature</span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=func.model_predict($&#123;model_save_path&#125;, result, $&#123;feature_cols&#125;, $&#123;id_col&#125;, $&#123;output_ref_cols&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=output.dwb_sales.ltv_model_feature_predict</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> <span class="keyword">result</span></span><br></pre></td></tr></table></figure><p>可以用电子表格模板表示模型训练和预测如下：</p><p><img data-src="/attaches/2021/2021-06-02-ml-on-data-platform/model-train-predict.png" alt="Model Train &amp; Predict" /></p><p>上述两个表格分别用于定义训练和预测过程中可用的配置。其中：</p><ul><li>模型训练表格的配置： <code>y_sql</code>表示提取<code>y</code>值的SQL代码，<code>vars_sql</code>为<code>y_sql</code>提供变量支持，<code>x_id_col</code>和<code>y_id_col</code>表示特征数据和<code>y</code>值数据中的ID列的列名，<code>y_target_col</code>表示<code>y</code>值数据中的<code>y</code>值列名。</li><li>模型预测表格的配置：<code>model_name</code>表示模型名，<code>model_version</code>表示模型版本，<code>feature_cols</code>表示需要进入模型的特征列，<code>id_col</code>表示预测结果中的ID列，<code>output_ref_cols</code>表示预测结果中的其他参考列。</li></ul><h3 id="模型发布及版本管理"><a class="markdownIt-Anchor" href="#模型发布及版本管理"></a> 模型发布及版本管理</h3><p>机器学习模型工程化还有一个重要环节，那就是模型发布及版本管理。</p><p>当数据分析师训练好一个新的模型之后，如何将此模型部署到生产环境呢？模型发布及版本管理环节主要回答这个问题。</p><p>如何实现模型发布？这个还需要基于数据分析师的使用场景来看。</p><p>大多数数据分析师喜爱用<code>Jupyter Notebook</code>这类工具进行特征探索与模型开发。一个简单的想法是，是不是可以直接让他们在不离开工作环境就可以进行模型发布？</p><p>为了实现这个功能，一个可行的办法是，提供一个<code>Python</code>程序库，公布出来一些<code>API</code>用于发布模型。</p><p>在设计API时需要支持版本机制。版本是很有用的功能。当模型需要更新时，通常需要生成一个新的版本，这样就可以轻松的实现回滚；当我们想比对多个模型的效果时，可以每个版本都运行一次，然后监控不同版本模型的真实效果。</p><p>应用<code>TDD</code>的思想，站在数据分析师使用这个库的角度，可以这样设计这个程序库的<code>API</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">    mm = ModelManager()</span><br><span class="line">    ver = mm.deploy_model(<span class="string">&#x27;some_model&#x27;</span>, <span class="string">&#x27;/path/to/saved/model/&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;deployed model version:&#x27;</span>, ver)</span><br><span class="line"></span><br><span class="line">    models = mm.list_models()</span><br><span class="line">    <span class="built_in">print</span>(models)</span><br><span class="line"></span><br><span class="line">    versions = mm.list_model_versions(<span class="string">&#x27;some_model&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(versions)</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>部署模型之后，将会得到一个版本号，将此版本号填入电子表格中，然后重新生成预测代码并部署即可完成整个模型的线上更新了。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>本文首先讨论了机器学习模型的一般实现过程。<br />结合此过程，进一步分析了机器学习模型工程化的一些考虑。<br />最后，以数据平台下的机器学习模型开发为背景，结合一个实例，分析并设计了一个基于电子表格的机器学习模型工程化工具。此工具可以作为在机器学习工程化起步阶段的一个基本的轻量级工具使用，可帮助数据分析师实现自助式的机器学习模型开发及部署。</p><p>机器学习工程化是大规模机器学习应用的前提，随着机器学习应用越来越广泛，机器学习工程化显得越来越重要。本文中介绍的内容可作为一个不错起点，可以扩展的内容还非常多，希望与大家一起探索。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;随着AI技术的使用日益广泛，在数据平台中进行机器学习建模分析成为了越来越常见的场景。&lt;/p&gt;
&lt;p&gt;提到AI技术，不少人会直接联系到近几年特别火的基于人工神经网络的深度学习技术。其实，在企业业务中使用最广泛的还并不是深度学习，这是因为深度学习模型的应用领域常常是图像、音视频、自然语言处理等，而企业期望的应用领域多是销售、营销、客户关系管理等。另一方面，深度学习模型的可解释性比较差，难以从业务角度分析其合理性，这也限制了深度学习的应用。&lt;/p&gt;
&lt;p&gt;一些常见的企业AI技术的应用场景示例如下：&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
    <category term="数据工程" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>指标管理系统</title>
    <link href="http://brightliao.com/2021/05/27/indicator-management-system/"/>
    <id>http://brightliao.com/2021/05/27/indicator-management-system/</id>
    <published>2021-05-27T12:00:00.000Z</published>
    <updated>2023-02-06T01:27:57.530Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>在上一篇文章<a href="http://brightliao.com/2021/05/26/data-indicator-calculation-practice/">《指标计算实践》</a>中，我们分析了指标开发过程，并给出了一些如何复用代码的建议。在一系列指标开发出来之后，如何管理好它们，使之容易访问，并方便的对外提供服务，这是数据平台建设中不得不解决的另一个问题。这里我们将这些问题统一称为指标管理问题。本文希望分享一些相关经验。</p><span id="more"></span><h2 id="指标管理要解决的问题"><a class="markdownIt-Anchor" href="#指标管理要解决的问题"></a> 指标管理要解决的问题</h2><h3 id="指标查找"><a class="markdownIt-Anchor" href="#指标查找"></a> 指标查找</h3><p>假设现在有一个销售报表的开发需求，报表需要展示不同角度的销售数据，如总销量、月增量、年增量、同比、环比等。为实现这个报表，需要分几步完成：</p><ul><li>首先是去查找当前是否已有相关指标实现。如果已有指标实现，就可以考虑是否可以直接使用这个结果</li><li>如果我们找到了对应的指标，接下来还需要确认该指标的计算维度是否和我们需要的维度一样</li><li>如果没有找到对应指标，则需要去查找相似指标，并找出相似指标的计算口径，以便可以正确的迁移到目标指标的计算上来</li></ul><p>根据这里的分析，指标管理需要支持指标的多维度搜索，并需要提供功能展示指标对应的计算代码。</p><h3 id="指标查询支持"><a class="markdownIt-Anchor" href="#指标查询支持"></a> 指标查询支持</h3><p>指标的数据查询是指标管理的另一重要功能。</p><p>在前面的文章<a href="/2021/03/15/data-management-practice/">《数据平台数据管理实践》</a>中，对于指标开发和指标对外服务，我们提到了两条有用的经验。即：</p><ul><li>把计算过程相似的指标合并到一起计算，并只输出为一张表</li><li>将获得的指标表合并为一张数据库宽表输出</li></ul><p>如果可以应用这两条原则，对于指标的使用人员而言，只需要查询最后的指标宽表即可。由于常常只是单表查询，这看起来似乎不是什么问题。但是在指标宽表中进行指标查询并不简单，主要会涉及到维度如何处理的问题。</p><p>举个例子，现在有一个活跃客户数量的指标，需要按照省市区及经销店维度进行统计。</p><p>活跃客户数量在这些维度间并没有汇总关系，因为客户可能会动态的移动。</p><p>比如，客户A在成都市购买了空调，但是后来搬家到了绵阳市，这个客户不再联系成都市的经销店了，但是也并没有完全失去联系，他改为联系绵阳市的经销店了。站在成都市的该经销店来看，此客户已不再活跃。站在四川省的范围来看，该客户还是活跃状态。</p><p>对于这类没有汇总关系的维度，在计算指标时，我们不得不计算每一个维度组合的指标结果。如果将不同维度的指标看做不同的指标，此时我们将得到五个指标：经销店活跃客户数、城市活跃客户数、市级活跃客户数、省级活跃客户数、全国活跃客户数。</p><p>按照前面合并存储的想法，我们可以将它们全部存储到一张数据库表中。如下图：</p><p><img data-src="/attaches/2021/2021-05-27-indicator-management-system/dau.png" alt="dau" /></p><p>由于五个指标都存储到了一张表，在查询时就需要注意：</p><ul><li>查询某经销店活跃用户数：<code>select 活跃客户数 from table where 经销商='A'</code></li><li>查询某城市区域活跃用户数：<code>select 活跃客户数 from table where 经销商 is null and 区='高新区' and 市='成都市'</code></li><li>查询某市级活跃用户数：<code>select 活跃客户数 from table where 区 is null and 市='成都市'</code></li><li>…</li></ul><p>上面的维度存在层级关系，即全国-&gt;省-&gt;市-&gt;区域-&gt;经销店。还有一些维度，它们之间没有层级关系，比如产品的型号和颜色。如果要统计这类维度的数据，那么维度存储上还需要稍加变化。</p><p>比如对于产品型号和颜色的销售指标，我们只支持全国-&gt;省-&gt;市的分析维度，其在数据库表中的存储如下：</p><p><img data-src="/attaches/2021/2021-05-27-indicator-management-system/dau-1.png" alt="dau-1" /></p><p>对应的查询为：</p><ul><li>查询某A型号产品市级活跃用户数：<code>select 活跃客户数 from table where 市='成都市' and 区='高新区' and 经销商 is null and 型号='A' and 颜色 is null</code></li><li>查询某白色产品市级活跃用户数：<code>select 活跃客户数 from table where 市='成都市' and 区='高新区' and 经销商 is null and 型号 is null and 颜色='白色'</code></li></ul><p>这样的查询是比较复杂的，如果需要在开发报表的时候还需要先根据指标存储逻辑来构造这个复杂<code>SQL</code>，那是很低效的，同时也容易出错。</p><p>从上面的分析中可以发现，在设计指标管理系统时，不仅需要在界面上支持数据查询，最好还要支持自动生成对应的查询语句。这个功能可以带来很多好处，比如：1. 可以便于开发人员从命令行查询数据；2. 可以便于下游系统进行数据集成等。</p><h2 id="指标管理系统设计"><a class="markdownIt-Anchor" href="#指标管理系统设计"></a> 指标管理系统设计</h2><p>有了上面的分析，下面来看一下如何设计一个指标管理系统。</p><h3 id="核心概念"><a class="markdownIt-Anchor" href="#核心概念"></a> 核心概念</h3><p>首先来看一下指标管理系统的几个核心概念。根据上面的分析，可以知道，这几个概念是比较重要的，即指标、维度、计算口径。</p><p>它们将包含这样一些属性：</p><ul><li>指标：名称、分类、分析域、计算频率、所支持的维度组、描述、关联的计算口径、关联的代码文件、所在表、对应字段等</li><li>维度：名称、英文名、分类、分析域、描述、说明等</li><li>计算口径：名称、规则、技术说明、关联指标等</li></ul><p>其中，某一个指标常常可以支持多个维度组合，我们可以将其称为维度组。比如，上面的活跃用户数指标就支持这样几个维度组：</p><ul><li>全国维度组：（无）</li><li>省级维度组：省</li><li>城市级维度组：省、市</li><li>区级维度组：省、市、区</li><li>产品型号维度组：省、市、区、产品型号</li><li>产品颜色维度组：省、市、区、产品颜色</li></ul><p>对指标进行查询时，查询将需要在某一个维度组中执行。同时，维度组中的维度如果存在聚合关系，还应该可以支持聚合查询。比如，有了<code>产品颜色维度组</code>，我们事实上可以支持<code>区级维度组</code>的数据查询，只需要将数据按照<code>省、市、区</code>分组，并将指标数据求和即可（对应<code>SQL</code>代码为<code>group by</code>与<code>sum</code>聚合函数）。</p><p>在指标管理系统中，需要支持上述概念对应的实体的信息查询及展示。同时，还需要按照上面的指标维度逻辑进行系统功能设计。</p><h3 id="维度和计算口径相关功能"><a class="markdownIt-Anchor" href="#维度和计算口径相关功能"></a> 维度和计算口径相关功能</h3><p>对于维度和计算口径，这两类实体在系统中只需要支持信息的展示、搜索，一个简单的设计是分别用两个页面来支持这些功能，即搜索页和详情页。其示意实现可以如下。</p><p>维度搜索页和详情页：</p><p><img data-src="/attaches/2021/2021-05-27-indicator-management-system/dim.png" alt="dim" /></p><p>计算口径（或规则）搜索页和详情页：</p><p><img data-src="/attaches/2021/2021-05-27-indicator-management-system/rule.png" alt="rule" /></p><h3 id="指标相关功能"><a class="markdownIt-Anchor" href="#指标相关功能"></a> 指标相关功能</h3><p>对于指标而言，根据上面的分析，可以同样的设计一个搜索页和详情展示页。如下：</p><p><img data-src="/attaches/2021/2021-05-27-indicator-management-system/indicator.png" alt="indicator" /></p><p>除了信息展示之外，还需要在这里支持指标查询的<code>SQL</code>生成。同时，由于生成了<code>SQL</code>，我们可以在指标管理系统中直接支持数据查询。可以设计一个指标查询页面，包含以下功能：</p><ul><li>可以输入数据库连接信息，以便进行指标数据查询</li><li>可以选择维度组进行查询</li><li>可以从维度组中选择想要查询的维度（可以支持按照某些汇总）</li><li>可以设置维度搜索条件，并发起数据查询</li><li>实时的根据维度选项及维度搜索条件生成<code>SQL</code></li><li>支持拷贝<code>SQL</code>，并支持跳转到<code>BI</code>工具进行可视化</li></ul><p>一个示例的设计图如下：</p><p><img data-src="/attaches/2021/2021-05-27-indicator-management-system/indicator-query.png" alt="indicator-query" /></p><h3 id="首页"><a class="markdownIt-Anchor" href="#首页"></a> 首页</h3><p>上面这些功能，如果都以独立的页面存在，将无法以统一的视角展示给用户。所以，一般而言，还需要一个指标管理系统的首页。可以在首页上展示一些统计信息，并提供到达各个功能页的入口。</p><p>一个示例的设计图如下：</p><p><img data-src="/attaches/2021/2021-05-27-indicator-management-system/indicator-home.png" alt="indicator-home" /></p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>本文分析了数据平台中的指标管理相关问题。为了应对这些问题，同时提高团队效率，我们需要建设一个指标管理系统。站在产品设计的角度，本文分析了一个基本的指标管理系统的功能构成，还给出了一个基本的产品设计。</p><p>在数据平台建设过程中，除了常规的数据开发工作，常常还需要有针对性的设计一些辅助系统，本文中的指标管理系统就是一个典型的实例。有了这些辅助系统，我们就可以借助它们将一些重要的经验逐步沉淀下来，同时借助它们提高团队效率。从定位上来说，这类数据辅助软件系统是处于数据平台更上层的。</p><p>从我们整个数据平台建设过程来看，上层软件系统建设也是其中非常重要的一环。</p><h2 id="附录"><a class="markdownIt-Anchor" href="#附录"></a> 附录</h2><h3 id="宽表合并输出的必要性"><a class="markdownIt-Anchor" href="#宽表合并输出的必要性"></a> 宽表合并输出的必要性</h3><p>可能有人觉得指标宽表查询太不方便了，易用性大打折扣，是否可以直接查询合并前的独立的指标表呢？这在实践中会有一些其他问题。</p><p>一般而言，在<code>BI</code>系统进行数据展示时，不能直接从<code>Hive</code>数据仓库中读取数据（否则，由于<code>Hive</code>需要临时启动计算任务来执行查询，延迟将非常高）。常见的做法是将这些数据输出到某一个外部的数据库中，如<code>MySQL</code>、<code>PostgreSQL</code>或<code>ClickHouse</code>等，然后让<code>BI</code>系统去对接这样的外部系统执行查询。</p><p>如果不合并指标宽表，直接将数量庞大的指标表同步到外部数据库中，这会带来以下问题：</p><ul><li>需要将很多张（可能有数百张）数据库表从<code>Hive</code>同步到指标服务数据库，同步速度将非常慢</li><li>外部指标服务数据库占用大量的存储空间（存在很多重复的维度数据）</li></ul><p>而合并指标宽表将能有效的减少数据量（主要是去除了重复的维度数据），并有效减少需要同步的数据表数量，从而缓解上述问题。</p><p>在实践过程中，为了在易用性和易维护性上取得平衡，我们也可以仅选择将维度相同（或相近）的指标进行宽表合并，从而得到少量（而不是只有一张）的指标宽表。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在上一篇文章&lt;a href=&quot;http://brightliao.com/2021/05/26/data-indicator-calculation-practice/&quot;&gt;《指标计算实践》&lt;/a&gt;中，我们分析了指标开发过程，并给出了一些如何复用代码的建议。在一系列指标开发出来之后，如何管理好它们，使之容易访问，并方便的对外提供服务，这是数据平台建设中不得不解决的另一个问题。这里我们将这些问题统一称为指标管理问题。本文希望分享一些相关经验。&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
  </entry>
  
  <entry>
    <title>指标计算实践</title>
    <link href="http://brightliao.com/2021/05/26/data-indicator-calculation-practice/"/>
    <id>http://brightliao.com/2021/05/26/data-indicator-calculation-practice/</id>
    <published>2021-05-26T12:00:00.000Z</published>
    <updated>2023-01-08T08:34:45.587Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2021/2021-05-26-data-indicator-calculation-practice/post-structure.png" alt="post structure" /></p><p>有了数据开发测试工具及<code>DWD</code>模型，数据开发看起来可以顺利往前推进了。下一步是数据开发真正产生业务价值的过程，即指标计算。前面的基础建设其实都是为了指标计算能高效高质量的完成。本文将尝试分享一些关于指标计算的实践经验。</p><p>在前面的文章<a href="http://bright.com/2021/03/15/data-management-practice/">数据平台数据管理实践</a>中，我们提到了基础数据层（也常被称为轻度汇总层）。这一层一般以<code>DWB</code>的缩写来表示，其全称是<code>Data Warehouse Basis</code>。<code>DWB</code>这样的数据分层是业界常见的数据仓库分层实践，对指标计算有很好的参考意义。</p><span id="more"></span><p>指标计算除了要处理指标逻辑之外，一个核心实践就是抽象和构建<code>DWB</code>数据层。本文将尝试分享一般的<code>DWB</code>构建过程，并从开发工具支持上提供一些思路来辅助解决数据应用中的复用问题。</p><h2 id="数据应用中的复用"><a class="markdownIt-Anchor" href="#数据应用中的复用"></a> 数据应用中的复用</h2><p>回顾前面文章中计算空调销量的例子，我们会考虑订单的状态，产品的范围等因素。在实现时，一般需要在第一步就根据这些条件做数据过滤，选出来需要做计算的数据。我们常常将这类数据过滤逻辑称作取数逻辑。</p><p>同样取数逻辑常常会在很多其他指标计算中使用。比如，当需要统计某一个用户产生了多少笔订单以确定高价值用户时，这里的指标取数逻辑就可能跟空调销量指标的取数逻辑相同。这提醒我们需要进行一定的抽象将这部分逻辑在项目中复用起来，以便可以有效的避免<code>bug</code>，并提高交付效率。</p><p>在一般的功能性软件开发中，我们可以通过代码复用来解决这个问题（比如抽象一个公共的模块）。在数据开发中，除了代码复用，还需要考虑计算复用，因为很多大数据量的计算是比较消耗资源的。</p><p>计算复用的一个典型示例还可以从“轻度汇总层”这个名字中引申得到，即某些高级汇总指标可以通过轻度汇总指标计算得到。比如计算空调销量，在业务上，除了希望能计算每日销量，还需要计算每月销量。在计算月销量时，可能可以根据日销量汇总得到。如果这样做，统计月销量可能只需要计算几十条数据就可以了，这可以非常快速的完成。</p><p>在数据应用开发中，我们需要有一些解决复用问题的方案。</p><h2 id="构建dwb层"><a class="markdownIt-Anchor" href="#构建dwb层"></a> 构建<code>DWB</code>层</h2><p>解决数据应用中的复用问题的一个常用思路就是抽象出<code>DWB</code>数据层。由于<code>DWB</code>的数据常常是由一个独立的数据任务产生，所以它同时解决了代码复用和计算复用的问题。</p><p>如何构建一个好的<code>DBW</code>数据层呢？</p><p>可以采用代码重构的思路。比如，在开发第一个指标的时候，我们将所有的代码放在了一起。开发第二个指标的时候，我们发现可以和第一个指标有一定的逻辑复用，于是我们抽象了一个<code>DWB</code>层的数据表，将公共的计算逻辑抽取出来用于构建这个表。构建这个表的代码一般还会形成一个独立的数据计算任务，在数据管道的另一个任务中执行。经过几轮重构之后，我们将得到一些比较稳定的公共层数据表，<code>DWB</code>数据层也就慢慢丰富起来了。</p><p>采用重构的思路构建<code>DWB</code>层数据表存在效率不高的问题。因为计算额外的数据表并不只是需要修改代码，我们还常常需要因此多次重跑数据。对于很多指标而言，都需要计算历史数据指标，这里的量级通常是很大的，在我们的实践过程中，重新跑一次全部历史数据可能需要一天到一周。相比修改代码，其实重新跑数据花费的时间更长。</p><p>更高效的做法可能是一开始就能有一个好的<code>DWB</code>表设计。这需要对业务和数据有足够的了解，同时有较多的数据开发经验。从我们的实践来看，这里的设计也有不少值得参考的经验。</p><p>从需要设计的数据表来看，一般的数据统计都会基于事实表展开，所以，我们常常可以对常用的事实表设计对应的<code>DBW</code>表。</p><p>从特定表的设计来看，首先是要选择合理的粒度。一般而言，可以选择轻度汇总粒度，也可以选择细节粒度。为了能灵活的支持所有上层指标，选择细节粒度的情况可能是居多的。选好粒度之后，主要有两种设计思路可以参考。一是建立少量字段的全量表，二是建立较多字段的增量表。</p><h3 id="轻度汇总粒度"><a class="markdownIt-Anchor" href="#轻度汇总粒度"></a> 轻度汇总粒度</h3><p>如果选择了轻度汇总粒度来构建<code>DWB</code>层，我们会发现一些<code>DWB</code>直接就存储了最终需要的指标数据。比如每日销量可以作为一个轻度汇总指标，它可以支持高级汇总指标月销量的计算。</p><p>这看起来有点奇怪，不过我们也无需担心，只需要在<code>DM</code>输出层建立一个数据映射即可。这一映射可以通过构建一个简单的物理表来实现。如果不想管理数据任务，也不想产生数据复制，还可以考虑通过数据表视图来实现。</p><h3 id="少量字段的全量表"><a class="markdownIt-Anchor" href="#少量字段的全量表"></a> 少量字段的全量表</h3><p>接下来，我们来看一下如何建立少量字段的全量表。为了阐述这一设计思路，我们主要需要回答几个相关问题。</p><p>为什么需要全量表？答案很简单，因为很多统计需要提取所有数据进行计算。空调销量就是一个例子，从逻辑上看，其统计时间范围是全量数据。有人可能会觉得是不是可以基于每天的销量数据进行汇总。这不总是能得到正确的值，因为订单存在取消、退货等情况。一个正确的销量统计可能需要根据所有订单的最新状态进行计算。</p><p>为什么是少量字段呢？这里的设计方式是建立全量表，即每天的数据分区都是一份全量的数据。既然如此，如果大量的字段都需要每天复制存储，那将带来巨大的存储空间占用。</p><p>字段少到什么程度是合适的呢？这个问题并没有统一的答案。可以参考以下做法：</p><ul><li>一般而言，我们需要提取所有的状态字段(如订单的状态，删除标记状态等)，然后根据这些状态字段计算一些标记字段供上层使用。比如可以将完成状态且非内部奖励且非翻新产品订单标记为<code>is_new_valid_order</code>，在计算销量的时候，可以简单的按这个标记字段进行数据过滤。</li><li>一些常用的关联维度放到这个全量表通常也是合适的。<ul><li>某些数据量特别大的关联表的维度，比如用户的年龄、性别等，尤其可以考虑放到全量表中。由于数据量大（用户表通常可以到千万级别），表关联是很慢的，放在<code>DWB</code>数据层来完成就可以避免上层多次进行数据关联，从而提高效率。</li><li>某些数据量特别小的关联表的维度，比如经销店的属性，可以考虑在全量<code>DWB</code>表中仅保留关联经销店<code>ID</code>，然后在上层进行表关联获取相关维度。是否要应用这个建议可能还需要评估加入这些维度之后会带来多大的存储增量，由于数据都是压缩存储的，这里带来的额外存储可能没有想象的那么大。</li></ul></li></ul><h3 id="较多字段的增量表"><a class="markdownIt-Anchor" href="#较多字段的增量表"></a> 较多字段的增量表</h3><p>一些指标的计算无需使用全量数据，这样的指标计算就可以只关心每日增量数据了。可以根据每日增量数据构建<code>DWB</code>表。</p><p>对于这样的增量数据<code>DWB</code>表，其数据量通常不大，因此，我们常常可以在此完成大部分维度的统一关联。这样上层的指标计算将能更简单更快的完成。</p><p>除了可以在此类<code>DWB</code>表中尽可能多的存储关联维度，计算并存储上面提到的标记字段也是合理的。这样可以推进取数逻辑复用，并有效简化上层指标计算的代码。</p><h3 id="增量的添加字段"><a class="markdownIt-Anchor" href="#增量的添加字段"></a> 增量的添加字段</h3><p><code>DWB</code>表的设计很难一蹴而就，因为指标需求往往不是一开始就确定的，而是随着业务的发展逐步完善的。因此，<code>DWB</code>表的设计需要具备一定的扩展性。这里的扩展性可以通过一定的方法来实现，比如：</p><ul><li>在全量表中尽量保留所有的数据，避免出现由于数据不够用需要全部重新构建数据表的情况</li><li>在新加字段之后，<code>DWB</code>的数据需要重跑，通常耗时很长。此时可以建立一个临时的<code>DWB</code>表，将数据输出到这个临时表中。一旦所有历史数据准备完毕，再一次性将原表归档（可以通过重命名实现）并将临时的<code>DWB</code>表重命名为原表名</li></ul><p>采用上述这样增量的方式完善<code>DWB</code>表，将可以有效减少由设计修改带来的对生产正在运行的指标的影响。</p><h2 id="代码复用"><a class="markdownIt-Anchor" href="#代码复用"></a> 代码复用</h2><p>构建一个物理的<code>DWB</code>层有一定的副作用，主要是需要管理额外的数据计算任务，并且，由于额外的数据计算任务的出现，<code>DWB</code>层计算逻辑的变更可能需要引入大量的数据重新计算。此时，我们也可以考虑只在代码层面进行复用，不构建单独的物理数据分层。</p><p>在刚开始的时候，<code>DWB</code>的设计还不够稳定，经常需要修改，<code>DWB</code>层的变更会尤其频繁，在此时选择只在代码层面进行复用就是一个好的时机。</p><p>我们的指标计算代码一般都是通过<code>SQL</code>编写而成，如何实现<code>SQL</code>代码的复用呢？这可能需要新的技术，或从数据工具上做一些支持。</p><h3 id="视图技术"><a class="markdownIt-Anchor" href="#视图技术"></a> 视图技术</h3><p>一个可选的可直接替代物理<code>DWB</code>分层的技术是视图。特别是对于增量的<code>DWB</code>表，可以考虑用视图的方式来构建。</p><p>通过视图构建<code>DWB</code>表有一些前提条件，那就是所有分区的计算逻辑是一致的，也即每个分区的数据可以由<code>DWD</code>层的对应分区计算得来。比如活跃用户数指标，如果计算口径是最近三天有交互，其计算需要选择最近三天的数据，这就不适合用视图来解决问题了。</p><p>除了视图技术，还有一个新的选择，那就是物化视图。</p><p><code>Hive</code> 3.0中引入了对<code>Materialized view</code>的支持，这就是物化视图了。顾名思义，物化视图就是物理化的视图，即提前计算好的视图，相当于有一个物理表。</p><p>在进行视图查询时，<code>SQL</code>引擎会将视图对应的<code>SQL</code>扩展到待执行的<code>SQL</code>中，所以实际的查询常常很复杂，速度也很慢。而物化视图就可以解决这个问题。</p><p>使用物化视图时，我们无需关心这个物理表的数据是什么时候跑出来的，也无需关心什么时候应该更新，<code>Hive</code>帮我们管理好了这一切。</p><p>由此看来，相比视图，物化视图可能是更好的选择。不过，<code>Hive</code>中的物化视图需要开启事务支持，这增加了一些限制。</p><h3 id="sql片段共享"><a class="markdownIt-Anchor" href="#sql片段共享"></a> <code>SQL</code>片段共享</h3><p>除了可以用视图技术来实现代码的复用，另一个更直接的方式就是共享<code>SQL</code>代码片段。这与我们编写其他语言的代码时抽象一个公共模块的思路一样。</p><p>在<a href="http://bright.com/2021/04/01/data-development-language-and-environment/">数据应用开发语言和环境</a>一文中，我们提到了一个新的<code>SQL</code>语法，即模板。一个简单的包含模板的<code>ETL</code>可以是：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=template.a</span></span><br><span class="line"><span class="comment">-- 将下面的sql片段保存为模板a</span></span><br><span class="line"><span class="number">1</span> <span class="keyword">as</span> a, <span class="number">2</span> <span class="keyword">as</span> b</span><br><span class="line"><span class="comment">-- target=temp.result</span></span><br><span class="line"><span class="comment">-- 读取数据，保存为一个临时的表（Spark的TempView）</span></span><br><span class="line"><span class="keyword">select</span> @&#123;a()&#125;, <span class="operator">*</span> <span class="keyword">from</span> some_table;</span><br></pre></td></tr></table></figure><p>模板可以支持在单个<code>ETL</code>文件中共享代码片段。但我们这里的问题是跨<code>ETL</code>共享代码。其实只需要对<code>SQL</code>处理器进行很少的修改就可以支持共享模板了。</p><p>简单来说，我们可以将共享模板定义到一个单独的文件里面，然后在运行时，先执行共享的模板，再执行模板<code>ETL</code>即可。</p><p>另一个思路是，继续增强<code>SQL</code>，增加新的语法，比如可以支持一个称为<code>include</code>指令的语法。<code>include</code>指令的工作方式类似<code>c</code>语言中的<code>include</code>指令，它可以将指令指定的文件内容扩展到当前位置。有了<code>include</code>指令，我们的<code>ETL</code>写起来可能是下面这样：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- shared_code.snippet.sql</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=template.a</span></span><br><span class="line"><span class="comment">-- 将下面的sql片段保存为模板a</span></span><br><span class="line"><span class="number">1</span> <span class="keyword">as</span> a, <span class="number">2</span> <span class="keyword">as</span> b</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- etl.sql</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- include=shared_code.snippet.sql</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=temp.result</span></span><br><span class="line"><span class="comment">-- 读取数据，保存为一个临时的表（Spark的TempView）</span></span><br><span class="line"><span class="keyword">select</span> @&#123;a()&#125;, <span class="operator">*</span> <span class="keyword">from</span> some_table;</span><br></pre></td></tr></table></figure><p>为支持这个新语法，我们需要在<code>SQL</code>处理器里面增加一个预处理的过程，在该预处理阶段完成文件内容扩展。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>指标计算过程中的一个重要问题是如何进行复用。本文尝试从<code>DWB</code>的构建及公共<code>SQL</code>片段提取两个方面分享了我们的一些实践经验。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/attaches/2021/2021-05-26-data-indicator-calculation-practice/post-structure.png&quot; alt=&quot;post structure&quot; /&gt;&lt;/p&gt;
&lt;p&gt;有了数据开发测试工具及&lt;code&gt;DWD&lt;/code&gt;模型，数据开发看起来可以顺利往前推进了。下一步是数据开发真正产生业务价值的过程，即指标计算。前面的基础建设其实都是为了指标计算能高效高质量的完成。本文将尝试分享一些关于指标计算的实践经验。&lt;/p&gt;
&lt;p&gt;在前面的文章&lt;a href=&quot;http://bright.com/2021/03/15/data-management-practice/&quot;&gt;数据平台数据管理实践&lt;/a&gt;中，我们提到了基础数据层（也常被称为轻度汇总层）。这一层一般以&lt;code&gt;DWB&lt;/code&gt;的缩写来表示，其全称是&lt;code&gt;Data Warehouse Basis&lt;/code&gt;。&lt;code&gt;DWB&lt;/code&gt;这样的数据分层是业界常见的数据仓库分层实践，对指标计算有很好的参考意义。&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
  </entry>
  
  <entry>
    <title>数据任务流水线</title>
    <link href="http://brightliao.com/2021/05/24/data-pipeline-for-data-project/"/>
    <id>http://brightliao.com/2021/05/24/data-pipeline-for-data-project/</id>
    <published>2021-05-24T12:00:00.000Z</published>
    <updated>2022-12-30T05:15:34.174Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h2 id="数据流水线"><a class="markdownIt-Anchor" href="#数据流水线"></a> 数据流水线</h2><p>在数据平台中进行数据开发时，数据任务流水线是常用于组织各个计算任务的方式。</p><p>比如，我们要想完成一个指标计算。第一个数据任务是将数据接入到数据平台，接着，需要一个任务将数据进行初步的数据清洗形成<code>DWD</code>中的数据，然后，下一个任务可能是计算初级汇总数据存入<code>DWB</code>，再然后，需要一个数据任务计算得到最终的指标结果，还有一些后续任务，比如宽表构建，导出到外部数据库中进行大屏展示等。</p><p>这一系列的任务需要按照先后关系一步步的完成，于是它们就构成了数据任务流水线。</p><span id="more"></span><p>实际项目中的流水线通常会非常复杂，因为我们有很多指标需要计算，它们各自会依赖不同的表。最终的数据流水线形态会是一系列有向无环图，这就是我们常说的<code>DAG</code>。</p><p>数据任务流水线看起来和<code>CI/CD</code>流水线有类似的特点。技术人员甚至会觉得可以用持续集成流水线来构建这样的数据任务流水线。事实上，用<code>Jenkins</code>或者<code>GoCD</code>也可以构建这样的流水线，但是由于它们主要被用作持续集成工具，实际使用下来会发现缺乏了很多数据流水线管理需要的功能。</p><h3 id="流水线设计"><a class="markdownIt-Anchor" href="#流水线设计"></a> 流水线设计</h3><p>那么，这样的数据流水线应该如何设计？需要有哪些管理功能呢？</p><p>回顾数据任务的各个步骤，可以发现需要设计以下这些数据流水线：</p><p>一、定期（如每天）自动触发的数据任务流水线，它将完成定期的数据接入，清洗，指标计算，宽表构建，宽表输出这一系列任务。这一流水线通常是端到端可输出指标结果的流水线。</p><p>二、首次全量数据接入任务流水线，用于第一次将全量数据接入到数据平台。它应该是手动触发的。</p><p>三、与定期自动运行的流水线相同的，但只能手动触发运行的一条流水线。这一流水线的引入是必要的，因为它可以很好的应对日常数据开发运维工作。</p><p>第一条流水线是比较好理解的。在实践中，一般我们会设计一个名为<code>data_date</code>（数据时间）的流水线参数，所有数据任务都需要计算这个参数指定的时间的数据。</p><p>第二条流水线也是必要的，因为第一次全量数据接入任务难以通过自动流水线来支持。如果强行通过参数来支持，将导致流水线的复杂度上升，同时也不便于团队理解。从单一职责原则来讲，也不建议用定期执行的流水线来支持需要手动执行的、运行次数很少的流水线。</p><p>第三条流水线的引入可能不太好理解。前面提到它是为了解决日常的数据开发运维工作，具体是指哪些呢？请看下面这些场景。</p><p>第一个场景是，当我们新开发了一个指标，除了需要计算指标上线之后的数据之外，还需要计算历史的数据的时候。此时，我们往往无法在自动触发运行的流水线中完成这样的任务，因为历史数据的时间跨度可能很长（比如一年），而自动运行的流水线一般只能计算某个固定时间点（如某一天）的数据，这将导致大量的历史任务需要调度运行，从而带来性能问题。</p><p>这里的性能问题可以简单分析一下。在执行分布式计算任务时，第一步是需要分配并启动计算资源。这一步常常比较耗时，如果使用流水线来调度，则每一个任务都需要重复这一过程，从而产生了大量的无必要的时间消耗。一个直接的优化方式是只启动一个任务，分配一次资源，将一系列的同类任务一次性执行完。不仅如此，如果多个时间点的数据计算可以通过分组聚合（<code>group by</code> + <code>aggregation</code>）来实现（比如，每日订单数量指标就可能可以通过分组聚合一次性计算一个长时间范围的数据），那将可以直接一次性计算一段时间的指标数据，这显然是性能更好的优化方式。不过，这样一来，就可能无法和自动运行的流水线共享同一套代码了。</p><p>通过一条独立的手动运行的流水线将很容易做到上述这些优化，所以，单独设计这样的流水线是值得的。</p><p>另一个类似的场景是在需要修改已有的指标的计算口径时。此时也常常需要重新计算一个很长时间段的数据任务。</p><p>除了上面的场景，还有一些其他的场景，比如某一天在<code>ODS</code>层执行了必要的数据修改，需要重跑某一些数据任务。</p><p>总之，设计一条与自动运行的流水线相同的手动运行的流水线好处多多。从我们的实践来看，是非常值得推荐的做法。</p><p>从上面的分析来看，这个手动运行的流水线还需要很好的支持只运行流水线中的部分任务。这一特性可以通过设计流水线参数来实现。比如，在我们的流水线中设计了两个参数，即<code>include</code>和<code>exclude</code>，分别表示需要包含的和需要排除的数据任务。</p><p>一个示例的数据任务流水线如下：</p><p><img data-src="/attaches/2021/2021-05-24-data-pipeline-for-data-project/data-pipelines.png" alt="data pipelines" /></p><h3 id="任务间依赖的实现"><a class="markdownIt-Anchor" href="#任务间依赖的实现"></a> 任务间依赖的实现</h3><p>通过数据流水线可以较好的管理数据任务间的依赖，同一条流水线中的任务总是会按照流水线中的先后顺序运行。</p><p>在实践过程中，我们会发现还存在一类跨流水线的任务依赖。比如，一般而言，我们会为每一个业务系统设计一条数据流水线（如售前系统流水线、售后系统流水线），但某些指标的计算会同时依赖多个业务系统的数据（比如售前到售后的转化率就需要依赖售前系统和售后系统数据）。这类指标的计算任务就会产生跨流水线的任务依赖（对于售前到售后转化率指标，它将同时依赖售前系统和售后系统流水线中的<code>DWD</code>数据层构建任务）。</p><p>如何解决跨流水线的任务依赖呢？一些流水线工具为这种场景提供了支持，比如，<code>Airflow</code>提供了一个虚拟的<code>ExternalTaskSensor</code>任务，它将等待其它流水线中的某一个任务完成，然后才会完成。</p><p>依赖流水线工具完成依赖任务检查是一个简单可行的方案。但是在实践中，仅使用工具进行依赖管理还显得不太够。比如，处于某种维护目的，我们需要将某一个数据分区删除重建。手动删除该分区之后，在数据流水线中，该任务的后续任务不会失败，而是会继续运行，这就可能导致其计算的结果不对。</p><p>所以，我们更推荐的做法是，除了使用工具来管理任务依赖，最好还能在任务的<code>ETL</code>代码中先对依赖的数据执行严格的检查再执行计算。</p><p>使用我们前面提到的<code>SQL</code>增强语法，一个简单的依赖检查示例如下。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 销量指标的计算依赖当天的`DWD`数据层中的订单表构建完成，强制检查对应的数据分区是否存在</span></span><br><span class="line"><span class="comment">-- target=check.ensure_partition_exists(dwd_sales.sales_order_h, $&#123;DATA_DATE&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- target=...</span></span><br></pre></td></tr></table></figure><p>上面的检查实际上是一个双保险，可以更进一步确认前置步骤是完成了的。</p><p>对于跨流水线的任务依赖，用这种方式有更好的效果。因为如果使用流水线工具来实现，则会导致流水线难以理解。试想，如果有两条以不同频率运行的流水线，我们能简单的推断出有跨流水线依赖的任务会什么时候运行吗？</p><p>但是，如果通过<code>ETL</code>代码检查来保证这种依赖关系，情况就会更简单了。代码里面明确的指定了<code>ETL</code>的输入依赖。</p><p>我们甚至可以摈弃掉复杂的跨流水线依赖配置，仅通过<code>ETL</code>代码来保证依赖关系。此时，我们可能需要配置好该检查的重试次数及超时时间（根据数据任务启动及运行时间进行设置）。</p><h2 id="流水线管理及工具选择"><a class="markdownIt-Anchor" href="#流水线管理及工具选择"></a> 流水线管理及工具选择</h2><p>前面分析了数据任务流水线的设计，可以看到，这样的设计对流水线工具提出了一些要求。持续集成工具如<code>Jenkins</code>或<code>GoCD</code>在这一领域提供的功能比较有限，在工具选择上，我们还需要更为专业的特定工具。</p><p>由于这类流水线工具的核心的功能是辅助进行<code>ETL</code>任务调度，我们也常常将其称作调度系统。常用的此类调度系统有<code>Oozie</code> <code>Airflow</code> <code>Azkaban</code>等。</p><p>这类调度系统通常提供了非常丰富的任务调度功能，其中有些是必要的，而另一些在数据流水线管理中则使用较少。下面，我们从任务调度需求出发，来分析一下一些基本的功能需求。</p><h3 id="流水线创建和编辑"><a class="markdownIt-Anchor" href="#流水线创建和编辑"></a> 流水线创建和编辑</h3><p>最基本的调度系统功能是需要支持以上流水线设计。如果流水线的配置人员更习惯使用界面化的配置，那应该提供一套基于web的配置界面，可以让用户可视化的编辑流水线，实现如添加节点，修改节点，配置节点任务，配置节点参数的功能。</p><p>可视化流水线配置可以很好的提升易用性，但其功能实现会较为复杂，且对于流水线的变更不易进行版本控制。</p><p>另一类流水线配置工具仅提供了基于配置文件的配置方式。比如<code>Oozie</code>支持使用<code>XML</code>进行配置，<code>Airflow</code>支持使用<code>Python</code>代码进行配置。它们虽然没有提供可视化的流水线编辑，但是大都提供了可视化的查看。这类工具对于习惯编写代码的开发人员其实更为友好，因为流水线配置文件代码可以很好的用版本管理工具管理起来，且可以通过代码实现配置的复用。</p><h3 id="任务调度"><a class="markdownIt-Anchor" href="#任务调度"></a> 任务调度</h3><p>除了流水线的创建和编辑，流水线的任务调度管理是另一个核心的功能。需要支持哪些调度管理功能呢？一般而言，下列功能是需要具备的：</p><ul><li>周期性流水线调度运行。</li><li>手动触发任务重新运行。在一些任务运行失败时，常常需要手动恢复运行，此时，常常还需要支持同时运行该任务的所有下级任务。</li><li>查看任务运行日志。任务日志是分析任务执行失败、时间过长等原因的重要手段。</li><li>控制并发任务数量。由于计算资源限制，常常需要控制可以并行运行的任务数量。还有一些任务，虽然任务间的执行顺序没有要求，但是多个任务不能并行运行，这也可以通过控制并发任务数量来实现。</li><li>周期调度的任务可以依赖前一个调度时点的任务。很多复合指标的计算会依赖上一个时点的数据，如今日销量比昨日的增量，这就需要调度系统可以支持设置这样的依赖。</li><li>支持跨<code>DAG</code>的任务依赖。在一些场景中，我们需要实现跨流水线的集成指标计算，此时就可能需要支持跨<code>DAG</code>的任务依赖。</li></ul><p><code>Airflow</code>和<code>Azkaban</code>可以较好的支持上述功能。它们实际上提供了一个任务状态的抽象，任务可以处于未开始运行、调度中、运行中、重试中、成功、失败等状态。对于上面提到的功能，比如按照依赖关系重新运行一组任务，可以通过将这组任务的状态重置到某一个状态来实现。</p><p>一个完善的任务调度系统的实现是很复杂的，如果有兴趣深入了解，大家可以参考对应的文档，或者阅读对应的开源代码。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>本文结合我们的项目实践，分析了如何在数据平台中设计数据流水线。一般情况下，三条流水线的设计可以较好的支持大部分的数据应用场景。</p><p>同时，本文分析了如何使用调度系统来支持流水线的实现，提到了一些重要的流水线调度功能。一个完善的数据平台最好能提供一站式的功能，而非使用各类设计风格各异的开源工具组合。我们在平台建设阶段虽然可以更多的使用这些工具，但是最好能划清任务调度系统在数据平台中的功能边界，即，有限制的使用这些工具。这可以为后续可能的自研调度系统铺平道路。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;数据流水线&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#数据流水线&quot;&gt;&lt;/a&gt; 数据流水线&lt;/h2&gt;
&lt;p&gt;在数据平台中进行数据开发时，数据任务流水线是常用于组织各个计算任务的方式。&lt;/p&gt;
&lt;p&gt;比如，我们要想完成一个指标计算。第一个数据任务是将数据接入到数据平台，接着，需要一个任务将数据进行初步的数据清洗形成&lt;code&gt;DWD&lt;/code&gt;中的数据，然后，下一个任务可能是计算初级汇总数据存入&lt;code&gt;DWB&lt;/code&gt;，再然后，需要一个数据任务计算得到最终的指标结果，还有一些后续任务，比如宽表构建，导出到外部数据库中进行大屏展示等。&lt;/p&gt;
&lt;p&gt;这一系列的任务需要按照先后关系一步步的完成，于是它们就构成了数据任务流水线。&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
  </entry>
  
  <entry>
    <title>基于点的数据分析与数据浏览器</title>
    <link href="http://brightliao.com/2021/05/10/data-browser-for-point-analysis/"/>
    <id>http://brightliao.com/2021/05/10/data-browser-for-point-analysis/</id>
    <published>2021-05-10T12:00:00.000Z</published>
    <updated>2022-12-16T01:48:08.317Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><h2 id="基于数据点的数据分析"><a class="markdownIt-Anchor" href="#基于数据点的数据分析"></a> 基于数据点的数据分析</h2><p>在进行数据分析时，常常会有基于数据点的分析需求。</p><p>比如，当做好一个客户画像应用的时候，我们可以得到某个客户的所有标签。如何验证这些标签的准确性呢？一个常用的方法是找到这个客户所有的相关数据，然后基于这些数据去验证标签的准确性。这就是基于数据点的分析，这里的数据点是前面提到的“某个”客户。</p><p>同样，当开发完指标之后，也可以尝试找出当前指标粒度（比如经销店粒度）下的所有事实及维度数据，从而进行验证。这里的数据点是“某个”经销店。</p><span id="more"></span><p>（下文为了简单，我们将基于数据点的数据分析简称为“点分析”。）</p><h2 id="编写sql实现点分析"><a class="markdownIt-Anchor" href="#编写sql实现点分析"></a> 编写SQL实现点分析</h2><p>想要完成这样的点分析，一般的做法是编写<code>SQL</code>查询相关数据，然后人为分析数据得到结论。</p><p>我们来看一下上面客户画像正确性验证的例子。要验证某一客户的画像，其实是要验证画像中的各种标签。一个典型的标签是客户的价值分级标签，从这个标签可以看出该客户是高价值的，还是低价值的。</p><p>从这个标签的计算口径中可以了解到，这个标签会统计客户在整个生命周期内的所有消费。这里的消费包括购买及后续的维修服务、保养服务等。</p><p>基于前面文章中建立的数据仓库模型，要实现这一分析，我们需要查询当前最新的业务数据，找出相关事实数据。</p><p>以“购买”事实为例，可以编写类似以下代码：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id <span class="keyword">from</span> (</span><br><span class="line">    <span class="keyword">select</span> <span class="operator">*</span>,</span><br><span class="line">        <span class="comment">-- 先根据订单id进行分组，然后根据时间排序，得到序号</span></span><br><span class="line">        <span class="built_in">row_number</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> id <span class="keyword">order</span> <span class="keyword">by</span> update_time <span class="keyword">desc</span>) n</span><br><span class="line">    <span class="keyword">from</span> <span class="keyword">order</span></span><br><span class="line">) order_with_sequence</span><br><span class="line"><span class="keyword">where</span> n <span class="operator">=</span> <span class="number">1</span>  <span class="comment">-- 取序号为1的订单，即最新订单</span></span><br><span class="line">    <span class="comment">-- 筛选客户相关的数据。这里的筛选不能放在内部查询order_with_sequence中完成，其语义不同，可能筛选出非预期的数据。</span></span><br><span class="line">    <span class="keyword">and</span> customer_id <span class="operator">=</span> <span class="string">&#x27;&#123;QUERY_CUSTOMER_ID&#125;&#x27;</span>; </span><br></pre></td></tr></table></figure><p>找到所有这些数据之后，需要进一步判断哪些数据是最终产生了有意义的订单的。这一步通常没有看起来那么简单，因为我们可能需要面对的是查询出来的数百个字段，需要从中找出关键的字段，并弄清楚其业务意义。</p><p>指标的计算口径在此时只能作为参考，因为这里的标签验证一定程度上就是为了确认计算口径的正确性。</p><p>最准确的答案应当来自当时直接接待该客户的业务人员，但想要联系当时的业务人员来确认也并非易事，通常要耗费较多的沟通时间。</p><p>总之，如何确认这些数据需要花费大量的时间查看及对比各个维度的数据。</p><h2 id="提高点分析的效率"><a class="markdownIt-Anchor" href="#提高点分析的效率"></a> 提高点分析的效率</h2><p>分析上述基于<code>SQL</code>的点分析过程，除了不可避免的需要人为去查看对比数据进行分析，还有一些可以从技术上提供方法进行优化的。比如：</p><ul><li>简化<code>SQL</code>编写的复杂度</li><li>提高<code>SQL</code>查询性能</li><li>提供工具让分析师更容易的查看数据</li></ul><p>下面主要从上述三点来进行分析。</p><h3 id="简化sql编写复杂度"><a class="markdownIt-Anchor" href="#简化sql编写复杂度"></a> 简化SQL编写复杂度</h3><p>比如上述查询最新订单的查询语句，需要分析人员正确理解如何提取最新数据。这里面涉及了一个不容易让人理解的开窗操作，并使得<code>SQL</code>更复杂了。</p><p>一个直接的解决方案是，对每张表的数据都建立一个最新数据的视图，查询最新数据的时候就无需关心这样的开窗操作。</p><p>对于订单，我们可以创建如下视图：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">view</span> order_latest_v <span class="keyword">as</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> (</span><br><span class="line">    <span class="keyword">select</span> <span class="operator">*</span>,</span><br><span class="line">        <span class="comment">-- 先根据订单id进行分组，然后根据时间排序，得到序号</span></span><br><span class="line">        <span class="built_in">row_number</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> id <span class="keyword">order</span> <span class="keyword">by</span> update_time <span class="keyword">desc</span>) n</span><br><span class="line">    <span class="keyword">from</span> <span class="keyword">order</span></span><br><span class="line">) order_with_sequence</span><br><span class="line"><span class="keyword">where</span> n <span class="operator">=</span> <span class="number">1</span> </span><br></pre></td></tr></table></figure><p>这样一来，查询某一客户的订单的<code>SQL</code>就变成：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> order_latest_v <span class="keyword">where</span> customer_id <span class="operator">=</span> <span class="string">&#x27;&#123;QUERY_CUSTOMER_ID&#125;&#x27;</span></span><br></pre></td></tr></table></figure><p>这一查询就比之前的查询简单很多了。对于数据分析师而言，他们就可以更高效的完成这类分析工作。</p><h3 id="提高sql查询性能"><a class="markdownIt-Anchor" href="#提高sql查询性能"></a> 提高SQL查询性能</h3><p>上述<code>SQL</code>在实际运行过程中可能会比较慢，主要是开窗和排序操作可能带来较多的数据<code>shuffle</code>（为了完成排序，各个子任务执行器需要相互传递数据）。</p><p>在我们的测试环境（1TB内存，100核）中，使用<code>Hive</code>对于一个大约1亿数据量200个字段的事实表进行查询，其响应时间超过了5分钟。对于数据分析师而言，这样的性能无疑将大大降低数据分析的效率。</p><p>所以很有必要从技术上提供一种高效的主要以业务键（通常是ID）作为查询条件的查询。</p><p>有以下技术方案可以提升这样的查询性能：</p><ul><li>对最新数据的视图进行物化，这样一来，耗时开窗和排序操作就可以预先计算好，而不是在查询时临时计算。这是一种典型的用空间换时间的做法。</li><li>采用更高效的技术方案。比如<code>Presto</code>或<code>Trino</code>，由于特定的计算优化，它们对基于<code>ID</code>类的查询响应更快。还比如<code>ClickHouse</code>，由于查询时大量使用向量计算，在这一场景下，其性能比<code>Hive</code>或<code>Spark</code>高很多。</li></ul><p>在实际情况下，我们常常可以综合考虑这些技术来设计技术方案。</p><h3 id="提供特定分析工具"><a class="markdownIt-Anchor" href="#提供特定分析工具"></a> 提供特定分析工具</h3><p>即便有了上述两点优化，基于<code>SQL</code>的点分析易用性还是不够好，因为分析师总是需要手动编写<code>SQL</code>来实现其查询。</p><p>仔细考察此类分析过程，可以发现以下模式：</p><ul><li>主要基于业务键（如客户ID）进行数据查询</li><li>希望方便的查看更多列的数据</li><li>希望方便的找到关联的其他表的数据</li><li>希望能只查看最新数据</li><li>希望能看到数据变更</li></ul><p>能不能基于这些模式来设计一个数据分析工具呢？</p><p>这个分析工具最好基于当前流行的<code>web</code>技术实现，以便用户直接打开浏览器即可使用。最好有一些便捷易用的功能可以支持上述分析过程，不用手动输入<code>SQL</code>进行查询，只需点击按钮或输入少许信息即可。</p><h2 id="数据浏览器"><a class="markdownIt-Anchor" href="#数据浏览器"></a> 数据浏览器</h2><p>事实上，前面提到的提高点分析效率的另外两点方法也可以受益于一个专用的<code>Web</code>分析工具。</p><p>主要的益处在于，有了分析工具，对于数据分析师而言，就无需关心底层实现机制了。用于获取最新数据的视图或物化视图，以及这些数据的存储位置，对于数据分析师而言都是透明的，他们只需要关注在数据分析这件事情本身上面。从这里的分析可以发现，整个点分析过程将能得到巨大的效率提升，从而更快产生价值。</p><p>如何设计实现这样一个数据工具呢？</p><h3 id="交互设计"><a class="markdownIt-Anchor" href="#交互设计"></a> 交互设计</h3><p>从数据分析师的用户旅程和使用场景进行分析，我们可以据此设计出点分析工具的交互流程。</p><p>对于最简单的数据搜索场景，可以分为以下几个步骤完成，即：</p><ul><li>选择需要分析的数据表</li><li>选择当前分析所关注的字段（有一些数据表的字段非常多）</li><li>输入字段筛选条件</li><li>点击查询，即可在表格中显示数据</li></ul><p>对于查询最新数据的场景，可以在搜索框附近设置搜索属性，这可以通过一个名为“仅显示最新值”复选框来实现。选中此复选框之后，获取的数据将不包括历史数据。</p><p>点分析还会关注某一条数据的变更情况。比如，分析订单状态的变更，可以知道该订单的实际业务流转情况。</p><p>这也可以通过设置搜索属性来实现。同样，可以设计一个名为“高亮变更”这样一个复选框，当分析师选中了这一复选框之后，搜索结果将高亮显示每一条数据的变化了的字段。</p><p>如果字段过多，可能会出现很多分析师不关心的无变化的数据列，此时如果可以有一个功能隐藏这些列就不错了。这一特性同样可以通过复选框来实现。我们可以设计一个“隐藏无变更列”复选框来实现。</p><p><img data-src="/attaches/2021/2021-05-10-data-browser-for-point-analysis/databrowser1.png" alt="data browser" /></p><p>从用户体验的角度来看，还有一些可以纳入分析工具的有用的功能。</p><h4 id="通过外键跳转到相关表的数据"><a class="markdownIt-Anchor" href="#通过外键跳转到相关表的数据"></a> 通过外键跳转到相关表的数据。</h4><p>比如，订单表可以关联到用户表，在浏览订单数据时，自然希望可以跳转到当前订单关联的用户的信息。</p><p>这可以通过在数据表格中为对应列的数据加上跳转链接来实现。</p><p>同时，由于我们同时具备代理键和业务键的关联关系，最好可以在这两个字段中都支持链接跳转。</p><p><img data-src="/attaches/2021/2021-05-10-data-browser-for-point-analysis/databrowser2.png" alt="data browser" /></p><h4 id="查看所有字段数据"><a class="markdownIt-Anchor" href="#查看所有字段数据"></a> 查看所有字段数据</h4><p>在一个数据表格中展示所有列的数据将带来性能问题，并且显示和浏览都不太方便。</p><p>一个简单的想法是，可以在代理键数据列中支持链接，分析师点击此链接时，可以在页面旁边打开一个界面展示这条数据对应的所有字段值。</p><p><img data-src="/attaches/2021/2021-05-10-data-browser-for-point-analysis/databrowser3.png" alt="data browser" /></p><h4 id="初始显示的字段"><a class="markdownIt-Anchor" href="#初始显示的字段"></a> 初始显示的字段</h4><p>当一张表有数百个字段时，给出一个默认的字段选择将是一个很不错的功能。这些默认选中的字段应当是最常用的一些分析字段。</p><p>我们可以统计分析师的使用情况，将最常用的字段提取出来作为这里的默认字段选择。一个简单的统计是从<code>ETL</code>中分析使用到的字段，然后排序取<code>TopN</code>。</p><p><img data-src="/attaches/2021/2021-05-10-data-browser-for-point-analysis/databrowser4.png" alt="data browser" /></p><h4 id="高效的选择字段"><a class="markdownIt-Anchor" href="#高效的选择字段"></a> 高效的选择字段</h4><p>为应对表字段太多的问题，最好还可以优化字段选择体验，使得分析师可以高效的选择需要查看的字段。</p><p>这可以通过以下几个功能点来实现：</p><ul><li>在选择字段的区域提供一个搜索框，分析师可以输入字段名来进行字段搜索</li><li>字段搜索可以支持多个字段的搜索，不同字段以逗号分隔</li><li>如果有搜索条件，字段列表将只显示搜索到的字段</li><li>提供“全选”和“清空”复选框，以便分析师可以全选或清空筛选出来的字段</li></ul><p><img data-src="/attaches/2021/2021-05-10-data-browser-for-point-analysis/databrowser5.png" alt="data browser" /></p><h4 id="快速选择数据表"><a class="markdownIt-Anchor" href="#快速选择数据表"></a> 快速选择数据表</h4><p>当数据表的数量很大的时候，想找到对应的表并切换过去是不容易的。</p><p>一个好的解决办法就是提供模糊搜索。可以在分析师输入一部分字符的时候就自动触发搜索，快速的过滤出包含这些字符的数据表。这可以提高分析师查找数据表的效率。</p><p>另一个可以增加的功能是，将数据表按照对应的业务系统进行分组。由于组的种类相对表的数量更为有限，这就可以辅助分析师找到想要的数据表。</p><p>我们还可以将数据表按照字母表进行排序，这也可以帮助设计师尽快找出想要的数据表。</p><p><img data-src="/attaches/2021/2021-05-10-data-browser-for-point-analysis/databrowser6.png" alt="data browser" /></p><h4 id="提供前进后退的导航"><a class="markdownIt-Anchor" href="#提供前进后退的导航"></a> 提供前进后退的导航</h4><p>前面的功能点有很多是关于跳转的，如果分析师不小心点错了，跳转到了不想浏览的数据，如何恢复到之前的查询结果呢？</p><p>在系统功能设计上可以提供一个前后导航的功能。当分析师点击后退时，界面的搜索及选择条件均切换到之前一次刷新数据的设置。如果分析师没有在此时进行查询条件修改，那么还可以通过点击“前进”按钮恢复到刚刚保存的搜索选项。</p><p><img data-src="/attaches/2021/2021-05-10-data-browser-for-point-analysis/databrowser7.png" alt="data browser" /></p><h4 id="对字段的中文展示"><a class="markdownIt-Anchor" href="#对字段的中文展示"></a> 对字段的中文展示</h4><p>对于数据分析师而言，虽然司空见惯在进行查询时使用英文的字段名，但是如果可以用中文的字段名作为辅助，将是一件喜闻乐见的事。</p><p>在设计系统功能时，可以提供一个切换语言的复选框，比如可以称为“显示中文”。当分析师勾选此复选框时，各处的字段名将以中文显示。</p><p><img data-src="/attaches/2021/2021-05-10-data-browser-for-point-analysis/databrowser8.png" alt="data browser" /></p><p>有了上面这些功能，相信这类点分析做起来就会效率很高了。由于此分析工具主要是完成数据浏览式的数据分析，我们可以将这个工具称作“数据浏览器”。要想“数据浏览器”好用，一个关键的技术要求是基于单表的查询要快速完成，一般而言，用户可接受的查询时间是秒级。如何从技术上进行支撑呢？下面来分析一下一些关键的技术设计。</p><h3 id="技术设计"><a class="markdownIt-Anchor" href="#技术设计"></a> 技术设计</h3><h4 id="元数据的获取"><a class="markdownIt-Anchor" href="#元数据的获取"></a> 元数据的获取</h4><p>“数据浏览器”的实现需要完善的元数据支持。回顾文章<a href="http://bright.com/2021/04/05/dwd-modeling-automation/">《数据仓库建模自动化》</a>中的内容，如果我们采用了基于<code>Excel</code>电子表格来实现自动化的建模，那么电子表格里面就包含了数据浏览器所需的所有元数据了。这些元数据包括数据表的名称，字段的名称、描述，哪些字段是主键（包括业务键和代理键），哪些字段是外键等。</p><p>在实现时，可以直接读取建模电子表格的内容，然后提取所有相关元数据，再在浏览器端加载这些元数据进行网页渲染即可。</p><h4 id="基于clickhouse的方案"><a class="markdownIt-Anchor" href="#基于clickhouse的方案"></a> 基于ClickHouse的方案</h4><p>前面在讨论“提高SQL查询性能”时提到，为了支持高效的单表查询，技术上可以考虑采用基于<code>Presto</code> <code>Trino</code> 或<code>ClickHouse</code>的方案。</p><p>在我们的实践中，选择了<code>ClickHouse</code>的方案。它的主要优势是提供了<a href="https://clickhouse.tech/docs/en/interfaces/http/">基于<code>Http</code>的查询接口</a>，这样一来，在实现时可以直接访问<code>ClickHouse</code>的查询接口，无需进行任何的服务器端开发工作。此时，<code>SQL</code>的构造直接在客户端中完成，甚至还可以提供一个展示<code>SQL</code>和拷贝<code>SQL</code>的功能，以便分析师可以保留这个查询在其他地方使用。</p><h4 id="安全性"><a class="markdownIt-Anchor" href="#安全性"></a> 安全性</h4><p>有人可能会担心安全性问题，毕竟<code>SQL</code>是从客户端发起的，这是不是给了恶意用户更多的攻击系统的可能？这个问题其实并没有想象的那么严重。我们可以类比<code>BI</code>工具或一些支持<code>SQL</code>的分析工具，它们的实现原理和安全性其实是一致的。</p><p>在客户端实现时，可以考虑提供一个输入框给分析师输入数据库连接信息及用户名密码，而不是直接由系统预置这样的信息。这样一来，数据安全控制就交给数据库来实现了。<code>ClickHouse</code>提供了较为完善的账号及权限控制机制，此时的安全性完全交给了<code>ClickHouse</code>来实现。</p><h4 id="弊端"><a class="markdownIt-Anchor" href="#弊端"></a> 弊端</h4><p>当前<code>ClickHouse</code>的方案也有弊端，一是需要额外多一个数据同步的过程，将数据从大数据平台同步到<code>ClickHouse</code>中，这带来了额外的维护负担和数据存储。另一个问题是，数据安全的控制也需要进行额外的配置。</p><p>对于数据安全，在实践中，一个值得考虑的做法是，将<code>Ranger</code>中的安全规则进行解析，然后将其迁移到<code>ClickHouse</code>中。比如，我们可以根据<code>Ranger</code>中的配置生成<code>ClickHouse</code>中的视图，然后只给分析师授予视图的访问权限，而不是物理表的访问权限。</p><p>这样做可以很好的应对安全规则少、粒度相对粗的场景（即用户共享同样的少数几套安全规则，或者基于少数的组进行授权）。但如果希望每个用户都支持一套独立的安全规则配置，则在实现时可能需要创建很多的视图，在管理上会带来一些不便。不过，由于安全规则配置和管理本身是一件比较麻烦的事情，相信大多数公司都不会将粒度做得太细，所以，这套方案应该可以解决大部分场景下的问题。</p><p>到这里，这个“数据浏览器”工具就跃然纸上了，经过上面的分析，我们应该可以较容易的实现这样一个数据分析工具。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>最后，总结一下全文。本文基于数据验证的场景提出了基于数据点的数据分析方法，接下来分析了如何实现这样的分析过程，以及如何从技术上支持这样的分析过程。接着，从设计专用的数据分析工具的思路出发，我们设计了一个基于<code>Web</code>的“数据浏览器”工具，它提供了丰富的功能，可以很好的支持“点分析”，可以很大程度上提高“点分析”的效率。最后，我们分析了如何从技术上进行“数据浏览器”的实现，对几个关键的问题进行了阐述。</p><p>事实上，还有很多其他的分析场景是可以从“点分析”中受益的，比如刚开始进行探索式数据分析时，“点分析”是一个很好的深入了解某一个业务场景的方法。经过技术分析可以发现，这一数据工具的实现也并不是难事。“数据浏览器”可以认为以较低的成本实现较大的价值的一个不错的案例。</p><p>在数据平台构建的过程中，我们常常需要根据实际需要来开发一些数据工具，以便提高效率。但这些数据工具的开发不能直接产生价值，所以，从精益的角度来看，应当评估其实现难度，不应一次性投入太大。这其中的平衡是不容易把握的，本位旨在以“数据浏览器”的案例与诸君共勉。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;基于数据点的数据分析&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#基于数据点的数据分析&quot;&gt;&lt;/a&gt; 基于数据点的数据分析&lt;/h2&gt;
&lt;p&gt;在进行数据分析时，常常会有基于数据点的分析需求。&lt;/p&gt;
&lt;p&gt;比如，当做好一个客户画像应用的时候，我们可以得到某个客户的所有标签。如何验证这些标签的准确性呢？一个常用的方法是找到这个客户所有的相关数据，然后基于这些数据去验证标签的准确性。这就是基于数据点的分析，这里的数据点是前面提到的“某个”客户。&lt;/p&gt;
&lt;p&gt;同样，当开发完指标之后，也可以尝试找出当前指标粒度（比如经销店粒度）下的所有事实及维度数据，从而进行验证。这里的数据点是“某个”经销店。&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
  </entry>
  
  <entry>
    <title>一个ETL自动化测试框架</title>
    <link href="http://brightliao.com/2021/04/25/data-testing-tool/"/>
    <id>http://brightliao.com/2021/04/25/data-testing-tool/</id>
    <published>2021-04-25T12:00:00.000Z</published>
    <updated>2022-12-05T06:19:38.133Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>在前一篇文章<a href="/2021/04/20/data-testing/">《数据测试实践》</a>中，我们探讨了数据应用如何做测试的问题。在数据测试中，<code>ETL</code>脚本的测试是个难题。一般而言，采用高集成度的测试方式（即运行<code>ETL</code>并比对结果，下文称集成测试）是更有效的做法。但是，这类测试的编写和维护却有较高的成本。如何降低<code>ETL</code>集成测试的成本呢？本文尝试从数据工具的角度分享一些我们的经验。</p><span id="more"></span><h2 id="etl集成测试的痛点"><a class="markdownIt-Anchor" href="#etl集成测试的痛点"></a> ETL集成测试的痛点</h2><p>ETL集成测试的编写和维护成本高在哪里呢？</p><p>我们先来看如何编写一个ETL集成测试。</p><p>对于某一个<code>ETL</code>任务，其工作过程一般是三个步骤：读取数据、处理数据、将数据写入新表。为构建这样一个集成测试，我们需要完成这样几步：</p><ul><li>为<code>ETL</code>测试构建一个运行环境</li><li>创建<code>ETL</code>需要读取的表，并将准备好的数据写入</li><li>创建<code>ETL</code>的正确输出结果表，并将准备好的数据写入</li><li>针对测试环境中的表运行<code>ETL</code>（可能需要做一定的修改，因为表名、数据库名可能不一样）</li><li>比对<code>ETL</code>任务生成的数据和第三步中构造的数据，如果两者一致，则测试通过</li></ul><p>一般而言，为了保证测试的有效性，我们希望构建一套类生产环境的<code>ETL</code>测试运行环境。如果额外搭建一套大数据平台环境，这带来的搭建和维护成本就比较高了。同时它还会带来一定的资源消耗，比如我们至少要准备3个节点的计算资源，且需要配置的CPU和内存还不能太低。</p><p>如果我们直接使用生产环境作为测试环境使用，这节省了集群的搭建和维护成本，但我们需要配置好运行<code>ETL</code>测试的用户权限，以防止在测试运行过程中错误的将数据写入了生产环境的数据库表。使用一套环境还有一个缺点，那就是在运行测试之前我们需要修改<code>ETL</code>脚本中的数据库名或数据表名，将它们指向测试对应的库或表。这也是一件麻烦事，而且极容易出错。</p><p>如果需要创建测试用的输入输出表，我们需要在准备测试用例时编写不少建表语句代码。同时，还需要注意数据表的<code>Schema</code>变化，比如某一天由于业务需要，我们将字段名字或类型做了修改，此时测试也不得不跟着修改。</p><p>比对数据这一步，也可能存在问题。由于并行计算的存在，<code>ETL</code>的输出结果中的数据很可能每次都不一样，是乱序的。此时我们在做比较的时候，需要注意将数据顺序对齐，这一般可以通过<code>order by</code>所有字段来实现。</p><h2 id="etl测试框架设计"><a class="markdownIt-Anchor" href="#etl测试框架设计"></a> ETL测试框架设计</h2><p>从以上<code>ETL</code>集成测试痛点分析可以看出，如果不借助任何框架和工具，只靠运维的手段来构建测试，将会非常复杂，且极易出错。如何解决这些痛点呢？我们可以考虑编写一个测试框架来做支持。</p><h3 id="愿景"><a class="markdownIt-Anchor" href="#愿景"></a> 愿景</h3><p>我们希望这个测试框架是轻量级的，简单可用。它不能直接产生价值，因此不能投入太多的精力。同时这个框架应当是易用的，尽量使得团队所有人都能一看就懂。这个框架还需要能辅助完成（或避免）前面痛点分析中的大部分复杂易错的操作。</p><h3 id="需求及设计"><a class="markdownIt-Anchor" href="#需求及设计"></a> 需求及设计</h3><p>要实现以上的愿景，第一个需要回答的问题是，使用者（开发人员或测试人员）应当如何和框架交互。</p><h4 id="交互接口"><a class="markdownIt-Anchor" href="#交互接口"></a> 交互接口</h4><p>在前面的文章<a href="/2021/04/05/dwd-modeling-automation/">《数据仓库建模自动化》</a>中，我们使用<code>Excel</code>电子表格作为交互方式。这里可以参考前面的做法，依然使用电子表格来让用户构建测试。</p><p>电子表格不仅是大家常用的熟悉的工具，还是天生的编辑表格数据的工具，用来构建测试用例应当是非常合适的选择。而且现在很多可以协同编辑电子表格的工具，如<code>Google Spreadsheet</code>等，使得我们可以多人协作进行测试用例的设计和编写。</p><h4 id="模板"><a class="markdownIt-Anchor" href="#模板"></a> 模板</h4><p>电子表格可以非常灵活的编辑数据，为了使得用户可以创建测试用例，我们需要设计一个固定的模板。</p><h5 id="测试文件和测试套件"><a class="markdownIt-Anchor" href="#测试文件和测试套件"></a> 测试文件和测试套件</h5><p>模板应当包含哪些元素呢？</p><p>首先，我们需要能从电子表格测试用例中知道对应的被测试<code>ETL</code>文件是哪个。采用<code>Convention over Configuration</code>的原则，我们可以限制电子表格的文件名，要求其必须和被测试<code>ETL</code>文件名相同。</p><p>其次，在很多现有的测试框架中，多个测试用例可以被组织成测试套件来统一管理。我们也最好能支持测试套件和测试用例。如何在电子表格中定义测试套件和用例呢？可以利用电子表格的标签页<code>Sheet</code>。一个直观的想法就是，每一个标签页是一个测试套件，同时每个标签页内可以支持多个测试用例。</p><p>为了使得标签页与测试套件能对应起来，我们可以限制标签页的名字格式必须为<code>suit_xx</code>。这还能获得一个额外的好处，那就是用户可以自由的添加新的标签页（只要名字不符合前面的规范格式），用于记录一些和该测试相关的信息。</p><h5 id="测试用例"><a class="markdownIt-Anchor" href="#测试用例"></a> 测试用例</h5><p>测试用例如何在电子表格中呈现呢？分析测试用例的必备元素，我们可以知道，一个测试用例应当包含：用例名、输入变量（用于支持<code>ETL</code>中的变量引用）、输入表、输出表。其中，输入表和输出表可以有多个。</p><p>在测试用例中，输入表无需填入原表的全部字段，只填入当前<code>ETL</code>需要用到的字段即可。输出表也可以只包括<code>ETL</code>输出表的部分关键的待验证的字段。</p><p>多个输出表的设计可以很好的支持对中间输出结果的验证。这一设计是更灵活的，它可以使得我们有能力测试到<code>ETL</code>的中间结果，而不只是对<code>ETL</code>的输出进行验证。</p><p>注意到用例中的各类信息的格式是不一样，用例名是一个字符串，输入变量可以是一个包含键值对的字典，输入表和输出表是表格。此时我们可以单独一列来标记信息类型。字符串可以直接置于信息类型旁边的单元格，字典可以置于信息类型旁边的两行表格区域（第一行表示键，第二行表示值）。</p><p>如下图示例，我们设计了一个用例用于测试一个统计空调销量的<code>ETL</code>。该<code>ETL</code>的输入表是<code>DWD</code>层的订单表和用户表，输出表为销量统计信息表。要运行此<code>ETL</code>，需要指定一个变量<code>DATA_DATE</code>，表示需要计算的时间。如果还需要支持其他变量，可以直接在旁边扩展添加。</p><p><img data-src="/attaches/2021/2021-04-25-data-testing-tool/case-design.png" alt="case design" /></p><h5 id="表格"><a class="markdownIt-Anchor" href="#表格"></a> 表格</h5><p>表格格式的支持非常简单，因为它可以和电子表格可以直接对应起来。在对应的输入类型后面，我们可以添加一列表示表名，如上图所示的订单表<code>dwd.fact_order_h</code>、用户表<code>dwd.dim_user_h</code>、输出表<code>dm.order_sales_count</code>。表名后面就可以是数据内容了。为了使得表格更容易理解和编辑，我们可以给列名所在的行标记一下特殊的颜色。如下图所示。</p><p><img data-src="/attaches/2021/2021-04-25-data-testing-tool/case-table-design.png" alt="case table design" /></p><p>上图中，我们把测试数据也填充了进去。事实上，在输出表格的数据中，我们还可以利用电子表格的公式功能来计算数据。比如，输出表格中的<code>province</code>值<code>四川</code>是通过用户表中的<code>province</code>值得来的，于是我们可以使用公式<code>=E10</code>来填充其值。如下图所示。</p><p><img data-src="/attaches/2021/2021-04-25-data-testing-tool/case-output-formula.png" alt="case output formula" /></p><p>使用公式来计算输出数据，可以帮助测试用例设计人员更好的理解输入和输出间的关系，大大加强了测试用例的可读性。在实际编写测试用例时，应该鼓励大家多使用这个功能。</p><h5 id="业务注解"><a class="markdownIt-Anchor" href="#业务注解"></a> 业务注解</h5><p>我们在前面的文章<a href="/2021/04/20/data-testing/">《数据测试实践》</a>中提到，<code>ETL</code>代码更容易出错的一个地方在于开发人员对业务和数据的理解不足。是不是可以通过测试用例的设计促进大家去加强对业务和数据的理解呢？</p><p>注意到输入表格的表名下面的单元格都是空的，是不是可以利用这个地方来加入一些数据注解呢？</p><p>事实上，我们可以要求测试用例设计人员必须对每一行数据添加注解，以注明数据的来历。这可以当做测试框架强加的一个设计限制。</p><p>这一设计虽然表面上看增加了测试用例设计人员的工作量，但是它带来的价值是巨大的。比如：</p><ul><li>可以很好的促进测试设计人员去思考数据来源，以便加强对业务和数据的理解</li><li>测试设计人员更加不容易设计出一些根本不存在的数据组合，从而保证测试的有效性</li><li>可以进一步增强测试的可理解性</li></ul><p>上述第二点非常重要，因为如果按照一般的软件测试用例设计方法去设计测试，则可能会设计出很多根本不存在的边界场景。比如示例中订单表的<code>user_key</code>字段是关联到用户表的外键，在业务上它不可能为空，但是如果没注意到这样的业务限制，则可能设计出为空的用例场景来。</p><p>由于输入数据是业务系统产生的，业务系统本身会对数据加入很多业务限制，所以很多数据组合是根本不会出现的，当然也没必要设计测试用例去覆盖了。如果设计出了很多类似上例这样的无效测试，则将对团队的测试构建和维护将带来非常多没必要的负担。</p><p>通过标注数据来历，可以较好的解决这个问题，因为它要求测试数据设计人员必须思考数据来历，从而促进测试设计人员去弄清当前数据是通过什么样的业务流程产生的。</p><p>下面是一个添加了注解的测试用例。</p><p><img data-src="/attaches/2021/2021-04-25-data-testing-tool/case-input-annotation.png" alt="case input annotation" /></p><h3 id="etl测试框架实现"><a class="markdownIt-Anchor" href="#etl测试框架实现"></a> ETL测试框架实现</h3><p>到这里，一个ETL测试框架的雏形已经显现出来，下面就是如何实现这一框架了。</p><p>考虑到电子表格不方便进行版本管理，我们可以参考之前的做法，尝试定义一个中间测试文件格式来存储电子表格中的测试用例。于是我们的框架的工作流程就变成：</p><p><img data-src="/attaches/2021/2021-04-25-data-testing-tool/workflow.png" alt="case work flow" /></p><p>我们需要开发两个工具，一个进行格式转换，另一个执行测试。</p><h4 id="格式转换工具"><a class="markdownIt-Anchor" href="#格式转换工具"></a> 格式转换工具</h4><p>格式转换工具只需要读取电子表格，然后将其内容保存为另一个格式即可。</p><p>选择什么格式呢？常用的保存数据的文件格式可以是<code>json</code> <code>yaml</code>等。这里我们考虑选择<code>json</code>格式。</p><p>在进行数据存储时，需要注意中间文件的可读性。一是可以考虑存储格式化之后的数据。二是需要关心格式化后的数据是否易读。</p><p>由于测试用例中有很多表格数据，如果我们把数据存储为一个二维列表（或对象的列表），文件内容将会非常长，可读性会较差，也不便于进行版本比较。一种更好的方式是将表格数据中的一行存储为文件中的一行，可以考虑使用嵌套的<code>json</code>来存储表格数据。比如以下示例：</p><p><img data-src="/attaches/2021/2021-04-25-data-testing-tool/json-case.png" alt="json case" /></p><p>使用<code>Python</code>，我们可以很容易的读取电子表格的内容。这里将会碰到的一个问题是表格中的数据类型的处理。在电子表格中，我们并没有设计一个地方让用户填入数据类型，这可以提升用户体验，但是在工具实现上就会更复杂一些了。</p><p>我们需要想办法找出数据的类型，还需要将电子表格中的数据转换为真实的数据类型。怎么做呢？</p><p>在前面的文章<a href="/2021/04/05/dwd-modeling-automation/">《数据仓库建模自动化》</a>中，我们提到了使用电子表格来做建模，电子表格会记录建模得到的所有表的字段的类型。这可以作为字段类型信息提取的入口。另一方面，如果是中间表，或者<code>DWB</code>层的表，此时我们可以将建表语句放到代码仓库中进行管理，于是可以从这些建表语句中提取字段类型。</p><p>有了字段类型，还需要实现一系列的转换规则，以便将电子表格中的数据转换为真正的类型进行存储。我们还可以把这些附加的信息写入到中间的测试用例文件中。一个较为完整的测试用例中间文件可以为：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;正确统计空调销量&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;etl_sql_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;dm.order_sales_count.sql&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;vars&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;DATA_DATE&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2021-04-25&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;inputs&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;dwd.order_h&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="string">&quot;[\&quot;order_key\&quot;, \&quot;order_id\&quot;, ... ]&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;column_types&quot;</span><span class="punctuation">:</span> <span class="string">&quot;[\&quot;string\&quot;, \&quot;string\&quot;]&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value_descriptions&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">          <span class="string">&quot;用户u1创建订单&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="string">&quot;用户u1付款&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="string">&quot;用户创建u2订单&quot;</span></span><br><span class="line">        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;values&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">          <span class="string">&quot;[\&quot;oa\&quot;, \&quot;o1\&quot;, ...]&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="string">&quot;[\&quot;ob\&quot;, \&quot;o1\&quot;, ...]&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="string">&quot;[\&quot;oc\&quot;, \&quot;o2\&quot;, ...]&quot;</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      ...</span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;outputs&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;dm.order_sales_count&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="string">&quot;[\&quot;province\&quot;, \&quot;is_reward\&quot;, ...]&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;column_types&quot;</span><span class="punctuation">:</span> <span class="string">&quot;[\&quot;string\&quot;, \&quot;boolean\&quot;, ...]&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value_descriptions&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;values&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">          <span class="string">&quot;[\&quot;四川\&quot;, false, ...&quot;</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  ...</span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure><h4 id="测试执行工具"><a class="markdownIt-Anchor" href="#测试执行工具"></a> 测试执行工具</h4><p>测试执行工具的功能是读取格式转换工具的输出，并执行测试。</p><p>首先我们要确定执行的环境。上面分析了如何选择执行环境，我们发现无论使用生产环境还是一个独立的测试环境代价都比较高。怎么办呢？这里可以考虑降低一些集成度，选择直接使用本地的<code>Spark</code>环境来执行测试。虽然和真实的环境会有一些差别，但是考虑到它可以节省很大的工作量并降低风险（无需操作生产环境），这样的取舍是值得的。</p><p>如果使用本地<code>Spark</code>环境，我们需要先为测试用例创建数据表，并写入数据。此时<code>Spark</code>会创建一个临时的数据库用于存储元数据，我们需要指定配置<code>spark.sql.warehouse.dir</code>以便可以设置一个用于存储数据的位置，比如可以设置为一个临时目录<code>/tmp/spark-warehouse-sqltest</code>。（此处如果设置为一个静态的临时目录，可能无法同时运行多个测试，如果有并行运行测试的需求，可以考虑随机生成一个临时目录。）</p><p>在运行<code>ETL</code>之后比较结果时，可以采用前面提到的策略，即将所有字段进行排序，然后依次比较每一行数据。</p><h4 id="生成标准测试用例"><a class="markdownIt-Anchor" href="#生成标准测试用例"></a> 生成标准测试用例</h4><p>测试执行工具本身可以是一个小的应用程序，我们可以通过它来直接运行测试。但是这对开发人员还不够友好，因为它与开发人员常用的测试方式不一样，很多现有的工具无法使用。比如，<code>PyCharm</code>可以识别用<code>Python</code>的测试框架<code>unittest</code>编写的测试，点击代码旁边的运行按钮就可以直接运行。</p><p>如何支持这个特性，以便提升开发人员的体验呢？</p><p>我们可以考虑在生成中间用例文件的时候，再生成一个<code>Python</code>版本的测试用例源代码文件。在实现上，这也不难，使用<code>Jinja</code>模板，可以很容易生成这个文件。</p><h3 id="其他"><a class="markdownIt-Anchor" href="#其他"></a> 其他</h3><p>到这里，我们的<code>ETL</code>测试框架就差不多实现了。框架本身还有哪些可扩展的地方呢？在使用这个框架时，有没有什么需要注意的问题呢？下面有几个点值得一提。</p><h4 id="在测试用例中同时运行多个etl"><a class="markdownIt-Anchor" href="#在测试用例中同时运行多个etl"></a> 在测试用例中同时运行多个<code>ETL</code></h4><p>有时候，我们的<code>ETL</code>可能会被拆分为多个更小的<code>ETL</code>。比如，当某个<code>ETL</code>比较复杂的时候，或者，当某个<code>ETL</code>的一部分代码可以被复用的时候等。</p><p>我们可能会有需求想要在一个测试用例里面运行多个<code>ETL</code>脚本，此时可以考虑扩展上面的<code>ETL</code>测试模板文件，使之可以支持选择需要包含的<code>ETL</code>文件。</p><p>在电子表格设计上，可以考虑新建一个标签页，然后在这一页中存储需要包含的<code>ETL</code>文件列表。事实上，类似<code>ETL</code>文件列表这样的信息可以抽象为测试用例的元信息。在将来我们还可能加入更多的类似元信息。于是，我们可以将这个标签页命名为<code>meta_info</code>。</p><h4 id="什么时候编写etl集成测试"><a class="markdownIt-Anchor" href="#什么时候编写etl集成测试"></a> 什么时候编写<code>ETL</code>集成测试</h4><p>本文讨论的<code>ETL</code>测试框架固然可以提高<code>ETL</code>测试的构建效率，但在使用过程中，需要特别注意的是，我们需要弄清楚何时应该用它来编写测试用例。</p><p>需要记住，每添加一个测试用例，都会增加一定的维护成本。这些成本包括：</p><ul><li>此类测试由于集成度比较高，运行起来并不快。当我们有成百上千个此类测试时，跑一遍所有的测试可能需要数十分钟到数小时。</li><li>当我们需要修改<code>ETL</code>代码时，需要同时修改测试用例。</li></ul><p>在这里，我想强调在文章<a href="/2021/04/20/data-testing/">《数据测试实践》</a>中提到的内容。</p><ul><li>加深对业务和数据的理解，可能比编写<code>ETL</code>测试更重要</li><li>通过<code>SQL</code>自定义函数来降低<code>ETL</code>中的复杂度，可能比编写<code>ETL</code>测试更重要</li><li>通过代码评审和结对编程来保证<code>ETL</code>质量，可能比编写<code>ETL</code>测试更重要</li></ul><h4 id="为测试人员创建etl测试环境"><a class="markdownIt-Anchor" href="#为测试人员创建etl测试环境"></a> 为测试人员创建<code>ETL</code>测试环境</h4><p>除了开发人员需要编写测试，测试人员也需要编写测试。<code>ETL</code>测试框架基于电子表格和用户进行交互，所以即便只有较少的编程背景，测试人员也可以很方便进行测试用例的编写。</p><p>但是，如果测试人员还需要构建一套本地的执行环境，这就不太友好了。我们可以考虑为测试人员搭建一套测试用的本地执行环境，然后将此环境部署成为一个<code>Web</code>服务。一旦可以将测试框架服务化，测试人员只需要打开网页便可以运行测试了，这将大大提高团队的工作效率。</p><p>有一个非常简单的可以实现测试框架服务化的办法，就是利用<code>CI</code>工具。比如在<code>Jenkins</code>中，每一个任务都可以设置一个参数，也包括一个文件参数。那么我们可以在<code>Jenkins</code>中创建一个用于运行测试的任务，然后只需要用户上传一个电子表格即可触发测试运行。</p><p>有了这样服务化之后的测试工具支持，相信团队内部的测试小伙伴们也可以愉快的工作了。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>本文讨论了如何构建一个<code>ETL</code>测试框架，以便用于解决我们编写及运行<code>ETL</code>测试中的痛点。</p><p>利用<code>Excel</code>电子表格，我们构建了一个轻量级的工具。它可以方便的支持测试用例编写和运行，能有效提高团队工作效率。</p><p><code>ETL</code>测试框架虽然好用，但我们还需要谨慎对待构建测试这件事，因为过多的测试可能会带来更高的维护成本。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在前一篇文章&lt;a href=&quot;/2021/04/20/data-testing/&quot;&gt;《数据测试实践》&lt;/a&gt;中，我们探讨了数据应用如何做测试的问题。在数据测试中，&lt;code&gt;ETL&lt;/code&gt;脚本的测试是个难题。一般而言，采用高集成度的测试方式（即运行&lt;code&gt;ETL&lt;/code&gt;并比对结果，下文称集成测试）是更有效的做法。但是，这类测试的编写和维护却有较高的成本。如何降低&lt;code&gt;ETL&lt;/code&gt;集成测试的成本呢？本文尝试从数据工具的角度分享一些我们的经验。&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
  </entry>
  
  <entry>
    <title>数据测试实践</title>
    <link href="http://brightliao.com/2021/04/20/data-testing/"/>
    <id>http://brightliao.com/2021/04/20/data-testing/</id>
    <published>2021-04-20T12:00:00.000Z</published>
    <updated>2022-11-28T01:24:45.115Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p><img data-src="/attaches/2021/2021-04-20-data-testing/structure.png" alt="data testing" /></p><p>在数据平台建设过程中，测试怎么做是一个值得思考的问题。由于数据应用开发和功能性软件系统开发存在很大的不同，在我们实践过程中，在开发人员和质量保证人员间常常有大量关于测试如何实施的讨论。下文将尝试总结一下数据应用开发的特点，并讨论在这些特点之下，对应的测试策略应该是怎么样的。</p><h2 id="功能性软件的测试"><a class="markdownIt-Anchor" href="#功能性软件的测试"></a> 功能性软件的测试</h2><p>先来回顾一下功能性软件系统开发中的测试。</p><span id="more"></span><p>测试一般分为自动化测试和手工测试。由于手工测试对人工依赖程度很高，如果主要依赖手工测试来保证软件质量，将无法满足软件快速迭代上线的需要。现代软件开发越来越强调自动化测试的作用，这也是敏捷软件开发的基本要求。有了全方位的自动化测试保障，就有可能做到每周上线，每日上线甚至随时上线。</p><p>这里主要讨论自动化测试。</p><h3 id="测试金字塔"><a class="markdownIt-Anchor" href="#测试金字塔"></a> 测试金字塔</h3><p>我们一般会按照如下测试金字塔的原则来组织自动化测试。</p><p><img data-src="/attaches/2021/2021-04-20-data-testing/test-pyramid-new.png" alt="testing pyramid" /></p><p>测试金字塔分为三层，自下而上分别对应单元测试、集成测试、端到端测试。</p><p>单元测试是指函数或类级别的，较小范围代码的测试，一般不依赖外部系统（可通过<code>Mock</code>或测试替身等实现）。单元测试的特点是运行速度非常快（最好全部在内存中运行），所以执行这种测试的成本也就很低。单元测试在测试金字塔的最底端，占的面积最大。这指导我们应该构建大量的这类测试，并以这类测试为主来保证软件质量。</p><p>集成测试是比单元测试集成程度更高的测试，它在运行时执行的代码路径更广，通常会依赖数据库、文件系统等外部环境。由于依赖了外部环境，集成测试的运行速度更慢，执行测试的成本更高。集成测试在测试金字塔的中间，这指导我们应该构建中等数量的这类测试。集成测试在<code>Web</code>应用场景中也常常被称为服务测试（Service Test）或<code>API</code>测试。</p><p>端到端测试是比集成测试更靠后的测试，通常通过直接模拟用户操作来构建这样的测试。由于需要模拟用户操作，所以它常常需要依赖一整套完整集成好的环境，这样一来，其运行速度也是最慢的。端到端测试在<code>Web</code>应用场景中也常常被称为<code>UI</code>测试。端到端测试在测试金字塔的顶端，这指导我们应该构建少量的这类测试。</p><p>测试的范围非常广，实施方法也非常灵活。哪里是重点？我们要在哪里发力？测试金字塔为我们指明了方向。</p><h2 id="一般软件的测试"><a class="markdownIt-Anchor" href="#一般软件的测试"></a> 一般软件的测试</h2><p>为了更深入的理解一般软件的测试要怎么做，我们需要进一步深入分析一下测试金字塔。</p><h3 id="测试带来的信心"><a class="markdownIt-Anchor" href="#测试带来的信心"></a> 测试带来的信心</h3><p>上文中的金字塔图示有一个特点并没有反映出来，那就是，越上层的测试给团队带来的信心越强。这还算好理解，试想，如果没有单元测试，只有端到端测试，我们是不是可以认为程序大部分还是可以正常工作的（可能存在一些边界场景有问题）？但是如果只有单元测试而没有端到端测试，我们连程序能不能运行都不知道！</p><p>端到端测试能带来很强的信心，但这常常构成另一个陷阱。由于端到端测试对团队有很大的吸引力，一些团队可能会选择直接构建大量的端到端测试而忽略单元测试。这些端到端测试运行缓慢，一般也难以修改，很快就会让团队举步维艰。缓慢的测试带来了缓慢的持续集成，高频率的上线就慢慢变得遥不可及。</p><p>单元测试虽然不能直接给人很强的信心，但是常常是更有效的测试手段，因为它可以很容易的覆盖到各种边界场景。</p><p>测试金字塔是敏捷软件开发所推崇的测试原则，它是在测试带来的信心和测试本身的可维护性两者中权衡做出的选择。测试金字塔可以指导我们构建足够的测试，使得团队既对软件质量有足够的信心，又不会有太多的测试维护负担。</p><p>既然是权衡，那么我们是否可以以单元测试和集成测试为主，而根本不构建端到端测试（此时端到端测试的功能通过手工测试完成）呢？</p><h3 id="测试集成度"><a class="markdownIt-Anchor" href="#测试集成度"></a> 测试集成度</h3><p>对于一些没有<code>UI</code>（或者说<code>GUI</code>）的应用，或者一些程序库、框架（如<code>Spring</code>）等，很多时候测试金字塔中的三类测试并不直接适用。我们可以这样理解：测试金字塔并非只是三层，它更多的是帮我们建立了在项目中组织测试的原则。</p><p>事实上，对于通用的软件测试，我们可以理解为存在一个集成度的属性。沿着金字塔往上，测试的集成度越高（依赖外部组件越多）。由于集成度更高，测试过程所要运行的代码就更多更复杂，测试运行时间就越长，测试构建和维护成本就越高。实践过程中，为了提高软件质量和可维护性，我们应当构建更多集成度低的测试。</p><p>有了测试集成度的理解，我们就可以知道，其实金字塔可以不是三层，它完全可以是两层或者四层、五层。这取决于我们怎么划定某一类测试的范围。同时，我们还可以知道，其实单元测试、集成测试与端到端测试其实并没有特别明显的界限。</p><p>下面，我们从测试集成度的角度来看如何构建单元测试。</p><p>上文提到，测试最好通过<code>Mock</code>或测试替身等实现，从而可以不依赖外部系统。但是，如果测试<code>Mock</code>或测试替身难以构造，或者构造之后我们发现测试代码和产品代码耦合非常严重，这时应该怎么办呢？一个可能的选择是考虑使用更高集成度的测试。</p><p><code>Spark</code>程序就是这样的一个例子。一旦使用了<code>Spark</code>的<code>DataFrame</code> <code>API</code>去编写代码，我们就几乎无法通过<code>Mock</code> <code>Spark</code>的<code>API</code>或构造一个<code>Spark</code>测试替身的方式编写测试。这时的测试就只能退一步选择集成度更高一些的测试，比如，启动一个本地的<code>Spark</code>环境，然后在这个环境中运行测试。</p><p>此时，上面的测试属于哪种测试呢？如果我们用三层测试金字塔的测试划分来看待问题，就很难给这样的测试一个准确的定位。不过，通常我们无需考虑这样的分类，而是可以把它当做集成度低的测试，即金字塔靠底端的测试。如果团队成员能达成一致，我们可以称其为单元测试，如果不能，称其为<code>Spark</code>测试也并非不可。</p><h3 id="一般软件的测试-2"><a class="markdownIt-Anchor" href="#一般软件的测试-2"></a> 一般软件的测试</h3><p>所以，对于一般的软件测试，我们可以认为测试策略应当符合一般意义的金字塔。金字塔的细节，比如应该有几层塔，每一层的范围应该是什么样，每一层应该用什么样的测试技术等等，这些问题需要根据具体的情况进行抉择。</p><p>在讨论一般软件的测试时，需要关注软件的测试何时停止，即，如何判断软件测试已经足够了呢？</p><p>在老马的《重构 第二版》中，有对于何时停止测试的观点：</p><blockquote><p>有一些测试规则建议会尝试保证我们测试一切的组合，虽然这些建议值得了解，但是实践中我们需要适可而止，因为测试达到一定程度之后，其边际效用会递减。如果编写太多测试，我们可能因为工作量太大而气馁。我们应该把注意力集中在最容易出错的地方，最没有信心的地方。</p><p>一些测试的指标，如覆盖率，能一定程度上衡量测试是否全面而有效，但是最佳的衡量方式可能来自于主观的感受，如果我们觉得对代码比较有信心，那就说明我们的测试做的不错了。</p></blockquote><p>主观的信心指数可能是衡量测试是否足够的重要参考。如果要问测试是否足够，我们要自问是否有信心软件能正常工作。</p><p>在实践过程中，我们还可以尝试分析每次<code>bug</code>出现的原因，如果是由于大部分<code>bug</code>是由于代码没有测试覆盖而产生的，此时我们可能应该编写更多的测试。但如果是由于其他的原因，比如需求分析不足或场景设计不完备而导致的，则应该在对应的阶段做加强，而不是一味的去添加测试。</p><h2 id="数据应用的测试"><a class="markdownIt-Anchor" href="#数据应用的测试"></a> 数据应用的测试</h2><p>有了前面对测试策略的分析，我们来看看数据应用的测试策略。</p><p>数据应用相比功能性软件有很大的不同，但数据应用也属于一般意义上的软件。数据应用有哪些特点，应该如何针对性的做测试呢？下面我们来探讨一下这几个问题。</p><p>根据<a href="/2021/04/01/data-development-language-and-environment/">前面的文章</a>分析，数据应用中的代码可以大致分为四类：基础框架（如增强<code>SQL</code>执行器）、以<code>SQL</code>为主的<code>ETL</code>脚本、<code>SQL</code>自定义函数（<code>udf</code>）、数据工具（如前文提到的<code>DWD</code>建模工具）。</p><h3 id="基础框架的测试"><a class="markdownIt-Anchor" href="#基础框架的测试"></a> 基础框架的测试</h3><p>基础框架代码是数据应用的核心代码，它不仅逻辑较为复杂，而且需要在生产运行时支持大量的<code>ETL</code>的运行。谁也不想提交了有问题的基础框架代码而导致大规模的<code>ETL</code>运行失败。所以我们应当非常重视基础框架的测试，以保证这部分代码的高质量。</p><p>基础框架的代码通常由<code>Python</code>或<code>Scala</code>编写，由于<code>Python</code>和<code>Scala</code>语言本身都有很好的测试支持，这十分有利于我们做测试。</p><p>基础框架的另一个特点是它通常没有<code>GUI</code>。</p><p>按照测试金字塔原理，我们应当为其建立更多的集成度低的测试（下文称单元测试）以及少量的集成度高的测试（下文称集成测试）。</p><p>比如，在<a href="/2021/04/01/data-development-language-and-environment/">前面的文章</a>中，我们增强了<code>SQL</code>的语法，加入了变量、函数、模板等新的语法元素。在运行时进行变量替换、函数调用等等功能通过基础框架实现。这部分功能逻辑较为复杂，应当建立更多的单元测试及少量的集成测试。</p><h3 id="etl脚本的测试"><a class="markdownIt-Anchor" href="#etl脚本的测试"></a> <code>ETL</code>脚本的测试</h3><p><code>ETL</code>脚本的测试可能是数据应用中的最大难点。</p><h4 id="采用偏集成的测试"><a class="markdownIt-Anchor" href="#采用偏集成的测试"></a> 采用偏集成的测试</h4><p><code>ETL</code>脚本一般基于<code>SQL</code>实现。<code>SQL</code>本身是一个高度定制化的<code>DSL</code>，如同<code>XML</code>配置一样。</p><p><code>XML</code>要如何测试？很多团队可能会直接忽略这类测试。但是用<code>SQL</code>编写的<code>ETL</code>代码有时候还是可以达到几百行的规模，有较多的逻辑，不测试的话难以给人以信心。如何测试呢？</p><p>如果采用基于<code>Mock</code>的方法写测试，我们会发现测试代码跟产品代码是一样的。所以，这样做意义不大。</p><p>如果采用高集成度的测试方式（下文称集成测试），即运行<code>ETL</code>并比对结果，我们将发现测试的编写和维护成本都较高。由于<code>ETL</code>脚本代码本身可能是比较简单且不易出错的，为了不易出错的代码编写测试本身就必要性不高，更何况测试的编写和维护成本还比较高。这就显得集成测试这一做法事倍功半。</p><p>这里可以举一个例子。比如对于一个分组求和并排序输出的<code>SQL</code>，它的代码可能是<code>select a, b, c, count(1) from t group by a, b, c order by a, b, c, count(1)</code>。如果我们去准备输入数据和输出数据，考虑到各种数据的组合场景，我们可能会花费很多的时间，这带来了较高的测试编写成本。并且，当我们要修改<code>SQL</code>时，我们还不得不修改测试，这带来了维护成本。当我们要运行这个测试时，我们不得不完成建表、写数据、运行脚本、比对结果的整个过程。这些过程都需要依赖外部系统，从而导致测试运行缓慢。这也是高维护成本的体现。</p><p>可见这两种测试方式都不是好的测试方式。</p><h4 id="测试构建原则"><a class="markdownIt-Anchor" href="#测试构建原则"></a> 测试构建原则</h4><p>那么有没有什么好的原则呢？我们从实践中总结出了几点比较有价值的思路供大家参考。</p><ul><li>将<code>ETL</code>脚本分为简单<code>ETL</code>和复杂<code>ETL</code>（可以通过代码行数，数据筛选条件多少等进行衡量）。简单的<code>ETL</code>通过代码评审或结对编程来保证代码质量，不做自动化测试。复杂的<code>ETL</code>通过建立集成测试来保证质量。</li><li>由于集成测试运行较慢，可以考虑：<ul><li>尽量少点用例数量，将多个用例合并为一个来运行（主要是将数据可以合并成单一的一套数据来运行）</li><li>将测试分级为需要频繁运行的测试和无需频繁运行的测试，比如可将测试分级P0-P5，P3-P5是经常（如每天或每次代码提交）要运行的测试，P0-P2可以低频（如每周）运行</li><li>开发测试支持工具，使得运行时可以尽量脱离缓慢的集群环境。如使用<code>Spark</code>读写本地表</li></ul></li><li>考虑将复杂的逻辑使用自定义函数实现，降低<code>ETL</code>脚本的复杂度。对自定义函数建立完整的单元测试。</li><li>将复杂的<code>ETL</code>脚本拆分为多个简单的<code>ETL</code>脚本实现，从而降低单个<code>ETL</code>脚本的复杂度。</li></ul><h4 id="加深对业务和数据的理解"><a class="markdownIt-Anchor" href="#加深对业务和数据的理解"></a> 加深对业务和数据的理解</h4><p>我们在实践过程中发现，其实大多数时候<code>ETL</code>脚本的问题不在于代码写错了，而在于对业务和数据理解不够。比如，前面文章中的空调销售的例子，如果我们在统计销量的时候不知道存在退货或者他店调货的业务实际情况，那我们就不知道数据中还有一些字段能反映这个业务，也就不能正确的计算销量了。</p><p>想要形成对数据的深入理解需要对长时间的业务知识积累和长时间对数据的探索分析（业务系统通常经历了长时间的发展，在此期间内业务规则复杂性不断增加，导致数据的复杂性不断增加）。对于刚加入团队的新人，他们更容易由于没有考虑到某些业务情况而导致数据计算错误。</p><p>加深对业务和数据的理解是进行高效和高质量<code>ETL</code>脚本开发的必由之路。</p><p>有没有什么好的实践方法可以帮助我们加深理解呢？以下几点是我们在实践中总结的值得参考的建议：</p><ul><li>通过思维导图/流程图来整理复杂的业务流程（或业务知识），形成知识库</li><li>尽量多的进行数据探索，发掘容易忽略的领域业务知识，并通过第一步进行记录</li><li>找业务系统团队沟通，找出更多的领域业务知识，并通过第一步进行记录</li><li>如果有条件，可以更频繁的实地使用业务系统，总结更多的领域业务知识，并通过第一步进行记录</li><li>针对第一步搜集到的这些容易忽略的特定领域业务流程，设计自动化测试用例进行覆盖</li></ul><h3 id="sql自定义函数的测试"><a class="markdownIt-Anchor" href="#sql自定义函数的测试"></a> <code>SQL</code>自定义函数的测试</h3><p>在基于<code>Hadoop</code>的分布式数据平台环境下，<code>SQL</code>自定义函数通常通过<code>Python</code>或<code>Scala</code>编写。由于这些代码通常对外部的依赖很少，通常只是单纯的根据输入数据计算得到输出数据，所以对这些代码建立测试是十分容易的事。事实上，我们很容易实现100%的测试覆盖率。</p><p>在组织测试时，我们可以用单元测试的方式，不依赖计算框架。比如，以下<code>Scala</code>编写的自定义函数：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> array_join_f = (arr: <span class="type">Seq</span>[<span class="type">Double</span>], item_format: <span class="type">String</span>, sep: <span class="type">String</span>) =&gt; ...</span><br><span class="line"><span class="keyword">val</span> array_join = udf(array_join_f)</span><br></pre></td></tr></table></figure><p>对其建立测试时，可以直接测试内部的转换函数<code>array_join_f</code>，一些示例的测试场景比如：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">assertEquals(array_join_f(<span class="literal">null</span>, <span class="literal">null</span>, <span class="literal">null</span>), ...)</span><br><span class="line">assertEquals(array_join_f(<span class="type">Array</span>[<span class="type">Double</span>](), <span class="literal">null</span>, <span class="literal">null</span>), ...)</span><br><span class="line">assertEquals(array_join_f(<span class="type">Array</span>[<span class="type">Double</span>](<span class="number">1</span>, <span class="number">2</span>), <span class="string">&quot;%.2f&quot;</span>, <span class="string">&quot;,&quot;</span>), ...)</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>在建立了单元测试之后，一般还需要考虑建立少量的集成测试，即通过<code>Spark</code>框架运行<code>SQL</code>来测试此自定义函数，一个示例可以是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">assertEquals(spark.sql(<span class="string">&#x27;select array_join(array(), &quot;%.2f&quot;, &quot;,&quot;)&#x27;</span>), ...)</span><br></pre></td></tr></table></figure><p>如果自定义函数本身十分简单，我们也可以直接通过<code>Spark</code>测试来覆盖所有场景。</p><p>从上面的讨论可以看出，<code>SQL</code>自定义函数是很容易测试的。除了好测试之外，<code>SQL</code>自定义函数还有很多好的特性，比如可以很好的降低<code>ETL</code>复杂度，可以很方便的被复用等。所以，我们应该尽量考虑将复杂的业务逻辑通过自定义函数封装起来。这也是业界数据开发所建议的做法（大多数的数据开发框架都对自定义函数提供了很好的支持，如<code>Hive</code> <code>Presto</code> <code>ClickHouse</code>等，大多数<code>ETL</code>开发工具也都支持自定义函数的开发）。</p><h3 id="数据工具的测试"><a class="markdownIt-Anchor" href="#数据工具的测试"></a> 数据工具的测试</h3><p>数据工具的实例可以参考文章<a href="/2021/04/05/dwd-modeling-automation/">《数据仓库建模自动化》</a>和<a href="/2021/04/10/data-development-tools/">《数据开发支持工具》</a>。</p><p>这些工具的一大特点是，它们是用于支持<code>ETL</code>开发的，仅在开发过程中使用。由于它们并不是在产品环境中运行的代码，所以我们可以降低对其的质量要求。</p><p>这些工具通常只是开发人员为了提高开发效率而编写的代码，存在较大的修改和重构的可能，所以，过早的去建立较完善的测试必要性不高。</p><p>在我们的实践过程中，这类代码通常只有很少的测试，我们只对那些特别复杂、没有信心能正确工作的地方建立单元测试。如果这些工具代码是通过<code>TDD</code>的方式编写的，通常其测试会更多一些。</p><h2 id="在持续集成流水线中运行测试"><a class="markdownIt-Anchor" href="#在持续集成流水线中运行测试"></a> 在持续集成流水线中运行测试</h2><p>前面我们讨论了如何针对数据应用编写测试，还有一个关于测试的重要话题，那就是如何在持续交付流水线中运行这些测试。</p><p>在功能性软件项目中，如果我们按照测试金字塔的三层来组织测试，那么在流水线中一般就会对应三个测试过程。</p><p>从上面的讨论可知，数据应用的测试被纵向分为四条线，如何对应到流水线上呢？如果我们采用同一个代码库管理所有的代码，可以考虑直接将流水线分为四条并行的流程，分别对应这四条线。如果是不同的代码库，则可以考虑对不同的代码库建立不同的流水线。在每条流水线内部，就可以按照单元测试、低集成测试、高集成测试这样的方式组织流水线任务。</p><h3 id="独立的etl流水线"><a class="markdownIt-Anchor" href="#独立的etl流水线"></a> 独立的<code>ETL</code>流水线</h3><p>对于<code>ETL</code>代码的测试，有一个值得思考的问题。那就是，<code>ETL</code>脚本之间通常独立性非常强，相互之间没有依赖。这是由于<code>ETL</code>代码常常由完善的领域特定语言<code>SQL</code>开发而成，与<code>Python</code>或<code>Scala</code>等通用编程语言编写的代码不同，<code>SQL</code>文件之间是没有依赖的（如果说有依赖，那也是通过数据库表产生依赖）。</p><p>既然如此，假设我们修改了某一个<code>ETL</code>文件的代码，是不是我们可以不用运行其他的<code>ETL</code>文件的测试呢？其实不仅如此，我们甚至可以单独上线部署此<code>ETL</code>，而不是一次性部署所有的<code>ETL</code>。这在一定程度上还降低了部署代码带来的风险。</p><p>有了上面的发现，我们可能要重新思考数据应用的持续交付流水线组织形式。</p><p>一个可能的办法是为每一个<code>ETL</code>文件建立一个流水线，完成测试、部署的任务。此时每个<code>ETL</code>可以理解为一个独立的小程序。</p><p>这样的想法在实践中不容易落地，因为这将导致大量的流水线存在（常常有上百条），从而给流水线工具带来了很大的压力。常用的流水线工具，如<code>Jenkins</code>，其设计是难以支撑这么大规模的流水线的创建和管理的。</p><p>要如何来支持上面这样的<code>ETL</code>流水线呢？可能需要我们开发新的流水线工具才行。</p><h3 id="云服务中的etl流水线"><a class="markdownIt-Anchor" href="#云服务中的etl流水线"></a> 云服务中的<code>ETL</code>流水线</h3><p>现在的一些云服务厂商在尝试这样做。他们通常会提供一个基于<code>Web</code>的<code>ETL</code>开发工具，同时会提供工具对当前的<code>ETL</code>的编写测试。此时，<code>ETL</code>开发人员可以在一个地方完成开发、测试、上线，这可以提高开发效率。</p><p>这类服务的一个常见缺点在于它尝试用一套<code>Web</code>系统来支持所有的<code>ETL</code>开发过程，这带来了大量繁杂的配置。这其实是将<code>ETL</code>开发过程的复杂性转化为了配置的复杂性。相比编写代码而言，多数开发人员不会喜欢这样的工作方式。（当前软件开发所推崇的是<code>Everthing as Code</code>的做法，尝试将所有开发相关过程中的东西代码化，从而可以更好的利用成熟的代码编辑器、版本管理等功能。而<code>Web</code>配置的方式与<code>Everthing as Code</code>背道而驰。）</p><p>对于这些数据云服务厂商提供的数据开发服务，如果可以同时支持通过代码和<code>Web</code>界面配置来实现数据开发，那将能得到更多开发者的喜爱。这在我看来是一个不错的发展方向。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>本文讨论了如何在数据平台建设过程中做测试这个话题。由于数据应用开发有很强的独特的特点（比如以<code>SQL</code>为主、有较多的支撑工具等），其测试与功能性软件开发的测试也存在很大的不同。</p><p>本文分析了如何在测试金字塔的指导下制定测试策略。测试金字塔不仅可以很好的指导功能性软件开发，在进行一般意义上的推广之后，可以很容易得到一般软件的测试策略。关于测试金字塔，本文分析了测试带来的质量信心及测试集成度，这两个概念可以帮助我们更深刻的理解测试金字塔背后的指导原则。</p><p>在最后，结合我们的实践经验，给出了一些数据应用中的测试构建实践。将数据应用分为四个不同模块来分别构建测试，可以很好的应对数据应用中的质量要求，同时保证有较好的可维护性。最后，我们讨论了如何在持续集成流水线中设计测试任务，留下了一个有待探索的方向，即如何针对单个<code>ETL</code>构建流水线。</p><p>数据应用的质量保证是不容易做到的，常常需要我们进行很多的权衡取舍才能找到最适合的方式。想要解决这一问题，还要发挥团队中所有人的能动性，多总结和思考才行。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/attaches/2021/2021-04-20-data-testing/structure.png&quot; alt=&quot;data testing&quot; /&gt;&lt;/p&gt;
&lt;p&gt;在数据平台建设过程中，测试怎么做是一个值得思考的问题。由于数据应用开发和功能性软件系统开发存在很大的不同，在我们实践过程中，在开发人员和质量保证人员间常常有大量关于测试如何实施的讨论。下文将尝试总结一下数据应用开发的特点，并讨论在这些特点之下，对应的测试策略应该是怎么样的。&lt;/p&gt;
&lt;h2 id=&quot;功能性软件的测试&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#功能性软件的测试&quot;&gt;&lt;/a&gt; 功能性软件的测试&lt;/h2&gt;
&lt;p&gt;先来回顾一下功能性软件系统开发中的测试。&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
  </entry>
  
  <entry>
    <title>数据开发支持工具</title>
    <link href="http://brightliao.com/2021/04/10/data-development-tools/"/>
    <id>http://brightliao.com/2021/04/10/data-development-tools/</id>
    <published>2021-04-10T12:00:00.000Z</published>
    <updated>2022-11-21T01:31:13.595Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="/attaches/assets/katex/katex.min.css"><p>在前面的文章<a href="http://brightliao.com/2021/04/01/data-development-language-and-environment/">《数据应用开发语言和环境》</a>中我们建议使用<code>SQL</code>来作为主要数据开发语言，并且，通常我们需要对标准的<code>SQL</code>进行增强，以便可以更好的支持复杂的数据开发。一些典型的需要新增的特性可以是变量、控制语句、模板等。</p><p>增强<code>SQL</code>固然是可以解决我们的数据开发问题，但是它也会给我们带来一些其他的不便。第一个烦恼可能就是，标准的<code>SQL</code>可以在很多数据工具中运行，比如<code>Superset</code>的<code>SQL</code>查询器、<code>Hive</code>的查询控制台等，而使用增强语法的<code>SQL</code>编写的代码则不行。由于我们将标准的<code>SQL</code>增强了，而<code>SQL</code>周边生态工具却无法感知这样的增强，这时各种不便就随之而来了。</p><span id="more"></span><h2 id="支持数据开发过程"><a class="markdownIt-Anchor" href="#支持数据开发过程"></a> 支持数据开发过程</h2><p>如何解决这个问题呢？想要在周边工具中进行<code>SQL</code>扩展不是一件简单的事情，可能需要花费大量的精力和时间。我们只能另寻他法。</p><p>从软件开发的视角来看这个问题，可以发现，我们现在有了编程语言，也有了编程语言的执行环境，基本的开发流程确实是打通了，但是还缺少的是对开发过程的支持。一般而言，开发过程支持完善与否将很大程度上决定团队开发效率的高低。下面我们一起来看看如何完善对于开发过程的支持。</p><p>开发过程主要包括代码编辑和调试。下面我们来看看如何支持它们。</p><h2 id="支持代码编辑"><a class="markdownIt-Anchor" href="#支持代码编辑"></a> 支持代码编辑</h2><p>代码编辑在当前还不会成为一个问题，因为：</p><ul><li>我们只是在标准<code>SQL</code>语法的基础上进行了增强，现有的编辑器的大部分现有功能还是可以照常使用的</li><li>大部分的语法增强是通过<code>SQL</code>语法的注释功能来实现的，可以兼容标准<code>SQL</code>语法</li><li>大部分编辑器其实只是提供<code>SQL</code>语法高亮和格式化的功能，新增的语法不会产生很大的影响</li></ul><h2 id="支持代码调试"><a class="markdownIt-Anchor" href="#支持代码调试"></a> 支持代码调试</h2><h3 id="命令行调试器"><a class="markdownIt-Anchor" href="#命令行调试器"></a> 命令行调试器</h3><p>现在我们来看调试过程。事实上，使用周边的<code>SQL</code>执行工具来快速验证<code>SQL</code>这个过程本身就是代码调试的过程。</p><p>有了增强<code>SQL</code>的语法，我们要如何做呢？回顾增强<code>SQL</code>的语法，我们在其中支持了多个步骤，每个步骤可以是执行<code>SQL</code>，定义变量或者调用外部函数。如果可以一个步骤一个步骤运行，并且可以在每个步骤之后查看当前的变量或<code>SQL</code>执行结果，那将是一件不错的事。这其实也就是一般的程序调试过程。</p><p>事实上，有了增强<code>SQL</code>的执行器（即前文提到的驱动器），要实现一个具备基本功能的增强<code>SQL</code>调试器并不困难。按照上面的描述，我们只需要在某一个步骤执行完成之后，先暂停执行，并提供接口查询当前上下文的数据即可。在程序暂停时，一般还可以允许运行一些代码，这也不难，提供接口执行<code>SQL</code>即可。这就是一个命令行的程序调试器雏形。</p><p>对应到一般在<code>IDE</code>里面进行调试的交互流程上，打断点的过程，就是指定需要在哪一个步骤暂停，至于查看断点时的状态和在断点时执行代码就跟上面的过程完全一致了。</p><p>根据前面的分析，我们可以设计一个命令行调试器类<code>Debugger</code>，它可以具有这些接口：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Debugger</span>:</span><br><span class="line">    <span class="comment"># 查询执行状态</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_started</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_inprogress</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_finished</span>(<span class="params">...</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查询执行步骤信息</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">step</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">current_step</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">next_step</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">last_step</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">left_step_count</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">print_steps</span>(<span class="params">...</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查看或设置执行过程中的变量</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">vars</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">set_vars</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">templates</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">tempviews</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">showdf</span>(<span class="params">...</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 执行某一步骤，实现暂停、继续等流程控制功能</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">step_on</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">step_to</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run_to</span>(<span class="params">...</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">restart</span>(<span class="params">...</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在断点过程中执行sql</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sql</span>(<span class="params">...</span>):</span><br></pre></td></tr></table></figure><p>上面这些接口借助增强<code>SQL</code>的执行器不难实现。有了<code>Debugger</code>类，一个典型的调试过程就变成：</p><ul><li>在任意<code>SQL</code>编辑器中编辑代码</li><li>打开<code>IPython</code>命令行</li><li>创建<code>Debugger</code>对象: <code>d = create_debugger(sql_file=..., ...)</code></li><li>打印所有步骤：<code>d.print_steps()</code></li><li>执行到某一步：<code>d.run_to(3)</code></li><li>在<code>SQL</code>编辑器中修改代码</li><li>重起调试：<code>d.restart()</code></li><li>…</li></ul><p>（具体实现代码见<a href="https://github.com/easysql/easy_sql/blob/main/easy_sql/sql_processor_debugger.py">这里</a>）</p><h3 id="打印代码执行报告"><a class="markdownIt-Anchor" href="#打印代码执行报告"></a> 打印代码执行报告</h3><p>为了辅助数据开发人员更清楚的理解增强<code>SQL</code>的执行过程，我们最好能打印每一步骤的执行情况，比如实际执行的SQL、执行开始时间、结束时间、当前步骤在整个执行过程中耗时百分比等信息。</p><p>一个简单的报告可以设计如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">===================== REPORT FOR step-1 ==================</span><br><span class="line">config: StepConfig(target=..., condition=None, line_no=1) </span><br><span class="line">sql: select 1 as a</span><br><span class="line">status: SUCCEEDED</span><br><span class="line">start time: 2021-04-10 10:05:30, end time: 2021-04-10 10:05:33, execution time: 2.251653s - 8.14%</span><br><span class="line">messages:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">===================== REPORT FOR step-2 ==================</span><br><span class="line">config: StepConfig(target=log.a, condition=None, line_no=4) </span><br><span class="line">sql: select &#x27;1&#x27; as a</span><br><span class="line">status: SUCCEEDED</span><br><span class="line">start time: 2021-04-10 10:05:33, end time: 2021-04-10 10:05:33, execution time: 0.069165s - 0.25%</span><br><span class="line">messages:</span><br><span class="line">a=&#x27;1&#x27;</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>为此，我们可以定义一个执行报告搜集器（<code>ReportCollector</code>），每当一个步骤开始或结束执行时，<code>SQL</code>执行器应当通知报告搜集器搜集该步骤的执行信息。在整个流程执行完成之后，<code>SQL</code>执行器可以调用报告搜集器打印整个过程中搜集到的执行报告。</p><p>有了报告搜集器，我们就可以更清楚的了解增强<code>SQL</code>执行过程中的细节了。由于我们的<code>SQL</code>执行基于<code>Spark</code>实现，有了这个报告搜集器，一些简单的<code>Spark</code>程序优化还可以直接通过查看报告来完成。</p><p>报告搜集器是一个十分好用的功能，当然需要集成到调试器中了。通过在<code>Debugger</code>类中加入<code>report()</code>方法，我们在调试过程中可以随时打印程序执行报告。</p><h3 id="打印日志与执行检查"><a class="markdownIt-Anchor" href="#打印日志与执行检查"></a> 打印日志与执行检查</h3><p>打印日志也是我们调试程序的常用手段，如何在增强<code>SQL</code>中支持日志打印呢？可以考虑定义一个任务类型为<code>log</code>，按照如下方式来使用：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=log.some_info_about_this_log</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> var_1, <span class="number">2</span> <span class="keyword">as</span> var_2</span><br></pre></td></tr></table></figure><p>日志打印结果可以在上述任务报告中出现，一个比较直观的设计可以是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">===================== REPORT FOR step-1 ==================</span><br><span class="line">config: StepConfig(target=log.some_info_about_this_log, condition=None, line_no=1) </span><br><span class="line">sql: select 1 as var_1, 2 as var_2</span><br><span class="line">status: SUCCEEDED</span><br><span class="line">start time: 2021-04-10 10:05:33, end time: 2021-04-10 10:05:33, execution time: 0.069165s - 0.25%</span><br><span class="line">messages:</span><br><span class="line">var_1=1, var_2=2</span><br></pre></td></tr></table></figure><p>很多编程语言都提供了<code>assert</code>语法，用以在开发过程中进行及时的假设验证，我们也可以在增强<code>SQL</code>增加这样的支持。可以考虑定义一个任务类型为<code>check</code>，按照如下方式来使用：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- target=check.actual_should_equal_expected</span></span><br><span class="line"><span class="keyword">select</span> <span class="number">1</span> <span class="keyword">as</span> actual, <span class="number">2</span> <span class="keyword">as</span> expected</span><br></pre></td></tr></table></figure><p>如果从结果集中的获取的<code>actual</code>值与<code>expected</code>值不相等，则此任务会失败，并打印错误消息。同时，这样的错误可以在上述任务报告中体现，一个比较直观的设计可以是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">===================== REPORT FOR step-1 ==================</span><br><span class="line">config: StepConfig(target=check.actual_should_equal_expected, condition=None, line_no=10) </span><br><span class="line">sql: select 1 as actual, 2 as expected</span><br><span class="line">status: FAILED</span><br><span class="line">start time: 2021-04-10 10:25:32, end time: 2021-04-10 10:25:32, execution time: 0.071442s - 0.52%</span><br><span class="line">messages:</span><br><span class="line">check [actual_should_equal_expected] failed! actual=1, expected=2, check_data=[...]</span><br></pre></td></tr></table></figure><h3 id="通过调试模式屏蔽调试过程中的副作用"><a class="markdownIt-Anchor" href="#通过调试模式屏蔽调试过程中的副作用"></a> 通过调试模式屏蔽调试过程中的副作用</h3><p>有了调试器，现在可以愉快的写代码了。但很快我们就会发现另一个需要解决的问题，那就是调试过程可能导致写入某些外部数据库表。这将带来一些风险，因为我们有可能在调试的时候把一些不应该被覆盖的数据库表给覆盖了。</p><p>要解决这个问题也很简单，我们可以在<code>SQL</code>执行器中引入一个<code>debug</code>标记来实现。有了<code>debug</code>标记，在执行某一步骤的时候，可以判断是否是向外部数据库表做写操作，如果是且<code>debug</code>为<code>true</code>，则跳过写操作，只是将该数据创建一个<code>TempView</code>而已。</p><p>上述写表操作只是一个场景而已，有了<code>debug</code>标记，我们还可以做很多事情，比如打印更多的调试信息等。</p><p><code>Debugger</code>类在调用<code>SQL</code>执行器时，应当将<code>debug</code>标记设置为<code>true</code>，这样我们就不用担心调试的时候产生任何不想发生的副作用了。</p><h2 id="web数据开发环境"><a class="markdownIt-Anchor" href="#web数据开发环境"></a> <code>Web</code>数据开发环境</h2><h3 id="在jupyterlab中调试代码"><a class="markdownIt-Anchor" href="#在jupyterlab中调试代码"></a> 在<code>JupyterLab</code>中调试代码</h3><p>有了上面这些功能，调试器看起来是不错了，但是要与<code>IDE</code>的交互体验比起来，命令行版本的还是过于简单了。能不能想办法增强一下呢？</p><p>数据分析师常用的用于运行代码的工具要算<code>JupyterLab</code>了。作为一个打开网页就能用的开发环境，<code>JupyterLab</code>有非常多十分好用的功能，比如，可以一段一段的定义和执行代码，可以支持嵌入<code>Markdown</code>文档，可以支持可视化结果展示，可以编辑多种语言代码等等。</p><p><code>JupyterLab</code>能不能作为我们的代码编辑器使用呢？</p><p>查看<code>JupyterLab</code>最新版本，我们会发现<code>JupyterLab</code>提供了<code>Code Console</code>的功能，且可以支持多个编辑器分屏。其操作界面如下：</p><p><img data-src="/attaches/2021/2021-04-10-data-development-tools/jupyter-console.png" alt="jupyter lab console" /></p><p>此时，大家可能已经想到了，可以借助这样的交互来实现我们的代码调试功能。<code>JupyterLab</code>不仅给我们提供了一个不错的编辑代码的界面，利用<code>Code Console</code>还可以实现一边写代码一边调试。</p><p>在<code>JupyterLab</code>中配置好调试器后，一个典型的使用过程如下：</p><p><img data-src="/attaches/2021/2021-04-10-data-development-tools/debugger-usage.gif" alt="debugger" /></p><p>使用<code>JupyterLab</code>还有一系列的其他好处，比如：</p><ul><li>开发人员无需安装配置本地环境（这常常非常耗时），只需要一个浏览器即可开始编写代码。</li><li>可以直接配置<code>JupyterLab</code>连接到数据平台集群环境，这样我们就可以直接在集群环境中调试，执行与生产时同样的代码，于是上线代码就更有信心了。</li></ul><h3 id="在容器中启动jupyterlab"><a class="markdownIt-Anchor" href="#在容器中启动jupyterlab"></a> 在容器中启动<code>JupyterLab</code></h3><p>在基于<code>Hadoop</code>的大数据集群中进行数据开发时，常常还有一个不够方便的地方，那就是客户端环境的构建。</p><p>我们常常需要集成了多种集群组件的客户端，比如<code>Spark</code>, <code>HDFS</code>, <code>Hive</code>, <code>HBase</code>等，这些客户端的配置需要保持和集群同步。如果自己去构建这样的客户端，不仅耗时，而且很容易出错。</p><p><code>Ambari</code>可以帮助我们自动配置集群节点，如软件安装，配置同步等繁琐的工作<code>Ambari</code>都可以帮我们搞定。当需要使用集群的客户端环境时，常常也是通过<code>Ambari</code>配置的集群节点来实现。</p><p>使用<code>Ambari</code>配置的集群节点作为客户端却有另一个缺点，那就是这样的节点常常由于数量较少而在团队中间共享（由于资源占用问题，我们一般不会配置过多的客户端节点）。</p><p>既然是共享的节点，大家都在节点上面操作，就容易发生冲突。比如，小A用自己的帐号登录了（通过<code>kinit</code>），此时小B想要访问集群，如果不使用其他的操作系统帐号，小B就会直接用到小A的帐号权限来访问系统，这不是期望的行为。还比如，小A需要在客户端中安装某一个版本1依赖库，而小B需要在客户端中安装同一个依赖库的版本2，这就产生了冲突，需要小A和小B相互协调才行。</p><p>容器技术是解决此问题的一个很好的方式。容器可以提供必要的环境隔离，使得团队成员可以自由的在自己的环境中进行操作，无需担心对他人造成影响。</p><p>如何实现呢？其实我们只需要一个运行了<code>sshd</code>的容器即可。通过暴露特定的端口，我们可以把运行着<code>sshd</code>的容器作为一个节点，注册到<code>Ambari</code>中，然后利用<code>Ambari</code>帮我们安装好相关的依赖软件。</p><p>软件安装完成之后，我们可以通过<code>docker save</code>命令将这样容器保存为一个基础容器镜像。然后通过运行多个此容器，我们就拥有了多个此类客户端了。由于容器运行成本非常低，可以为每个需要编写代码的团队成员运行一个容器作为他自己的客户端使用。这样一来，开发人员环境隔离问题就迎刃而解了。</p><p>在容器环境中运行一个<code>JupyterLab</code>来支持开发是一个不错的主意。这样一来，每个人都拥有了自己的一套独立的用<code>JupyterLab</code>打造的开发环境了。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>前面的文章中我们提到使用增强<code>SQL</code>来进行数据开发，但是这带来了一些额外的使用成本。本文讨论了如何支持增强<code>SQL</code>的代码编辑和调试功能。</p><p>通过实现一个增强<code>SQL</code>调试器，并在<code>JupyterLab</code>中运行此调试器，我们可以打造了一个基于<code>Web</code>的轻量级数据开发环境，这能很大程度上提高数据开发的效率。为了更好的支持数据开发，我们还可以考虑在<code>SQL</code>执行器中增加执行报告搜集的功能，在调试器中随时打印执行报告对于数据开发是一件好事。除此之外，还可以在<code>SQL</code>执行器中引入调试标记，这可以用来避免调试过程的可能的副作用。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在前面的文章&lt;a href=&quot;http://brightliao.com/2021/04/01/data-development-language-and-environment/&quot;&gt;《数据应用开发语言和环境》&lt;/a&gt;中我们建议使用&lt;code&gt;SQL&lt;/code&gt;来作为主要数据开发语言，并且，通常我们需要对标准的&lt;code&gt;SQL&lt;/code&gt;进行增强，以便可以更好的支持复杂的数据开发。一些典型的需要新增的特性可以是变量、控制语句、模板等。&lt;/p&gt;
&lt;p&gt;增强&lt;code&gt;SQL&lt;/code&gt;固然是可以解决我们的数据开发问题，但是它也会给我们带来一些其他的不便。第一个烦恼可能就是，标准的&lt;code&gt;SQL&lt;/code&gt;可以在很多数据工具中运行，比如&lt;code&gt;Superset&lt;/code&gt;的&lt;code&gt;SQL&lt;/code&gt;查询器、&lt;code&gt;Hive&lt;/code&gt;的查询控制台等，而使用增强语法的&lt;code&gt;SQL&lt;/code&gt;编写的代码则不行。由于我们将标准的&lt;code&gt;SQL&lt;/code&gt;增强了，而&lt;code&gt;SQL&lt;/code&gt;周边生态工具却无法感知这样的增强，这时各种不便就随之而来了。&lt;/p&gt;</summary>
    
    
    
    <category term="数据" scheme="http://brightliao.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
    <category term="数据" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
    <category term="数据平台" scheme="http://brightliao.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/"/>
    
  </entry>
  
</feed>
